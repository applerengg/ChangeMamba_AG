=> merge config from /storage/alperengenc/change_detection/ChangeMamba_AG/changedetection/configs/vssm1/vssm_base_224.yaml
Successfully load ckpt /storage/alperengenc/change_detection/ChangeMamba_AG/pretrained_weight/vssm_base_0229_ckpt_epoch_237.pth
_IncompatibleKeys(missing_keys=['outnorm0.weight', 'outnorm0.bias', 'outnorm1.weight', 'outnorm1.bias', 'outnorm2.weight', 'outnorm2.bias', 'outnorm3.weight', 'outnorm3.bias'], unexpected_keys=['classifier.norm.weight', 'classifier.norm.bias', 'classifier.head.weight', 'classifier.head.bias'])
False
iter is 50, loc. loss = 0.011721811257302761, classif. loss = 2.340566635131836    (2025-08-07_19-58-33)
iter is 100, loc. loss = 0.018129490315914154, classif. loss = 0.8256444931030273   (2025-08-07_19-58-47)
iter is 150, loc. loss = 0.005932674743235111, classif. loss = 0.3815990090370178   (2025-08-07_19-59-01)
iter is 200, loc. loss = 0.560471773147583   , classif. loss = 0.46440649032592773  (2025-08-07_19-59-15)
iter is 250, loc. loss = 0.004235507920384407, classif. loss = 0.1823066771030426   (2025-08-07_19-59-29)
iter is 300, loc. loss = 0.3869597017765045  , classif. loss = 0.25972089171409607  (2025-08-07_19-59-43)
iter is 350, loc. loss = 0.004639101214706898, classif. loss = 0.13620410859584808  (2025-08-07_19-59-57)
iter is 400, loc. loss = 0.4957014322280884  , classif. loss = 0.0847497433423996   (2025-08-07_20-00-11)
iter is 450, loc. loss = 0.3603073060512543  , classif. loss = 0.08297742903232574  (2025-08-07_20-00-25)
iter is 500, loc. loss = 0.005563359707593918, classif. loss = 0.17196744680404663  (2025-08-07_20-00-39)
iter is 550, loc. loss = 0.3850017786026001  , classif. loss = 0.5440315008163452   (2025-08-07_20-00-53)
iter is 600, loc. loss = 0.008350100368261337, classif. loss = 0.07822020351886749  (2025-08-07_20-01-07)
iter is 650, loc. loss = 0.7890172004699707  , classif. loss = 0.6169561743736267   (2025-08-07_20-01-21)
iter is 700, loc. loss = 0.0005703282076865435, classif. loss = 0.07804091274738312  (2025-08-07_20-01-35)
iter is 750, loc. loss = 0.02247077040374279 , classif. loss = 0.16454622149467468  (2025-08-07_20-01-49)
iter is 800, loc. loss = 0.4729783833026886  , classif. loss = 1.5916364192962646   (2025-08-07_20-02-03)
iter is 850, loc. loss = 0.49619758129119873 , classif. loss = 1.219741940498352    (2025-08-07_20-02-17)
iter is 900, loc. loss = 0.28322073817253113 , classif. loss = 0.21649333834648132  (2025-08-07_20-02-31)
iter is 950, loc. loss = 0.3091088533401489  , classif. loss = 2.078632354736328    (2025-08-07_20-02-45)
iter is 1000, loc. loss = 0.32141751050949097 , classif. loss = 0.1192954033613205   (2025-08-07_20-02-59)
iter is 1050, loc. loss = 0.004860291723161936, classif. loss = 0.09264205396175385  (2025-08-07_20-03-13)
iter is 1100, loc. loss = 0.3860926330089569  , classif. loss = 0.32725709676742554  (2025-08-07_20-03-27)
iter is 1150, loc. loss = 0.0008172604721039534, classif. loss = 0.04478893056511879  (2025-08-07_20-03-41)
iter is 1200, loc. loss = 0.00568812619894743 , classif. loss = 0.059859976172447205 (2025-08-07_20-03-55)
iter is 1250, loc. loss = 0.28877049684524536 , classif. loss = 0.19565588235855103  (2025-08-07_20-04-09)
iter is 1300, loc. loss = 0.2926909923553467  , classif. loss = 0.08703719824552536  (2025-08-07_20-04-23)
iter is 1350, loc. loss = 0.00039555568946525455, classif. loss = 0.04039384424686432  (2025-08-07_20-04-37)
iter is 1400, loc. loss = 0.32037901878356934 , classif. loss = 0.2451413869857788   (2025-08-07_20-04-51)
iter is 1450, loc. loss = 0.39027929306030273 , classif. loss = 1.013016939163208    (2025-08-07_20-05-04)
iter is 1500, loc. loss = 0.22136729955673218 , classif. loss = 0.4847475290298462   (2025-08-07_20-05-18)
iter is 1550, loc. loss = 0.34532758593559265 , classif. loss = 0.09309825301170349  (2025-08-07_20-05-32)
iter is 1600, loc. loss = 0.1536765694618225  , classif. loss = 0.02433950826525688  (2025-08-07_20-05-46)
iter is 1650, loc. loss = 0.0019946033135056496, classif. loss = 0.07428458333015442  (2025-08-07_20-06-00)
iter is 1700, loc. loss = 0.0009456354891881347, classif. loss = 0.0455094613134861   (2025-08-07_20-06-14)
iter is 1750, loc. loss = 0.000933887786231935, classif. loss = 0.08707363903522491  (2025-08-07_20-06-28)
iter is 1800, loc. loss = 0.12760227918624878 , classif. loss = 0.6783442497253418   (2025-08-07_20-06-42)
iter is 1850, loc. loss = 0.4133473038673401  , classif. loss = 0.0793524980545044   (2025-08-07_20-06-56)
iter is 1900, loc. loss = 0.0017477839719504118, classif. loss = 0.033573273569345474 (2025-08-07_20-07-10)
iter is 1950, loc. loss = 0.15724480152130127 , classif. loss = 0.12431184947490692  (2025-08-07_20-07-24)
iter is 2000, loc. loss = 0.4500039219856262  , classif. loss = 0.3784046173095703   (2025-08-07_20-07-38)
iter is 2050, loc. loss = 0.020301107317209244, classif. loss = 0.07733090221881866  (2025-08-07_20-07-52)
iter is 2100, loc. loss = 0.004982097540050745, classif. loss = 0.22466714680194855  (2025-08-07_20-08-06)
iter is 2150, loc. loss = 0.005684853997081518, classif. loss = 0.09794533252716064  (2025-08-07_20-08-20)
iter is 2200, loc. loss = 0.004272484220564365, classif. loss = 0.042404383420944214 (2025-08-07_20-08-34)
iter is 2250, loc. loss = 0.4647428095340729  , classif. loss = 0.09054666757583618  (2025-08-07_20-08-48)
iter is 2300, loc. loss = 0.3753272294998169  , classif. loss = 0.8183920383453369   (2025-08-07_20-09-02)
iter is 2350, loc. loss = 0.019991682842373848, classif. loss = 0.8460167050361633   (2025-08-07_20-09-16)
iter is 2400, loc. loss = 0.2141820639371872  , classif. loss = 0.4617810547351837   (2025-08-07_20-09-30)
iter is 2450, loc. loss = 0.1804060935974121  , classif. loss = 1.1662882566452026   (2025-08-07_20-09-44)
iter is 2500, loc. loss = 0.37011653184890747 , classif. loss = 0.3735026717185974   (2025-08-07_20-09-58)
iter is 2550, loc. loss = 0.0003524220664985478, classif. loss = 0.029256977140903473 (2025-08-07_20-10-11)
iter is 2600, loc. loss = 0.00016926100943237543, classif. loss = 0.04074542969465256  (2025-08-07_20-10-25)
iter is 2650, loc. loss = 0.0008611906669102609, classif. loss = 0.025002371519804    (2025-08-07_20-10-39)
iter is 2700, loc. loss = 0.0008037026855163276, classif. loss = 0.03970809280872345  (2025-08-07_20-10-53)
iter is 2750, loc. loss = 0.4916625916957855  , classif. loss = 1.922605276107788    (2025-08-07_20-11-07)
iter is 2800, loc. loss = 0.18580110371112823 , classif. loss = 1.3076984882354736   (2025-08-07_20-11-21)
iter is 2850, loc. loss = 0.003983133938163519, classif. loss = 0.10005547106266022  (2025-08-07_20-11-35)
iter is 2900, loc. loss = 0.47125282883644104 , classif. loss = 0.349880188703537    (2025-08-07_20-11-49)
iter is 2950, loc. loss = 0.2655069828033447  , classif. loss = 0.05438612774014473  (2025-08-07_20-12-03)
iter is 3000, loc. loss = 0.5093979835510254  , classif. loss = 1.3024353981018066   (2025-08-07_20-12-17)
iter is 3050, loc. loss = 0.29846903681755066 , classif. loss = 0.21056699752807617  (2025-08-07_20-12-31)
iter is 3100, loc. loss = 0.26561176776885986 , classif. loss = 0.15595903992652893  (2025-08-07_20-12-45)
iter is 3150, loc. loss = 0.26877349615097046 , classif. loss = 0.06438914686441422  (2025-08-07_20-12-59)
iter is 3200, loc. loss = 0.00661672605201602 , classif. loss = 0.12230409681797028  (2025-08-07_20-13-13)
iter is 3250, loc. loss = 0.5005723237991333  , classif. loss = 1.647983431816101    (2025-08-07_20-13-27)
iter is 3300, loc. loss = 0.47155335545539856 , classif. loss = 1.251453161239624    (2025-08-07_20-13-41)
iter is 3350, loc. loss = 0.005539911799132824, classif. loss = 0.0325738862156868   (2025-08-07_20-13-55)
iter is 3400, loc. loss = 0.206043541431427   , classif. loss = 0.4512817859649658   (2025-08-07_20-14-09)
iter is 3450, loc. loss = 0.4248742461204529  , classif. loss = 0.1955198496580124   (2025-08-07_20-14-23)
iter is 3500, loc. loss = 0.30614006519317627 , classif. loss = 0.20451495051383972  (2025-08-07_20-14-37)
iter is 3550, loc. loss = 0.8500975370407104  , classif. loss = 0.4663063883781433   (2025-08-07_20-14-51)
iter is 3600, loc. loss = 0.24627122282981873 , classif. loss = 0.18003082275390625  (2025-08-07_20-15-05)
iter is 3650, loc. loss = 0.009466488845646381, classif. loss = 0.08108554780483246  (2025-08-07_20-15-19)
iter is 3700, loc. loss = 0.4819648563861847  , classif. loss = 0.3665512204170227   (2025-08-07_20-15-33)
iter is 3750, loc. loss = 0.31702283024787903 , classif. loss = 0.241408109664917    (2025-08-07_20-15-46)
iter is 3800, loc. loss = 0.4045221507549286  , classif. loss = 0.661424994468689    (2025-08-07_20-16-00)
iter is 3850, loc. loss = 0.2289043664932251  , classif. loss = 0.18105685710906982  (2025-08-07_20-16-14)
iter is 3900, loc. loss = 0.16107670962810516 , classif. loss = 0.23316338658332825  (2025-08-07_20-16-28)
iter is 3950, loc. loss = 0.13595151901245117 , classif. loss = 0.07742888480424881  (2025-08-07_20-16-42)
iter is 4000, loc. loss = 0.40718695521354675 , classif. loss = 0.23327726125717163  (2025-08-07_20-16-56)
iter is 4050, loc. loss = 0.03480767458677292 , classif. loss = 1.3287792205810547   (2025-08-07_20-17-10)
iter is 4100, loc. loss = 0.22571125626564026 , classif. loss = 0.18182024359703064  (2025-08-07_20-17-24)
iter is 4150, loc. loss = 0.005185967311263084, classif. loss = 0.05880039930343628  (2025-08-07_20-17-38)
iter is 4200, loc. loss = 0.29126885533332825 , classif. loss = 1.5192155838012695   (2025-08-07_20-17-52)
iter is 4250, loc. loss = 0.0949147418141365  , classif. loss = 0.034526243805885315 (2025-08-07_20-18-06)
iter is 4300, loc. loss = 0.3624512851238251  , classif. loss = 0.8680163621902466   (2025-08-07_20-18-20)
iter is 4350, loc. loss = 0.22268831729888916 , classif. loss = 0.0892447680234909   (2025-08-07_20-18-34)
iter is 4400, loc. loss = 0.0009929208317771554, classif. loss = 0.03267717361450195  (2025-08-07_20-18-48)
iter is 4450, loc. loss = 0.4236530065536499  , classif. loss = 0.20184366405010223  (2025-08-07_20-19-02)
iter is 4500, loc. loss = 0.15610332787036896 , classif. loss = 0.0258193276822567   (2025-08-07_20-19-16)
iter is 4550, loc. loss = 0.3123486638069153  , classif. loss = 0.13247066736221313  (2025-08-07_20-19-30)
iter is 4600, loc. loss = 0.12981177866458893 , classif. loss = 0.6719484925270081   (2025-08-07_20-19-44)
iter is 4650, loc. loss = 0.22515061497688293 , classif. loss = 0.16575872898101807  (2025-08-07_20-19-58)
iter is 4700, loc. loss = 0.24028852581977844 , classif. loss = 0.1917026937007904   (2025-08-07_20-20-12)
iter is 4750, loc. loss = 0.1990310251712799  , classif. loss = 0.17591415345668793  (2025-08-07_20-20-26)
iter is 4800, loc. loss = 0.3322264552116394  , classif. loss = 1.4880778789520264   (2025-08-07_20-20-40)
iter is 4850, loc. loss = 0.5016604065895081  , classif. loss = 1.8955705165863037   (2025-08-07_20-20-54)
iter is 4900, loc. loss = 0.1619453877210617  , classif. loss = 0.13506871461868286  (2025-08-07_20-21-08)
iter is 4950, loc. loss = 0.25690925121307373 , classif. loss = 0.1863327920436859   (2025-08-07_20-21-21)
iter is 5000, loc. loss = 0.3102554976940155  , classif. loss = 0.2507248520851135   (2025-08-07_20-21-35)
---------starting evaluation-----------
validation:    0/1866 (2025-08-07_20-21-36)
validation:  100/1866 (2025-08-07_20-22-21)
validation:  200/1866 (2025-08-07_20-23-05)
validation:  300/1866 (2025-08-07_20-23-48)
validation:  400/1866 (2025-08-07_20-24-32)
validation:  500/1866 (2025-08-07_20-25-15)
validation:  600/1866 (2025-08-07_20-25-59)
validation:  700/1866 (2025-08-07_20-26-42)
validation:  800/1866 (2025-08-07_20-27-25)
validation:  900/1866 (2025-08-07_20-28-08)
validation: 1000/1866 (2025-08-07_20-28-52)
validation: 1100/1866 (2025-08-07_20-29-35)
validation: 1200/1866 (2025-08-07_20-30-18)
validation: 1300/1866 (2025-08-07_20-31-02)
validation: 1400/1866 (2025-08-07_20-31-45)
validation: 1500/1866 (2025-08-07_20-32-28)
validation: 1600/1866 (2025-08-07_20-33-12)
validation: 1700/1866 (2025-08-07_20-33-55)
validation: 1800/1866 (2025-08-07_20-34-38)
lofF1 is 0.741952976635265, clfF1 is 0.0, oaF1 is 0.22258589299057951, sub class F1 score is [0.42925798 0.         0.         0.        ]
iter is 5050, loc. loss = 0.1375189870595932  , classif. loss = 0.1895490288734436   (2025-08-07_20-35-25)
iter is 5100, loc. loss = 0.3296872079372406  , classif. loss = 0.33891841769218445  (2025-08-07_20-35-47)
iter is 5150, loc. loss = 0.3871947228908539  , classif. loss = 0.3285943269729614   (2025-08-07_20-36-07)
iter is 5200, loc. loss = 0.2943628132343292  , classif. loss = 0.1950628161430359   (2025-08-07_20-36-24)
iter is 5250, loc. loss = 0.00013558179489336908, classif. loss = 0.01894211769104004  (2025-08-07_20-36-43)
iter is 5300, loc. loss = 0.5704895853996277  , classif. loss = 0.18741190433502197  (2025-08-07_20-36-59)
iter is 5350, loc. loss = 0.31217843294143677 , classif. loss = 0.2831038236618042   (2025-08-07_20-37-18)
iter is 5400, loc. loss = 0.0011021823156625032, classif. loss = 0.0187641903758049   (2025-08-07_20-37-36)
iter is 5450, loc. loss = 0.22547976672649384 , classif. loss = 0.15633752942085266  (2025-08-07_20-37-51)
iter is 5500, loc. loss = 0.5204240083694458  , classif. loss = 1.7911128997802734   (2025-08-07_20-38-07)
iter is 5550, loc. loss = 0.009430395439267159, classif. loss = 0.21621204912662506  (2025-08-07_20-38-21)
iter is 5600, loc. loss = 0.330110102891922   , classif. loss = 0.07007992267608643  (2025-08-07_20-38-36)
iter is 5650, loc. loss = 0.0009225128451362252, classif. loss = 0.043353624641895294 (2025-08-07_20-38-52)
iter is 5700, loc. loss = 0.17687171697616577 , classif. loss = 0.04604557529091835  (2025-08-07_20-39-07)
iter is 5750, loc. loss = 0.1806079000234604  , classif. loss = 0.11735378950834274  (2025-08-07_20-39-23)
iter is 5800, loc. loss = 0.20281054079532623 , classif. loss = 0.11063331365585327  (2025-08-07_20-39-37)
iter is 5850, loc. loss = 0.0004088460118509829, classif. loss = 0.012252380140125751 (2025-08-07_20-39-52)
iter is 5900, loc. loss = 0.31324490904808044 , classif. loss = 0.3212423324584961   (2025-08-07_20-40-06)
iter is 5950, loc. loss = 0.4155055582523346  , classif. loss = 1.4071037769317627   (2025-08-07_20-40-20)
iter is 6000, loc. loss = 0.41098278760910034 , classif. loss = 0.1289362758398056   (2025-08-07_20-40-35)
iter is 6050, loc. loss = 0.2531416416168213  , classif. loss = 0.07668789476156235  (2025-08-07_20-40-49)
iter is 6100, loc. loss = 0.25224387645721436 , classif. loss = 0.2575951814651489   (2025-08-07_20-41-03)
iter is 6150, loc. loss = 0.33226653933525085 , classif. loss = 0.1317959576845169   (2025-08-07_20-41-18)
iter is 6200, loc. loss = 0.1796931028366089  , classif. loss = 0.4155728816986084   (2025-08-07_20-41-32)
iter is 6250, loc. loss = 0.34850671887397766 , classif. loss = 0.0775279849767685   (2025-08-07_20-41-46)
iter is 6300, loc. loss = 0.28713423013687134 , classif. loss = 0.22276949882507324  (2025-08-07_20-42-00)
iter is 6350, loc. loss = 0.003666945965960622, classif. loss = 0.018589727580547333 (2025-08-07_20-42-14)
iter is 6400, loc. loss = 0.1328486055135727  , classif. loss = 1.4748209714889526   (2025-08-07_20-42-28)
iter is 6450, loc. loss = 0.0012507947394624352, classif. loss = 0.025327593088150024 (2025-08-07_20-42-42)
iter is 6500, loc. loss = 0.1466134935617447  , classif. loss = 0.2929316759109497   (2025-08-07_20-42-56)
iter is 6550, loc. loss = 0.31942296028137207 , classif. loss = 0.7822955250740051   (2025-08-07_20-43-10)
iter is 6600, loc. loss = 0.21750114858150482 , classif. loss = 0.17006167769432068  (2025-08-07_20-43-25)
iter is 6650, loc. loss = 0.27194732427597046 , classif. loss = 0.3428536057472229   (2025-08-07_20-43-39)
iter is 6700, loc. loss = 0.5074923634529114  , classif. loss = 0.34084588289260864  (2025-08-07_20-43-53)
iter is 6750, loc. loss = 0.42247188091278076 , classif. loss = 0.3187046945095062   (2025-08-07_20-44-07)
iter is 6800, loc. loss = 0.4541219174861908  , classif. loss = 0.34472209215164185  (2025-08-07_20-44-21)
iter is 6850, loc. loss = 0.003517603036016226, classif. loss = 0.04430092126131058  (2025-08-07_20-44-35)
iter is 6900, loc. loss = 0.2706347703933716  , classif. loss = 0.21386954188346863  (2025-08-07_20-44-49)
iter is 6950, loc. loss = 0.11226914823055267 , classif. loss = 0.04606916010379791  (2025-08-07_20-45-03)
iter is 7000, loc. loss = 0.0006704173283651471, classif. loss = 0.017891759052872658 (2025-08-07_20-45-17)
iter is 7050, loc. loss = 0.25685277581214905 , classif. loss = 0.18564030528068542  (2025-08-07_20-45-32)
iter is 7100, loc. loss = 0.39561963081359863 , classif. loss = 0.9479477405548096   (2025-08-07_20-45-46)
iter is 7150, loc. loss = 0.2281576544046402  , classif. loss = 0.24798041582107544  (2025-08-07_20-46-00)
iter is 7200, loc. loss = 0.4984462857246399  , classif. loss = 0.17736265063285828  (2025-08-07_20-46-14)
iter is 7250, loc. loss = 0.2946211099624634  , classif. loss = 0.8306304216384888   (2025-08-07_20-46-28)
iter is 7300, loc. loss = 0.27774152159690857 , classif. loss = 0.1670050024986267   (2025-08-07_20-46-42)
iter is 7350, loc. loss = 0.2818886637687683  , classif. loss = 0.21567273139953613  (2025-08-07_20-46-56)
iter is 7400, loc. loss = 0.21287959814071655 , classif. loss = 1.561389446258545    (2025-08-07_20-47-10)
iter is 7450, loc. loss = 0.26107507944107056 , classif. loss = 0.13520386815071106  (2025-08-07_20-47-24)
iter is 7500, loc. loss = 0.367153525352478   , classif. loss = 0.13205407559871674  (2025-08-07_20-47-39)
iter is 7550, loc. loss = 0.22442156076431274 , classif. loss = 0.1474827527999878   (2025-08-07_20-47-53)
iter is 7600, loc. loss = 0.007841331884264946, classif. loss = 0.04661398008465767  (2025-08-07_20-48-07)
iter is 7650, loc. loss = 0.19524051249027252 , classif. loss = 0.10840354859828949  (2025-08-07_20-48-21)
iter is 7700, loc. loss = 0.2144722044467926  , classif. loss = 0.1426534801721573   (2025-08-07_20-48-35)
iter is 7750, loc. loss = 0.0019884773064404726, classif. loss = 0.037634484469890594 (2025-08-07_20-48-49)
iter is 7800, loc. loss = 0.25717708468437195 , classif. loss = 0.06318750977516174  (2025-08-07_20-49-03)
iter is 7850, loc. loss = 0.14520424604415894 , classif. loss = 0.14188994467258453  (2025-08-07_20-49-17)
iter is 7900, loc. loss = 0.25274303555488586 , classif. loss = 0.1987377405166626   (2025-08-07_20-49-32)
iter is 7950, loc. loss = 0.2070196121931076  , classif. loss = 0.1474035382270813   (2025-08-07_20-49-46)
iter is 8000, loc. loss = 0.32750749588012695 , classif. loss = 0.2590421438217163   (2025-08-07_20-50-00)
iter is 8050, loc. loss = 0.2594316601753235  , classif. loss = 0.1528836190700531   (2025-08-07_20-50-15)
iter is 8100, loc. loss = 0.2732389569282532  , classif. loss = 0.0873866155743599   (2025-08-07_20-50-29)
iter is 8150, loc. loss = 0.23437383770942688 , classif. loss = 0.0874628871679306   (2025-08-07_20-50-43)
iter is 8200, loc. loss = 0.25686168670654297 , classif. loss = 0.16177037358283997  (2025-08-07_20-51-00)
iter is 8250, loc. loss = 0.0005636856076307595, classif. loss = 0.02093210257589817  (2025-08-07_20-51-15)
iter is 8300, loc. loss = 0.3737088143825531  , classif. loss = 2.0455322265625      (2025-08-07_20-51-29)
iter is 8350, loc. loss = 0.2713448107242584  , classif. loss = 0.26825255155563354  (2025-08-07_20-51-43)
iter is 8400, loc. loss = 0.15610849857330322 , classif. loss = 0.06732544302940369  (2025-08-07_20-51-57)
iter is 8450, loc. loss = 0.001007248880341649, classif. loss = 0.020702995359897614 (2025-08-07_20-52-11)
iter is 8500, loc. loss = 0.298017680644989   , classif. loss = 0.2601141929626465   (2025-08-07_20-52-26)
iter is 8550, loc. loss = 0.015733331441879272, classif. loss = 0.6876423954963684   (2025-08-07_20-52-40)
iter is 8600, loc. loss = 0.2754877805709839  , classif. loss = 0.2228926122188568   (2025-08-07_20-52-55)
iter is 8650, loc. loss = 0.383398175239563   , classif. loss = 1.3298625946044922   (2025-08-07_20-53-10)
iter is 8700, loc. loss = 0.2965894341468811  , classif. loss = 0.2913052439689636   (2025-08-07_20-53-25)
iter is 8750, loc. loss = 0.21452823281288147 , classif. loss = 0.12467178702354431  (2025-08-07_20-53-39)
iter is 8800, loc. loss = 0.193680077791214   , classif. loss = 0.3194940388202667   (2025-08-07_20-53-54)
iter is 8850, loc. loss = 0.19584542512893677 , classif. loss = 0.3747556805610657   (2025-08-07_20-54-08)
iter is 8900, loc. loss = 0.3192142844200134  , classif. loss = 1.430069088935852    (2025-08-07_20-54-22)
iter is 8950, loc. loss = 0.3661404848098755  , classif. loss = 1.5968703031539917   (2025-08-07_20-54-36)
iter is 9000, loc. loss = 0.22073478996753693 , classif. loss = 0.06563692539930344  (2025-08-07_20-54-51)
iter is 9050, loc. loss = 0.2642039656639099  , classif. loss = 0.08012756705284119  (2025-08-07_20-55-05)
iter is 9100, loc. loss = 0.2853487432003021  , classif. loss = 1.1002826690673828   (2025-08-07_20-55-20)
iter is 9150, loc. loss = 0.48610228300094604 , classif. loss = 0.38161593675613403  (2025-08-07_20-55-34)
iter is 9200, loc. loss = 0.019015345722436905, classif. loss = 0.9496133923530579   (2025-08-07_20-55-48)
iter is 9250, loc. loss = 0.24504414200782776 , classif. loss = 0.0489344485104084   (2025-08-07_20-56-02)
iter is 9300, loc. loss = 0.25594061613082886 , classif. loss = 0.11108777672052383  (2025-08-07_20-56-16)
iter is 9350, loc. loss = 0.24510838091373444 , classif. loss = 0.1753891110420227   (2025-08-07_20-56-30)
iter is 9400, loc. loss = 0.27450335025787354 , classif. loss = 1.5125701427459717   (2025-08-07_20-56-45)
iter is 9450, loc. loss = 0.20268286764621735 , classif. loss = 0.2198888510465622   (2025-08-07_20-56-59)
iter is 9500, loc. loss = 0.4496877193450928  , classif. loss = 0.40414363145828247  (2025-08-07_20-57-13)
iter is 9550, loc. loss = 0.001873436151072383, classif. loss = 0.6875922083854675   (2025-08-07_20-57-27)
iter is 9600, loc. loss = 0.2837616205215454  , classif. loss = 0.06867995113134384  (2025-08-07_20-57-41)
iter is 9650, loc. loss = 0.23728114366531372 , classif. loss = 0.2626221179962158   (2025-08-07_20-57-55)
iter is 9700, loc. loss = 0.2302296757698059  , classif. loss = 0.2580788731575012   (2025-08-07_20-58-10)
iter is 9750, loc. loss = 0.1311548948287964  , classif. loss = 0.05745798349380493  (2025-08-07_20-58-24)
iter is 9800, loc. loss = 0.27774855494499207 , classif. loss = 0.13475187122821808  (2025-08-07_20-58-38)
iter is 9850, loc. loss = 0.31141427159309387 , classif. loss = 0.1253044158220291   (2025-08-07_20-58-52)
iter is 9900, loc. loss = 0.10168193280696869 , classif. loss = 0.03094409592449665  (2025-08-07_20-59-06)
iter is 9950, loc. loss = 0.0008486084407195449, classif. loss = 0.02181798219680786  (2025-08-07_20-59-21)
iter is 10000, loc. loss = 0.0009963780175894499, classif. loss = 0.020146112889051437 (2025-08-07_20-59-35)
---------starting evaluation-----------
validation:    0/1866 (2025-08-07_20-59-35)
validation:  100/1866 (2025-08-07_21-00-17)
validation:  200/1866 (2025-08-07_21-01-00)
validation:  300/1866 (2025-08-07_21-01-42)
validation:  400/1866 (2025-08-07_21-02-24)
validation:  500/1866 (2025-08-07_21-03-07)
validation:  600/1866 (2025-08-07_21-03-49)
validation:  700/1866 (2025-08-07_21-04-31)
validation:  800/1866 (2025-08-07_21-05-14)
validation:  900/1866 (2025-08-07_21-05-56)
validation: 1000/1866 (2025-08-07_21-06-38)
validation: 1100/1866 (2025-08-07_21-07-21)
validation: 1200/1866 (2025-08-07_21-08-03)
validation: 1300/1866 (2025-08-07_21-08-45)
validation: 1400/1866 (2025-08-07_21-09-28)
validation: 1500/1866 (2025-08-07_21-10-10)
validation: 1600/1866 (2025-08-07_21-10-52)
validation: 1700/1866 (2025-08-07_21-11-35)
validation: 1800/1866 (2025-08-07_21-12-17)
lofF1 is 0.7619692199789978, clfF1 is 0.0, oaF1 is 0.22859076599369932, sub class F1 score is [0.36233891 0.         0.         0.        ]
iter is 10050, loc. loss = 0.1487516164779663  , classif. loss = 0.44136670231819153  (2025-08-07_21-13-03)
iter is 10100, loc. loss = 0.005114397034049034, classif. loss = 0.200320303440094    (2025-08-07_21-13-29)
iter is 10150, loc. loss = 0.01443290151655674 , classif. loss = 0.396999716758728    (2025-08-07_21-13-50)
iter is 10200, loc. loss = 0.453904926776886   , classif. loss = 1.0425193309783936   (2025-08-07_21-14-09)
iter is 10250, loc. loss = 0.000681806355714798, classif. loss = 0.021372172981500626 (2025-08-07_21-14-29)
iter is 10300, loc. loss = 0.20926259458065033 , classif. loss = 0.11308364570140839  (2025-08-07_21-14-47)
iter is 10350, loc. loss = 0.2267417460680008  , classif. loss = 0.015691392123699188 (2025-08-07_21-15-06)
iter is 10400, loc. loss = 0.001494537922553718, classif. loss = 0.008911846205592155 (2025-08-07_21-15-25)
iter is 10450, loc. loss = 0.19316811859607697 , classif. loss = 0.11060011386871338  (2025-08-07_21-15-43)
iter is 10500, loc. loss = 0.2809503674507141  , classif. loss = 0.08141007274389267  (2025-08-07_21-16-01)
iter is 10550, loc. loss = 0.19048574566841125 , classif. loss = 0.09276079386472702  (2025-08-07_21-16-19)
iter is 10600, loc. loss = 0.24692513048648834 , classif. loss = 0.10355859994888306  (2025-08-07_21-16-35)
iter is 10650, loc. loss = 0.0013501027133315802, classif. loss = 0.025141499936580658 (2025-08-07_21-16-52)
iter is 10700, loc. loss = 0.4926610291004181  , classif. loss = 0.9727128744125366   (2025-08-07_21-17-08)
iter is 10750, loc. loss = 0.2652166187763214  , classif. loss = 0.18852317333221436  (2025-08-07_21-17-24)
iter is 10800, loc. loss = 0.8890020847320557  , classif. loss = 2.580693244934082    (2025-08-07_21-17-40)
iter is 10850, loc. loss = 0.001065797870978713, classif. loss = 0.01911366730928421  (2025-08-07_21-17-55)
iter is 10900, loc. loss = 0.25137948989868164 , classif. loss = 0.2848135828971863   (2025-08-07_21-18-10)
iter is 10950, loc. loss = 0.10165289044380188 , classif. loss = 0.7100087404251099   (2025-08-07_21-18-24)
iter is 11000, loc. loss = 0.30308088660240173 , classif. loss = 0.15668094158172607  (2025-08-07_21-18-41)
iter is 11050, loc. loss = 0.0007546395063400269, classif. loss = 0.03867858648300171  (2025-08-07_21-18-56)
iter is 11100, loc. loss = 0.2544165253639221  , classif. loss = 0.13981905579566956  (2025-08-07_21-19-10)
iter is 11150, loc. loss = 0.22667597234249115 , classif. loss = 0.2617596685886383   (2025-08-07_21-19-25)
iter is 11200, loc. loss = 0.24560658633708954 , classif. loss = 0.4055522084236145   (2025-08-07_21-19-39)
iter is 11250, loc. loss = 0.49174073338508606 , classif. loss = 0.0506955161690712   (2025-08-07_21-19-53)
iter is 11300, loc. loss = 0.2563486099243164  , classif. loss = 0.9914295673370361   (2025-08-07_21-20-07)
iter is 11350, loc. loss = 0.39622464776039124 , classif. loss = 0.7003096342086792   (2025-08-07_21-20-21)
iter is 11400, loc. loss = 0.26948070526123047 , classif. loss = 0.19899892807006836  (2025-08-07_21-20-35)
iter is 11450, loc. loss = 0.1365506947040558  , classif. loss = 0.7669184803962708   (2025-08-07_21-20-50)
iter is 11500, loc. loss = 0.265296995639801   , classif. loss = 0.24256111681461334  (2025-08-07_21-21-04)
iter is 11550, loc. loss = 0.003641862655058503, classif. loss = 0.1161150336265564   (2025-08-07_21-21-18)
iter is 11600, loc. loss = 0.3972475528717041  , classif. loss = 0.9643754959106445   (2025-08-07_21-21-32)
iter is 11650, loc. loss = 0.17933332920074463 , classif. loss = 0.3287932276725769   (2025-08-07_21-21-46)
iter is 11700, loc. loss = 0.1170639842748642  , classif. loss = 0.12468566000461578  (2025-08-07_21-22-00)
iter is 11750, loc. loss = 0.24401414394378662 , classif. loss = 1.8693509101867676   (2025-08-07_21-22-14)
iter is 11800, loc. loss = 0.0014098073588684201, classif. loss = 0.01149878092110157  (2025-08-07_21-22-28)
iter is 11850, loc. loss = 0.295414537191391   , classif. loss = 0.22362354397773743  (2025-08-07_21-22-43)
iter is 11900, loc. loss = 0.21039719879627228 , classif. loss = 0.05521933734416962  (2025-08-07_21-22-57)
iter is 11950, loc. loss = 0.35328006744384766 , classif. loss = 0.40826869010925293  (2025-08-07_21-23-11)
iter is 12000, loc. loss = 0.1579732894897461  , classif. loss = 0.13659271597862244  (2025-08-07_21-23-25)
iter is 12050, loc. loss = 0.20324969291687012 , classif. loss = 0.7423855662345886   (2025-08-07_21-23-39)
iter is 12100, loc. loss = 0.2901865541934967  , classif. loss = 0.4131912589073181   (2025-08-07_21-23-53)
iter is 12150, loc. loss = 0.2110099494457245  , classif. loss = 0.2101626694202423   (2025-08-07_21-24-07)
iter is 12200, loc. loss = 0.21346372365951538 , classif. loss = 0.24641016125679016  (2025-08-07_21-24-21)
iter is 12250, loc. loss = 0.519955039024353   , classif. loss = 0.445461630821228    (2025-08-07_21-24-36)
iter is 12300, loc. loss = 0.1936691254377365  , classif. loss = 0.0487726628780365   (2025-08-07_21-24-50)
iter is 12350, loc. loss = 0.0016635654028505087, classif. loss = 0.022832881659269333 (2025-08-07_21-25-04)
iter is 12400, loc. loss = 0.00023324850189965218, classif. loss = 0.011736048385500908 (2025-08-07_21-25-18)
iter is 12450, loc. loss = 0.13857696950435638 , classif. loss = 0.0910218209028244   (2025-08-07_21-25-32)
iter is 12500, loc. loss = 0.0004854050057474524, classif. loss = 0.008602752350270748 (2025-08-07_21-25-46)
The accuracy of the best round is  [np.float64(0.7619692199789978), np.float64(0.0), np.float64(0.22859076599369932), array([0.36233891, 0.        , 0.        , 0.        ])]
