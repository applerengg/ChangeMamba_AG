2025-10-06 20:14:58,483 | INFO | MAIN - START
2025-10-06 20:14:58,483 | INFO |  > FOCAL LOSS set to False
2025-10-06 20:14:58,483 | INFO |  > ALINGNMENT set to False
2025-10-06 20:14:58,483 | INFO |  > ATTENTION GATE set to -> Building: False, Damage: False
2025-10-06 20:14:58,484 | INFO | Command Line Args:
{
    "cfg": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/configs/vssm1/vssm_base_224.yaml",
    "opts": null,
    "pretrained_weight_path": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/pretrained_weight/vssm_base_0229_ckpt_epoch_237.pth",
    "dataset": "xBD",
    "type": "train",
    "train_dataset_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/train_combined",
    "train_data_list_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/train_combined/train_list2.txt",
    "test_dataset_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/test",
    "test_data_list_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/test/test_list2.txt",
    "shuffle": true,
    "batch_size": 8,
    "crop_size": 256,
    "start_iter": 0,
    "cuda": true,
    "max_iters": 400000,
    "model_type": "MambaBDA_Base",
    "model_param_path": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-06_20-14-57_MambaBDA_Base_xBD",
    "resume": null,
    "learning_rate": 0.0001,
    "momentum": 0.9,
    "weight_decay": 0.005,
    "logfile": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/LOGLAR_CMAG/train_2025-10-06_20-14-57_MambaBDA_Base_xBD.log",
    "extension": "png",
    "focal_loss": false,
    "enable_alignment": false,
    "enable_attn_gate_building": false,
    "enable_attn_gate_damage": false,
    "deterministic": false,
    "validations": 16,
    "measure_train_scores": true
}
2025-10-06 20:14:58,484 | INFO | Starting in RANDOM mode / not deterministic.
2025-10-06 20:14:58,490 | INFO |  > TRAIN EVALUATION params: TRAIN_BUF_MAXLEN = 8000
2025-10-06 20:14:58,490 | INFO |  > ALIGNMENT params: alignment_args = AlignmentArgs(enabled=False, stages=None, mid_ch=None)
2025-10-06 20:14:58,490 | INFO |  > ATTENTION GATE params: attn_gate_args = AttentionGateArgs(enable_building_ag=False, enable_damage_ag=False)
2025-10-06 20:14:58,490 | INFO | ChangeMambaBDA class
2025-10-06 20:14:59,751 | INFO | ---------starting training-----------
2025-10-06 20:14:59,822 | INFO | VAL_STEP=3125, (number_of_validations = 16)
2025-10-06 20:15:34,252 | INFO | iter is 50 / 50000 [skipped    0] | loc. loss = 0.5212430954, classif. loss = 0.6684710383
2025-10-06 20:16:05,583 | INFO | iter is 100 / 50000 [skipped    1] | loc. loss = 0.6852706671, classif. loss = 1.2318626642
2025-10-06 20:16:36,986 | INFO | iter is 150 / 50000 [skipped    2] | loc. loss = 0.3735173941, classif. loss = 1.1521272659
2025-10-06 20:17:08,340 | INFO | iter is 200 / 50000 [skipped    3] | loc. loss = 0.4009830356, classif. loss = 1.0276761055
2025-10-06 20:17:39,788 | INFO | iter is 250 / 50000 [skipped    4] | loc. loss = 0.5429219007, classif. loss = 0.9612971544
2025-10-06 20:18:11,839 | INFO | iter is 300 / 50000 [skipped    4] | loc. loss = 0.3351331353, classif. loss = 0.0594831184
2025-10-06 20:18:43,318 | INFO | iter is 350 / 50000 [skipped    5] | loc. loss = 0.4868075252, classif. loss = 1.0129551888
2025-10-06 20:19:14,185 | INFO | iter is 400 / 50000 [skipped    7] | loc. loss = 0.4305745363, classif. loss = 0.3979680538
2025-10-06 20:19:46,492 | INFO | iter is 450 / 50000 [skipped    7] | loc. loss = 0.4091047347, classif. loss = 0.8902207613
2025-10-06 20:20:18,153 | INFO | iter is 500 / 50000 [skipped    8] | loc. loss = 0.4922616184, classif. loss = 1.3014431000
2025-10-06 20:20:50,205 | INFO | iter is 550 / 50000 [skipped    8] | loc. loss = 0.4956750274, classif. loss = 0.4681249857
2025-10-06 20:21:22,299 | INFO | iter is 600 / 50000 [skipped    8] | loc. loss = 0.2979610264, classif. loss = 0.1054699421
2025-10-06 20:21:54,367 | INFO | iter is 650 / 50000 [skipped    8] | loc. loss = 0.4805536866, classif. loss = 1.2750595808
2025-10-06 20:22:25,856 | INFO | iter is 700 / 50000 [skipped    9] | loc. loss = 0.3144445419, classif. loss = 1.5984294415
2025-10-06 20:22:58,110 | INFO | iter is 750 / 50000 [skipped    9] | loc. loss = 0.3645597696, classif. loss = 1.1001641750
2025-10-06 20:23:30,181 | INFO | iter is 800 / 50000 [skipped    9] | loc. loss = 0.1736284196, classif. loss = 0.6220529079
2025-10-06 20:24:01,678 | INFO | iter is 850 / 50000 [skipped   10] | loc. loss = 0.1372566670, classif. loss = 0.0101076420
2025-10-06 20:24:33,289 | INFO | iter is 900 / 50000 [skipped   11] | loc. loss = 0.2233077139, classif. loss = 1.5479758978
2025-10-06 20:25:05,507 | INFO | iter is 950 / 50000 [skipped   11] | loc. loss = 0.2581995428, classif. loss = 3.1665127277
2025-10-06 20:25:37,637 | INFO | iter is 1000 / 50000 [skipped   11] | loc. loss = 0.3029744327, classif. loss = 0.8149996400
2025-10-06 20:26:09,849 | INFO | iter is 1050 / 50000 [skipped   11] | loc. loss = 0.3114944994, classif. loss = 1.9351493120
2025-10-06 20:26:41,967 | INFO | iter is 1100 / 50000 [skipped   11] | loc. loss = 0.2851181030, classif. loss = 0.4765769243
2025-10-06 20:27:13,548 | INFO | iter is 1150 / 50000 [skipped   12] | loc. loss = 0.2987484336, classif. loss = 4.3358359337
2025-10-06 20:27:45,797 | INFO | iter is 1200 / 50000 [skipped   12] | loc. loss = 0.2157713771, classif. loss = 0.8444610238
2025-10-06 20:28:17,981 | INFO | iter is 1250 / 50000 [skipped   12] | loc. loss = 0.1503807455, classif. loss = 0.8834881783
2025-10-06 20:28:50,150 | INFO | iter is 1300 / 50000 [skipped   12] | loc. loss = 0.2137448341, classif. loss = 0.9668239355
2025-10-06 20:29:22,373 | INFO | iter is 1350 / 50000 [skipped   12] | loc. loss = 0.5334205627, classif. loss = 1.4661290646
2025-10-06 20:29:54,589 | INFO | iter is 1400 / 50000 [skipped   12] | loc. loss = 0.2222342044, classif. loss = 0.0784480870
2025-10-06 20:30:26,767 | INFO | iter is 1450 / 50000 [skipped   12] | loc. loss = 0.1944921315, classif. loss = 1.2227911949
2025-10-06 20:30:58,325 | INFO | iter is 1500 / 50000 [skipped   13] | loc. loss = 0.2711836696, classif. loss = 0.3594049215
2025-10-06 20:31:30,566 | INFO | iter is 1550 / 50000 [skipped   13] | loc. loss = 0.3603369296, classif. loss = 1.1648765802
2025-10-06 20:32:01,571 | INFO | iter is 1600 / 50000 [skipped   15] | loc. loss = 0.2268527001, classif. loss = 0.0605988353
2025-10-06 20:32:33,150 | INFO | iter is 1650 / 50000 [skipped   16] | loc. loss = 0.1801580191, classif. loss = 0.4979295433
2025-10-06 20:33:05,361 | INFO | iter is 1700 / 50000 [skipped   16] | loc. loss = 0.3499135971, classif. loss = 0.8982048035
2025-10-06 20:33:37,074 | INFO | iter is 1750 / 50000 [skipped   17] | loc. loss = 0.2986377180, classif. loss = 0.9386855364
2025-10-06 20:34:09,296 | INFO | iter is 1800 / 50000 [skipped   17] | loc. loss = 0.2912622392, classif. loss = 0.0197385773
2025-10-06 20:34:41,524 | INFO | iter is 1850 / 50000 [skipped   17] | loc. loss = 0.2093883455, classif. loss = 0.3787761927
2025-10-06 20:35:13,753 | INFO | iter is 1900 / 50000 [skipped   17] | loc. loss = 0.1517781317, classif. loss = 0.7934777141
2025-10-06 20:35:45,485 | INFO | iter is 1950 / 50000 [skipped   18] | loc. loss = 0.3832824528, classif. loss = 1.0267423391
2025-10-06 20:36:17,778 | INFO | iter is 2000 / 50000 [skipped   18] | loc. loss = 0.1808710545, classif. loss = 2.3906388283
2025-10-06 20:36:50,112 | INFO | iter is 2050 / 50000 [skipped   18] | loc. loss = 0.2773664594, classif. loss = 0.0474811308
2025-10-06 20:37:22,371 | INFO | iter is 2100 / 50000 [skipped   18] | loc. loss = 0.1789459884, classif. loss = 0.8360367417
2025-10-06 20:37:54,669 | INFO | iter is 2150 / 50000 [skipped   18] | loc. loss = 0.2604907751, classif. loss = 0.9032070637
2025-10-06 20:38:26,899 | INFO | iter is 2200 / 50000 [skipped   18] | loc. loss = 0.3617085814, classif. loss = 1.1770865917
2025-10-06 20:38:59,122 | INFO | iter is 2250 / 50000 [skipped   18] | loc. loss = 0.1571543366, classif. loss = 1.3670238256
2025-10-06 20:39:31,456 | INFO | iter is 2300 / 50000 [skipped   18] | loc. loss = 0.4755000174, classif. loss = 0.0982217193
2025-10-06 20:40:02,636 | INFO | iter is 2350 / 50000 [skipped   20] | loc. loss = 0.1889874339, classif. loss = 1.2015254498
2025-10-06 20:40:34,959 | INFO | iter is 2400 / 50000 [skipped   20] | loc. loss = 0.2381065488, classif. loss = 0.5932972431
2025-10-06 20:41:06,701 | INFO | iter is 2450 / 50000 [skipped   21] | loc. loss = 0.2449710369, classif. loss = 0.9568616152
2025-10-06 20:41:38,976 | INFO | iter is 2500 / 50000 [skipped   21] | loc. loss = 0.1721486002, classif. loss = 0.5876477957
2025-10-06 20:42:11,265 | INFO | iter is 2550 / 50000 [skipped   21] | loc. loss = 0.3067262769, classif. loss = 1.2080622911
2025-10-06 20:42:43,712 | INFO | iter is 2600 / 50000 [skipped   21] | loc. loss = 0.3448216021, classif. loss = 0.6501312852
2025-10-06 20:43:16,101 | INFO | iter is 2650 / 50000 [skipped   21] | loc. loss = 0.2035519183, classif. loss = 1.4122846127
2025-10-06 20:43:47,300 | INFO | iter is 2700 / 50000 [skipped   23] | loc. loss = 0.2237430513, classif. loss = 0.9096917510
2025-10-06 20:44:19,759 | INFO | iter is 2750 / 50000 [skipped   23] | loc. loss = 0.2455850393, classif. loss = 1.4687967300
2025-10-06 20:44:52,200 | INFO | iter is 2800 / 50000 [skipped   23] | loc. loss = 0.2718752623, classif. loss = 1.5414414406
2025-10-06 20:45:23,405 | INFO | iter is 2850 / 50000 [skipped   25] | loc. loss = 0.1955400705, classif. loss = 0.6900534630
2025-10-06 20:45:55,821 | INFO | iter is 2900 / 50000 [skipped   25] | loc. loss = 0.2708216906, classif. loss = 0.4027510881
2025-10-06 20:46:28,234 | INFO | iter is 2950 / 50000 [skipped   25] | loc. loss = 0.3093676567, classif. loss = 1.6105829477
2025-10-06 20:47:00,655 | INFO | iter is 3000 / 50000 [skipped   25] | loc. loss = 0.4331241250, classif. loss = 0.5273495913
2025-10-06 20:47:32,391 | INFO | iter is 3050 / 50000 [skipped   26] | loc. loss = 0.2902255952, classif. loss = 0.6724281311
2025-10-06 20:48:04,260 | INFO | iter is 3100 / 50000 [skipped   27] | loc. loss = 0.2513976693, classif. loss = 0.0358449742
2025-10-06 20:48:20,461 | INFO | ---------starting evaluation-----------
2025-10-06 20:48:22,328 | INFO | validation:    0/ 933 (2025-10-06_20-48-22)
2025-10-06 20:49:08,326 | INFO | validation:  100/ 933 (2025-10-06_20-49-08)
2025-10-06 20:49:54,238 | INFO | validation:  200/ 933 (2025-10-06_20-49-54)
2025-10-06 20:50:40,175 | INFO | validation:  300/ 933 (2025-10-06_20-50-40)
2025-10-06 20:51:26,124 | INFO | validation:  400/ 933 (2025-10-06_20-51-26)
2025-10-06 20:52:12,085 | INFO | validation:  500/ 933 (2025-10-06_20-52-12)
2025-10-06 20:52:58,051 | INFO | validation:  600/ 933 (2025-10-06_20-52-58)
2025-10-06 20:53:44,021 | INFO | validation:  700/ 933 (2025-10-06_20-53-44)
2025-10-06 20:54:29,980 | INFO | validation:  800/ 933 (2025-10-06_20-54-29)
2025-10-06 20:55:15,945 | INFO | validation:  900/ 933 (2025-10-06_20-55-15)
2025-10-06 20:55:31,736 | INFO | Confusion Matrix of Localization:
[[906914311  13445538]
 [  9651711  48309848]]
2025-10-06 20:55:31,736 | INFO | Confusion Matrix of Localization - Normalized:
[[0.985391   0.014609  ]
 [0.16651918 0.83348082]]
2025-10-06 20:55:31,736 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 31867353  2009040  9825322   157026]
 [       0  1050005  1944398  1706537    41031]
 [       0   537483   524102  4347448   119897]
 [       0   161720    95280   367771  2444519]]
2025-10-06 20:55:31,736 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.72659069 0.04580706 0.22402198 0.00358027]
 [0.         0.22142797 0.41004004 0.35987926 0.00865273]
 [0.         0.09721284 0.09479266 0.78630911 0.02168539]
 [0.         0.05268971 0.03104301 0.11982283 0.79644445]]
2025-10-06 20:55:31,736 | INFO | lofF1 is 80.7068, clfF1 is 54.7333, oaF1 is 62.5254, sub class F1 score is [82.2645 41.7486 39.9288 83.8346]
2025-10-06 20:55:31,993 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-06_20-14-57_MambaBDA_Base_xBD/model_step3125.pth
2025-10-06 20:55:31,993 | INFO | ---------starting train set evaluation-----------
2025-10-06 20:55:31,993 | INFO | Train buffer size: 3098.
2025-10-06 20:55:43,901 | INFO | [TrainBuf] locF1 is 73.5231, clfF1 is 40.7776, oaF1 is 50.6013, sub class F1 score is [90.5722 19.6813 44.6865 72.1276]
2025-10-06 20:56:00,022 | INFO | iter is 3150 / 50000 [skipped   27] | loc. loss = 0.2234665751, classif. loss = 0.8788470030
2025-10-06 20:56:31,468 | INFO | iter is 3200 / 50000 [skipped   28] | loc. loss = 0.2016071677, classif. loss = 0.9301483035
2025-10-06 20:57:03,583 | INFO | iter is 3250 / 50000 [skipped   28] | loc. loss = 0.1949155629, classif. loss = 0.5035111904
2025-10-06 20:57:35,668 | INFO | iter is 3300 / 50000 [skipped   28] | loc. loss = 0.2892820835, classif. loss = 0.9193340540
2025-10-06 20:58:07,286 | INFO | iter is 3350 / 50000 [skipped   29] | loc. loss = 0.2578388453, classif. loss = 1.0088787079
2025-10-06 20:58:39,395 | INFO | iter is 3400 / 50000 [skipped   29] | loc. loss = 0.3232395053, classif. loss = 3.0594959259
2025-10-06 20:59:11,582 | INFO | iter is 3450 / 50000 [skipped   29] | loc. loss = 0.3462888598, classif. loss = 0.1652666032
2025-10-06 20:59:42,628 | INFO | iter is 3500 / 50000 [skipped   31] | loc. loss = 0.1667368114, classif. loss = 0.1581647694
2025-10-06 21:00:14,721 | INFO | iter is 3550 / 50000 [skipped   31] | loc. loss = 0.3819099665, classif. loss = 0.6951751709
2025-10-06 21:00:46,986 | INFO | iter is 3600 / 50000 [skipped   31] | loc. loss = 0.2341542989, classif. loss = 0.0685611665
2025-10-06 21:01:19,115 | INFO | iter is 3650 / 50000 [skipped   31] | loc. loss = 0.2950475216, classif. loss = 0.2002116740
2025-10-06 21:01:51,317 | INFO | iter is 3700 / 50000 [skipped   31] | loc. loss = 0.2624206543, classif. loss = 1.1001588106
2025-10-06 21:02:22,886 | INFO | iter is 3750 / 50000 [skipped   32] | loc. loss = 0.1522878408, classif. loss = 0.5488587022
2025-10-06 21:02:54,547 | INFO | iter is 3800 / 50000 [skipped   33] | loc. loss = 0.1823082119, classif. loss = 0.1543169618
2025-10-06 21:03:26,757 | INFO | iter is 3850 / 50000 [skipped   33] | loc. loss = 0.2053634226, classif. loss = 1.3091993332
2025-10-06 21:03:58,351 | INFO | iter is 3900 / 50000 [skipped   34] | loc. loss = 0.3376887441, classif. loss = 0.8448555470
2025-10-06 21:04:30,590 | INFO | iter is 3950 / 50000 [skipped   34] | loc. loss = 0.2046829015, classif. loss = 0.1319133639
2025-10-06 21:05:02,273 | INFO | iter is 4000 / 50000 [skipped   35] | loc. loss = 0.2724598050, classif. loss = 1.4028794765
2025-10-06 21:05:33,960 | INFO | iter is 4050 / 50000 [skipped   36] | loc. loss = 0.1962901652, classif. loss = 1.5384876728
2025-10-06 21:06:06,093 | INFO | iter is 4100 / 50000 [skipped   36] | loc. loss = 0.2951718271, classif. loss = 0.4375575185
2025-10-06 21:06:38,364 | INFO | iter is 4150 / 50000 [skipped   36] | loc. loss = 0.4729471207, classif. loss = 1.6245026588
2025-10-06 21:07:10,624 | INFO | iter is 4200 / 50000 [skipped   36] | loc. loss = 0.2835980058, classif. loss = 0.7107379436
2025-10-06 21:07:42,885 | INFO | iter is 4250 / 50000 [skipped   36] | loc. loss = 0.2710044980, classif. loss = 0.0825100914
2025-10-06 21:08:15,117 | INFO | iter is 4300 / 50000 [skipped   36] | loc. loss = 0.2057554871, classif. loss = 0.9197282195
2025-10-06 21:08:47,366 | INFO | iter is 4350 / 50000 [skipped   36] | loc. loss = 0.2250072807, classif. loss = 0.1822402775
2025-10-06 21:09:19,594 | INFO | iter is 4400 / 50000 [skipped   36] | loc. loss = 0.2408123761, classif. loss = 1.2041902542
2025-10-06 21:09:51,828 | INFO | iter is 4450 / 50000 [skipped   36] | loc. loss = 0.2958247066, classif. loss = 0.6616613865
2025-10-06 21:10:22,951 | INFO | iter is 4500 / 50000 [skipped   38] | loc. loss = 0.2385724783, classif. loss = 0.0622010790
2025-10-06 21:10:55,202 | INFO | iter is 4550 / 50000 [skipped   38] | loc. loss = 0.2348153144, classif. loss = 0.5622678995
2025-10-06 21:11:27,571 | INFO | iter is 4600 / 50000 [skipped   38] | loc. loss = 0.2086740285, classif. loss = 0.1906201541
2025-10-06 21:11:59,406 | INFO | iter is 4650 / 50000 [skipped   39] | loc. loss = 0.2893041968, classif. loss = 0.8266781569
2025-10-06 21:12:31,720 | INFO | iter is 4700 / 50000 [skipped   39] | loc. loss = 0.3293770254, classif. loss = 0.0161615014
2025-10-06 21:13:04,065 | INFO | iter is 4750 / 50000 [skipped   39] | loc. loss = 0.2620709538, classif. loss = 1.2461360693
2025-10-06 21:14:08,146 | INFO | iter is 4850 / 50000 [skipped   40] | loc. loss = 0.1912647039, classif. loss = 0.2229068875
2025-10-06 21:14:40,504 | INFO | iter is 4900 / 50000 [skipped   40] | loc. loss = 0.1956771463, classif. loss = 1.2735327482
2025-10-06 21:15:12,860 | INFO | iter is 4950 / 50000 [skipped   40] | loc. loss = 0.2473065853, classif. loss = 1.8606454134
2025-10-06 21:15:45,189 | INFO | iter is 5000 / 50000 [skipped   40] | loc. loss = 0.2501700521, classif. loss = 0.5055288076
2025-10-06 21:16:16,998 | INFO | iter is 5050 / 50000 [skipped   41] | loc. loss = 0.1909797341, classif. loss = 0.8521119356
2025-10-06 21:16:49,355 | INFO | iter is 5100 / 50000 [skipped   41] | loc. loss = 0.2519297302, classif. loss = 0.9743011594
2025-10-06 21:17:21,119 | INFO | iter is 5150 / 50000 [skipped   42] | loc. loss = 0.2299203575, classif. loss = 0.2893191874
2025-10-06 21:17:52,864 | INFO | iter is 5200 / 50000 [skipped   43] | loc. loss = 0.2141181529, classif. loss = 1.0722039938
2025-10-06 21:18:24,634 | INFO | iter is 5250 / 50000 [skipped   44] | loc. loss = 0.2401669174, classif. loss = 0.9328116775
2025-10-06 21:18:57,044 | INFO | iter is 5300 / 50000 [skipped   44] | loc. loss = 0.2037412822, classif. loss = 0.2156831920
2025-10-06 21:19:29,456 | INFO | iter is 5350 / 50000 [skipped   44] | loc. loss = 0.2821963429, classif. loss = 0.4706911743
2025-10-06 21:20:01,883 | INFO | iter is 5400 / 50000 [skipped   44] | loc. loss = 0.1609727144, classif. loss = 0.1528326273
2025-10-06 21:20:33,702 | INFO | iter is 5450 / 50000 [skipped   45] | loc. loss = 0.1986082494, classif. loss = 0.9007493258
2025-10-06 21:21:06,121 | INFO | iter is 5500 / 50000 [skipped   45] | loc. loss = 0.2271506190, classif. loss = 0.7325181961
2025-10-06 21:21:37,898 | INFO | iter is 5550 / 50000 [skipped   46] | loc. loss = 0.3419704735, classif. loss = 0.8860566616
2025-10-06 21:22:10,327 | INFO | iter is 5600 / 50000 [skipped   46] | loc. loss = 0.2511968613, classif. loss = 0.5007558465
2025-10-06 21:22:42,195 | INFO | iter is 5650 / 50000 [skipped   47] | loc. loss = 0.1681103408, classif. loss = 1.0541486740
2025-10-06 21:23:13,995 | INFO | iter is 5700 / 50000 [skipped   48] | loc. loss = 0.1602805704, classif. loss = 0.8625562191
2025-10-06 21:23:46,438 | INFO | iter is 5750 / 50000 [skipped   48] | loc. loss = 0.2548035681, classif. loss = 0.9162520170
2025-10-06 21:24:18,766 | INFO | iter is 5800 / 50000 [skipped   48] | loc. loss = 0.1510602534, classif. loss = 1.0639870167
2025-10-06 21:24:50,673 | INFO | iter is 5850 / 50000 [skipped   49] | loc. loss = 0.2464416176, classif. loss = 0.7459659576
2025-10-06 21:25:54,422 | INFO | iter is 5950 / 50000 [skipped   51] | loc. loss = 0.2103247643, classif. loss = 0.9881515503
2025-10-06 21:26:26,906 | INFO | iter is 6000 / 50000 [skipped   51] | loc. loss = 0.2487690449, classif. loss = 0.6552673578
2025-10-06 21:26:59,371 | INFO | iter is 6050 / 50000 [skipped   51] | loc. loss = 0.2967314422, classif. loss = 0.1304776669
2025-10-06 21:27:31,889 | INFO | iter is 6100 / 50000 [skipped   51] | loc. loss = 0.1743951440, classif. loss = 1.1966412067
2025-10-06 21:28:04,361 | INFO | iter is 6150 / 50000 [skipped   51] | loc. loss = 0.2099082768, classif. loss = 2.1448826790
2025-10-06 21:28:36,908 | INFO | iter is 6200 / 50000 [skipped   51] | loc. loss = 0.2361100316, classif. loss = 0.4752295911
2025-10-06 21:29:09,384 | INFO | iter is 6250 / 50000 [skipped   51] | loc. loss = 0.2028843015, classif. loss = 0.0720243081
2025-10-06 21:29:09,386 | INFO | ---------starting evaluation-----------
2025-10-06 21:29:11,379 | INFO | validation:    0/ 933 (2025-10-06_21-29-11)
2025-10-06 21:29:57,456 | INFO | validation:  100/ 933 (2025-10-06_21-29-57)
2025-10-06 21:30:43,483 | INFO | validation:  200/ 933 (2025-10-06_21-30-43)
2025-10-06 21:31:29,480 | INFO | validation:  300/ 933 (2025-10-06_21-31-29)
2025-10-06 21:32:15,502 | INFO | validation:  400/ 933 (2025-10-06_21-32-15)
2025-10-06 21:33:01,527 | INFO | validation:  500/ 933 (2025-10-06_21-33-01)
2025-10-06 21:33:47,557 | INFO | validation:  600/ 933 (2025-10-06_21-33-47)
2025-10-06 21:34:33,584 | INFO | validation:  700/ 933 (2025-10-06_21-34-33)
2025-10-06 21:35:19,616 | INFO | validation:  800/ 933 (2025-10-06_21-35-19)
2025-10-06 21:36:05,662 | INFO | validation:  900/ 933 (2025-10-06_21-36-05)
2025-10-06 21:36:21,510 | INFO | Confusion Matrix of Localization:
[[911261679   9098170]
 [ 11217522  46744037]]
2025-10-06 21:36:21,510 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99011455 0.00988545]
 [0.19353382 0.80646618]]
2025-10-06 21:36:21,510 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42120915   547618  1136386    53822]
 [       0  2303128  1318974  1082869    37000]
 [       0   801049   398388  4207074   122419]
 [       0   496796    42739   285344  2244411]]
2025-10-06 21:36:21,510 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96037675 0.01248595 0.02591014 0.00122717]
 [0.         0.48569002 0.2781489  0.22835842 0.00780266]
 [0.         0.14488319 0.07205517 0.76092011 0.02214154]
 [0.         0.16186023 0.01392472 0.09296743 0.73124762]]
2025-10-06 21:36:21,510 | INFO | lofF1 is 82.1485, clfF1 is 62.2876, oaF1 is 68.2459, sub class F1 score is [94.0402 37.4193 68.7396 81.2171]
2025-10-06 21:36:21,767 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-06_20-14-57_MambaBDA_Base_xBD/model_step6250.pth
2025-10-06 21:36:21,767 | INFO | ---------starting train set evaluation-----------
2025-10-06 21:36:21,767 | INFO | Train buffer size: 3101.
2025-10-06 21:36:33,993 | INFO | [TrainBuf] locF1 is 81.8965, clfF1 is 55.5645, oaF1 is 63.4641, sub class F1 score is [93.24   30.6192 61.9574 80.231 ]
2025-10-06 21:37:06,087 | INFO | iter is 6300 / 50000 [skipped   51] | loc. loss = 0.2378404737, classif. loss = 0.7971673012
2025-10-06 21:37:38,319 | INFO | iter is 6350 / 50000 [skipped   51] | loc. loss = 0.3032738566, classif. loss = 1.6905418634
2025-10-06 21:38:09,888 | INFO | iter is 6400 / 50000 [skipped   52] | loc. loss = 0.2800662518, classif. loss = 0.8472690582
2025-10-06 21:38:42,005 | INFO | iter is 6450 / 50000 [skipped   52] | loc. loss = 0.1931360662, classif. loss = 0.1592152268
2025-10-06 21:39:14,084 | INFO | iter is 6500 / 50000 [skipped   52] | loc. loss = 0.3383640051, classif. loss = 0.3926815093
2025-10-06 21:39:45,083 | INFO | iter is 6550 / 50000 [skipped   54] | loc. loss = 0.2317701578, classif. loss = 0.4935935736
2025-10-06 21:40:17,152 | INFO | iter is 6600 / 50000 [skipped   54] | loc. loss = 0.1947560608, classif. loss = 0.0702385455
2025-10-06 21:40:48,169 | INFO | iter is 6650 / 50000 [skipped   56] | loc. loss = 0.0805842429, classif. loss = 0.0558016673
2025-10-06 21:41:19,732 | INFO | iter is 6700 / 50000 [skipped   57] | loc. loss = 0.2489048094, classif. loss = 1.2213857174
2025-10-06 21:41:51,303 | INFO | iter is 6750 / 50000 [skipped   58] | loc. loss = 0.2776626647, classif. loss = 0.1753670871
2025-10-06 21:42:22,868 | INFO | iter is 6800 / 50000 [skipped   59] | loc. loss = 0.1914234012, classif. loss = 0.0527910292
2025-10-06 21:42:55,080 | INFO | iter is 6850 / 50000 [skipped   59] | loc. loss = 0.3164217472, classif. loss = 0.7124909163
2025-10-06 21:43:27,326 | INFO | iter is 6900 / 50000 [skipped   59] | loc. loss = 0.2261373997, classif. loss = 0.2199988812
2025-10-06 21:43:58,430 | INFO | iter is 6950 / 50000 [skipped   61] | loc. loss = 0.3001726866, classif. loss = 0.1765066683
2025-10-06 21:44:30,641 | INFO | iter is 7000 / 50000 [skipped   61] | loc. loss = 0.2377073467, classif. loss = 0.8264695406
2025-10-06 21:45:02,206 | INFO | iter is 7050 / 50000 [skipped   62] | loc. loss = 0.1868335456, classif. loss = 1.4993542433
2025-10-06 21:45:33,808 | INFO | iter is 7100 / 50000 [skipped   63] | loc. loss = 0.2591421604, classif. loss = 0.7395997047
2025-10-06 21:46:06,074 | INFO | iter is 7150 / 50000 [skipped   63] | loc. loss = 0.2855330706, classif. loss = 0.4971761107
2025-10-06 21:46:38,335 | INFO | iter is 7200 / 50000 [skipped   63] | loc. loss = 0.2036204189, classif. loss = 0.1338653266
2025-10-06 21:47:09,433 | INFO | iter is 7250 / 50000 [skipped   65] | loc. loss = 0.2518478930, classif. loss = 2.4974052906
2025-10-06 21:47:40,511 | INFO | iter is 7300 / 50000 [skipped   67] | loc. loss = 0.2899394929, classif. loss = 0.6850647330
2025-10-06 21:48:12,809 | INFO | iter is 7350 / 50000 [skipped   67] | loc. loss = 0.2546000481, classif. loss = 0.1943964660
2025-10-06 21:48:44,505 | INFO | iter is 7400 / 50000 [skipped   68] | loc. loss = 0.2125834674, classif. loss = 0.0788870454
2025-10-06 21:49:16,787 | INFO | iter is 7450 / 50000 [skipped   68] | loc. loss = 0.1799769253, classif. loss = 0.3379042745
2025-10-06 21:49:49,017 | INFO | iter is 7500 / 50000 [skipped   68] | loc. loss = 0.1304962784, classif. loss = 0.1747172624
2025-10-06 21:50:21,354 | INFO | iter is 7550 / 50000 [skipped   68] | loc. loss = 0.1702632010, classif. loss = 0.0319037102
2025-10-06 21:50:53,624 | INFO | iter is 7600 / 50000 [skipped   68] | loc. loss = 0.2523198724, classif. loss = 0.5787672997
2025-10-06 21:51:25,942 | INFO | iter is 7650 / 50000 [skipped   68] | loc. loss = 0.2724707723, classif. loss = 0.4412489533
2025-10-06 21:51:58,261 | INFO | iter is 7700 / 50000 [skipped   68] | loc. loss = 0.3785109520, classif. loss = 0.2244938910
2025-10-06 21:52:30,641 | INFO | iter is 7750 / 50000 [skipped   68] | loc. loss = 0.1703278720, classif. loss = 0.5727148056
2025-10-06 21:53:03,056 | INFO | iter is 7800 / 50000 [skipped   68] | loc. loss = 0.1838285327, classif. loss = 0.5704631805
2025-10-06 21:53:35,411 | INFO | iter is 7850 / 50000 [skipped   68] | loc. loss = 0.2821950614, classif. loss = 1.0625545979
2025-10-06 21:54:07,790 | INFO | iter is 7900 / 50000 [skipped   68] | loc. loss = 0.3613023162, classif. loss = 0.6768227816
2025-10-06 21:54:40,199 | INFO | iter is 7950 / 50000 [skipped   68] | loc. loss = 0.2619614303, classif. loss = 2.6991753578
2025-10-06 21:55:12,537 | INFO | iter is 8000 / 50000 [skipped   68] | loc. loss = 0.2073820829, classif. loss = 1.2356723547
2025-10-06 21:55:44,907 | INFO | iter is 8050 / 50000 [skipped   68] | loc. loss = 0.2564051747, classif. loss = 1.2319428921
2025-10-06 21:56:17,247 | INFO | iter is 8100 / 50000 [skipped   68] | loc. loss = 0.2192481756, classif. loss = 0.2305078506
2025-10-06 21:56:49,638 | INFO | iter is 8150 / 50000 [skipped   68] | loc. loss = 0.2334852219, classif. loss = 0.5502458811
2025-10-06 21:57:21,353 | INFO | iter is 8200 / 50000 [skipped   69] | loc. loss = 0.1450414211, classif. loss = 0.8790109754
2025-10-06 21:57:52,603 | INFO | iter is 8250 / 50000 [skipped   71] | loc. loss = 0.2180455327, classif. loss = 0.0054590572
2025-10-06 21:58:24,938 | INFO | iter is 8300 / 50000 [skipped   71] | loc. loss = 0.2131286263, classif. loss = 0.7087227106
2025-10-06 21:58:56,730 | INFO | iter is 8350 / 50000 [skipped   72] | loc. loss = 0.3007807732, classif. loss = 1.5428863764
2025-10-06 21:59:29,181 | INFO | iter is 8400 / 50000 [skipped   72] | loc. loss = 0.2258594632, classif. loss = 1.1133058071
2025-10-06 22:00:01,565 | INFO | iter is 8450 / 50000 [skipped   72] | loc. loss = 0.1725299805, classif. loss = 0.5022252202
2025-10-06 22:00:34,036 | INFO | iter is 8500 / 50000 [skipped   72] | loc. loss = 0.2484790087, classif. loss = 0.0485640317
2025-10-06 22:01:06,527 | INFO | iter is 8550 / 50000 [skipped   72] | loc. loss = 0.2846162915, classif. loss = 1.6911990643
2025-10-06 22:01:38,329 | INFO | iter is 8600 / 50000 [skipped   73] | loc. loss = 0.1811165661, classif. loss = 0.8144226670
2025-10-06 22:02:10,715 | INFO | iter is 8650 / 50000 [skipped   73] | loc. loss = 0.1087323874, classif. loss = 0.5043411255
2025-10-06 22:02:43,228 | INFO | iter is 8700 / 50000 [skipped   73] | loc. loss = 0.2345364988, classif. loss = 1.3323118687
2025-10-06 22:03:15,782 | INFO | iter is 8750 / 50000 [skipped   73] | loc. loss = 0.2303250730, classif. loss = 0.2247071266
2025-10-06 22:03:48,265 | INFO | iter is 8800 / 50000 [skipped   73] | loc. loss = 0.2216131985, classif. loss = 1.2524050474
2025-10-06 22:04:20,761 | INFO | iter is 8850 / 50000 [skipped   73] | loc. loss = 0.2054942995, classif. loss = 1.2529866695
2025-10-06 22:04:53,320 | INFO | iter is 8900 / 50000 [skipped   73] | loc. loss = 0.1972217262, classif. loss = 0.2463569790
2025-10-06 22:05:25,839 | INFO | iter is 8950 / 50000 [skipped   73] | loc. loss = 0.1984240860, classif. loss = 0.4762031436
2025-10-06 22:05:57,778 | INFO | iter is 9000 / 50000 [skipped   74] | loc. loss = 0.2303498685, classif. loss = 0.6347275972
2025-10-06 22:06:30,316 | INFO | iter is 9050 / 50000 [skipped   74] | loc. loss = 0.2694064081, classif. loss = 0.6696052551
2025-10-06 22:07:02,828 | INFO | iter is 9100 / 50000 [skipped   74] | loc. loss = 0.2045445889, classif. loss = 0.2323909253
2025-10-06 22:07:34,742 | INFO | iter is 9150 / 50000 [skipped   75] | loc. loss = 0.1499330550, classif. loss = 1.1861878633
2025-10-06 22:08:07,242 | INFO | iter is 9200 / 50000 [skipped   75] | loc. loss = 0.2725664079, classif. loss = 1.0953459740
2025-10-06 22:08:39,772 | INFO | iter is 9250 / 50000 [skipped   75] | loc. loss = 0.3929534853, classif. loss = 0.4006304145
2025-10-06 22:09:12,195 | INFO | iter is 9300 / 50000 [skipped   75] | loc. loss = 0.1568535566, classif. loss = 0.6840501428
2025-10-06 22:09:43,528 | INFO | iter is 9350 / 50000 [skipped   77] | loc. loss = 0.1873325706, classif. loss = 1.2815519571
2025-10-06 22:09:59,851 | INFO | ---------starting evaluation-----------
2025-10-06 22:10:01,910 | INFO | validation:    0/ 933 (2025-10-06_22-10-01)
2025-10-06 22:10:48,273 | INFO | validation:  100/ 933 (2025-10-06_22-10-48)
2025-10-06 22:11:34,567 | INFO | validation:  200/ 933 (2025-10-06_22-11-34)
2025-10-06 22:12:20,842 | INFO | validation:  300/ 933 (2025-10-06_22-12-20)
2025-10-06 22:13:07,107 | INFO | validation:  400/ 933 (2025-10-06_22-13-07)
2025-10-06 22:13:53,382 | INFO | validation:  500/ 933 (2025-10-06_22-13-53)
2025-10-06 22:14:39,649 | INFO | validation:  600/ 933 (2025-10-06_22-14-39)
2025-10-06 22:15:25,910 | INFO | validation:  700/ 933 (2025-10-06_22-15-25)
2025-10-06 22:16:12,187 | INFO | validation:  800/ 933 (2025-10-06_22-16-12)
2025-10-06 22:16:58,454 | INFO | validation:  900/ 933 (2025-10-06_22-16-58)
2025-10-06 22:17:14,305 | INFO | Confusion Matrix of Localization:
[[912307018   8052831]
 [ 10695853  47265706]]
2025-10-06 22:17:14,305 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99125035 0.00874965]
 [0.18453356 0.81546644]]
2025-10-06 22:17:14,306 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41152326  1590523  1083690    32202]
 [       0  1882106  1726256  1090477    43132]
 [       0   652034   379350  4378624   118922]
 [       0   336926    43213   340341  2348810]]
2025-10-06 22:17:14,306 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.38292460e-01 3.62646753e-02 2.47086436e-02
  7.34220802e-04]
 [0.00000000e+00 3.96903735e-01 3.64037654e-01 2.29962815e-01
  9.09579582e-03]
 [0.00000000e+00 1.17931318e-01 6.86118291e-02 7.91947809e-01
  2.15090442e-02]
 [0.00000000e+00 1.09773270e-01 1.40791519e-02 1.10885905e-01
  7.65261673e-01]]
2025-10-06 22:17:14,306 | INFO | lofF1 is 83.4493, clfF1 is 65.1727, oaF1 is 70.6556, sub class F1 score is [93.6534 40.7073 70.4975 83.7014]
2025-10-06 22:17:14,563 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-06_20-14-57_MambaBDA_Base_xBD/model_step9375.pth
2025-10-06 22:17:14,563 | INFO | ---------starting train set evaluation-----------
2025-10-06 22:17:14,563 | INFO | Train buffer size: 3099.
2025-10-06 22:17:26,622 | INFO | [TrainBuf] locF1 is 82.7921, clfF1 is 61.2299, oaF1 is 67.6986, sub class F1 score is [93.8547 37.2419 63.8388 82.2583]
2025-10-06 22:17:42,675 | INFO | iter is 9400 / 50000 [skipped   77] | loc. loss = 0.2388425469, classif. loss = 0.6251018047
2025-10-06 22:18:14,798 | INFO | iter is 9450 / 50000 [skipped   77] | loc. loss = 0.1976710111, classif. loss = 0.4602159858
2025-10-06 22:18:46,408 | INFO | iter is 9500 / 50000 [skipped   78] | loc. loss = 0.2938073277, classif. loss = 1.0087014437
2025-10-06 22:19:18,531 | INFO | iter is 9550 / 50000 [skipped   78] | loc. loss = 0.2562196255, classif. loss = 0.1600670516
2025-10-06 22:19:50,196 | INFO | iter is 9600 / 50000 [skipped   79] | loc. loss = 0.1729439050, classif. loss = 0.0571973957
2025-10-06 22:20:22,300 | INFO | iter is 9650 / 50000 [skipped   79] | loc. loss = 0.2970205545, classif. loss = 0.1376790404
2025-10-06 22:20:53,841 | INFO | iter is 9700 / 50000 [skipped   80] | loc. loss = 0.2064032108, classif. loss = 0.6877659559
2025-10-06 22:21:26,076 | INFO | iter is 9750 / 50000 [skipped   80] | loc. loss = 0.1260492206, classif. loss = 0.8750252128
2025-10-06 22:21:58,198 | INFO | iter is 9800 / 50000 [skipped   80] | loc. loss = 0.1663919687, classif. loss = 0.3786723018
2025-10-06 22:22:30,426 | INFO | iter is 9850 / 50000 [skipped   80] | loc. loss = 0.1554825604, classif. loss = 1.6488003731
2025-10-06 22:23:02,565 | INFO | iter is 9900 / 50000 [skipped   80] | loc. loss = 0.1279064417, classif. loss = 0.1582632810
2025-10-06 22:23:34,151 | INFO | iter is 9950 / 50000 [skipped   81] | loc. loss = 0.3193571866, classif. loss = 1.1710423231
2025-10-06 22:24:06,317 | INFO | iter is 10000 / 50000 [skipped   81] | loc. loss = 0.2311271131, classif. loss = 1.4377930164
2025-10-06 22:24:37,853 | INFO | iter is 10050 / 50000 [skipped   82] | loc. loss = 0.4640128911, classif. loss = 2.9968862534
2025-10-06 22:25:10,151 | INFO | iter is 10100 / 50000 [skipped   82] | loc. loss = 0.1554181129, classif. loss = 0.7540018559
2025-10-06 22:25:42,394 | INFO | iter is 10150 / 50000 [skipped   82] | loc. loss = 0.3792377114, classif. loss = 0.0188324433
2025-10-06 22:26:14,742 | INFO | iter is 10200 / 50000 [skipped   82] | loc. loss = 0.1937042177, classif. loss = 0.4902415276
2025-10-06 22:26:46,350 | INFO | iter is 10250 / 50000 [skipped   83] | loc. loss = 0.2423324585, classif. loss = 0.4136843681
2025-10-06 22:27:18,635 | INFO | iter is 10300 / 50000 [skipped   83] | loc. loss = 0.2159729302, classif. loss = 0.8555774689
2025-10-06 22:27:50,287 | INFO | iter is 10350 / 50000 [skipped   84] | loc. loss = 0.1809330136, classif. loss = 1.3458244801
2025-10-06 22:28:22,512 | INFO | iter is 10400 / 50000 [skipped   84] | loc. loss = 0.1710229069, classif. loss = 0.4291004241
2025-10-06 22:28:54,842 | INFO | iter is 10450 / 50000 [skipped   84] | loc. loss = 0.1399077177, classif. loss = 0.0536467880
2025-10-06 22:29:27,060 | INFO | iter is 10500 / 50000 [skipped   84] | loc. loss = 0.1706973463, classif. loss = 0.0557357520
2025-10-06 22:29:59,413 | INFO | iter is 10550 / 50000 [skipped   84] | loc. loss = 0.2200524062, classif. loss = 1.2175310850
2025-10-06 22:30:31,719 | INFO | iter is 10600 / 50000 [skipped   84] | loc. loss = 0.2853829563, classif. loss = 0.9646713734
2025-10-06 22:31:04,039 | INFO | iter is 10650 / 50000 [skipped   84] | loc. loss = 0.2575280070, classif. loss = 0.4111984968
2025-10-06 22:31:35,160 | INFO | iter is 10700 / 50000 [skipped   86] | loc. loss = 0.2155692875, classif. loss = 0.3127709925
2025-10-06 22:32:07,485 | INFO | iter is 10750 / 50000 [skipped   86] | loc. loss = 0.1483566910, classif. loss = 0.1998098493
2025-10-06 22:32:38,757 | INFO | iter is 10800 / 50000 [skipped   88] | loc. loss = 0.1516067088, classif. loss = 0.0257008374
2025-10-06 22:33:10,482 | INFO | iter is 10850 / 50000 [skipped   89] | loc. loss = 0.2610355020, classif. loss = 1.0789568424
2025-10-06 22:33:41,646 | INFO | iter is 10900 / 50000 [skipped   91] | loc. loss = 0.2575660348, classif. loss = 0.9291003346
2025-10-06 22:34:13,957 | INFO | iter is 10950 / 50000 [skipped   91] | loc. loss = 0.2738013864, classif. loss = 0.5586457253
2025-10-06 22:34:45,015 | INFO | iter is 11000 / 50000 [skipped   93] | loc. loss = 0.2057506144, classif. loss = 0.5275957584
2025-10-06 22:35:16,831 | INFO | iter is 11050 / 50000 [skipped   94] | loc. loss = 0.1661758125, classif. loss = 0.6882761717
2025-10-06 22:35:47,985 | INFO | iter is 11100 / 50000 [skipped   96] | loc. loss = 0.1459939331, classif. loss = 1.2992295027
2025-10-06 22:36:20,402 | INFO | iter is 11150 / 50000 [skipped   96] | loc. loss = 0.1166636199, classif. loss = 0.0271570180
2025-10-06 22:36:52,146 | INFO | iter is 11200 / 50000 [skipped   97] | loc. loss = 0.2119023502, classif. loss = 0.5740550756
2025-10-06 22:37:24,602 | INFO | iter is 11250 / 50000 [skipped   97] | loc. loss = 0.2643167675, classif. loss = 3.7978672981
2025-10-06 22:37:56,348 | INFO | iter is 11300 / 50000 [skipped   98] | loc. loss = 0.2623676062, classif. loss = 0.1630118489
2025-10-06 22:38:28,653 | INFO | iter is 11350 / 50000 [skipped   98] | loc. loss = 0.3740356565, classif. loss = 0.0651960522
2025-10-06 22:39:01,120 | INFO | iter is 11400 / 50000 [skipped   98] | loc. loss = 0.2406613976, classif. loss = 1.4400262833
2025-10-06 22:39:33,524 | INFO | iter is 11450 / 50000 [skipped   98] | loc. loss = 0.1132765561, classif. loss = 0.5194864869
2025-10-06 22:40:05,938 | INFO | iter is 11500 / 50000 [skipped   98] | loc. loss = 0.2207354456, classif. loss = 0.9123865366
2025-10-06 22:40:38,336 | INFO | iter is 11550 / 50000 [skipped   98] | loc. loss = 0.2520725429, classif. loss = 0.7402584553
2025-10-06 22:41:10,725 | INFO | iter is 11600 / 50000 [skipped   98] | loc. loss = 0.2177389860, classif. loss = 1.7044550180
2025-10-06 22:41:42,591 | INFO | iter is 11650 / 50000 [skipped   99] | loc. loss = 0.2675371170, classif. loss = 1.2432880402
2025-10-06 22:42:14,991 | INFO | iter is 11700 / 50000 [skipped   99] | loc. loss = 0.2099160254, classif. loss = 0.2075859308
2025-10-06 22:42:47,438 | INFO | iter is 11750 / 50000 [skipped   99] | loc. loss = 0.1759843975, classif. loss = 0.0228937045
2025-10-06 22:43:19,822 | INFO | iter is 11800 / 50000 [skipped   99] | loc. loss = 0.0959041640, classif. loss = 0.4508044720
2025-10-06 22:43:52,332 | INFO | iter is 11850 / 50000 [skipped   99] | loc. loss = 0.2838344276, classif. loss = 2.0309224129
2025-10-06 22:44:24,818 | INFO | iter is 11900 / 50000 [skipped   99] | loc. loss = 0.2067202330, classif. loss = 1.3910539150
2025-10-06 22:44:57,256 | INFO | iter is 11950 / 50000 [skipped   99] | loc. loss = 0.2384338677, classif. loss = 1.0725457668
2025-10-06 22:45:29,725 | INFO | iter is 12000 / 50000 [skipped   99] | loc. loss = 0.2171381116, classif. loss = 0.1748980582
2025-10-06 22:46:01,598 | INFO | iter is 12050 / 50000 [skipped  100] | loc. loss = 0.2109855413, classif. loss = 0.1269786358
2025-10-06 22:46:33,583 | INFO | iter is 12100 / 50000 [skipped  101] | loc. loss = 0.1020051688, classif. loss = 2.0447518826
2025-10-06 22:47:06,111 | INFO | iter is 12150 / 50000 [skipped  101] | loc. loss = 0.1715437919, classif. loss = 1.1257332563
2025-10-06 22:47:38,569 | INFO | iter is 12200 / 50000 [skipped  101] | loc. loss = 0.1995874792, classif. loss = 0.5391637683
2025-10-06 22:48:09,916 | INFO | iter is 12250 / 50000 [skipped  103] | loc. loss = 0.1964878589, classif. loss = 0.7904566526
2025-10-06 22:48:42,374 | INFO | iter is 12300 / 50000 [skipped  103] | loc. loss = 0.2741545737, classif. loss = 0.8109864593
2025-10-06 22:49:14,974 | INFO | iter is 12350 / 50000 [skipped  103] | loc. loss = 0.2630672753, classif. loss = 0.7270679474
2025-10-06 22:49:46,843 | INFO | iter is 12400 / 50000 [skipped  104] | loc. loss = 0.0814793259, classif. loss = 0.2714609504
2025-10-06 22:50:19,402 | INFO | iter is 12450 / 50000 [skipped  104] | loc. loss = 0.2503017187, classif. loss = 1.1364591122
2025-10-06 22:50:51,397 | INFO | iter is 12500 / 50000 [skipped  105] | loc. loss = 0.3205844462, classif. loss = 0.1450455189
2025-10-06 22:50:51,398 | INFO | ---------starting evaluation-----------
2025-10-06 22:50:53,494 | INFO | validation:    0/ 933 (2025-10-06_22-50-53)
2025-10-06 22:51:39,937 | INFO | validation:  100/ 933 (2025-10-06_22-51-39)
2025-10-06 22:52:26,292 | INFO | validation:  200/ 933 (2025-10-06_22-52-26)
2025-10-06 22:53:12,649 | INFO | validation:  300/ 933 (2025-10-06_22-53-12)
2025-10-06 22:53:58,979 | INFO | validation:  400/ 933 (2025-10-06_22-53-58)
2025-10-06 22:54:45,326 | INFO | validation:  500/ 933 (2025-10-06_22-54-45)
2025-10-06 22:55:31,674 | INFO | validation:  600/ 933 (2025-10-06_22-55-31)
2025-10-06 22:56:18,005 | INFO | validation:  700/ 933 (2025-10-06_22-56-18)
2025-10-06 22:57:04,361 | INFO | validation:  800/ 933 (2025-10-06_22-57-04)
2025-10-06 22:57:50,714 | INFO | validation:  900/ 933 (2025-10-06_22-57-50)
2025-10-06 22:58:06,746 | INFO | Confusion Matrix of Localization:
[[910257716  10102133]
 [  9320744  48640815]]
2025-10-06 22:58:06,747 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98902371 0.01097629]
 [0.16080906 0.83919094]]
2025-10-06 22:58:06,747 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42779561   538682   434609   105889]
 [       0  2322075  1883275   483296    53325]
 [       0   990324   456817  3937654   144135]
 [       0   361240    50964   276655  2380431]]
2025-10-06 22:58:06,747 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.97539419 0.0122822  0.00990929 0.00241432]
 [0.         0.48968562 0.39715026 0.1019188  0.01124532]
 [0.         0.17911675 0.08262304 0.71219097 0.02606924]
 [0.         0.11769497 0.01660449 0.09013648 0.77556406]]
2025-10-06 22:58:06,747 | INFO | lofF1 is 83.3572, clfF1 is 70.7401, oaF1 is 74.5252, sub class F1 score is [94.7373 49.0966 73.8693 82.7534]
2025-10-06 22:58:07,007 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-06_20-14-57_MambaBDA_Base_xBD/model_step12500.pth
2025-10-06 22:58:07,007 | INFO | ---------starting train set evaluation-----------
2025-10-06 22:58:07,007 | INFO | Train buffer size: 3097.
2025-10-06 22:58:18,920 | INFO | [TrainBuf] locF1 is 83.4200, clfF1 is 64.3366, oaF1 is 70.0616, sub class F1 score is [94.217  40.8439 66.966  82.3533]
2025-10-06 22:58:51,009 | INFO | iter is 12550 / 50000 [skipped  105] | loc. loss = 0.1343944073, classif. loss = 0.1200853735
2025-10-06 22:59:22,620 | INFO | iter is 12600 / 50000 [skipped  106] | loc. loss = 0.5064160824, classif. loss = 0.1717501432
2025-10-06 22:59:54,136 | INFO | iter is 12650 / 50000 [skipped  107] | loc. loss = 0.2524220347, classif. loss = 0.6428439021
2025-10-06 23:00:26,311 | INFO | iter is 12700 / 50000 [skipped  107] | loc. loss = 0.0732928365, classif. loss = 0.0191763714
2025-10-06 23:00:58,509 | INFO | iter is 12750 / 50000 [skipped  107] | loc. loss = 0.1685904115, classif. loss = 1.1405628920
2025-10-06 23:02:01,727 | INFO | iter is 12850 / 50000 [skipped  109] | loc. loss = 0.2293683290, classif. loss = 0.7041013837
2025-10-06 23:02:33,875 | INFO | iter is 12900 / 50000 [skipped  109] | loc. loss = 0.2290017903, classif. loss = 0.0660728067
2025-10-06 23:03:06,010 | INFO | iter is 12950 / 50000 [skipped  109] | loc. loss = 0.2027229071, classif. loss = 0.4567203224
2025-10-06 23:03:37,689 | INFO | iter is 13000 / 50000 [skipped  110] | loc. loss = 0.1460788548, classif. loss = 0.6585595608
2025-10-06 23:04:09,834 | INFO | iter is 13050 / 50000 [skipped  110] | loc. loss = 0.1792104244, classif. loss = 1.3258404732
2025-10-06 23:04:42,021 | INFO | iter is 13100 / 50000 [skipped  110] | loc. loss = 0.1990966052, classif. loss = 0.8495823145
2025-10-06 23:05:13,605 | INFO | iter is 13150 / 50000 [skipped  111] | loc. loss = 0.2705510259, classif. loss = 1.0929038525
2025-10-06 23:05:45,856 | INFO | iter is 13200 / 50000 [skipped  111] | loc. loss = 0.1681769490, classif. loss = 0.5348085165
2025-10-06 23:06:18,160 | INFO | iter is 13250 / 50000 [skipped  111] | loc. loss = 0.2351384461, classif. loss = 0.9172497392
2025-10-06 23:06:49,239 | INFO | iter is 13300 / 50000 [skipped  113] | loc. loss = 0.1957810074, classif. loss = 0.6032417417
2025-10-06 23:07:21,559 | INFO | iter is 13350 / 50000 [skipped  113] | loc. loss = 0.2365279943, classif. loss = 0.6137887239
2025-10-06 23:07:53,780 | INFO | iter is 13400 / 50000 [skipped  113] | loc. loss = 0.2196206450, classif. loss = 0.8065617085
2025-10-06 23:08:25,449 | INFO | iter is 13450 / 50000 [skipped  114] | loc. loss = 0.2061596215, classif. loss = 0.8146844506
2025-10-06 23:08:57,179 | INFO | iter is 13500 / 50000 [skipped  115] | loc. loss = 0.2775835395, classif. loss = 0.5926900506
2025-10-06 23:09:28,838 | INFO | iter is 13550 / 50000 [skipped  116] | loc. loss = 0.2412857264, classif. loss = 0.5413642526
2025-10-06 23:10:01,177 | INFO | iter is 13600 / 50000 [skipped  116] | loc. loss = 0.1598446965, classif. loss = 1.0324087143
2025-10-06 23:10:33,433 | INFO | iter is 13650 / 50000 [skipped  116] | loc. loss = 0.1627489179, classif. loss = 0.4298276007
2025-10-06 23:11:05,755 | INFO | iter is 13700 / 50000 [skipped  116] | loc. loss = 0.2452939153, classif. loss = 4.7553396225
2025-10-06 23:11:38,117 | INFO | iter is 13750 / 50000 [skipped  116] | loc. loss = 0.2630296648, classif. loss = 0.7948142290
2025-10-06 23:12:09,864 | INFO | iter is 13800 / 50000 [skipped  117] | loc. loss = 0.2564258575, classif. loss = 0.3981966674
2025-10-06 23:12:41,631 | INFO | iter is 13850 / 50000 [skipped  118] | loc. loss = 0.2674345076, classif. loss = 0.5709825158
2025-10-06 23:13:13,346 | INFO | iter is 13900 / 50000 [skipped  119] | loc. loss = 0.2330850363, classif. loss = 0.0356894583
2025-10-06 23:13:44,502 | INFO | iter is 13950 / 50000 [skipped  121] | loc. loss = 0.1921723932, classif. loss = 0.6762552857
2025-10-06 23:14:16,901 | INFO | iter is 14000 / 50000 [skipped  121] | loc. loss = 0.2406943440, classif. loss = 0.3586456180
2025-10-06 23:14:48,689 | INFO | iter is 14050 / 50000 [skipped  122] | loc. loss = 0.2383982837, classif. loss = 0.5215398073
2025-10-06 23:15:20,487 | INFO | iter is 14100 / 50000 [skipped  123] | loc. loss = 0.2093407512, classif. loss = 0.3049727082
2025-10-06 23:15:52,290 | INFO | iter is 14150 / 50000 [skipped  124] | loc. loss = 0.0842740759, classif. loss = 0.2177605182
2025-10-06 23:16:24,714 | INFO | iter is 14200 / 50000 [skipped  124] | loc. loss = 0.2305692732, classif. loss = 0.4976906776
2025-10-06 23:16:57,139 | INFO | iter is 14250 / 50000 [skipped  124] | loc. loss = 0.2255573571, classif. loss = 1.5763878822
2025-10-06 23:17:28,414 | INFO | iter is 14300 / 50000 [skipped  126] | loc. loss = 0.2789412439, classif. loss = 0.5225365162
2025-10-06 23:17:59,021 | INFO | iter is 14350 / 50000 [skipped  129] | loc. loss = 0.1866876930, classif. loss = 2.0295338631
2025-10-06 23:18:31,496 | INFO | iter is 14400 / 50000 [skipped  129] | loc. loss = 0.3232333064, classif. loss = 1.4969675541
2025-10-06 23:19:03,868 | INFO | iter is 14450 / 50000 [skipped  129] | loc. loss = 0.1958939582, classif. loss = 2.2399377823
2025-10-06 23:19:35,615 | INFO | iter is 14500 / 50000 [skipped  130] | loc. loss = 0.2214906812, classif. loss = 0.6260796785
2025-10-06 23:20:08,014 | INFO | iter is 14550 / 50000 [skipped  130] | loc. loss = 0.1660652310, classif. loss = 0.7545104027
2025-10-06 23:20:40,496 | INFO | iter is 14600 / 50000 [skipped  130] | loc. loss = 0.1480810195, classif. loss = 0.1718568504
2025-10-06 23:21:12,899 | INFO | iter is 14650 / 50000 [skipped  130] | loc. loss = 0.0756299868, classif. loss = 0.0066680727
2025-10-06 23:21:45,325 | INFO | iter is 14700 / 50000 [skipped  130] | loc. loss = 0.2228231579, classif. loss = 0.7502622604
2025-10-06 23:22:17,706 | INFO | iter is 14750 / 50000 [skipped  130] | loc. loss = 0.2322552800, classif. loss = 0.3026860654
2025-10-06 23:22:49,580 | INFO | iter is 14800 / 50000 [skipped  131] | loc. loss = 0.1933187246, classif. loss = 0.2763951719
2025-10-06 23:23:21,417 | INFO | iter is 14850 / 50000 [skipped  132] | loc. loss = 0.2128112465, classif. loss = 0.1113040373
2025-10-06 23:23:53,836 | INFO | iter is 14900 / 50000 [skipped  132] | loc. loss = 0.2527781129, classif. loss = 0.6178774238
2025-10-06 23:24:26,217 | INFO | iter is 14950 / 50000 [skipped  132] | loc. loss = 0.3260142505, classif. loss = 0.7295141220
2025-10-06 23:24:58,603 | INFO | iter is 15000 / 50000 [skipped  132] | loc. loss = 0.1777656972, classif. loss = 0.0823630393
2025-10-06 23:25:31,076 | INFO | iter is 15050 / 50000 [skipped  132] | loc. loss = 0.1656905115, classif. loss = 0.0287059937
2025-10-06 23:26:03,489 | INFO | iter is 15100 / 50000 [skipped  132] | loc. loss = 0.3035078943, classif. loss = 0.2674327791
2025-10-06 23:26:35,352 | INFO | iter is 15150 / 50000 [skipped  133] | loc. loss = 0.2542818487, classif. loss = 0.7484495640
2025-10-06 23:27:07,858 | INFO | iter is 15200 / 50000 [skipped  133] | loc. loss = 0.7257131338, classif. loss = 0.8898152709
2025-10-06 23:27:39,801 | INFO | iter is 15250 / 50000 [skipped  134] | loc. loss = 0.2590835094, classif. loss = 4.2185897827
2025-10-06 23:28:12,335 | INFO | iter is 15300 / 50000 [skipped  134] | loc. loss = 0.1479642838, classif. loss = 0.8389085531
2025-10-06 23:28:44,800 | INFO | iter is 15350 / 50000 [skipped  134] | loc. loss = 0.2266330421, classif. loss = 0.1253167242
2025-10-06 23:29:16,659 | INFO | iter is 15400 / 50000 [skipped  135] | loc. loss = 0.1918785870, classif. loss = 1.7461510897
2025-10-06 23:29:48,584 | INFO | iter is 15450 / 50000 [skipped  136] | loc. loss = 0.2688555717, classif. loss = 0.4794555902
2025-10-06 23:30:21,141 | INFO | iter is 15500 / 50000 [skipped  136] | loc. loss = 0.1833390892, classif. loss = 0.5333333015
2025-10-06 23:30:53,624 | INFO | iter is 15550 / 50000 [skipped  136] | loc. loss = 0.1563245803, classif. loss = 1.2224380970
2025-10-06 23:31:26,165 | INFO | iter is 15600 / 50000 [skipped  136] | loc. loss = 0.2734410465, classif. loss = 1.2199927568
2025-10-06 23:31:42,521 | INFO | ---------starting evaluation-----------
2025-10-06 23:31:44,659 | INFO | validation:    0/ 933 (2025-10-06_23-31-44)
2025-10-06 23:32:31,097 | INFO | validation:  100/ 933 (2025-10-06_23-32-31)
2025-10-06 23:33:17,461 | INFO | validation:  200/ 933 (2025-10-06_23-33-17)
2025-10-06 23:34:03,826 | INFO | validation:  300/ 933 (2025-10-06_23-34-03)
2025-10-06 23:34:50,199 | INFO | validation:  400/ 933 (2025-10-06_23-34-50)
2025-10-06 23:35:36,554 | INFO | validation:  500/ 933 (2025-10-06_23-35-36)
2025-10-06 23:36:22,936 | INFO | validation:  600/ 933 (2025-10-06_23-36-22)
2025-10-06 23:37:09,315 | INFO | validation:  700/ 933 (2025-10-06_23-37-09)
2025-10-06 23:37:55,740 | INFO | validation:  800/ 933 (2025-10-06_23-37-55)
2025-10-06 23:38:42,166 | INFO | validation:  900/ 933 (2025-10-06_23-38-42)
2025-10-06 23:38:58,198 | INFO | Confusion Matrix of Localization:
[[910454718   9905131]
 [  8751529  49210030]]
2025-10-06 23:38:58,198 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98923776 0.01076224]
 [0.1509885  0.8490115 ]]
2025-10-06 23:38:58,198 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 39439448  3758404   537945   122944]
 [       0   690411  3387533   636857    27170]
 [       0   343218  1054283  4004694   126735]
 [       0   150096   111841   275469  2531884]]
2025-10-06 23:38:58,198 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.89923803 0.08569339 0.0122654  0.00280318]
 [0.         0.14559579 0.71437236 0.13430217 0.00572968]
 [0.         0.06207675 0.19068482 0.72431628 0.02292216]
 [0.         0.04890251 0.03643872 0.08975007 0.82490869]]
2025-10-06 23:38:58,198 | INFO | lofF1 is 84.0646, clfF1 is 72.3329, oaF1 is 75.8524, sub class F1 score is [93.3678 51.9002 72.9194 86.1475]
2025-10-06 23:38:58,455 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-06_20-14-57_MambaBDA_Base_xBD/model_step15625.pth
2025-10-06 23:38:58,456 | INFO | ---------starting train set evaluation-----------
2025-10-06 23:38:58,456 | INFO | Train buffer size: 3094.
2025-10-06 23:39:10,438 | INFO | [TrainBuf] locF1 is 84.1799, clfF1 is 66.5951, oaF1 is 71.8705, sub class F1 score is [94.4519 44.7578 65.4389 84.3653]
2025-10-06 23:39:26,497 | INFO | iter is 15650 / 50000 [skipped  136] | loc. loss = 0.1545596123, classif. loss = 2.9075610638
2025-10-06 23:39:58,580 | INFO | iter is 15700 / 50000 [skipped  136] | loc. loss = 0.1889892519, classif. loss = 0.4154756963
2025-10-06 23:40:29,504 | INFO | iter is 15750 / 50000 [skipped  138] | loc. loss = 0.2255262434, classif. loss = 0.3553872705
2025-10-06 23:41:01,580 | INFO | iter is 15800 / 50000 [skipped  138] | loc. loss = 0.1674642563, classif. loss = 0.0179490261
2025-10-06 23:41:33,696 | INFO | iter is 15850 / 50000 [skipped  138] | loc. loss = 0.1631716490, classif. loss = 0.0858224854
2025-10-06 23:42:05,939 | INFO | iter is 15900 / 50000 [skipped  138] | loc. loss = 0.1864601076, classif. loss = 0.5743337274
2025-10-06 23:42:38,071 | INFO | iter is 15950 / 50000 [skipped  138] | loc. loss = 0.2160396725, classif. loss = 0.1869311333
2025-10-06 23:43:10,344 | INFO | iter is 16000 / 50000 [skipped  138] | loc. loss = 0.1795994788, classif. loss = 0.4722957611
2025-10-06 23:43:42,517 | INFO | iter is 16050 / 50000 [skipped  138] | loc. loss = 0.2173336744, classif. loss = 0.0879952982
2025-10-06 23:44:14,786 | INFO | iter is 16100 / 50000 [skipped  138] | loc. loss = 0.0985504910, classif. loss = 0.0209515579
2025-10-06 23:44:46,357 | INFO | iter is 16150 / 50000 [skipped  139] | loc. loss = 0.1893834323, classif. loss = 0.3899918795
2025-10-06 23:45:18,521 | INFO | iter is 16200 / 50000 [skipped  139] | loc. loss = 0.2600193024, classif. loss = 2.3238639832
2025-10-06 23:45:50,857 | INFO | iter is 16250 / 50000 [skipped  139] | loc. loss = 0.2269794345, classif. loss = 1.0466090441
2025-10-06 23:46:23,051 | INFO | iter is 16300 / 50000 [skipped  139] | loc. loss = 0.2173249573, classif. loss = 0.9273294806
2025-10-06 23:46:55,346 | INFO | iter is 16350 / 50000 [skipped  139] | loc. loss = 0.2168136537, classif. loss = 0.4262053370
2025-10-06 23:47:27,036 | INFO | iter is 16400 / 50000 [skipped  140] | loc. loss = 0.2971909940, classif. loss = 1.2931965590
2025-10-06 23:47:59,315 | INFO | iter is 16450 / 50000 [skipped  140] | loc. loss = 0.1979262829, classif. loss = 0.1357406825
2025-10-06 23:48:31,586 | INFO | iter is 16500 / 50000 [skipped  140] | loc. loss = 0.0981512070, classif. loss = 0.0839616060
2025-10-06 23:49:03,885 | INFO | iter is 16550 / 50000 [skipped  140] | loc. loss = 0.2505142689, classif. loss = 1.7974653244
2025-10-06 23:49:36,275 | INFO | iter is 16600 / 50000 [skipped  140] | loc. loss = 0.2770634890, classif. loss = 0.8103175163
2025-10-06 23:50:08,015 | INFO | iter is 16650 / 50000 [skipped  141] | loc. loss = 0.1809903979, classif. loss = 2.0302076340
2025-10-06 23:50:40,347 | INFO | iter is 16700 / 50000 [skipped  141] | loc. loss = 0.1982937008, classif. loss = 0.8919582963
2025-10-06 23:51:12,647 | INFO | iter is 16750 / 50000 [skipped  141] | loc. loss = 0.2528912127, classif. loss = 0.0749686584
2025-10-06 23:51:45,031 | INFO | iter is 16800 / 50000 [skipped  141] | loc. loss = 0.2982811034, classif. loss = 1.2755916119
2025-10-06 23:52:17,259 | INFO | iter is 16850 / 50000 [skipped  141] | loc. loss = 0.2053002715, classif. loss = 1.1436551809
2025-10-06 23:52:48,299 | INFO | iter is 16900 / 50000 [skipped  143] | loc. loss = 0.1904528439, classif. loss = 0.4475407898
2025-10-06 23:53:20,718 | INFO | iter is 16950 / 50000 [skipped  143] | loc. loss = 0.1695689261, classif. loss = 0.4489204884
2025-10-06 23:53:53,035 | INFO | iter is 17000 / 50000 [skipped  143] | loc. loss = 0.2869022489, classif. loss = 0.6941800117
2025-10-06 23:54:25,436 | INFO | iter is 17050 / 50000 [skipped  143] | loc. loss = 0.3073531091, classif. loss = 0.3998151422
2025-10-06 23:54:57,750 | INFO | iter is 17100 / 50000 [skipped  143] | loc. loss = 0.4023813605, classif. loss = 2.2650153637
2025-10-06 23:55:30,172 | INFO | iter is 17150 / 50000 [skipped  143] | loc. loss = 0.1799555123, classif. loss = 1.1858141422
2025-10-06 23:56:01,944 | INFO | iter is 17200 / 50000 [skipped  144] | loc. loss = 0.2088023275, classif. loss = 0.0843386576
2025-10-06 23:56:34,325 | INFO | iter is 17250 / 50000 [skipped  144] | loc. loss = 0.2579861283, classif. loss = 0.1520537436
2025-10-06 23:57:06,713 | INFO | iter is 17300 / 50000 [skipped  144] | loc. loss = 0.1763420701, classif. loss = 0.5999532342
2025-10-06 23:57:39,153 | INFO | iter is 17350 / 50000 [skipped  144] | loc. loss = 0.2110103369, classif. loss = 0.0561422631
2025-10-06 23:58:11,569 | INFO | iter is 17400 / 50000 [skipped  144] | loc. loss = 0.2230060697, classif. loss = 0.5646622181
2025-10-06 23:58:43,399 | INFO | iter is 17450 / 50000 [skipped  145] | loc. loss = 0.1768179089, classif. loss = 0.0968209803
2025-10-06 23:59:15,822 | INFO | iter is 17500 / 50000 [skipped  145] | loc. loss = 0.1107326373, classif. loss = 1.4056826830
2025-10-06 23:59:48,232 | INFO | iter is 17550 / 50000 [skipped  145] | loc. loss = 0.1574481726, classif. loss = 0.3750332594
2025-10-07 00:00:20,649 | INFO | iter is 17600 / 50000 [skipped  145] | loc. loss = 0.1357285827, classif. loss = 1.1507347822
2025-10-07 00:00:53,112 | INFO | iter is 17650 / 50000 [skipped  145] | loc. loss = 0.1606282890, classif. loss = 0.4708755314
2025-10-07 00:01:25,511 | INFO | iter is 17700 / 50000 [skipped  145] | loc. loss = 0.1834300011, classif. loss = 1.5358238220
2025-10-07 00:01:57,232 | INFO | iter is 17750 / 50000 [skipped  147] | loc. loss = 0.2551714182, classif. loss = 0.6312231421
2025-10-07 00:02:29,839 | INFO | iter is 17800 / 50000 [skipped  147] | loc. loss = 0.2423847020, classif. loss = 1.7030783892
2025-10-07 00:03:02,575 | INFO | iter is 17850 / 50000 [skipped  147] | loc. loss = 0.2926386595, classif. loss = 0.5327634215
2025-10-07 00:03:35,371 | INFO | iter is 17900 / 50000 [skipped  147] | loc. loss = 0.2796598673, classif. loss = 1.0303152800
2025-10-07 00:04:08,060 | INFO | iter is 17950 / 50000 [skipped  147] | loc. loss = 0.2227848619, classif. loss = 0.5845510364
2025-10-07 00:04:40,066 | INFO | iter is 18000 / 50000 [skipped  148] | loc. loss = 0.2217097133, classif. loss = 0.4452694058
2025-10-07 00:05:12,547 | INFO | iter is 18050 / 50000 [skipped  148] | loc. loss = 0.2466189265, classif. loss = 0.9148648381
2025-10-07 00:05:45,108 | INFO | iter is 18100 / 50000 [skipped  148] | loc. loss = 0.3094140887, classif. loss = 0.9596433043
2025-10-07 00:06:17,002 | INFO | iter is 18150 / 50000 [skipped  149] | loc. loss = 0.2715325952, classif. loss = 0.4227235317
2025-10-07 00:06:48,936 | INFO | iter is 18200 / 50000 [skipped  150] | loc. loss = 0.2041838169, classif. loss = 0.1550151110
2025-10-07 00:07:21,406 | INFO | iter is 18250 / 50000 [skipped  150] | loc. loss = 0.1878870279, classif. loss = 0.6675926447
2025-10-07 00:07:53,880 | INFO | iter is 18300 / 50000 [skipped  150] | loc. loss = 0.2335173190, classif. loss = 0.0092940778
2025-10-07 00:08:25,835 | INFO | iter is 18350 / 50000 [skipped  151] | loc. loss = 0.2638581693, classif. loss = 0.7886727452
2025-10-07 00:08:57,636 | INFO | iter is 18400 / 50000 [skipped  152] | loc. loss = 0.3547448814, classif. loss = 0.5908647776
2025-10-07 00:09:29,575 | INFO | iter is 18450 / 50000 [skipped  153] | loc. loss = 0.1503719091, classif. loss = 0.2153478563
2025-10-07 00:10:01,577 | INFO | iter is 18500 / 50000 [skipped  154] | loc. loss = 0.2371331304, classif. loss = 0.0040884535
2025-10-07 00:10:34,163 | INFO | iter is 18550 / 50000 [skipped  154] | loc. loss = 0.3317738771, classif. loss = 2.1525292397
2025-10-07 00:11:06,218 | INFO | iter is 18600 / 50000 [skipped  155] | loc. loss = 0.2599765062, classif. loss = 0.0217035171
2025-10-07 00:11:38,704 | INFO | iter is 18650 / 50000 [skipped  155] | loc. loss = 0.2075672150, classif. loss = 0.1737101376
2025-10-07 00:12:10,697 | INFO | iter is 18700 / 50000 [skipped  156] | loc. loss = 0.1067094058, classif. loss = 0.0812298805
2025-10-07 00:12:43,202 | INFO | iter is 18750 / 50000 [skipped  156] | loc. loss = 0.1650049388, classif. loss = 1.5684587955
2025-10-07 00:12:43,204 | INFO | ---------starting evaluation-----------
2025-10-07 00:12:45,366 | INFO | validation:    0/ 933 (2025-10-07_00-12-45)
2025-10-07 00:13:31,459 | INFO | validation:  100/ 933 (2025-10-07_00-13-31)
2025-10-07 00:14:17,534 | INFO | validation:  200/ 933 (2025-10-07_00-14-17)
2025-10-07 00:15:03,588 | INFO | validation:  300/ 933 (2025-10-07_00-15-03)
2025-10-07 00:15:49,635 | INFO | validation:  400/ 933 (2025-10-07_00-15-49)
2025-10-07 00:16:35,696 | INFO | validation:  500/ 933 (2025-10-07_00-16-35)
2025-10-07 00:17:21,768 | INFO | validation:  600/ 933 (2025-10-07_00-17-21)
2025-10-07 00:18:07,818 | INFO | validation:  700/ 933 (2025-10-07_00-18-07)
2025-10-07 00:18:53,880 | INFO | validation:  800/ 933 (2025-10-07_00-18-53)
2025-10-07 00:19:39,993 | INFO | validation:  900/ 933 (2025-10-07_00-19-39)
2025-10-07 00:19:55,936 | INFO | Confusion Matrix of Localization:
[[911074130   9285719]
 [  9671614  48289945]]
2025-10-07 00:19:55,937 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98991077 0.01008923]
 [0.16686256 0.83313744]]
2025-10-07 00:19:55,937 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42815024   827310   147552    68855]
 [       0  2056082  2430069   229519    26301]
 [       0  1152103   986550  3266102   124175]
 [       0   206945    71965   268004  2522376]]
2025-10-07 00:19:55,937 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.97620276 0.01886306 0.00336426 0.00156993]
 [0.         0.43359228 0.51245969 0.0484016  0.00554643]
 [0.         0.20837721 0.17843416 0.59072949 0.02245914]
 [0.         0.06742439 0.02344679 0.08731791 0.82181091]]
2025-10-07 00:19:55,937 | INFO | lofF1 is 83.5920, clfF1 is 72.5580, oaF1 is 75.8682, sub class F1 score is [95.0506 53.6565 69.1963 86.8139]
2025-10-07 00:19:56,200 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-06_20-14-57_MambaBDA_Base_xBD/model_step18750.pth
2025-10-07 00:19:56,200 | INFO | ---------starting train set evaluation-----------
2025-10-07 00:19:56,200 | INFO | Train buffer size: 3105.
2025-10-07 00:20:08,207 | INFO | [TrainBuf] locF1 is 84.5229, clfF1 is 67.0460, oaF1 is 72.2890, sub class F1 score is [94.6898 44.3047 67.2278 85.8074]
2025-10-07 00:20:39,803 | INFO | iter is 18800 / 50000 [skipped  157] | loc. loss = 0.3511361480, classif. loss = 0.0579761490
2025-10-07 00:21:11,902 | INFO | iter is 18850 / 50000 [skipped  157] | loc. loss = 0.1882478744, classif. loss = 0.4698827267
2025-10-07 00:21:43,486 | INFO | iter is 18900 / 50000 [skipped  158] | loc. loss = 0.2001836449, classif. loss = 1.0038497448
2025-10-07 00:22:15,698 | INFO | iter is 18950 / 50000 [skipped  158] | loc. loss = 0.2542250752, classif. loss = 0.2367347777
2025-10-07 00:22:47,297 | INFO | iter is 19000 / 50000 [skipped  159] | loc. loss = 0.0934864432, classif. loss = 1.4095104933
2025-10-07 00:23:18,326 | INFO | iter is 19050 / 50000 [skipped  161] | loc. loss = 0.1923040748, classif. loss = 0.8921844959
2025-10-07 00:23:50,504 | INFO | iter is 19100 / 50000 [skipped  161] | loc. loss = 0.1552951634, classif. loss = 0.3621810973
2025-10-07 00:24:22,717 | INFO | iter is 19150 / 50000 [skipped  161] | loc. loss = 0.2207315564, classif. loss = 0.7317432761
2025-10-07 00:24:54,939 | INFO | iter is 19200 / 50000 [skipped  161] | loc. loss = 0.2407652438, classif. loss = 0.3931702077
2025-10-07 00:25:27,097 | INFO | iter is 19250 / 50000 [skipped  161] | loc. loss = 0.2634711862, classif. loss = 1.6972115040
2025-10-07 00:25:59,381 | INFO | iter is 19300 / 50000 [skipped  161] | loc. loss = 0.4191239774, classif. loss = 1.0284428596
2025-10-07 00:26:31,589 | INFO | iter is 19350 / 50000 [skipped  161] | loc. loss = 0.2584730685, classif. loss = 0.0115657952
2025-10-07 00:27:03,855 | INFO | iter is 19400 / 50000 [skipped  161] | loc. loss = 0.2245207280, classif. loss = 0.0770355463
2025-10-07 00:27:36,090 | INFO | iter is 19450 / 50000 [skipped  161] | loc. loss = 0.2750301063, classif. loss = 0.6259674430
2025-10-07 00:28:07,748 | INFO | iter is 19500 / 50000 [skipped  162] | loc. loss = 0.2443283051, classif. loss = 1.0552177429
2025-10-07 00:28:39,385 | INFO | iter is 19550 / 50000 [skipped  163] | loc. loss = 0.1875379831, classif. loss = 1.0590276718
2025-10-07 00:29:11,699 | INFO | iter is 19600 / 50000 [skipped  163] | loc. loss = 0.2129281014, classif. loss = 0.0531121865
2025-10-07 00:29:43,951 | INFO | iter is 19650 / 50000 [skipped  163] | loc. loss = 0.1920648366, classif. loss = 0.7905524969
2025-10-07 00:30:16,224 | INFO | iter is 19700 / 50000 [skipped  163] | loc. loss = 0.2453632951, classif. loss = 0.0748097748
2025-10-07 00:30:47,945 | INFO | iter is 19750 / 50000 [skipped  164] | loc. loss = 0.2397418022, classif. loss = 0.1037005037
2025-10-07 00:31:19,633 | INFO | iter is 19800 / 50000 [skipped  165] | loc. loss = 0.2353037894, classif. loss = 0.9529343247
2025-10-07 00:31:51,897 | INFO | iter is 19850 / 50000 [skipped  165] | loc. loss = 0.2654259205, classif. loss = 0.7548708320
2025-10-07 00:32:23,595 | INFO | iter is 19900 / 50000 [skipped  166] | loc. loss = 0.1775785983, classif. loss = 1.6987546682
2025-10-07 00:32:55,896 | INFO | iter is 19950 / 50000 [skipped  166] | loc. loss = 0.2306482792, classif. loss = 0.2689536214
2025-10-07 00:33:28,210 | INFO | iter is 20000 / 50000 [skipped  166] | loc. loss = 0.2362924367, classif. loss = 0.7021375299
2025-10-07 00:34:00,515 | INFO | iter is 20050 / 50000 [skipped  166] | loc. loss = 0.3012964427, classif. loss = 0.2352879643
2025-10-07 00:34:32,837 | INFO | iter is 20100 / 50000 [skipped  166] | loc. loss = 0.1225910261, classif. loss = 0.4593309462
2025-10-07 00:35:05,118 | INFO | iter is 20150 / 50000 [skipped  166] | loc. loss = 0.1672728956, classif. loss = 2.3300995827
2025-10-07 00:35:36,394 | INFO | iter is 20200 / 50000 [skipped  168] | loc. loss = 0.2507137358, classif. loss = 1.3765413761
2025-10-07 00:36:08,730 | INFO | iter is 20250 / 50000 [skipped  168] | loc. loss = 0.2154296786, classif. loss = 0.1318462938
2025-10-07 00:36:40,433 | INFO | iter is 20300 / 50000 [skipped  169] | loc. loss = 0.1348295808, classif. loss = 0.3458797336
2025-10-07 00:37:12,184 | INFO | iter is 20350 / 50000 [skipped  170] | loc. loss = 0.2571579516, classif. loss = 0.1546815932
2025-10-07 00:37:44,581 | INFO | iter is 20400 / 50000 [skipped  170] | loc. loss = 0.0497701690, classif. loss = 0.5303570032
2025-10-07 00:38:16,304 | INFO | iter is 20450 / 50000 [skipped  171] | loc. loss = 0.2346749753, classif. loss = 0.2112042308
2025-10-07 00:38:48,094 | INFO | iter is 20500 / 50000 [skipped  172] | loc. loss = 0.1755085289, classif. loss = 2.5602283478
2025-10-07 00:39:20,449 | INFO | iter is 20550 / 50000 [skipped  172] | loc. loss = 0.2938744426, classif. loss = 0.3023439348
2025-10-07 00:39:52,328 | INFO | iter is 20600 / 50000 [skipped  173] | loc. loss = 0.1947699487, classif. loss = 0.4239401221
2025-10-07 00:40:24,648 | INFO | iter is 20650 / 50000 [skipped  173] | loc. loss = 0.2419661880, classif. loss = 1.4384996891
2025-10-07 00:40:57,034 | INFO | iter is 20700 / 50000 [skipped  173] | loc. loss = 0.2469383776, classif. loss = 0.3382468820
2025-10-07 00:41:29,386 | INFO | iter is 20750 / 50000 [skipped  173] | loc. loss = 0.2278653979, classif. loss = 1.2897938490
2025-10-07 00:42:01,872 | INFO | iter is 20800 / 50000 [skipped  173] | loc. loss = 0.1556124389, classif. loss = 1.1831126213
2025-10-07 00:42:34,278 | INFO | iter is 20850 / 50000 [skipped  173] | loc. loss = 0.2002225220, classif. loss = 0.6106204987
2025-10-07 00:43:06,694 | INFO | iter is 20900 / 50000 [skipped  173] | loc. loss = 0.1961762905, classif. loss = 0.8944510818
2025-10-07 00:43:39,051 | INFO | iter is 20950 / 50000 [skipped  173] | loc. loss = 0.1988641918, classif. loss = 0.4494114518
2025-10-07 00:44:11,515 | INFO | iter is 21000 / 50000 [skipped  173] | loc. loss = 0.2572619319, classif. loss = 1.4711948633
2025-10-07 00:44:43,930 | INFO | iter is 21050 / 50000 [skipped  173] | loc. loss = 0.1775467843, classif. loss = 0.4962716401
2025-10-07 00:45:16,248 | INFO | iter is 21100 / 50000 [skipped  173] | loc. loss = 0.2935048044, classif. loss = 0.4340240359
2025-10-07 00:45:48,671 | INFO | iter is 21150 / 50000 [skipped  173] | loc. loss = 0.1721692234, classif. loss = 0.7405506372
2025-10-07 00:46:21,192 | INFO | iter is 21200 / 50000 [skipped  173] | loc. loss = 0.2449021041, classif. loss = 0.7320942283
2025-10-07 00:46:53,018 | INFO | iter is 21250 / 50000 [skipped  174] | loc. loss = 0.2203781307, classif. loss = 0.0784318224
2025-10-07 00:47:25,501 | INFO | iter is 21300 / 50000 [skipped  174] | loc. loss = 0.1879882663, classif. loss = 0.2431218177
2025-10-07 00:47:57,383 | INFO | iter is 21350 / 50000 [skipped  175] | loc. loss = 0.1366203725, classif. loss = 0.2792564332
2025-10-07 00:48:29,873 | INFO | iter is 21400 / 50000 [skipped  175] | loc. loss = 0.1875702739, classif. loss = 0.5163601041
2025-10-07 00:49:01,704 | INFO | iter is 21450 / 50000 [skipped  176] | loc. loss = 0.2568683624, classif. loss = 2.6178431511
2025-10-07 00:49:34,142 | INFO | iter is 21500 / 50000 [skipped  176] | loc. loss = 0.1549008787, classif. loss = 0.0152365640
2025-10-07 00:50:06,627 | INFO | iter is 21550 / 50000 [skipped  176] | loc. loss = 0.1252237111, classif. loss = 0.3737042546
2025-10-07 00:50:37,930 | INFO | iter is 21600 / 50000 [skipped  178] | loc. loss = 0.1971515864, classif. loss = 0.5320010185
2025-10-07 00:51:10,469 | INFO | iter is 21650 / 50000 [skipped  178] | loc. loss = 0.3097441196, classif. loss = 0.5866672397
2025-10-07 00:51:42,996 | INFO | iter is 21700 / 50000 [skipped  178] | loc. loss = 0.1330501288, classif. loss = 2.6821217537
2025-10-07 00:52:15,462 | INFO | iter is 21750 / 50000 [skipped  178] | loc. loss = 0.1870520264, classif. loss = 1.6078395844
2025-10-07 00:52:47,898 | INFO | iter is 21800 / 50000 [skipped  178] | loc. loss = 0.2418877184, classif. loss = 2.1917791367
2025-10-07 00:53:20,379 | INFO | iter is 21850 / 50000 [skipped  178] | loc. loss = 0.1273015887, classif. loss = 0.8091764450
2025-10-07 00:53:36,611 | INFO | ---------starting evaluation-----------
2025-10-07 00:53:38,819 | INFO | validation:    0/ 933 (2025-10-07_00-53-38)
2025-10-07 00:54:24,903 | INFO | validation:  100/ 933 (2025-10-07_00-54-24)
2025-10-07 00:55:10,940 | INFO | validation:  200/ 933 (2025-10-07_00-55-10)
2025-10-07 00:55:56,936 | INFO | validation:  300/ 933 (2025-10-07_00-55-56)
2025-10-07 00:56:42,935 | INFO | validation:  400/ 933 (2025-10-07_00-56-42)
2025-10-07 00:57:28,953 | INFO | validation:  500/ 933 (2025-10-07_00-57-28)
2025-10-07 00:58:14,965 | INFO | validation:  600/ 933 (2025-10-07_00-58-14)
2025-10-07 00:59:00,956 | INFO | validation:  700/ 933 (2025-10-07_00-59-00)
2025-10-07 00:59:46,956 | INFO | validation:  800/ 933 (2025-10-07_00-59-46)
2025-10-07 01:00:32,979 | INFO | validation:  900/ 933 (2025-10-07_01-00-32)
2025-10-07 01:00:48,884 | INFO | Confusion Matrix of Localization:
[[911320928   9038921]
 [ 10238849  47722710]]
2025-10-07 01:00:48,885 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99017893 0.00982107]
 [0.17664896 0.82335104]]
2025-10-07 01:00:48,885 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42132438  1120871   557208    48224]
 [       0  1906869  2177780   645592    11730]
 [       0   803945   556363  4072781    95841]
 [       0   236738    94587   302547  2435418]]
2025-10-07 01:00:48,885 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96063948 0.02555639 0.01270461 0.00109953]
 [0.         0.40212582 0.45925629 0.13614423 0.00247365]
 [0.         0.14540698 0.10062761 0.73663096 0.01733446]
 [0.         0.07713119 0.03081722 0.09857231 0.79347927]]
2025-10-07 01:00:48,885 | INFO | lofF1 is 83.1963, clfF1 is 71.7274, oaF1 is 75.1680, sub class F1 score is [94.7449 50.1124 73.3368 86.0495]
2025-10-07 01:00:48,886 | INFO | ---------starting train set evaluation-----------
2025-10-07 01:00:48,886 | INFO | Train buffer size: 3103.
2025-10-07 01:01:00,905 | INFO | [TrainBuf] locF1 is 84.6440, clfF1 is 69.6532, oaF1 is 74.1505, sub class F1 score is [94.9374 47.3051 69.6952 87.6691]
2025-10-07 01:01:16,990 | INFO | iter is 21900 / 50000 [skipped  178] | loc. loss = 0.3347444534, classif. loss = 0.0540766306
2025-10-07 01:01:48,516 | INFO | iter is 21950 / 50000 [skipped  179] | loc. loss = 0.2209655046, classif. loss = 0.1457632780
2025-10-07 01:02:20,636 | INFO | iter is 22000 / 50000 [skipped  179] | loc. loss = 0.2678934336, classif. loss = 0.0506117456
2025-10-07 01:02:52,805 | INFO | iter is 22050 / 50000 [skipped  179] | loc. loss = 0.1116339862, classif. loss = 2.0956692696
2025-10-07 01:03:24,334 | INFO | iter is 22100 / 50000 [skipped  180] | loc. loss = 0.0846951827, classif. loss = 0.0277579874
2025-10-07 01:03:55,382 | INFO | iter is 22150 / 50000 [skipped  182] | loc. loss = 0.2447481453, classif. loss = 0.4511273503
2025-10-07 01:04:27,540 | INFO | iter is 22200 / 50000 [skipped  182] | loc. loss = 0.2839264870, classif. loss = 1.1137483120
2025-10-07 01:04:59,098 | INFO | iter is 22250 / 50000 [skipped  183] | loc. loss = 0.1728354990, classif. loss = 0.1863237917
2025-10-07 01:05:31,285 | INFO | iter is 22300 / 50000 [skipped  183] | loc. loss = 0.2347155213, classif. loss = 1.5157328844
2025-10-07 01:06:02,878 | INFO | iter is 22350 / 50000 [skipped  184] | loc. loss = 0.1882625669, classif. loss = 0.8212906718
2025-10-07 01:06:34,508 | INFO | iter is 22400 / 50000 [skipped  185] | loc. loss = 0.2349794656, classif. loss = 1.2245383263
2025-10-07 01:07:06,688 | INFO | iter is 22450 / 50000 [skipped  185] | loc. loss = 0.1820557714, classif. loss = 0.9865638018
2025-10-07 01:07:38,923 | INFO | iter is 22500 / 50000 [skipped  185] | loc. loss = 0.1772565544, classif. loss = 0.7136487961
2025-10-07 01:08:10,559 | INFO | iter is 22550 / 50000 [skipped  186] | loc. loss = 0.2013243437, classif. loss = 0.1971521080
2025-10-07 01:08:42,247 | INFO | iter is 22600 / 50000 [skipped  187] | loc. loss = 0.1275110990, classif. loss = 0.0057505788
2025-10-07 01:09:14,575 | INFO | iter is 22650 / 50000 [skipped  187] | loc. loss = 0.0947036743, classif. loss = 0.6946957707
2025-10-07 01:09:46,824 | INFO | iter is 22700 / 50000 [skipped  187] | loc. loss = 0.1395777762, classif. loss = 0.1486538351
2025-10-07 01:10:19,075 | INFO | iter is 22750 / 50000 [skipped  187] | loc. loss = 0.2120822519, classif. loss = 0.5102480054
2025-10-07 01:10:51,355 | INFO | iter is 22800 / 50000 [skipped  187] | loc. loss = 0.1351761967, classif. loss = 0.1432049721
2025-10-07 01:11:23,633 | INFO | iter is 22850 / 50000 [skipped  187] | loc. loss = 0.2075422704, classif. loss = 0.0306571461
2025-10-07 01:11:54,731 | INFO | iter is 22900 / 50000 [skipped  189] | loc. loss = 0.1328452379, classif. loss = 0.0409457237
2025-10-07 01:12:27,115 | INFO | iter is 22950 / 50000 [skipped  189] | loc. loss = 0.2210507244, classif. loss = 0.1920729578
2025-10-07 01:12:58,895 | INFO | iter is 23000 / 50000 [skipped  190] | loc. loss = 0.2498007864, classif. loss = 0.4640178084
2025-10-07 01:13:31,165 | INFO | iter is 23050 / 50000 [skipped  190] | loc. loss = 0.2557204962, classif. loss = 2.3569848537
2025-10-07 01:14:03,549 | INFO | iter is 23100 / 50000 [skipped  190] | loc. loss = 0.2460966408, classif. loss = 0.5451163054
2025-10-07 01:14:35,842 | INFO | iter is 23150 / 50000 [skipped  190] | loc. loss = 0.2254587412, classif. loss = 0.7397332191
2025-10-07 01:15:08,228 | INFO | iter is 23200 / 50000 [skipped  190] | loc. loss = 0.2084703296, classif. loss = 0.9014473557
2025-10-07 01:15:40,619 | INFO | iter is 23250 / 50000 [skipped  190] | loc. loss = 0.2045754790, classif. loss = 0.1172391921
2025-10-07 01:16:13,000 | INFO | iter is 23300 / 50000 [skipped  190] | loc. loss = 0.2343920171, classif. loss = 0.6003142595
2025-10-07 01:16:44,789 | INFO | iter is 23350 / 50000 [skipped  191] | loc. loss = 0.1891297996, classif. loss = 0.9971927404
2025-10-07 01:17:17,198 | INFO | iter is 23400 / 50000 [skipped  191] | loc. loss = 0.1376295835, classif. loss = 0.6299883723
2025-10-07 01:17:48,975 | INFO | iter is 23450 / 50000 [skipped  192] | loc. loss = 0.2754668295, classif. loss = 1.1415299177
2025-10-07 01:18:21,373 | INFO | iter is 23500 / 50000 [skipped  192] | loc. loss = 0.1140395552, classif. loss = 0.0429548398
2025-10-07 01:18:53,188 | INFO | iter is 23550 / 50000 [skipped  193] | loc. loss = 0.3214864135, classif. loss = 1.0273305178
2025-10-07 01:19:25,526 | INFO | iter is 23600 / 50000 [skipped  193] | loc. loss = 0.2448776513, classif. loss = 1.0396010876
2025-10-07 01:19:57,337 | INFO | iter is 23650 / 50000 [skipped  194] | loc. loss = 0.1660133898, classif. loss = 1.1016006470
2025-10-07 01:20:29,131 | INFO | iter is 23700 / 50000 [skipped  195] | loc. loss = 0.2020604610, classif. loss = 0.8011887670
2025-10-07 01:21:01,006 | INFO | iter is 23750 / 50000 [skipped  196] | loc. loss = 0.2004680634, classif. loss = 1.8324043751
2025-10-07 01:21:33,339 | INFO | iter is 23800 / 50000 [skipped  196] | loc. loss = 0.2667724788, classif. loss = 0.2668945193
2025-10-07 01:22:05,760 | INFO | iter is 23850 / 50000 [skipped  196] | loc. loss = 0.1212759912, classif. loss = 0.0203720815
2025-10-07 01:22:37,605 | INFO | iter is 23900 / 50000 [skipped  197] | loc. loss = 0.2037025541, classif. loss = 1.3871603012
2025-10-07 01:23:09,995 | INFO | iter is 23950 / 50000 [skipped  197] | loc. loss = 0.1520512998, classif. loss = 0.7154135108
2025-10-07 01:23:42,500 | INFO | iter is 24000 / 50000 [skipped  197] | loc. loss = 0.1330026239, classif. loss = 0.0403151177
2025-10-07 01:24:14,856 | INFO | iter is 24050 / 50000 [skipped  197] | loc. loss = 0.2015920430, classif. loss = 1.7572965622
2025-10-07 01:24:46,726 | INFO | iter is 24100 / 50000 [skipped  198] | loc. loss = 0.1995021105, classif. loss = 0.2752293944
2025-10-07 01:25:19,131 | INFO | iter is 24150 / 50000 [skipped  198] | loc. loss = 0.1286514848, classif. loss = 0.9219248891
2025-10-07 01:25:51,639 | INFO | iter is 24200 / 50000 [skipped  198] | loc. loss = 0.2357755899, classif. loss = 0.0945002511
2025-10-07 01:26:24,157 | INFO | iter is 24250 / 50000 [skipped  198] | loc. loss = 0.2448414564, classif. loss = 0.1031687856
2025-10-07 01:26:56,673 | INFO | iter is 24300 / 50000 [skipped  198] | loc. loss = 0.1090188622, classif. loss = 0.5901474357
2025-10-07 01:27:29,161 | INFO | iter is 24350 / 50000 [skipped  198] | loc. loss = 0.2498657703, classif. loss = 0.8225315809
2025-10-07 01:28:01,613 | INFO | iter is 24400 / 50000 [skipped  198] | loc. loss = 0.1734148860, classif. loss = 1.5794181824
2025-10-07 01:28:34,145 | INFO | iter is 24450 / 50000 [skipped  198] | loc. loss = 0.1698337346, classif. loss = 0.8277716637
2025-10-07 01:29:06,647 | INFO | iter is 24500 / 50000 [skipped  198] | loc. loss = 0.1464950591, classif. loss = 0.9593499899
2025-10-07 01:29:39,217 | INFO | iter is 24550 / 50000 [skipped  198] | loc. loss = 0.1392471790, classif. loss = 0.8067274094
2025-10-07 01:30:11,732 | INFO | iter is 24600 / 50000 [skipped  198] | loc. loss = 0.2641631663, classif. loss = 0.0331273749
2025-10-07 01:30:44,284 | INFO | iter is 24650 / 50000 [skipped  198] | loc. loss = 0.1069994047, classif. loss = 0.2677366138
2025-10-07 01:31:16,729 | INFO | iter is 24700 / 50000 [skipped  198] | loc. loss = 0.1395799816, classif. loss = 1.4252936840
2025-10-07 01:31:49,343 | INFO | iter is 24750 / 50000 [skipped  198] | loc. loss = 0.1296999454, classif. loss = 0.0256768316
2025-10-07 01:32:20,607 | INFO | iter is 24800 / 50000 [skipped  200] | loc. loss = 0.2026794851, classif. loss = 0.1974613816
2025-10-07 01:32:52,577 | INFO | iter is 24850 / 50000 [skipped  201] | loc. loss = 0.2667272091, classif. loss = 0.6854293942
2025-10-07 01:33:25,115 | INFO | iter is 24900 / 50000 [skipped  201] | loc. loss = 0.2870767415, classif. loss = 0.6094118357
2025-10-07 01:33:57,687 | INFO | iter is 24950 / 50000 [skipped  201] | loc. loss = 0.2192615122, classif. loss = 0.9207242131
2025-10-07 01:34:30,288 | INFO | iter is 25000 / 50000 [skipped  201] | loc. loss = 0.1511647701, classif. loss = 0.7007647753
2025-10-07 01:34:30,289 | INFO | ---------starting evaluation-----------
2025-10-07 01:34:32,502 | INFO | validation:    0/ 933 (2025-10-07_01-34-32)
2025-10-07 01:35:18,976 | INFO | validation:  100/ 933 (2025-10-07_01-35-18)
2025-10-07 01:36:05,348 | INFO | validation:  200/ 933 (2025-10-07_01-36-05)
2025-10-07 01:36:51,695 | INFO | validation:  300/ 933 (2025-10-07_01-36-51)
2025-10-07 01:37:38,060 | INFO | validation:  400/ 933 (2025-10-07_01-37-38)
2025-10-07 01:38:24,403 | INFO | validation:  500/ 933 (2025-10-07_01-38-24)
2025-10-07 01:39:10,755 | INFO | validation:  600/ 933 (2025-10-07_01-39-10)
2025-10-07 01:39:57,103 | INFO | validation:  700/ 933 (2025-10-07_01-39-57)
2025-10-07 01:40:43,459 | INFO | validation:  800/ 933 (2025-10-07_01-40-43)
2025-10-07 01:41:29,823 | INFO | validation:  900/ 933 (2025-10-07_01-41-29)
2025-10-07 01:41:46,155 | INFO | Confusion Matrix of Localization:
[[912711997   7647852]
 [  9957130  48004429]]
2025-10-07 01:41:46,155 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99169037 0.00830963]
 [0.17178851 0.82821149]]
2025-10-07 01:41:46,155 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42079809   966253   754032    58647]
 [       0  1559719  2510852   652613    18787]
 [       0   517680   649558  4270933    90759]
 [       0   192569    42115   373542  2461064]]
2025-10-07 01:41:46,155 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95943951 0.02203102 0.01719229 0.00133718]
 [0.         0.32891787 0.52949544 0.13762484 0.00396185]
 [0.         0.09363114 0.11748349 0.77247008 0.01641529]
 [0.         0.06274057 0.01372141 0.12170306 0.80183495]]
2025-10-07 01:41:46,155 | INFO | lofF1 is 84.5045, clfF1 is 74.9628, oaF1 is 77.8253, sub class F1 score is [95.4098 56.3556 73.7636 86.3751]
2025-10-07 01:41:46,414 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-06_20-14-57_MambaBDA_Base_xBD/model_step25000.pth
2025-10-07 01:41:46,414 | INFO | ---------starting train set evaluation-----------
2025-10-07 01:41:46,415 | INFO | Train buffer size: 3102.
2025-10-07 01:41:58,505 | INFO | [TrainBuf] locF1 is 84.9752, clfF1 is 69.5737, oaF1 is 74.1941, sub class F1 score is [94.7481 47.4585 70.3734 85.78  ]
2025-10-07 01:42:30,553 | INFO | iter is 25050 / 50000 [skipped  201] | loc. loss = 0.1665901244, classif. loss = 0.6350522041
2025-10-07 01:43:02,676 | INFO | iter is 25100 / 50000 [skipped  201] | loc. loss = 0.2483694702, classif. loss = 0.4032060206
2025-10-07 01:43:34,331 | INFO | iter is 25150 / 50000 [skipped  202] | loc. loss = 0.1971711963, classif. loss = 0.0210549422
2025-10-07 01:44:06,467 | INFO | iter is 25200 / 50000 [skipped  202] | loc. loss = 0.2276109755, classif. loss = 0.7424394488
2025-10-07 01:44:38,705 | INFO | iter is 25250 / 50000 [skipped  202] | loc. loss = 0.2964046597, classif. loss = 0.4826434851
2025-10-07 01:45:09,669 | INFO | iter is 25300 / 50000 [skipped  204] | loc. loss = 0.1826461852, classif. loss = 0.1093577966
2025-10-07 01:45:41,904 | INFO | iter is 25350 / 50000 [skipped  204] | loc. loss = 0.2620664835, classif. loss = 0.7443218231
2025-10-07 01:46:14,090 | INFO | iter is 25400 / 50000 [skipped  204] | loc. loss = 0.1526411474, classif. loss = 1.0574970245
2025-10-07 01:46:46,311 | INFO | iter is 25450 / 50000 [skipped  204] | loc. loss = 0.2061012387, classif. loss = 0.3736789227
2025-10-07 01:47:18,520 | INFO | iter is 25500 / 50000 [skipped  204] | loc. loss = 0.1832506210, classif. loss = 0.8271451592
2025-10-07 01:47:50,176 | INFO | iter is 25550 / 50000 [skipped  205] | loc. loss = 0.1816564798, classif. loss = 0.0436167493
2025-10-07 01:48:22,402 | INFO | iter is 25600 / 50000 [skipped  205] | loc. loss = 0.1457291991, classif. loss = 0.7631158829
2025-10-07 01:48:53,506 | INFO | iter is 25650 / 50000 [skipped  207] | loc. loss = 0.1750730276, classif. loss = 0.4864471257
2025-10-07 01:49:25,750 | INFO | iter is 25700 / 50000 [skipped  207] | loc. loss = 0.1670109034, classif. loss = 0.0628336668
2025-10-07 01:49:58,003 | INFO | iter is 25750 / 50000 [skipped  207] | loc. loss = 0.1422542334, classif. loss = 0.9286501408
2025-10-07 01:50:30,219 | INFO | iter is 25800 / 50000 [skipped  207] | loc. loss = 0.1919799447, classif. loss = 1.3616535664
2025-10-07 01:51:01,976 | INFO | iter is 25850 / 50000 [skipped  208] | loc. loss = 0.2173376381, classif. loss = 0.0933489949
2025-10-07 01:51:34,198 | INFO | iter is 25900 / 50000 [skipped  208] | loc. loss = 0.2877505422, classif. loss = 0.7612559795
2025-10-07 01:52:05,427 | INFO | iter is 25950 / 50000 [skipped  210] | loc. loss = 0.2866665423, classif. loss = 0.6743034720
2025-10-07 01:52:37,117 | INFO | iter is 26000 / 50000 [skipped  211] | loc. loss = 0.1157979444, classif. loss = 0.0529283062
2025-10-07 01:53:09,469 | INFO | iter is 26050 / 50000 [skipped  211] | loc. loss = 0.1585913599, classif. loss = 0.1523084491
2025-10-07 01:53:41,731 | INFO | iter is 26100 / 50000 [skipped  211] | loc. loss = 0.2107494026, classif. loss = 0.0697471052
2025-10-07 01:54:13,975 | INFO | iter is 26150 / 50000 [skipped  211] | loc. loss = 0.2161762416, classif. loss = 1.5771298409
2025-10-07 01:54:46,344 | INFO | iter is 26200 / 50000 [skipped  211] | loc. loss = 0.3558377028, classif. loss = 1.0871219635
2025-10-07 01:55:18,572 | INFO | iter is 26250 / 50000 [skipped  211] | loc. loss = 0.1811144501, classif. loss = 1.5598192215
2025-10-07 01:55:50,986 | INFO | iter is 26300 / 50000 [skipped  211] | loc. loss = 0.2390822321, classif. loss = 0.0789510682
2025-10-07 01:56:22,702 | INFO | iter is 26350 / 50000 [skipped  212] | loc. loss = 0.2268567681, classif. loss = 0.1266698837
2025-10-07 01:56:55,075 | INFO | iter is 26400 / 50000 [skipped  212] | loc. loss = 0.2019450217, classif. loss = 0.3670709133
2025-10-07 01:57:27,399 | INFO | iter is 26450 / 50000 [skipped  212] | loc. loss = 0.2637797594, classif. loss = 0.3872138858
2025-10-07 01:57:59,174 | INFO | iter is 26500 / 50000 [skipped  213] | loc. loss = 0.1833468825, classif. loss = 0.3500401080
2025-10-07 01:58:31,040 | INFO | iter is 26550 / 50000 [skipped  214] | loc. loss = 0.1864340305, classif. loss = 1.4453370571
2025-10-07 01:59:03,399 | INFO | iter is 26600 / 50000 [skipped  214] | loc. loss = 0.1321908981, classif. loss = 0.5328847766
2025-10-07 01:59:35,864 | INFO | iter is 26650 / 50000 [skipped  214] | loc. loss = 0.2427826375, classif. loss = 0.8756349087
2025-10-07 02:00:08,187 | INFO | iter is 26700 / 50000 [skipped  214] | loc. loss = 0.3381876945, classif. loss = 0.2808313370
2025-10-07 02:00:40,573 | INFO | iter is 26750 / 50000 [skipped  214] | loc. loss = 0.1485279351, classif. loss = 0.7393944263
2025-10-07 02:01:12,941 | INFO | iter is 26800 / 50000 [skipped  214] | loc. loss = 0.1103315949, classif. loss = 0.5611817837
2025-10-07 02:01:45,378 | INFO | iter is 26850 / 50000 [skipped  214] | loc. loss = 0.2583420873, classif. loss = 1.5914692879
2025-10-07 02:02:17,886 | INFO | iter is 26900 / 50000 [skipped  214] | loc. loss = 0.1825142354, classif. loss = 0.0401381217
2025-10-07 02:02:50,336 | INFO | iter is 26950 / 50000 [skipped  214] | loc. loss = 0.1818265915, classif. loss = 1.4242411852
2025-10-07 02:03:22,892 | INFO | iter is 27000 / 50000 [skipped  214] | loc. loss = 0.3120135665, classif. loss = 0.0204987768
2025-10-07 02:04:26,588 | INFO | iter is 27100 / 50000 [skipped  216] | loc. loss = 0.1089156792, classif. loss = 0.1103019863
2025-10-07 02:04:59,084 | INFO | iter is 27150 / 50000 [skipped  216] | loc. loss = 0.1924892962, classif. loss = 0.8390021324
2025-10-07 02:05:31,530 | INFO | iter is 27200 / 50000 [skipped  216] | loc. loss = 0.2164774388, classif. loss = 0.0401300117
2025-10-07 02:06:04,048 | INFO | iter is 27250 / 50000 [skipped  216] | loc. loss = 0.1594366431, classif. loss = 0.3256023526
2025-10-07 02:06:35,866 | INFO | iter is 27300 / 50000 [skipped  217] | loc. loss = 0.1205772460, classif. loss = 0.0851581842
2025-10-07 02:07:07,783 | INFO | iter is 27350 / 50000 [skipped  218] | loc. loss = 0.1039120406, classif. loss = 0.6489371657
2025-10-07 02:07:40,210 | INFO | iter is 27400 / 50000 [skipped  218] | loc. loss = 0.1395685971, classif. loss = 0.9265814424
2025-10-07 02:08:11,640 | INFO | iter is 27450 / 50000 [skipped  220] | loc. loss = 0.2612422109, classif. loss = 3.2707281113
2025-10-07 02:08:44,066 | INFO | iter is 27500 / 50000 [skipped  220] | loc. loss = 0.2054158747, classif. loss = 0.0456457213
2025-10-07 02:09:16,568 | INFO | iter is 27550 / 50000 [skipped  220] | loc. loss = 0.1055411845, classif. loss = 0.0793742388
2025-10-07 02:09:49,024 | INFO | iter is 27600 / 50000 [skipped  220] | loc. loss = 0.2266410887, classif. loss = 0.9941438437
2025-10-07 02:10:21,560 | INFO | iter is 27650 / 50000 [skipped  220] | loc. loss = 0.1255468875, classif. loss = 0.8243940473
2025-10-07 02:10:54,020 | INFO | iter is 27700 / 50000 [skipped  220] | loc. loss = 0.2079788595, classif. loss = 0.3841314912
2025-10-07 02:11:26,015 | INFO | iter is 27750 / 50000 [skipped  221] | loc. loss = 0.2698560655, classif. loss = 0.8146816492
2025-10-07 02:11:58,649 | INFO | iter is 27800 / 50000 [skipped  221] | loc. loss = 0.2106565982, classif. loss = 0.1517976820
2025-10-07 02:12:31,095 | INFO | iter is 27850 / 50000 [skipped  221] | loc. loss = 0.1857554764, classif. loss = 0.0466250367
2025-10-07 02:13:03,699 | INFO | iter is 27900 / 50000 [skipped  221] | loc. loss = 0.1885279864, classif. loss = 0.8820706010
2025-10-07 02:13:36,152 | INFO | iter is 27950 / 50000 [skipped  221] | loc. loss = 0.1861863136, classif. loss = 0.8487192392
2025-10-07 02:14:07,544 | INFO | iter is 28000 / 50000 [skipped  223] | loc. loss = 0.1483305842, classif. loss = 0.0398183689
2025-10-07 02:14:39,464 | INFO | iter is 28050 / 50000 [skipped  224] | loc. loss = 0.1669911891, classif. loss = 0.7548434734
2025-10-07 02:15:12,014 | INFO | iter is 28100 / 50000 [skipped  224] | loc. loss = 0.3000535667, classif. loss = 0.4757694006
2025-10-07 02:15:28,275 | INFO | ---------starting evaluation-----------
2025-10-07 02:15:30,486 | INFO | validation:    0/ 933 (2025-10-07_02-15-30)
2025-10-07 02:16:16,812 | INFO | validation:  100/ 933 (2025-10-07_02-16-16)
2025-10-07 02:17:03,063 | INFO | validation:  200/ 933 (2025-10-07_02-17-03)
2025-10-07 02:17:49,294 | INFO | validation:  300/ 933 (2025-10-07_02-17-49)
2025-10-07 02:18:35,530 | INFO | validation:  400/ 933 (2025-10-07_02-18-35)
2025-10-07 02:19:21,778 | INFO | validation:  500/ 933 (2025-10-07_02-19-21)
2025-10-07 02:20:08,028 | INFO | validation:  600/ 933 (2025-10-07_02-20-08)
2025-10-07 02:20:54,240 | INFO | validation:  700/ 933 (2025-10-07_02-20-54)
2025-10-07 02:21:40,467 | INFO | validation:  800/ 933 (2025-10-07_02-21-40)
2025-10-07 02:22:26,696 | INFO | validation:  900/ 933 (2025-10-07_02-22-26)
2025-10-07 02:22:42,712 | INFO | Confusion Matrix of Localization:
[[911503879   8855970]
 [  8827178  49134381]]
2025-10-07 02:22:42,712 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99037771 0.00962229]
 [0.15229366 0.84770634]]
2025-10-07 02:22:42,713 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41813350  1327173   539325   178893]
 [       0  1474920  2825316   399403    42332]
 [       0   559700  1013314  3795213   160703]
 [       0   150231    47118   264000  2607941]]
2025-10-07 02:22:42,713 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95336412 0.03026017 0.01229686 0.00407884]
 [0.         0.31103522 0.59581048 0.08422721 0.00892709]
 [0.         0.10123116 0.18327488 0.68642812 0.02906584]
 [0.         0.0489465  0.01535143 0.08601338 0.84968869]]
2025-10-07 02:22:42,713 | INFO | lofF1 is 84.7496, clfF1 is 74.6150, oaF1 is 77.6554, sub class F1 score is [95.1851 56.7624 72.1052 86.0826]
2025-10-07 02:22:42,714 | INFO | ---------starting train set evaluation-----------
2025-10-07 02:22:42,714 | INFO | Train buffer size: 3102.
2025-10-07 02:22:54,773 | INFO | [TrainBuf] locF1 is 85.0884, clfF1 is 69.4735, oaF1 is 74.1580, sub class F1 score is [95.05   47.4395 69.4431 86.3899]
2025-10-07 02:23:10,832 | INFO | iter is 28150 / 50000 [skipped  224] | loc. loss = 0.1794594228, classif. loss = 0.4818372130
2025-10-07 02:23:42,992 | INFO | iter is 28200 / 50000 [skipped  224] | loc. loss = 0.1788315475, classif. loss = 0.0572859123
2025-10-07 02:24:15,110 | INFO | iter is 28250 / 50000 [skipped  224] | loc. loss = 0.1398203522, classif. loss = 1.3285582066
2025-10-07 02:24:46,204 | INFO | iter is 28300 / 50000 [skipped  226] | loc. loss = 0.1216769069, classif. loss = 1.5528639555
2025-10-07 02:25:18,437 | INFO | iter is 28350 / 50000 [skipped  226] | loc. loss = 0.3387085199, classif. loss = 1.7876248360
2025-10-07 02:25:50,674 | INFO | iter is 28400 / 50000 [skipped  226] | loc. loss = 0.1310312897, classif. loss = 0.5454624295
2025-10-07 02:26:22,938 | INFO | iter is 28450 / 50000 [skipped  226] | loc. loss = 0.2221458405, classif. loss = 0.0423602462
2025-10-07 02:26:55,077 | INFO | iter is 28500 / 50000 [skipped  226] | loc. loss = 0.1696995497, classif. loss = 0.0113118971
2025-10-07 02:27:27,319 | INFO | iter is 28550 / 50000 [skipped  226] | loc. loss = 0.1256083250, classif. loss = 0.1937653571
2025-10-07 02:27:58,986 | INFO | iter is 28600 / 50000 [skipped  227] | loc. loss = 0.3228258491, classif. loss = 1.5427532196
2025-10-07 02:28:31,266 | INFO | iter is 28650 / 50000 [skipped  227] | loc. loss = 0.1855002195, classif. loss = 0.3403626382
2025-10-07 02:29:02,878 | INFO | iter is 28700 / 50000 [skipped  228] | loc. loss = 0.3677876890, classif. loss = 0.9885669351
2025-10-07 02:29:35,064 | INFO | iter is 28750 / 50000 [skipped  228] | loc. loss = 0.1693356484, classif. loss = 0.8063099384
2025-10-07 02:30:07,327 | INFO | iter is 28800 / 50000 [skipped  228] | loc. loss = 0.2564312816, classif. loss = 0.0474402606
2025-10-07 02:30:39,512 | INFO | iter is 28850 / 50000 [skipped  228] | loc. loss = 0.1281350404, classif. loss = 1.0551466942
2025-10-07 02:31:11,778 | INFO | iter is 28900 / 50000 [skipped  228] | loc. loss = 0.2367354184, classif. loss = 0.4270039797
2025-10-07 02:31:42,893 | INFO | iter is 28950 / 50000 [skipped  230] | loc. loss = 0.2142166644, classif. loss = 0.6260871291
2025-10-07 02:32:15,242 | INFO | iter is 29000 / 50000 [skipped  230] | loc. loss = 0.1274696738, classif. loss = 0.4429031610
2025-10-07 02:32:47,500 | INFO | iter is 29050 / 50000 [skipped  230] | loc. loss = 0.2569117248, classif. loss = 0.0498166308
2025-10-07 02:33:19,736 | INFO | iter is 29100 / 50000 [skipped  230] | loc. loss = 0.2916274369, classif. loss = 0.6689068079
2025-10-07 02:33:52,039 | INFO | iter is 29150 / 50000 [skipped  230] | loc. loss = 0.2486575246, classif. loss = 0.5423921943
2025-10-07 02:34:24,359 | INFO | iter is 29200 / 50000 [skipped  230] | loc. loss = 0.1991410553, classif. loss = 0.0479825512
2025-10-07 02:34:56,135 | INFO | iter is 29250 / 50000 [skipped  231] | loc. loss = 0.0831519663, classif. loss = 0.4032099545
2025-10-07 02:35:28,400 | INFO | iter is 29300 / 50000 [skipped  231] | loc. loss = 0.2965496480, classif. loss = 0.8013501763
2025-10-07 02:36:00,724 | INFO | iter is 29350 / 50000 [skipped  231] | loc. loss = 0.1416732371, classif. loss = 1.3839280605
2025-10-07 02:36:32,978 | INFO | iter is 29400 / 50000 [skipped  231] | loc. loss = 0.2209862620, classif. loss = 0.0560008064
2025-10-07 02:37:05,344 | INFO | iter is 29450 / 50000 [skipped  231] | loc. loss = 0.1675533801, classif. loss = 0.4779452682
2025-10-07 02:37:37,739 | INFO | iter is 29500 / 50000 [skipped  231] | loc. loss = 0.2776815891, classif. loss = 0.5611709356
2025-10-07 02:38:10,064 | INFO | iter is 29550 / 50000 [skipped  231] | loc. loss = 0.1988627166, classif. loss = 0.0136684347
2025-10-07 02:38:41,968 | INFO | iter is 29600 / 50000 [skipped  232] | loc. loss = 0.1098625883, classif. loss = 0.0622141734
2025-10-07 02:39:13,701 | INFO | iter is 29650 / 50000 [skipped  233] | loc. loss = 0.2605790794, classif. loss = 0.2023792565
2025-10-07 02:39:46,094 | INFO | iter is 29700 / 50000 [skipped  233] | loc. loss = 0.1738178432, classif. loss = 0.0217712224
2025-10-07 02:40:18,489 | INFO | iter is 29750 / 50000 [skipped  233] | loc. loss = 0.2345364988, classif. loss = 1.6343023777
2025-10-07 02:40:50,932 | INFO | iter is 29800 / 50000 [skipped  233] | loc. loss = 0.2386583239, classif. loss = 0.0234773755
2025-10-07 02:41:23,290 | INFO | iter is 29850 / 50000 [skipped  233] | loc. loss = 0.1779658198, classif. loss = 0.3727135360
2025-10-07 02:41:55,778 | INFO | iter is 29900 / 50000 [skipped  233] | loc. loss = 0.2204285264, classif. loss = 0.0222566091
2025-10-07 02:42:27,556 | INFO | iter is 29950 / 50000 [skipped  234] | loc. loss = 0.2552824020, classif. loss = 0.3517608345
2025-10-07 02:42:59,982 | INFO | iter is 30000 / 50000 [skipped  234] | loc. loss = 0.1355203241, classif. loss = 1.5174176693
2025-10-07 02:43:32,418 | INFO | iter is 30050 / 50000 [skipped  234] | loc. loss = 0.2435588539, classif. loss = 0.0083165355
2025-10-07 02:44:04,851 | INFO | iter is 30100 / 50000 [skipped  234] | loc. loss = 0.2003611475, classif. loss = 1.0132486820
2025-10-07 02:45:08,635 | INFO | iter is 30200 / 50000 [skipped  236] | loc. loss = 0.2727290094, classif. loss = 0.1290908754
2025-10-07 02:45:40,550 | INFO | iter is 30250 / 50000 [skipped  237] | loc. loss = 0.1948924512, classif. loss = 2.4833569527
2025-10-07 02:46:12,422 | INFO | iter is 30300 / 50000 [skipped  238] | loc. loss = 0.1522583216, classif. loss = 0.1123248041
2025-10-07 02:46:44,908 | INFO | iter is 30350 / 50000 [skipped  238] | loc. loss = 0.2031149268, classif. loss = 0.5018178225
2025-10-07 02:47:17,315 | INFO | iter is 30400 / 50000 [skipped  238] | loc. loss = 0.2317467183, classif. loss = 0.2200318575
2025-10-07 02:47:49,875 | INFO | iter is 30450 / 50000 [skipped  238] | loc. loss = 0.1625268757, classif. loss = 0.5546689630
2025-10-07 02:48:22,359 | INFO | iter is 30500 / 50000 [skipped  238] | loc. loss = 0.2584506869, classif. loss = 0.7657250166
2025-10-07 02:48:54,781 | INFO | iter is 30550 / 50000 [skipped  238] | loc. loss = 0.1883194149, classif. loss = 0.7811632156
2025-10-07 02:49:27,304 | INFO | iter is 30600 / 50000 [skipped  238] | loc. loss = 0.1387369931, classif. loss = 0.1139811426
2025-10-07 02:49:59,738 | INFO | iter is 30650 / 50000 [skipped  238] | loc. loss = 0.3230547011, classif. loss = 0.5866894722
2025-10-07 02:50:31,668 | INFO | iter is 30700 / 50000 [skipped  239] | loc. loss = 0.2412634492, classif. loss = 0.8971637487
2025-10-07 02:51:03,536 | INFO | iter is 30750 / 50000 [skipped  240] | loc. loss = 0.2632680535, classif. loss = 0.9594327211
2025-10-07 02:51:35,448 | INFO | iter is 30800 / 50000 [skipped  241] | loc. loss = 0.1393208355, classif. loss = 0.5744578838
2025-10-07 02:52:07,929 | INFO | iter is 30850 / 50000 [skipped  241] | loc. loss = 0.2044035047, classif. loss = 0.8536753654
2025-10-07 02:52:40,531 | INFO | iter is 30900 / 50000 [skipped  241] | loc. loss = 0.2328741401, classif. loss = 0.0138143692
2025-10-07 02:53:13,053 | INFO | iter is 30950 / 50000 [skipped  241] | loc. loss = 0.1675979644, classif. loss = 0.3861373663
2025-10-07 02:53:44,909 | INFO | iter is 31000 / 50000 [skipped  242] | loc. loss = 0.1741812676, classif. loss = 0.4414990544
2025-10-07 02:54:16,893 | INFO | iter is 31050 / 50000 [skipped  243] | loc. loss = 0.1553518623, classif. loss = 0.0601263493
2025-10-07 02:54:48,267 | INFO | iter is 31100 / 50000 [skipped  245] | loc. loss = 0.1999288499, classif. loss = 0.5582112074
2025-10-07 02:55:20,817 | INFO | iter is 31150 / 50000 [skipped  245] | loc. loss = 0.1687342227, classif. loss = 0.0754087120
2025-10-07 02:55:52,791 | INFO | iter is 31200 / 50000 [skipped  246] | loc. loss = 0.1425129771, classif. loss = 0.6519242525
2025-10-07 02:56:24,242 | INFO | iter is 31250 / 50000 [skipped  248] | loc. loss = 0.2444144785, classif. loss = 0.0578614995
2025-10-07 02:56:24,244 | INFO | ---------starting evaluation-----------
2025-10-07 02:56:26,451 | INFO | validation:    0/ 933 (2025-10-07_02-56-26)
2025-10-07 02:57:12,662 | INFO | validation:  100/ 933 (2025-10-07_02-57-12)
2025-10-07 02:57:58,809 | INFO | validation:  200/ 933 (2025-10-07_02-57-58)
2025-10-07 02:58:44,962 | INFO | validation:  300/ 933 (2025-10-07_02-58-44)
2025-10-07 02:59:31,130 | INFO | validation:  400/ 933 (2025-10-07_02-59-31)
2025-10-07 03:00:17,292 | INFO | validation:  500/ 933 (2025-10-07_03-00-17)
2025-10-07 03:01:03,458 | INFO | validation:  600/ 933 (2025-10-07_03-01-03)
2025-10-07 03:01:49,620 | INFO | validation:  700/ 933 (2025-10-07_03-01-49)
2025-10-07 03:02:35,793 | INFO | validation:  800/ 933 (2025-10-07_03-02-35)
2025-10-07 03:03:21,953 | INFO | validation:  900/ 933 (2025-10-07_03-03-21)
2025-10-07 03:03:38,242 | INFO | Confusion Matrix of Localization:
[[911593005   8766844]
 [  9155248  48806311]]
2025-10-07 03:03:38,242 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99047455 0.00952545]
 [0.15795379 0.84204621]]
2025-10-07 03:03:38,243 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42173238   963991   527868   193644]
 [       0  1881010  2321599   492004    47358]
 [       0   652135   636251  4058313   182231]
 [       0    67110    35891   354766  2611523]]
2025-10-07 03:03:38,243 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96156974 0.02197945 0.01203564 0.00441517]
 [0.         0.39667261 0.48958524 0.10375517 0.00998699]
 [0.         0.11794959 0.1150767  0.73401418 0.03295954]
 [0.         0.02186499 0.01169358 0.11558569 0.85085574]]
2025-10-07 03:03:38,243 | INFO | lofF1 is 84.4877, clfF1 is 73.4797, oaF1 is 76.7821, sub class F1 score is [95.1646 53.3719 74.0441 85.5669]
2025-10-07 03:03:38,245 | INFO | ---------starting train set evaluation-----------
2025-10-07 03:03:38,245 | INFO | Train buffer size: 3101.
2025-10-07 03:03:50,254 | INFO | [TrainBuf] locF1 is 85.0619, clfF1 is 70.5852, oaF1 is 74.9282, sub class F1 score is [94.8295 48.8292 71.6544 85.5549]
2025-10-07 03:04:22,292 | INFO | iter is 31300 / 50000 [skipped  248] | loc. loss = 0.2356556654, classif. loss = 1.6068466902
2025-10-07 03:04:54,445 | INFO | iter is 31350 / 50000 [skipped  248] | loc. loss = 0.1065707654, classif. loss = 0.7995200157
2025-10-07 03:05:26,005 | INFO | iter is 31400 / 50000 [skipped  249] | loc. loss = 0.2767319083, classif. loss = 0.7452899218
2025-10-07 03:05:57,540 | INFO | iter is 31450 / 50000 [skipped  250] | loc. loss = 0.2905225158, classif. loss = 0.6923213601
2025-10-07 03:06:29,796 | INFO | iter is 31500 / 50000 [skipped  250] | loc. loss = 0.1400170028, classif. loss = 0.0392561220
2025-10-07 03:07:01,926 | INFO | iter is 31550 / 50000 [skipped  250] | loc. loss = 0.1820475757, classif. loss = 1.5852154493
2025-10-07 03:07:34,186 | INFO | iter is 31600 / 50000 [skipped  250] | loc. loss = 0.1235356778, classif. loss = 0.1749753952
2025-10-07 03:08:06,321 | INFO | iter is 31650 / 50000 [skipped  250] | loc. loss = 0.1875058860, classif. loss = 0.3245857954
2025-10-07 03:08:37,865 | INFO | iter is 31700 / 50000 [skipped  251] | loc. loss = 0.1586400717, classif. loss = 0.7564597726
2025-10-07 03:09:10,132 | INFO | iter is 31750 / 50000 [skipped  251] | loc. loss = 0.1727470011, classif. loss = 0.8342995644
2025-10-07 03:09:42,297 | INFO | iter is 31800 / 50000 [skipped  251] | loc. loss = 0.2206573039, classif. loss = 1.0870904922
2025-10-07 03:10:14,613 | INFO | iter is 31850 / 50000 [skipped  251] | loc. loss = 0.1423504204, classif. loss = 0.0450505018
2025-10-07 03:10:46,295 | INFO | iter is 31900 / 50000 [skipped  252] | loc. loss = 0.1243588850, classif. loss = 0.1024800986
2025-10-07 03:11:18,567 | INFO | iter is 31950 / 50000 [skipped  252] | loc. loss = 0.2189699709, classif. loss = 0.5885623693
2025-10-07 03:11:50,803 | INFO | iter is 32000 / 50000 [skipped  252] | loc. loss = 0.1880152822, classif. loss = 0.0395984091
2025-10-07 03:12:23,033 | INFO | iter is 32050 / 50000 [skipped  252] | loc. loss = 0.1926983744, classif. loss = 0.4884253442
2025-10-07 03:12:55,368 | INFO | iter is 32100 / 50000 [skipped  252] | loc. loss = 0.2412319928, classif. loss = 1.3835585117
2025-10-07 03:13:27,567 | INFO | iter is 32150 / 50000 [skipped  252] | loc. loss = 0.2437738478, classif. loss = 0.5516914725
2025-10-07 03:13:59,885 | INFO | iter is 32200 / 50000 [skipped  252] | loc. loss = 0.1473289877, classif. loss = 0.3659355044
2025-10-07 03:14:32,108 | INFO | iter is 32250 / 50000 [skipped  252] | loc. loss = 0.1323326826, classif. loss = 0.7032219172
2025-10-07 03:15:04,386 | INFO | iter is 32300 / 50000 [skipped  252] | loc. loss = 0.1794559956, classif. loss = 0.0133492090
2025-10-07 03:15:36,759 | INFO | iter is 32350 / 50000 [skipped  252] | loc. loss = 0.1993443668, classif. loss = 0.7102403045
2025-10-07 03:16:09,097 | INFO | iter is 32400 / 50000 [skipped  252] | loc. loss = 0.2471532226, classif. loss = 0.0272449739
2025-10-07 03:16:39,724 | INFO | iter is 32450 / 50000 [skipped  255] | loc. loss = 0.2884135544, classif. loss = 0.2515387535
2025-10-07 03:17:11,531 | INFO | iter is 32500 / 50000 [skipped  256] | loc. loss = 0.1970626414, classif. loss = 4.9368071556
2025-10-07 03:17:43,922 | INFO | iter is 32550 / 50000 [skipped  256] | loc. loss = 0.4958853126, classif. loss = 0.1262510419
2025-10-07 03:18:16,213 | INFO | iter is 32600 / 50000 [skipped  256] | loc. loss = 0.2856767178, classif. loss = 1.1846385002
2025-10-07 03:18:48,549 | INFO | iter is 32650 / 50000 [skipped  256] | loc. loss = 0.2246957570, classif. loss = 1.2514727116
2025-10-07 03:19:20,384 | INFO | iter is 32700 / 50000 [skipped  257] | loc. loss = 0.1844266355, classif. loss = 0.0451853946
2025-10-07 03:19:52,764 | INFO | iter is 32750 / 50000 [skipped  257] | loc. loss = 0.2201074809, classif. loss = 0.3334239125
2025-10-07 03:20:25,173 | INFO | iter is 32800 / 50000 [skipped  257] | loc. loss = 0.2376400083, classif. loss = 0.6399883032
2025-10-07 03:20:56,992 | INFO | iter is 32850 / 50000 [skipped  258] | loc. loss = 0.2108323574, classif. loss = 0.4614185095
2025-10-07 03:21:29,343 | INFO | iter is 32900 / 50000 [skipped  258] | loc. loss = 0.1882171929, classif. loss = 0.0464414731
2025-10-07 03:22:01,815 | INFO | iter is 32950 / 50000 [skipped  258] | loc. loss = 0.0803837702, classif. loss = 0.9520741701
2025-10-07 03:22:33,589 | INFO | iter is 33000 / 50000 [skipped  259] | loc. loss = 0.2168616802, classif. loss = 1.8291621208
2025-10-07 03:23:06,056 | INFO | iter is 33050 / 50000 [skipped  259] | loc. loss = 0.2116100490, classif. loss = 0.6092184186
2025-10-07 03:23:38,457 | INFO | iter is 33100 / 50000 [skipped  259] | loc. loss = 0.2363945693, classif. loss = 0.7664268613
2025-10-07 03:24:10,241 | INFO | iter is 33150 / 50000 [skipped  260] | loc. loss = 0.2448823750, classif. loss = 0.4538807869
2025-10-07 03:24:42,667 | INFO | iter is 33200 / 50000 [skipped  260] | loc. loss = 0.1689889431, classif. loss = 1.3698873520
2025-10-07 03:25:15,069 | INFO | iter is 33250 / 50000 [skipped  260] | loc. loss = 0.0730240196, classif. loss = 0.1389345825
2025-10-07 03:25:47,583 | INFO | iter is 33300 / 50000 [skipped  260] | loc. loss = 0.1846441329, classif. loss = 1.6522972584
2025-10-07 03:26:19,996 | INFO | iter is 33350 / 50000 [skipped  260] | loc. loss = 0.1102685258, classif. loss = 0.0831809342
2025-10-07 03:26:51,893 | INFO | iter is 33400 / 50000 [skipped  261] | loc. loss = 0.1963776350, classif. loss = 0.6491744518
2025-10-07 03:27:23,718 | INFO | iter is 33450 / 50000 [skipped  262] | loc. loss = 0.1766217798, classif. loss = 0.6464704275
2025-10-07 03:27:56,087 | INFO | iter is 33500 / 50000 [skipped  262] | loc. loss = 0.2415621132, classif. loss = 0.6236752868
2025-10-07 03:28:27,912 | INFO | iter is 33550 / 50000 [skipped  263] | loc. loss = 0.1926282048, classif. loss = 0.4016402960
2025-10-07 03:29:00,326 | INFO | iter is 33600 / 50000 [skipped  263] | loc. loss = 0.2141988575, classif. loss = 0.2841834128
2025-10-07 03:29:32,849 | INFO | iter is 33650 / 50000 [skipped  263] | loc. loss = 0.1578307748, classif. loss = 0.6894706488
2025-10-07 03:30:05,332 | INFO | iter is 33700 / 50000 [skipped  263] | loc. loss = 0.1730924249, classif. loss = 0.0082417745
2025-10-07 03:30:36,609 | INFO | iter is 33750 / 50000 [skipped  265] | loc. loss = 0.1985498071, classif. loss = 1.0105704069
2025-10-07 03:31:09,147 | INFO | iter is 33800 / 50000 [skipped  265] | loc. loss = 0.3253417611, classif. loss = 0.6054763794
2025-10-07 03:32:13,581 | INFO | iter is 33900 / 50000 [skipped  266] | loc. loss = 0.0579245314, classif. loss = 0.0005722400
2025-10-07 03:32:46,033 | INFO | iter is 33950 / 50000 [skipped  266] | loc. loss = 0.1047418192, classif. loss = 0.0243090708
2025-10-07 03:33:17,920 | INFO | iter is 34000 / 50000 [skipped  267] | loc. loss = 0.2583171129, classif. loss = 1.4346363544
2025-10-07 03:33:49,843 | INFO | iter is 34050 / 50000 [skipped  268] | loc. loss = 0.2070535719, classif. loss = 0.4912249446
2025-10-07 03:34:22,333 | INFO | iter is 34100 / 50000 [skipped  268] | loc. loss = 0.1775039285, classif. loss = 1.1818535328
2025-10-07 03:34:54,320 | INFO | iter is 34150 / 50000 [skipped  269] | loc. loss = 0.2349804640, classif. loss = 0.0122938789
2025-10-07 03:35:26,235 | INFO | iter is 34200 / 50000 [skipped  270] | loc. loss = 0.2091335952, classif. loss = 0.2385654896
2025-10-07 03:35:58,682 | INFO | iter is 34250 / 50000 [skipped  270] | loc. loss = 0.1809311509, classif. loss = 1.1406390667
2025-10-07 03:36:31,287 | INFO | iter is 34300 / 50000 [skipped  270] | loc. loss = 0.2112220526, classif. loss = 1.2123422623
2025-10-07 03:37:03,777 | INFO | iter is 34350 / 50000 [skipped  270] | loc. loss = 0.2665029168, classif. loss = 0.0137475505
2025-10-07 03:37:20,013 | INFO | ---------starting evaluation-----------
2025-10-07 03:37:22,217 | INFO | validation:    0/ 933 (2025-10-07_03-37-22)
2025-10-07 03:38:08,625 | INFO | validation:  100/ 933 (2025-10-07_03-38-08)
2025-10-07 03:38:55,064 | INFO | validation:  200/ 933 (2025-10-07_03-38-55)
2025-10-07 03:39:41,468 | INFO | validation:  300/ 933 (2025-10-07_03-39-41)
2025-10-07 03:40:27,858 | INFO | validation:  400/ 933 (2025-10-07_03-40-27)
2025-10-07 03:41:14,264 | INFO | validation:  500/ 933 (2025-10-07_03-41-14)
2025-10-07 03:42:00,669 | INFO | validation:  600/ 933 (2025-10-07_03-42-00)
2025-10-07 03:42:47,053 | INFO | validation:  700/ 933 (2025-10-07_03-42-47)
2025-10-07 03:43:33,436 | INFO | validation:  800/ 933 (2025-10-07_03-43-33)
2025-10-07 03:44:19,814 | INFO | validation:  900/ 933 (2025-10-07_03-44-19)
2025-10-07 03:44:35,876 | INFO | Confusion Matrix of Localization:
[[913084287   7275562]
 [ 10218961  47742598]]
2025-10-07 03:44:35,876 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99209487 0.00790513]
 [0.17630583 0.82369417]]
2025-10-07 03:44:35,876 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40881766  1233751  1681185    62039]
 [       0  1245924  2095006  1377535    23506]
 [       0   480088   564746  4363295   120801]
 [       0   145530    50832   331228  2541700]]
2025-10-07 03:44:35,876 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.93212356 0.02813011 0.03833181 0.00141452]
 [0.         0.26274391 0.44180068 0.2904984  0.00495701]
 [0.         0.08683199 0.10214381 0.7891753  0.02184889]
 [0.         0.04741487 0.01656148 0.10791681 0.82810683]]
2025-10-07 03:44:35,876 | INFO | lofF1 is 84.5153, clfF1 is 68.9797, oaF1 is 73.6404, sub class F1 score is [94.402  48.237  65.7015 87.3836]
2025-10-07 03:44:35,878 | INFO | ---------starting train set evaluation-----------
2025-10-07 03:44:35,879 | INFO | Train buffer size: 3103.
2025-10-07 03:44:47,885 | INFO | [TrainBuf] locF1 is 85.4470, clfF1 is 72.7096, oaF1 is 76.5308, sub class F1 score is [95.5222 50.8886 75.4893 85.8597]
2025-10-07 03:45:03,957 | INFO | iter is 34400 / 50000 [skipped  270] | loc. loss = 0.1993021518, classif. loss = 0.2835712731
2025-10-07 03:45:36,073 | INFO | iter is 34450 / 50000 [skipped  270] | loc. loss = 0.1937118471, classif. loss = 0.5895301104
2025-10-07 03:46:08,178 | INFO | iter is 34500 / 50000 [skipped  270] | loc. loss = 0.1664644927, classif. loss = 0.0214507207
2025-10-07 03:46:39,737 | INFO | iter is 34550 / 50000 [skipped  271] | loc. loss = 0.2708958387, classif. loss = 1.5158025026
2025-10-07 03:47:11,910 | INFO | iter is 34600 / 50000 [skipped  271] | loc. loss = 0.2779822052, classif. loss = 0.3555222452
2025-10-07 03:47:44,089 | INFO | iter is 34650 / 50000 [skipped  271] | loc. loss = 0.2455291897, classif. loss = 2.6495397091
2025-10-07 03:48:16,270 | INFO | iter is 34700 / 50000 [skipped  271] | loc. loss = 0.1907319278, classif. loss = 0.1704934537
2025-10-07 03:48:48,421 | INFO | iter is 34750 / 50000 [skipped  271] | loc. loss = 0.1399514079, classif. loss = 1.5594639778
2025-10-07 03:49:20,656 | INFO | iter is 34800 / 50000 [skipped  271] | loc. loss = 0.2233099490, classif. loss = 0.7018976808
2025-10-07 03:49:52,853 | INFO | iter is 34850 / 50000 [skipped  271] | loc. loss = 0.1948428303, classif. loss = 0.7448579073
2025-10-07 03:50:24,487 | INFO | iter is 34900 / 50000 [skipped  272] | loc. loss = 0.1718843281, classif. loss = 0.8793274164
2025-10-07 03:50:56,149 | INFO | iter is 34950 / 50000 [skipped  273] | loc. loss = 0.1392368823, classif. loss = 0.5661815405
2025-10-07 03:51:28,419 | INFO | iter is 35000 / 50000 [skipped  273] | loc. loss = 0.1811567098, classif. loss = 0.5820996761
2025-10-07 03:52:00,057 | INFO | iter is 35050 / 50000 [skipped  274] | loc. loss = 0.2801293135, classif. loss = 2.6739819050
2025-10-07 03:52:32,301 | INFO | iter is 35100 / 50000 [skipped  274] | loc. loss = 0.1448910534, classif. loss = 1.8267856836
2025-10-07 03:53:04,571 | INFO | iter is 35150 / 50000 [skipped  274] | loc. loss = 0.2657547593, classif. loss = 0.5397423506
2025-10-07 03:53:36,837 | INFO | iter is 35200 / 50000 [skipped  274] | loc. loss = 0.1546255201, classif. loss = 0.0981664062
2025-10-07 03:54:09,065 | INFO | iter is 35250 / 50000 [skipped  274] | loc. loss = 0.3999732733, classif. loss = 0.5024957657
2025-10-07 03:54:41,311 | INFO | iter is 35300 / 50000 [skipped  274] | loc. loss = 0.2500679791, classif. loss = 0.8566203117
2025-10-07 03:55:13,574 | INFO | iter is 35350 / 50000 [skipped  274] | loc. loss = 0.3215110898, classif. loss = 0.5328776836
2025-10-07 03:55:45,870 | INFO | iter is 35400 / 50000 [skipped  274] | loc. loss = 0.2877463400, classif. loss = 3.3719933033
2025-10-07 03:56:18,147 | INFO | iter is 35450 / 50000 [skipped  274] | loc. loss = 0.1637825966, classif. loss = 1.0230305195
2025-10-07 03:56:50,369 | INFO | iter is 35500 / 50000 [skipped  274] | loc. loss = 0.1299222410, classif. loss = 0.9553170204
2025-10-07 03:57:22,107 | INFO | iter is 35550 / 50000 [skipped  275] | loc. loss = 0.1118903011, classif. loss = 1.1744590998
2025-10-07 03:57:54,465 | INFO | iter is 35600 / 50000 [skipped  275] | loc. loss = 0.2196085006, classif. loss = 1.0349335670
2025-10-07 03:58:26,733 | INFO | iter is 35650 / 50000 [skipped  275] | loc. loss = 0.1855479181, classif. loss = 0.0253323391
2025-10-07 03:58:59,043 | INFO | iter is 35700 / 50000 [skipped  275] | loc. loss = 0.2019204646, classif. loss = 2.0490088463
2025-10-07 03:59:31,388 | INFO | iter is 35750 / 50000 [skipped  275] | loc. loss = 0.1270131469, classif. loss = 0.0203967020
2025-10-07 04:00:03,761 | INFO | iter is 35800 / 50000 [skipped  275] | loc. loss = 0.3086913228, classif. loss = 0.5482549071
2025-10-07 04:00:35,521 | INFO | iter is 35850 / 50000 [skipped  276] | loc. loss = 0.3227123022, classif. loss = 0.4606967568
2025-10-07 04:01:07,867 | INFO | iter is 35900 / 50000 [skipped  276] | loc. loss = 0.1593852192, classif. loss = 0.8320722580
2025-10-07 04:01:39,578 | INFO | iter is 35950 / 50000 [skipped  277] | loc. loss = 0.2172176689, classif. loss = 0.5830928087
2025-10-07 04:02:12,002 | INFO | iter is 36000 / 50000 [skipped  277] | loc. loss = 0.2819410861, classif. loss = 1.5099910498
2025-10-07 04:02:43,812 | INFO | iter is 36050 / 50000 [skipped  278] | loc. loss = 0.1819851547, classif. loss = 0.0844923854
2025-10-07 04:03:16,168 | INFO | iter is 36100 / 50000 [skipped  278] | loc. loss = 0.2440094203, classif. loss = 0.4109897614
2025-10-07 04:03:48,548 | INFO | iter is 36150 / 50000 [skipped  278] | loc. loss = 0.1753033400, classif. loss = 0.8002939820
2025-10-07 04:04:20,963 | INFO | iter is 36200 / 50000 [skipped  278] | loc. loss = 0.0890037566, classif. loss = 0.9517068267
2025-10-07 04:04:53,412 | INFO | iter is 36250 / 50000 [skipped  278] | loc. loss = 0.2116185576, classif. loss = 0.1549522877
2025-10-07 04:05:25,780 | INFO | iter is 36300 / 50000 [skipped  278] | loc. loss = 0.1620664746, classif. loss = 0.6183488369
2025-10-07 04:05:58,145 | INFO | iter is 36350 / 50000 [skipped  278] | loc. loss = 0.1975837350, classif. loss = 0.4549579918
2025-10-07 04:06:30,634 | INFO | iter is 36400 / 50000 [skipped  278] | loc. loss = 0.1955016255, classif. loss = 0.3615677953
2025-10-07 04:07:02,999 | INFO | iter is 36450 / 50000 [skipped  278] | loc. loss = 0.1283591837, classif. loss = 0.1536090672
2025-10-07 04:07:35,392 | INFO | iter is 36500 / 50000 [skipped  278] | loc. loss = 0.0935965702, classif. loss = 0.4873369634
2025-10-07 04:08:07,193 | INFO | iter is 36550 / 50000 [skipped  279] | loc. loss = 0.2211734951, classif. loss = 1.3612486124
2025-10-07 04:08:39,683 | INFO | iter is 36600 / 50000 [skipped  279] | loc. loss = 0.1276165843, classif. loss = 0.0069373632
2025-10-07 04:09:12,091 | INFO | iter is 36650 / 50000 [skipped  279] | loc. loss = 0.1943583637, classif. loss = 0.1063534990
2025-10-07 04:09:44,504 | INFO | iter is 36700 / 50000 [skipped  279] | loc. loss = 0.2098502219, classif. loss = 0.0154628353
2025-10-07 04:10:16,967 | INFO | iter is 36750 / 50000 [skipped  279] | loc. loss = 0.2370501757, classif. loss = 1.9660720825
2025-10-07 04:10:49,428 | INFO | iter is 36800 / 50000 [skipped  279] | loc. loss = 0.2122438103, classif. loss = 1.3091641665
2025-10-07 04:11:21,938 | INFO | iter is 36850 / 50000 [skipped  279] | loc. loss = 0.2079152167, classif. loss = 0.0705396459
2025-10-07 04:11:54,384 | INFO | iter is 36900 / 50000 [skipped  279] | loc. loss = 0.2322160751, classif. loss = 0.8153594732
2025-10-07 04:12:26,798 | INFO | iter is 36950 / 50000 [skipped  279] | loc. loss = 0.1248120219, classif. loss = 0.9059199691
2025-10-07 04:12:58,644 | INFO | iter is 37000 / 50000 [skipped  280] | loc. loss = 0.2419794947, classif. loss = 0.3069006503
2025-10-07 04:13:31,246 | INFO | iter is 37050 / 50000 [skipped  280] | loc. loss = 0.1606844217, classif. loss = 0.6616973877
2025-10-07 04:14:03,742 | INFO | iter is 37100 / 50000 [skipped  280] | loc. loss = 0.1275687814, classif. loss = 0.0824170932
2025-10-07 04:14:35,737 | INFO | iter is 37150 / 50000 [skipped  281] | loc. loss = 0.2537320256, classif. loss = 0.2482920587
2025-10-07 04:15:06,488 | INFO | iter is 37200 / 50000 [skipped  284] | loc. loss = 0.0895624608, classif. loss = 0.0829161406
2025-10-07 04:15:39,089 | INFO | iter is 37250 / 50000 [skipped  284] | loc. loss = 0.0902060568, classif. loss = 0.1853993386
2025-10-07 04:16:11,658 | INFO | iter is 37300 / 50000 [skipped  284] | loc. loss = 0.1862620860, classif. loss = 0.6730530858
2025-10-07 04:16:42,987 | INFO | iter is 37350 / 50000 [skipped  286] | loc. loss = 0.2045235783, classif. loss = 0.7775692940
2025-10-07 04:17:15,473 | INFO | iter is 37400 / 50000 [skipped  286] | loc. loss = 0.1593267769, classif. loss = 0.6064594388
2025-10-07 04:17:48,067 | INFO | iter is 37450 / 50000 [skipped  286] | loc. loss = 0.1319155991, classif. loss = 1.6707515717
2025-10-07 04:18:19,913 | INFO | iter is 37500 / 50000 [skipped  287] | loc. loss = 0.1734189093, classif. loss = 0.9501653910
2025-10-07 04:18:19,914 | INFO | ---------starting evaluation-----------
2025-10-07 04:18:22,126 | INFO | validation:    0/ 933 (2025-10-07_04-18-22)
2025-10-07 04:19:08,333 | INFO | validation:  100/ 933 (2025-10-07_04-19-08)
2025-10-07 04:19:54,506 | INFO | validation:  200/ 933 (2025-10-07_04-19-54)
2025-10-07 04:20:40,650 | INFO | validation:  300/ 933 (2025-10-07_04-20-40)
2025-10-07 04:21:26,851 | INFO | validation:  400/ 933 (2025-10-07_04-21-26)
2025-10-07 04:22:13,008 | INFO | validation:  500/ 933 (2025-10-07_04-22-13)
2025-10-07 04:22:59,176 | INFO | validation:  600/ 933 (2025-10-07_04-22-59)
2025-10-07 04:23:45,356 | INFO | validation:  700/ 933 (2025-10-07_04-23-45)
2025-10-07 04:24:31,511 | INFO | validation:  800/ 933 (2025-10-07_04-24-31)
2025-10-07 04:25:17,703 | INFO | validation:  900/ 933 (2025-10-07_04-25-17)
2025-10-07 04:25:33,952 | INFO | Confusion Matrix of Localization:
[[913183385   7176464]
 [  9922629  48038930]]
2025-10-07 04:25:33,952 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99220255 0.00779745]
 [0.17119327 0.82880673]]
2025-10-07 04:25:33,952 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41128895  1649001   977523   103322]
 [       0  1018971  2495225  1162003    65772]
 [       0   388248   367254  4604562   168866]
 [       0   115051    24117   338605  2591517]]
2025-10-07 04:25:33,952 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.93775822 0.037598   0.02228799 0.00235579]
 [0.         0.21488343 0.52619997 0.24504642 0.01387018]
 [0.         0.07022118 0.06642406 0.8328125  0.03054226]
 [0.         0.03748456 0.00785752 0.1103203  0.84433762]]
2025-10-07 04:25:33,952 | INFO | lofF1 is 84.8917, clfF1 is 73.5617, oaF1 is 76.9607, sub class F1 score is [95.0848 53.7905 73.0209 86.4017]
2025-10-07 04:25:33,954 | INFO | ---------starting train set evaluation-----------
2025-10-07 04:25:33,954 | INFO | Train buffer size: 3108.
2025-10-07 04:25:45,960 | INFO | [TrainBuf] locF1 is 85.3049, clfF1 is 70.0019, oaF1 is 74.5928, sub class F1 score is [95.1416 48.108  70.9078 85.1693]
2025-10-07 04:26:18,000 | INFO | iter is 37550 / 50000 [skipped  287] | loc. loss = 0.1579823196, classif. loss = 0.3023542464
2025-10-07 04:26:50,123 | INFO | iter is 37600 / 50000 [skipped  287] | loc. loss = 0.3224188387, classif. loss = 0.7378975153
2025-10-07 04:27:22,338 | INFO | iter is 37650 / 50000 [skipped  287] | loc. loss = 0.2029476762, classif. loss = 1.0019083023
2025-10-07 04:27:54,483 | INFO | iter is 37700 / 50000 [skipped  287] | loc. loss = 0.1995311677, classif. loss = 0.7972799540
2025-10-07 04:28:26,632 | INFO | iter is 37750 / 50000 [skipped  287] | loc. loss = 0.2497854233, classif. loss = 0.8145814538
2025-10-07 04:28:58,189 | INFO | iter is 37800 / 50000 [skipped  288] | loc. loss = 0.2143682390, classif. loss = 0.6064633131
2025-10-07 04:29:30,335 | INFO | iter is 37850 / 50000 [skipped  288] | loc. loss = 0.1370659173, classif. loss = 0.6483005285
2025-10-07 04:30:02,508 | INFO | iter is 37900 / 50000 [skipped  288] | loc. loss = 0.1572406888, classif. loss = 0.6102322936
2025-10-07 04:30:34,756 | INFO | iter is 37950 / 50000 [skipped  288] | loc. loss = 0.1987470388, classif. loss = 0.0489930809
2025-10-07 04:31:07,033 | INFO | iter is 38000 / 50000 [skipped  288] | loc. loss = 0.2040372640, classif. loss = 0.5639491677
2025-10-07 04:31:39,184 | INFO | iter is 38050 / 50000 [skipped  288] | loc. loss = 0.2614189982, classif. loss = 0.4101674855
2025-10-07 04:32:11,506 | INFO | iter is 38100 / 50000 [skipped  288] | loc. loss = 0.1331210285, classif. loss = 1.7386237383
2025-10-07 04:32:42,540 | INFO | iter is 38150 / 50000 [skipped  290] | loc. loss = 0.2187347710, classif. loss = 0.8606534004
2025-10-07 04:33:14,261 | INFO | iter is 38200 / 50000 [skipped  291] | loc. loss = 0.3405916393, classif. loss = 0.7257367969
2025-10-07 04:33:46,529 | INFO | iter is 38250 / 50000 [skipped  291] | loc. loss = 0.2539317906, classif. loss = 0.2235476077
2025-10-07 04:34:18,847 | INFO | iter is 38300 / 50000 [skipped  291] | loc. loss = 0.2295997739, classif. loss = 0.6085017920
2025-10-07 04:34:51,135 | INFO | iter is 38350 / 50000 [skipped  291] | loc. loss = 0.1500508487, classif. loss = 0.5426235199
2025-10-07 04:35:23,469 | INFO | iter is 38400 / 50000 [skipped  291] | loc. loss = 0.2193747163, classif. loss = 0.8146590590
2025-10-07 04:35:55,792 | INFO | iter is 38450 / 50000 [skipped  291] | loc. loss = 0.2195316404, classif. loss = 0.6093379259
2025-10-07 04:36:28,015 | INFO | iter is 38500 / 50000 [skipped  291] | loc. loss = 0.1606866419, classif. loss = 0.8289164305
2025-10-07 04:37:00,317 | INFO | iter is 38550 / 50000 [skipped  291] | loc. loss = 0.1689811349, classif. loss = 0.7947030067
2025-10-07 04:37:31,953 | INFO | iter is 38600 / 50000 [skipped  292] | loc. loss = 0.1580520123, classif. loss = 0.7669814825
2025-10-07 04:38:04,337 | INFO | iter is 38650 / 50000 [skipped  292] | loc. loss = 0.2580471039, classif. loss = 0.5671398044
2025-10-07 04:38:36,628 | INFO | iter is 38700 / 50000 [skipped  292] | loc. loss = 0.1006058529, classif. loss = 0.4700403810
2025-10-07 04:39:08,350 | INFO | iter is 38750 / 50000 [skipped  293] | loc. loss = 0.2256944329, classif. loss = 0.8922779560
2025-10-07 04:39:40,667 | INFO | iter is 38800 / 50000 [skipped  293] | loc. loss = 0.1987328529, classif. loss = 1.0698587894
2025-10-07 04:40:12,989 | INFO | iter is 38850 / 50000 [skipped  293] | loc. loss = 0.2210160196, classif. loss = 0.6927218437
2025-10-07 04:40:45,371 | INFO | iter is 38900 / 50000 [skipped  293] | loc. loss = 0.4008964896, classif. loss = 0.0036528197
2025-10-07 04:41:17,702 | INFO | iter is 38950 / 50000 [skipped  293] | loc. loss = 0.2940374911, classif. loss = 0.1736883819
2025-10-07 04:41:50,119 | INFO | iter is 39000 / 50000 [skipped  293] | loc. loss = 0.3741866946, classif. loss = 0.9981169701
2025-10-07 04:42:22,482 | INFO | iter is 39050 / 50000 [skipped  293] | loc. loss = 0.2091027796, classif. loss = 0.6547411084
2025-10-07 04:42:54,875 | INFO | iter is 39100 / 50000 [skipped  293] | loc. loss = 0.2162352949, classif. loss = 0.4818768203
2025-10-07 04:43:27,158 | INFO | iter is 39150 / 50000 [skipped  293] | loc. loss = 0.2866277993, classif. loss = 0.0160442479
2025-10-07 04:43:59,578 | INFO | iter is 39200 / 50000 [skipped  293] | loc. loss = 0.1748497635, classif. loss = 0.7267733812
2025-10-07 04:44:31,999 | INFO | iter is 39250 / 50000 [skipped  293] | loc. loss = 0.1215598732, classif. loss = 0.2546654940
2025-10-07 04:45:03,812 | INFO | iter is 39300 / 50000 [skipped  294] | loc. loss = 0.1925188601, classif. loss = 0.0558315516
2025-10-07 04:45:35,690 | INFO | iter is 39350 / 50000 [skipped  295] | loc. loss = 0.1517140567, classif. loss = 0.0586243160
2025-10-07 04:46:08,065 | INFO | iter is 39400 / 50000 [skipped  295] | loc. loss = 0.1604335606, classif. loss = 0.0391781107
2025-10-07 04:46:40,498 | INFO | iter is 39450 / 50000 [skipped  295] | loc. loss = 0.3347223997, classif. loss = 0.3677356839
2025-10-07 04:47:12,879 | INFO | iter is 39500 / 50000 [skipped  295] | loc. loss = 0.2312751263, classif. loss = 0.1573117971
2025-10-07 04:47:45,304 | INFO | iter is 39550 / 50000 [skipped  295] | loc. loss = 0.2660597563, classif. loss = 0.5703123808
2025-10-07 04:48:17,134 | INFO | iter is 39600 / 50000 [skipped  296] | loc. loss = 0.2195492238, classif. loss = 0.6684082747
2025-10-07 04:48:49,597 | INFO | iter is 39650 / 50000 [skipped  296] | loc. loss = 0.2398813963, classif. loss = 0.7056006789
2025-10-07 04:49:21,429 | INFO | iter is 39700 / 50000 [skipped  297] | loc. loss = 0.1120274290, classif. loss = 0.5082119703
2025-10-07 04:49:53,901 | INFO | iter is 39750 / 50000 [skipped  297] | loc. loss = 0.1415244490, classif. loss = 0.0453031212
2025-10-07 04:50:26,435 | INFO | iter is 39800 / 50000 [skipped  297] | loc. loss = 0.2618343532, classif. loss = 0.0822988302
2025-10-07 04:50:58,872 | INFO | iter is 39850 / 50000 [skipped  297] | loc. loss = 0.2692352831, classif. loss = 0.9947882891
2025-10-07 04:51:31,389 | INFO | iter is 39900 / 50000 [skipped  297] | loc. loss = 0.1842270195, classif. loss = 0.1312798858
2025-10-07 04:52:03,783 | INFO | iter is 39950 / 50000 [skipped  297] | loc. loss = 0.2502829731, classif. loss = 0.6776843667
2025-10-07 04:52:36,345 | INFO | iter is 40000 / 50000 [skipped  297] | loc. loss = 0.1281474382, classif. loss = 0.8091758490
2025-10-07 04:53:08,757 | INFO | iter is 40050 / 50000 [skipped  297] | loc. loss = 0.2261299491, classif. loss = 0.1380127370
2025-10-07 04:53:40,684 | INFO | iter is 40100 / 50000 [skipped  298] | loc. loss = 0.2696383297, classif. loss = 0.5277478099
2025-10-07 04:54:13,207 | INFO | iter is 40150 / 50000 [skipped  298] | loc. loss = 0.2085464001, classif. loss = 1.2244290113
2025-10-07 04:54:45,744 | INFO | iter is 40200 / 50000 [skipped  298] | loc. loss = 0.2493005544, classif. loss = 0.9185352325
2025-10-07 04:55:18,240 | INFO | iter is 40250 / 50000 [skipped  298] | loc. loss = 0.2177620530, classif. loss = 0.1550475955
2025-10-07 04:55:50,689 | INFO | iter is 40300 / 50000 [skipped  298] | loc. loss = 0.1646015048, classif. loss = 0.0164574496
2025-10-07 04:56:23,284 | INFO | iter is 40350 / 50000 [skipped  298] | loc. loss = 0.2774738073, classif. loss = 0.2596262693
2025-10-07 04:56:55,186 | INFO | iter is 40400 / 50000 [skipped  299] | loc. loss = 0.1358490139, classif. loss = 0.1160207242
2025-10-07 04:57:27,804 | INFO | iter is 40450 / 50000 [skipped  299] | loc. loss = 0.1437291205, classif. loss = 0.0425992608
2025-10-07 04:58:00,326 | INFO | iter is 40500 / 50000 [skipped  299] | loc. loss = 0.2689849138, classif. loss = 0.6232662201
2025-10-07 04:58:32,390 | INFO | iter is 40550 / 50000 [skipped  300] | loc. loss = 0.2933118939, classif. loss = 0.4872273505
2025-10-07 04:59:04,870 | INFO | iter is 40600 / 50000 [skipped  300] | loc. loss = 0.2432756126, classif. loss = 1.0425547361
2025-10-07 04:59:21,211 | INFO | ---------starting evaluation-----------
2025-10-07 04:59:23,432 | INFO | validation:    0/ 933 (2025-10-07_04-59-23)
2025-10-07 05:00:09,768 | INFO | validation:  100/ 933 (2025-10-07_05-00-09)
2025-10-07 05:00:56,012 | INFO | validation:  200/ 933 (2025-10-07_05-00-56)
2025-10-07 05:01:42,238 | INFO | validation:  300/ 933 (2025-10-07_05-01-42)
2025-10-07 05:02:28,477 | INFO | validation:  400/ 933 (2025-10-07_05-02-28)
2025-10-07 05:03:14,748 | INFO | validation:  500/ 933 (2025-10-07_05-03-14)
2025-10-07 05:04:01,030 | INFO | validation:  600/ 933 (2025-10-07_05-04-01)
2025-10-07 05:04:47,295 | INFO | validation:  700/ 933 (2025-10-07_05-04-47)
2025-10-07 05:05:33,573 | INFO | validation:  800/ 933 (2025-10-07_05-05-33)
2025-10-07 05:06:19,853 | INFO | validation:  900/ 933 (2025-10-07_05-06-19)
2025-10-07 05:06:35,819 | INFO | Confusion Matrix of Localization:
[[911675372   8684477]
 [  8918479  49043080]]
2025-10-07 05:06:35,820 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99056404 0.00943596]
 [0.15386886 0.84613114]]
2025-10-07 05:06:35,820 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40428828  1603764  1695074   131075]
 [       0   965731  2400078  1344394    31768]
 [       0   349251   415912  4607730   156037]
 [       0    95958    40790   320781  2611761]]
2025-10-07 05:06:35,820 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.92179636 0.03656658 0.03864849 0.00298857]
 [0.         0.20365603 0.50613511 0.28350954 0.00669932]
 [0.         0.06316792 0.07522468 0.83338548 0.02822192]
 [0.         0.03126391 0.01328972 0.1045131  0.85093328]]
2025-10-07 05:06:35,820 | INFO | lofF1 is 84.7843, clfF1 is 71.5534, oaF1 is 75.5227, sub class F1 score is [94.3513 52.1613 68.2783 87.0597]
2025-10-07 05:06:35,822 | INFO | ---------starting train set evaluation-----------
2025-10-07 05:06:35,822 | INFO | Train buffer size: 3112.
2025-10-07 05:06:47,864 | INFO | [TrainBuf] locF1 is 85.5723, clfF1 is 72.0760, oaF1 is 76.1249, sub class F1 score is [95.4741 49.9759 74.2297 86.6432]
2025-10-07 05:07:03,944 | INFO | iter is 40650 / 50000 [skipped  300] | loc. loss = 0.3366334736, classif. loss = 0.3451114595
2025-10-07 05:07:35,978 | INFO | iter is 40700 / 50000 [skipped  300] | loc. loss = 0.2009447813, classif. loss = 0.5896326303
2025-10-07 05:08:08,145 | INFO | iter is 40750 / 50000 [skipped  300] | loc. loss = 0.1492677182, classif. loss = 0.8848508596
2025-10-07 05:08:39,702 | INFO | iter is 40800 / 50000 [skipped  301] | loc. loss = 0.2101182044, classif. loss = 0.0266576782
2025-10-07 05:09:11,953 | INFO | iter is 40850 / 50000 [skipped  301] | loc. loss = 0.1908106208, classif. loss = 1.0952266455
2025-10-07 05:09:43,524 | INFO | iter is 40900 / 50000 [skipped  302] | loc. loss = 0.1871505380, classif. loss = 1.4569511414
2025-10-07 05:10:15,698 | INFO | iter is 40950 / 50000 [skipped  302] | loc. loss = 0.1961972117, classif. loss = 0.6706200242
2025-10-07 05:10:47,933 | INFO | iter is 41000 / 50000 [skipped  302] | loc. loss = 0.2490746379, classif. loss = 0.4554448724
2025-10-07 05:11:19,535 | INFO | iter is 41050 / 50000 [skipped  303] | loc. loss = 0.1414749026, classif. loss = 0.0497646928
2025-10-07 05:11:51,191 | INFO | iter is 41100 / 50000 [skipped  304] | loc. loss = 0.2678121328, classif. loss = 1.3938267231
2025-10-07 05:12:23,407 | INFO | iter is 41150 / 50000 [skipped  304] | loc. loss = 0.2560710013, classif. loss = 0.1338327974
2025-10-07 05:12:55,693 | INFO | iter is 41200 / 50000 [skipped  304] | loc. loss = 0.2953794599, classif. loss = 0.3849439621
2025-10-07 05:13:27,911 | INFO | iter is 41250 / 50000 [skipped  304] | loc. loss = 0.4345933795, classif. loss = 1.3467605114
2025-10-07 05:14:00,081 | INFO | iter is 41300 / 50000 [skipped  304] | loc. loss = 0.2434181720, classif. loss = 0.3071954250
2025-10-07 05:14:32,284 | INFO | iter is 41350 / 50000 [skipped  304] | loc. loss = 0.1842834055, classif. loss = 0.2376797795
2025-10-07 05:15:04,526 | INFO | iter is 41400 / 50000 [skipped  304] | loc. loss = 0.1781060100, classif. loss = 0.0317783281
2025-10-07 05:15:36,829 | INFO | iter is 41450 / 50000 [skipped  304] | loc. loss = 0.1651285142, classif. loss = 0.1044101268
2025-10-07 05:16:09,173 | INFO | iter is 41500 / 50000 [skipped  304] | loc. loss = 0.2102721334, classif. loss = 1.0699254274
2025-10-07 05:16:40,299 | INFO | iter is 41550 / 50000 [skipped  306] | loc. loss = 0.2383754551, classif. loss = 0.4106980264
2025-10-07 05:17:12,678 | INFO | iter is 41600 / 50000 [skipped  306] | loc. loss = 0.1707680821, classif. loss = 1.0088598728
2025-10-07 05:17:43,767 | INFO | iter is 41650 / 50000 [skipped  308] | loc. loss = 0.1975687742, classif. loss = 0.0431183577
2025-10-07 05:18:16,112 | INFO | iter is 41700 / 50000 [skipped  308] | loc. loss = 0.1298713088, classif. loss = 0.4687922895
2025-10-07 05:18:48,312 | INFO | iter is 41750 / 50000 [skipped  308] | loc. loss = 0.1170905977, classif. loss = 0.0407027416
2025-10-07 05:19:19,996 | INFO | iter is 41800 / 50000 [skipped  309] | loc. loss = 0.1860873997, classif. loss = 0.1043191850
2025-10-07 05:19:52,416 | INFO | iter is 41850 / 50000 [skipped  309] | loc. loss = 0.1575104445, classif. loss = 0.6641398072
2025-10-07 05:20:56,531 | INFO | iter is 41950 / 50000 [skipped  310] | loc. loss = 0.1540614963, classif. loss = 0.3896496296
2025-10-07 05:21:28,833 | INFO | iter is 42000 / 50000 [skipped  310] | loc. loss = 0.1586081982, classif. loss = 0.1246124953
2025-10-07 05:22:00,620 | INFO | iter is 42050 / 50000 [skipped  311] | loc. loss = 0.2121402025, classif. loss = 2.1196074486
2025-10-07 05:22:32,383 | INFO | iter is 42100 / 50000 [skipped  312] | loc. loss = 0.2151122987, classif. loss = 0.0257836375
2025-10-07 05:23:04,725 | INFO | iter is 42150 / 50000 [skipped  312] | loc. loss = 0.2189719677, classif. loss = 1.0156968832
2025-10-07 05:23:36,573 | INFO | iter is 42200 / 50000 [skipped  313] | loc. loss = 0.2519422472, classif. loss = 0.4740511179
2025-10-07 05:24:08,859 | INFO | iter is 42250 / 50000 [skipped  313] | loc. loss = 0.2024673074, classif. loss = 0.7725697756
2025-10-07 05:24:40,699 | INFO | iter is 42300 / 50000 [skipped  314] | loc. loss = 0.2075382024, classif. loss = 0.1584288776
2025-10-07 05:25:13,082 | INFO | iter is 42350 / 50000 [skipped  314] | loc. loss = 0.2109348178, classif. loss = 3.1066644192
2025-10-07 05:25:45,003 | INFO | iter is 42400 / 50000 [skipped  315] | loc. loss = 0.2083985806, classif. loss = 0.4587188959
2025-10-07 05:26:15,688 | INFO | iter is 42450 / 50000 [skipped  318] | loc. loss = 0.0700651109, classif. loss = 2.7748131752
2025-10-07 05:26:46,900 | INFO | iter is 42500 / 50000 [skipped  320] | loc. loss = 0.1898199171, classif. loss = 0.0595241487
2025-10-07 05:27:19,320 | INFO | iter is 42550 / 50000 [skipped  320] | loc. loss = 0.1878909618, classif. loss = 1.4203889370
2025-10-07 05:27:51,169 | INFO | iter is 42600 / 50000 [skipped  321] | loc. loss = 0.0678645968, classif. loss = 1.0177441835
2025-10-07 05:28:23,161 | INFO | iter is 42650 / 50000 [skipped  322] | loc. loss = 0.1631110609, classif. loss = 0.8724701405
2025-10-07 05:28:54,936 | INFO | iter is 42700 / 50000 [skipped  323] | loc. loss = 0.3132652342, classif. loss = 1.0718032122
2025-10-07 05:29:27,387 | INFO | iter is 42750 / 50000 [skipped  323] | loc. loss = 0.1667341292, classif. loss = 1.3408293724
2025-10-07 05:29:59,828 | INFO | iter is 42800 / 50000 [skipped  323] | loc. loss = 0.1862572283, classif. loss = 0.5329751968
2025-10-07 05:30:31,790 | INFO | iter is 42850 / 50000 [skipped  324] | loc. loss = 0.1769801080, classif. loss = 0.5226638913
2025-10-07 05:31:03,682 | INFO | iter is 42900 / 50000 [skipped  325] | loc. loss = 0.3619739413, classif. loss = 1.4624434710
2025-10-07 05:31:36,164 | INFO | iter is 42950 / 50000 [skipped  325] | loc. loss = 0.2121931463, classif. loss = 0.0230250452
2025-10-07 05:32:08,678 | INFO | iter is 43000 / 50000 [skipped  325] | loc. loss = 0.1024071053, classif. loss = 2.9670181274
2025-10-07 05:32:41,130 | INFO | iter is 43050 / 50000 [skipped  325] | loc. loss = 0.2179763913, classif. loss = 0.2959632277
2025-10-07 05:33:13,614 | INFO | iter is 43100 / 50000 [skipped  325] | loc. loss = 0.1683951616, classif. loss = 0.5234686732
2025-10-07 05:33:46,110 | INFO | iter is 43150 / 50000 [skipped  325] | loc. loss = 0.7610093355, classif. loss = 0.7992228270
2025-10-07 05:34:18,086 | INFO | iter is 43200 / 50000 [skipped  326] | loc. loss = 0.1661874801, classif. loss = 0.6111431122
2025-10-07 05:34:50,582 | INFO | iter is 43250 / 50000 [skipped  326] | loc. loss = 0.1443994492, classif. loss = 0.5032432079
2025-10-07 05:35:22,603 | INFO | iter is 43300 / 50000 [skipped  327] | loc. loss = 0.2830985188, classif. loss = 0.7695919275
2025-10-07 05:35:54,545 | INFO | iter is 43350 / 50000 [skipped  328] | loc. loss = 0.1705489308, classif. loss = 0.0181404445
2025-10-07 05:36:26,499 | INFO | iter is 43400 / 50000 [skipped  329] | loc. loss = 0.1462042332, classif. loss = 1.3659228086
2025-10-07 05:36:58,412 | INFO | iter is 43450 / 50000 [skipped  330] | loc. loss = 0.2039417326, classif. loss = 0.7749142647
2025-10-07 05:37:30,414 | INFO | iter is 43500 / 50000 [skipped  331] | loc. loss = 0.2029967010, classif. loss = 1.1120727062
2025-10-07 05:38:03,007 | INFO | iter is 43550 / 50000 [skipped  331] | loc. loss = 0.2249180079, classif. loss = 0.6382488012
2025-10-07 05:38:35,594 | INFO | iter is 43600 / 50000 [skipped  331] | loc. loss = 0.3833756745, classif. loss = 1.1817765236
2025-10-07 05:39:07,039 | INFO | iter is 43650 / 50000 [skipped  333] | loc. loss = 0.1364455521, classif. loss = 1.2848937511
2025-10-07 05:39:39,597 | INFO | iter is 43700 / 50000 [skipped  333] | loc. loss = 0.1754741520, classif. loss = 0.0982889086
2025-10-07 05:40:12,240 | INFO | iter is 43750 / 50000 [skipped  333] | loc. loss = 0.1278353035, classif. loss = 0.0028655068
2025-10-07 05:40:12,242 | INFO | ---------starting evaluation-----------
2025-10-07 05:40:14,458 | INFO | validation:    0/ 933 (2025-10-07_05-40-14)
2025-10-07 05:41:00,637 | INFO | validation:  100/ 933 (2025-10-07_05-41-00)
2025-10-07 05:41:46,709 | INFO | validation:  200/ 933 (2025-10-07_05-41-46)
2025-10-07 05:42:32,770 | INFO | validation:  300/ 933 (2025-10-07_05-42-32)
2025-10-07 05:43:18,844 | INFO | validation:  400/ 933 (2025-10-07_05-43-18)
2025-10-07 05:44:04,913 | INFO | validation:  500/ 933 (2025-10-07_05-44-04)
2025-10-07 05:44:50,989 | INFO | validation:  600/ 933 (2025-10-07_05-44-50)
2025-10-07 05:45:37,056 | INFO | validation:  700/ 933 (2025-10-07_05-45-37)
2025-10-07 05:46:23,150 | INFO | validation:  800/ 933 (2025-10-07_05-46-23)
2025-10-07 05:47:09,258 | INFO | validation:  900/ 933 (2025-10-07_05-47-09)
2025-10-07 05:47:25,527 | INFO | Confusion Matrix of Localization:
[[912844947   7514902]
 [  9488188  48473371]]
2025-10-07 05:47:25,527 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99183482 0.00816518]
 [0.16369794 0.83630206]]
2025-10-07 05:47:25,527 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41290955  1474179   984906   108701]
 [       0  1189056  2432290  1090612    30013]
 [       0   420035   410866  4610282    87747]
 [       0    94051    29055   421145  2525039]]
2025-10-07 05:47:25,527 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.94145327 0.03361198 0.02245632 0.00247843]
 [0.         0.25075143 0.51292806 0.22999128 0.00632922]
 [0.         0.0759704  0.07431203 0.83384706 0.01587052]
 [0.         0.03064259 0.00946636 0.13721251 0.82267853]]
2025-10-07 05:47:25,527 | INFO | lofF1 is 85.0784, clfF1 is 73.4888, oaF1 is 76.9657, sub class F1 score is [95.0826 53.5254 72.9713 86.7593]
2025-10-07 05:47:25,529 | INFO | ---------starting train set evaluation-----------
2025-10-07 05:47:25,529 | INFO | Train buffer size: 3092.
2025-10-07 05:47:37,516 | INFO | [TrainBuf] locF1 is 85.5240, clfF1 is 72.8159, oaF1 is 76.6283, sub class F1 score is [95.6772 52.484  72.5642 85.8597]
2025-10-07 05:48:09,118 | INFO | iter is 43800 / 50000 [skipped  334] | loc. loss = 0.1292178035, classif. loss = 0.0125255845
2025-10-07 05:48:41,224 | INFO | iter is 43850 / 50000 [skipped  334] | loc. loss = 0.2397151887, classif. loss = 0.8269680738
2025-10-07 05:49:13,480 | INFO | iter is 43900 / 50000 [skipped  334] | loc. loss = 0.0934604928, classif. loss = 0.2073958218
2025-10-07 05:49:45,057 | INFO | iter is 43950 / 50000 [skipped  335] | loc. loss = 0.1683155894, classif. loss = 0.1359206587
2025-10-07 05:50:17,293 | INFO | iter is 44000 / 50000 [skipped  335] | loc. loss = 0.4134739339, classif. loss = 0.2148276567
2025-10-07 05:50:48,848 | INFO | iter is 44050 / 50000 [skipped  336] | loc. loss = 0.1192074120, classif. loss = 0.2777656019
2025-10-07 05:51:21,094 | INFO | iter is 44100 / 50000 [skipped  336] | loc. loss = 0.2321027964, classif. loss = 0.3220993280
2025-10-07 05:51:53,282 | INFO | iter is 44150 / 50000 [skipped  336] | loc. loss = 0.2488204390, classif. loss = 0.3423231244
2025-10-07 05:52:25,442 | INFO | iter is 44200 / 50000 [skipped  336] | loc. loss = 0.1920660436, classif. loss = 1.2135491371
2025-10-07 05:52:57,099 | INFO | iter is 44250 / 50000 [skipped  337] | loc. loss = 0.1110195518, classif. loss = 0.6220300794
2025-10-07 05:53:29,358 | INFO | iter is 44300 / 50000 [skipped  337] | loc. loss = 0.1960667074, classif. loss = 0.1641466469
2025-10-07 05:54:01,015 | INFO | iter is 44350 / 50000 [skipped  338] | loc. loss = 0.2209384590, classif. loss = 0.1001098305
2025-10-07 05:54:32,104 | INFO | iter is 44400 / 50000 [skipped  340] | loc. loss = 0.1396674663, classif. loss = 0.0505559295
2025-10-07 05:55:04,397 | INFO | iter is 44450 / 50000 [skipped  340] | loc. loss = 0.2109017819, classif. loss = 0.1116283908
2025-10-07 05:55:36,076 | INFO | iter is 44500 / 50000 [skipped  341] | loc. loss = 0.2793323100, classif. loss = 1.2162564993
2025-10-07 05:56:07,775 | INFO | iter is 44550 / 50000 [skipped  342] | loc. loss = 0.1278098226, classif. loss = 2.0337407589
2025-10-07 05:56:39,460 | INFO | iter is 44600 / 50000 [skipped  343] | loc. loss = 0.2954655886, classif. loss = 0.1085797995
2025-10-07 05:57:11,758 | INFO | iter is 44650 / 50000 [skipped  343] | loc. loss = 0.2446122617, classif. loss = 0.7445269823
2025-10-07 05:57:42,853 | INFO | iter is 44700 / 50000 [skipped  345] | loc. loss = 0.2450617403, classif. loss = 0.3655838966
2025-10-07 05:58:15,105 | INFO | iter is 44750 / 50000 [skipped  345] | loc. loss = 0.2022797763, classif. loss = 0.2601296008
2025-10-07 05:58:47,430 | INFO | iter is 44800 / 50000 [skipped  345] | loc. loss = 0.1917854697, classif. loss = 0.0126211215
2025-10-07 05:59:19,208 | INFO | iter is 44850 / 50000 [skipped  346] | loc. loss = 0.1851973534, classif. loss = 0.1362915784
2025-10-07 05:59:51,551 | INFO | iter is 44900 / 50000 [skipped  346] | loc. loss = 0.1786475480, classif. loss = 1.0038983822
2025-10-07 06:00:23,929 | INFO | iter is 44950 / 50000 [skipped  346] | loc. loss = 0.1461840719, classif. loss = 1.7067122459
2025-10-07 06:00:55,635 | INFO | iter is 45000 / 50000 [skipped  347] | loc. loss = 0.2801600397, classif. loss = 0.7372418642
2025-10-07 06:01:27,317 | INFO | iter is 45050 / 50000 [skipped  348] | loc. loss = 0.2051611692, classif. loss = 0.3393028378
2025-10-07 06:01:59,094 | INFO | iter is 45100 / 50000 [skipped  349] | loc. loss = 0.1463846117, classif. loss = 0.0851682276
2025-10-07 06:02:31,481 | INFO | iter is 45150 / 50000 [skipped  349] | loc. loss = 0.2281088084, classif. loss = 1.2707059383
2025-10-07 06:03:03,871 | INFO | iter is 45200 / 50000 [skipped  349] | loc. loss = 0.2927101552, classif. loss = 0.4910043776
2025-10-07 06:03:36,198 | INFO | iter is 45250 / 50000 [skipped  349] | loc. loss = 0.1583968103, classif. loss = 1.1978657246
2025-10-07 06:04:08,677 | INFO | iter is 45300 / 50000 [skipped  349] | loc. loss = 0.2939963639, classif. loss = 0.3351150751
2025-10-07 06:04:40,996 | INFO | iter is 45350 / 50000 [skipped  349] | loc. loss = 0.3493284285, classif. loss = 0.2313738763
2025-10-07 06:05:13,431 | INFO | iter is 45400 / 50000 [skipped  349] | loc. loss = 0.1440556347, classif. loss = 1.0301964283
2025-10-07 06:05:45,889 | INFO | iter is 45450 / 50000 [skipped  349] | loc. loss = 0.2266442776, classif. loss = 0.1554885507
2025-10-07 06:06:18,312 | INFO | iter is 45500 / 50000 [skipped  349] | loc. loss = 0.1763295680, classif. loss = 0.3745688498
2025-10-07 06:06:50,151 | INFO | iter is 45550 / 50000 [skipped  350] | loc. loss = 0.2336246371, classif. loss = 0.8406859636
2025-10-07 06:07:21,870 | INFO | iter is 45600 / 50000 [skipped  351] | loc. loss = 0.2311364412, classif. loss = 0.2452871650
2025-10-07 06:07:54,348 | INFO | iter is 45650 / 50000 [skipped  351] | loc. loss = 0.1584411412, classif. loss = 0.8149852753
2025-10-07 06:08:26,674 | INFO | iter is 45700 / 50000 [skipped  351] | loc. loss = 0.1258049011, classif. loss = 0.0958382264
2025-10-07 06:08:58,501 | INFO | iter is 45750 / 50000 [skipped  352] | loc. loss = 0.1776271611, classif. loss = 0.1320337206
2025-10-07 06:09:30,982 | INFO | iter is 45800 / 50000 [skipped  352] | loc. loss = 0.2353662550, classif. loss = 0.2438021600
2025-10-07 06:10:03,396 | INFO | iter is 45850 / 50000 [skipped  352] | loc. loss = 0.0887434110, classif. loss = 1.0130461454
2025-10-07 06:10:35,307 | INFO | iter is 45900 / 50000 [skipped  353] | loc. loss = 0.2381601781, classif. loss = 0.7089955807
2025-10-07 06:11:07,110 | INFO | iter is 45950 / 50000 [skipped  354] | loc. loss = 0.1616930366, classif. loss = 1.8876481056
2025-10-07 06:11:39,568 | INFO | iter is 46000 / 50000 [skipped  354] | loc. loss = 0.2924837768, classif. loss = 0.3108494580
2025-10-07 06:12:12,096 | INFO | iter is 46050 / 50000 [skipped  354] | loc. loss = 0.2551614642, classif. loss = 0.2573526204
2025-10-07 06:12:44,524 | INFO | iter is 46100 / 50000 [skipped  354] | loc. loss = 0.2470930666, classif. loss = 0.6523064375
2025-10-07 06:13:17,067 | INFO | iter is 46150 / 50000 [skipped  354] | loc. loss = 0.1612990797, classif. loss = 0.2195770741
2025-10-07 06:13:48,967 | INFO | iter is 46200 / 50000 [skipped  355] | loc. loss = 0.1636545807, classif. loss = 0.4444529116
2025-10-07 06:14:20,927 | INFO | iter is 46250 / 50000 [skipped  356] | loc. loss = 0.3209393322, classif. loss = 0.2189809829
2025-10-07 06:14:53,396 | INFO | iter is 46300 / 50000 [skipped  356] | loc. loss = 0.4385187626, classif. loss = 0.9106959105
2025-10-07 06:15:25,281 | INFO | iter is 46350 / 50000 [skipped  357] | loc. loss = 0.0938236713, classif. loss = 0.9185179472
2025-10-07 06:15:57,793 | INFO | iter is 46400 / 50000 [skipped  357] | loc. loss = 0.1618777066, classif. loss = 0.4605576396
2025-10-07 06:16:30,299 | INFO | iter is 46450 / 50000 [skipped  357] | loc. loss = 0.1232657060, classif. loss = 0.0162449554
2025-10-07 06:17:02,875 | INFO | iter is 46500 / 50000 [skipped  357] | loc. loss = 0.2409241945, classif. loss = 1.0135867596
2025-10-07 06:17:35,356 | INFO | iter is 46550 / 50000 [skipped  357] | loc. loss = 0.2416103631, classif. loss = 0.1874257475
2025-10-07 06:18:07,938 | INFO | iter is 46600 / 50000 [skipped  357] | loc. loss = 0.2124219090, classif. loss = 0.3986157179
2025-10-07 06:18:39,374 | INFO | iter is 46650 / 50000 [skipped  359] | loc. loss = 0.2056434005, classif. loss = 0.3028731942
2025-10-07 06:19:11,932 | INFO | iter is 46700 / 50000 [skipped  359] | loc. loss = 0.1444627643, classif. loss = 0.3099375367
2025-10-07 06:19:44,537 | INFO | iter is 46750 / 50000 [skipped  359] | loc. loss = 0.1417557448, classif. loss = 0.7938067913
2025-10-07 06:20:16,487 | INFO | iter is 46800 / 50000 [skipped  360] | loc. loss = 0.1516973972, classif. loss = 1.7944617271
2025-10-07 06:20:48,981 | INFO | iter is 46850 / 50000 [skipped  360] | loc. loss = 0.2883899212, classif. loss = 0.9122825861
2025-10-07 06:21:05,359 | INFO | ---------starting evaluation-----------
2025-10-07 06:21:07,577 | INFO | validation:    0/ 933 (2025-10-07_06-21-07)
2025-10-07 06:21:53,936 | INFO | validation:  100/ 933 (2025-10-07_06-21-53)
2025-10-07 06:22:40,232 | INFO | validation:  200/ 933 (2025-10-07_06-22-40)
2025-10-07 06:23:26,567 | INFO | validation:  300/ 933 (2025-10-07_06-23-26)
2025-10-07 06:24:12,894 | INFO | validation:  400/ 933 (2025-10-07_06-24-12)
2025-10-07 06:24:59,190 | INFO | validation:  500/ 933 (2025-10-07_06-24-59)
2025-10-07 06:25:45,488 | INFO | validation:  600/ 933 (2025-10-07_06-25-45)
2025-10-07 06:26:31,803 | INFO | validation:  700/ 933 (2025-10-07_06-26-31)
2025-10-07 06:27:18,108 | INFO | validation:  800/ 933 (2025-10-07_06-27-18)
2025-10-07 06:28:04,411 | INFO | validation:  900/ 933 (2025-10-07_06-28-04)
2025-10-07 06:28:20,641 | INFO | Confusion Matrix of Localization:
[[910020163  10339686]
 [  7620201  50341358]]
2025-10-07 06:28:20,642 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98876561 0.01123439]
 [0.13146991 0.86853009]]
2025-10-07 06:28:20,642 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41467356  1533027   765468    92890]
 [       0  1142379  2812163   749613    37816]
 [       0   508979   655749  4266130    98072]
 [       0   111294    61635   374852  2521509]]
2025-10-07 06:28:20,642 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.94547529 0.03495374 0.01745303 0.00211794]
 [0.         0.24090805 0.59303674 0.15808047 0.00797474]
 [0.         0.09205741 0.11860324 0.77160138 0.01773797]
 [0.         0.0362605  0.02008119 0.12212987 0.82152843]]
2025-10-07 06:28:20,642 | INFO | lofF1 is 84.8622, clfF1 is 75.2329, oaF1 is 78.1217, sub class F1 score is [95.2301 57.3645 73.019  86.6561]
2025-10-07 06:28:20,895 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-06_20-14-57_MambaBDA_Base_xBD/model_step46875.pth
2025-10-07 06:28:20,895 | INFO | ---------starting train set evaluation-----------
2025-10-07 06:28:20,896 | INFO | Train buffer size: 3098.
2025-10-07 06:28:32,871 | INFO | [TrainBuf] locF1 is 85.5508, clfF1 is 71.7328, oaF1 is 75.8782, sub class F1 score is [95.3466 50.3902 72.44   86.0228]
2025-10-07 06:28:48,951 | INFO | iter is 46900 / 50000 [skipped  360] | loc. loss = 0.1703708768, classif. loss = 1.4867310524
2025-10-07 06:29:20,533 | INFO | iter is 46950 / 50000 [skipped  361] | loc. loss = 0.1852560788, classif. loss = 0.4174830914
2025-10-07 06:29:52,733 | INFO | iter is 47000 / 50000 [skipped  361] | loc. loss = 0.1359049231, classif. loss = 0.5417524576
2025-10-07 06:30:24,260 | INFO | iter is 47050 / 50000 [skipped  362] | loc. loss = 0.2249761522, classif. loss = 0.6069264412
2025-10-07 06:30:56,524 | INFO | iter is 47100 / 50000 [skipped  362] | loc. loss = 0.1002547741, classif. loss = 0.0308483876
2025-10-07 06:31:28,090 | INFO | iter is 47150 / 50000 [skipped  363] | loc. loss = 0.3668373227, classif. loss = 0.1206744462
2025-10-07 06:32:00,265 | INFO | iter is 47200 / 50000 [skipped  363] | loc. loss = 0.2633053660, classif. loss = 1.0602731705
2025-10-07 06:32:32,524 | INFO | iter is 47250 / 50000 [skipped  363] | loc. loss = 0.1651180089, classif. loss = 0.6236089468
2025-10-07 06:33:04,670 | INFO | iter is 47300 / 50000 [skipped  363] | loc. loss = 0.2871022224, classif. loss = 0.7538783550
2025-10-07 06:33:36,912 | INFO | iter is 47350 / 50000 [skipped  363] | loc. loss = 0.2911414802, classif. loss = 0.7239639759
2025-10-07 06:34:09,066 | INFO | iter is 47400 / 50000 [skipped  363] | loc. loss = 0.1695578843, classif. loss = 0.3403793275
2025-10-07 06:34:40,765 | INFO | iter is 47450 / 50000 [skipped  364] | loc. loss = 0.1678797305, classif. loss = 0.0610156171
2025-10-07 06:35:12,983 | INFO | iter is 47500 / 50000 [skipped  364] | loc. loss = 0.1252666116, classif. loss = 0.0905378982
2025-10-07 06:35:45,222 | INFO | iter is 47550 / 50000 [skipped  364] | loc. loss = 0.1798496246, classif. loss = 1.1052484512
2025-10-07 06:36:17,597 | INFO | iter is 47600 / 50000 [skipped  364] | loc. loss = 0.1989215761, classif. loss = 0.5662835836
2025-10-07 06:36:49,238 | INFO | iter is 47650 / 50000 [skipped  365] | loc. loss = 0.1408508122, classif. loss = 0.0991025269
2025-10-07 06:37:21,504 | INFO | iter is 47700 / 50000 [skipped  365] | loc. loss = 0.2381978035, classif. loss = 0.2963961363
2025-10-07 06:37:53,801 | INFO | iter is 47750 / 50000 [skipped  365] | loc. loss = 0.1034987494, classif. loss = 0.0761927366
2025-10-07 06:38:26,084 | INFO | iter is 47800 / 50000 [skipped  365] | loc. loss = 0.1711714864, classif. loss = 2.1954514980
2025-10-07 06:38:57,912 | INFO | iter is 47850 / 50000 [skipped  366] | loc. loss = 0.2750447392, classif. loss = 0.5995109081
2025-10-07 06:39:30,194 | INFO | iter is 47900 / 50000 [skipped  366] | loc. loss = 0.0882335380, classif. loss = 0.8888946772
2025-10-07 06:40:02,473 | INFO | iter is 47950 / 50000 [skipped  366] | loc. loss = 0.1998919994, classif. loss = 0.7532224655
2025-10-07 06:40:34,776 | INFO | iter is 48000 / 50000 [skipped  366] | loc. loss = 0.2072327733, classif. loss = 0.6617842913
2025-10-07 06:41:06,513 | INFO | iter is 48050 / 50000 [skipped  367] | loc. loss = 0.1526783705, classif. loss = 0.0595531352
2025-10-07 06:41:38,872 | INFO | iter is 48100 / 50000 [skipped  367] | loc. loss = 0.1859642863, classif. loss = 0.5026440024
2025-10-07 06:42:10,611 | INFO | iter is 48150 / 50000 [skipped  368] | loc. loss = 0.1674023271, classif. loss = 0.5757789016
2025-10-07 06:42:41,842 | INFO | iter is 48200 / 50000 [skipped  370] | loc. loss = 0.2889234722, classif. loss = 0.4285831153
2025-10-07 06:43:14,193 | INFO | iter is 48250 / 50000 [skipped  370] | loc. loss = 0.2432572544, classif. loss = 0.7266308069
2025-10-07 06:43:46,625 | INFO | iter is 48300 / 50000 [skipped  370] | loc. loss = 0.2634987235, classif. loss = 1.0537962914
2025-10-07 06:44:18,950 | INFO | iter is 48350 / 50000 [skipped  370] | loc. loss = 0.2981590033, classif. loss = 0.0687887520
2025-10-07 06:44:51,302 | INFO | iter is 48400 / 50000 [skipped  370] | loc. loss = 0.1095349714, classif. loss = 0.3581044376
2025-10-07 06:45:23,683 | INFO | iter is 48450 / 50000 [skipped  370] | loc. loss = 0.2019165605, classif. loss = 0.4806939363
2025-10-07 06:45:56,078 | INFO | iter is 48500 / 50000 [skipped  370] | loc. loss = 0.1586336195, classif. loss = 0.0380337350
2025-10-07 06:46:28,475 | INFO | iter is 48550 / 50000 [skipped  370] | loc. loss = 0.1976954341, classif. loss = 0.4494196177
2025-10-07 06:47:00,848 | INFO | iter is 48600 / 50000 [skipped  370] | loc. loss = 0.1571106911, classif. loss = 0.3371748030
2025-10-07 06:47:33,278 | INFO | iter is 48650 / 50000 [skipped  370] | loc. loss = 0.1817371994, classif. loss = 1.7538545132
2025-10-07 06:48:05,700 | INFO | iter is 48700 / 50000 [skipped  370] | loc. loss = 0.2271749079, classif. loss = 0.6075760126
2025-10-07 06:48:38,074 | INFO | iter is 48750 / 50000 [skipped  370] | loc. loss = 0.1226772740, classif. loss = 0.9396343231
2025-10-07 06:49:10,558 | INFO | iter is 48800 / 50000 [skipped  370] | loc. loss = 0.1631032377, classif. loss = 1.1610044241
2025-10-07 06:49:42,949 | INFO | iter is 48850 / 50000 [skipped  370] | loc. loss = 0.1852725744, classif. loss = 0.5500485897
2025-10-07 06:50:14,865 | INFO | iter is 48900 / 50000 [skipped  371] | loc. loss = 0.2388715595, classif. loss = 0.8871742487
2025-10-07 06:50:47,260 | INFO | iter is 48950 / 50000 [skipped  371] | loc. loss = 0.1915392727, classif. loss = 0.1793963611
2025-10-07 06:51:19,704 | INFO | iter is 49000 / 50000 [skipped  371] | loc. loss = 0.2456509918, classif. loss = 0.2950516939
2025-10-07 06:51:52,196 | INFO | iter is 49050 / 50000 [skipped  371] | loc. loss = 0.2643165588, classif. loss = 1.0904576778
2025-10-07 06:52:24,030 | INFO | iter is 49100 / 50000 [skipped  372] | loc. loss = 0.1505968422, classif. loss = 0.8945876360
2025-10-07 06:52:56,501 | INFO | iter is 49150 / 50000 [skipped  372] | loc. loss = 0.1234031320, classif. loss = 0.1358662844
2025-10-07 06:53:28,968 | INFO | iter is 49200 / 50000 [skipped  372] | loc. loss = 0.2387867868, classif. loss = 0.7684167624
2025-10-07 06:54:00,817 | INFO | iter is 49250 / 50000 [skipped  373] | loc. loss = 0.1305819452, classif. loss = 0.0714139566
2025-10-07 06:54:33,333 | INFO | iter is 49300 / 50000 [skipped  373] | loc. loss = 0.1811935753, classif. loss = 0.1911368072
2025-10-07 06:55:05,166 | INFO | iter is 49350 / 50000 [skipped  374] | loc. loss = 0.1475011706, classif. loss = 0.5064197183
2025-10-07 06:55:37,689 | INFO | iter is 49400 / 50000 [skipped  374] | loc. loss = 0.2571297586, classif. loss = 0.2916337848
2025-10-07 06:56:10,219 | INFO | iter is 49450 / 50000 [skipped  374] | loc. loss = 0.1479446739, classif. loss = 1.6972162724
2025-10-07 06:56:42,667 | INFO | iter is 49500 / 50000 [skipped  374] | loc. loss = 0.1329936534, classif. loss = 0.0210696645
2025-10-07 06:57:15,232 | INFO | iter is 49550 / 50000 [skipped  374] | loc. loss = 0.1960454285, classif. loss = 0.5573458672
2025-10-07 06:57:47,066 | INFO | iter is 49600 / 50000 [skipped  375] | loc. loss = 0.1117774248, classif. loss = 0.2823566496
2025-10-07 06:58:19,582 | INFO | iter is 49650 / 50000 [skipped  375] | loc. loss = 0.2624886334, classif. loss = 1.4619585276
2025-10-07 06:58:52,028 | INFO | iter is 49700 / 50000 [skipped  375] | loc. loss = 0.1697250605, classif. loss = 0.8187815547
2025-10-07 06:59:24,520 | INFO | iter is 49750 / 50000 [skipped  375] | loc. loss = 0.2435532808, classif. loss = 0.5778276324
2025-10-07 06:59:57,078 | INFO | iter is 49800 / 50000 [skipped  375] | loc. loss = 0.2041193992, classif. loss = 0.2251729369
2025-10-07 07:00:29,588 | INFO | iter is 49850 / 50000 [skipped  375] | loc. loss = 0.2119978964, classif. loss = 0.8222454786
2025-10-07 07:01:02,137 | INFO | iter is 49900 / 50000 [skipped  375] | loc. loss = 0.2035768628, classif. loss = 0.0556890592
2025-10-07 07:01:34,110 | INFO | iter is 49950 / 50000 [skipped  376] | loc. loss = 0.1913882196, classif. loss = 0.9619474411
2025-10-07 07:02:05,700 | INFO | iter is 50000 / 50000 [skipped  377] | loc. loss = 0.1897321343, classif. loss = 0.4008536637
2025-10-07 07:02:05,700 | INFO | -----------Training is completed-----------
2025-10-07 07:02:05,949 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-06_20-14-57_MambaBDA_Base_xBD/model_step50000_last.pth
2025-10-07 07:02:05,950 | INFO | !! Total Skipped: 377 (0.75%)
2025-10-07 07:02:05,951 | INFO | ---------starting evaluation-----------
2025-10-07 07:02:08,175 | INFO | validation:    0/ 933 (2025-10-07_07-02-08)
2025-10-07 07:02:54,615 | INFO | validation:  100/ 933 (2025-10-07_07-02-54)
2025-10-07 07:03:40,962 | INFO | validation:  200/ 933 (2025-10-07_07-03-40)
2025-10-07 07:04:27,262 | INFO | validation:  300/ 933 (2025-10-07_07-04-27)
2025-10-07 07:05:13,562 | INFO | validation:  400/ 933 (2025-10-07_07-05-13)
2025-10-07 07:05:59,866 | INFO | validation:  500/ 933 (2025-10-07_07-05-59)
2025-10-07 07:06:46,219 | INFO | validation:  600/ 933 (2025-10-07_07-06-46)
2025-10-07 07:07:32,558 | INFO | validation:  700/ 933 (2025-10-07_07-07-32)
2025-10-07 07:08:18,890 | INFO | validation:  800/ 933 (2025-10-07_07-08-18)
2025-10-07 07:09:05,227 | INFO | validation:  900/ 933 (2025-10-07_07-09-05)
2025-10-07 07:09:21,430 | INFO | Confusion Matrix of Localization:
[[910621225   9738624]
 [  7718189  50243370]]
2025-10-07 07:09:21,430 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98941868 0.01058132]
 [0.13316048 0.86683952]]
2025-10-07 07:09:21,430 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42012001  1294824   442996   108920]
 [       0  1293028  2723239   658942    66762]
 [       0   499007   671297  4212073   146553]
 [       0   113118    32927   315068  2608177]]
2025-10-07 07:09:21,430 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95789346 0.0295226  0.01010052 0.00248343]
 [0.         0.27267733 0.5742842  0.13895952 0.01407896]
 [0.         0.09025381 0.12141536 0.76182426 0.02650658]
 [0.         0.03685478 0.01072789 0.10265175 0.84976558]]
2025-10-07 07:09:21,430 | INFO | lofF1 is 85.1990, clfF1 is 76.0885, oaF1 is 78.8217, sub class F1 score is [95.7256 57.5479 75.4986 86.9435]
2025-10-07 07:09:21,432 | INFO | loc_f1_score=np.float64(85.199), harmonic_mean_f1=np.float64(76.0885), oaf1=np.float64(78.8217), damage_f1_score=array([95.7256, 57.5479, 75.4986, 86.9435])
2025-10-07 07:09:21,432 | INFO | ---------starting train set evaluation-----------
2025-10-07 07:09:21,432 | INFO | Train buffer size: 3108.
2025-10-07 07:09:33,390 | INFO | [TrainBuf] locF1 is 85.8768, clfF1 is 71.7571, oaF1 is 75.9930, sub class F1 score is [95.2218 51.9519 70.4383 84.7716]
2025-10-07 07:09:33,411 | INFO | Validation Results:
2025-10-07 07:09:33,412 | INFO | [TEST ] Step  3125: (np.float64(80.7068), np.float64(54.7333), np.float64(62.5254), array([82.2645, 41.7486, 39.9288, 83.8346]))
2025-10-07 07:09:33,412 | INFO | [TRAIN] Step  3125: (np.float64(73.5231), np.float64(40.7776), np.float64(50.6013), array([90.5722, 19.6813, 44.6865, 72.1276]))

2025-10-07 07:09:33,412 | INFO | [TEST ] Step  6250: (np.float64(82.1485), np.float64(62.2876), np.float64(68.2459), array([94.0402, 37.4193, 68.7396, 81.2171]))
2025-10-07 07:09:33,412 | INFO | [TRAIN] Step  6250: (np.float64(81.8965), np.float64(55.5645), np.float64(63.4641), array([93.24  , 30.6192, 61.9574, 80.231 ]))

2025-10-07 07:09:33,412 | INFO | [TEST ] Step  9375: (np.float64(83.4493), np.float64(65.1727), np.float64(70.6556), array([93.6534, 40.7073, 70.4975, 83.7014]))
2025-10-07 07:09:33,412 | INFO | [TRAIN] Step  9375: (np.float64(82.7921), np.float64(61.2299), np.float64(67.6986), array([93.8547, 37.2419, 63.8388, 82.2583]))

2025-10-07 07:09:33,412 | INFO | [TEST ] Step 12500: (np.float64(83.3572), np.float64(70.7401), np.float64(74.5252), array([94.7373, 49.0966, 73.8693, 82.7534]))
2025-10-07 07:09:33,412 | INFO | [TRAIN] Step 12500: (np.float64(83.42), np.float64(64.3366), np.float64(70.0616), array([94.217 , 40.8439, 66.966 , 82.3533]))

2025-10-07 07:09:33,412 | INFO | [TEST ] Step 15625: (np.float64(84.0646), np.float64(72.3329), np.float64(75.8524), array([93.3678, 51.9002, 72.9194, 86.1475]))
2025-10-07 07:09:33,412 | INFO | [TRAIN] Step 15625: (np.float64(84.1799), np.float64(66.5951), np.float64(71.8705), array([94.4519, 44.7578, 65.4389, 84.3653]))

2025-10-07 07:09:33,412 | INFO | [TEST ] Step 18750: (np.float64(83.592), np.float64(72.558), np.float64(75.8682), array([95.0506, 53.6565, 69.1963, 86.8139]))
2025-10-07 07:09:33,412 | INFO | [TRAIN] Step 18750: (np.float64(84.5229), np.float64(67.046), np.float64(72.289), array([94.6898, 44.3047, 67.2278, 85.8074]))

2025-10-07 07:09:33,412 | INFO | [TEST ] Step 21875: (np.float64(83.1963), np.float64(71.7274), np.float64(75.168), array([94.7449, 50.1124, 73.3368, 86.0495]))
2025-10-07 07:09:33,412 | INFO | [TRAIN] Step 21875: (np.float64(84.644), np.float64(69.6532), np.float64(74.1505), array([94.9374, 47.3051, 69.6952, 87.6691]))

2025-10-07 07:09:33,412 | INFO | [TEST ] Step 25000: (np.float64(84.5045), np.float64(74.9628), np.float64(77.8253), array([95.4098, 56.3556, 73.7636, 86.3751]))
2025-10-07 07:09:33,412 | INFO | [TRAIN] Step 25000: (np.float64(84.9752), np.float64(69.5737), np.float64(74.1941), array([94.7481, 47.4585, 70.3734, 85.78  ]))

2025-10-07 07:09:33,413 | INFO | [TEST ] Step 28125: (np.float64(84.7496), np.float64(74.615), np.float64(77.6554), array([95.1851, 56.7624, 72.1052, 86.0826]))
2025-10-07 07:09:33,413 | INFO | [TRAIN] Step 28125: (np.float64(85.0884), np.float64(69.4735), np.float64(74.158), array([95.05  , 47.4395, 69.4431, 86.3899]))

2025-10-07 07:09:33,413 | INFO | [TEST ] Step 31250: (np.float64(84.4877), np.float64(73.4797), np.float64(76.7821), array([95.1646, 53.3719, 74.0441, 85.5669]))
2025-10-07 07:09:33,413 | INFO | [TRAIN] Step 31250: (np.float64(85.0619), np.float64(70.5852), np.float64(74.9282), array([94.8295, 48.8292, 71.6544, 85.5549]))

2025-10-07 07:09:33,413 | INFO | [TEST ] Step 34375: (np.float64(84.5153), np.float64(68.9797), np.float64(73.6404), array([94.402 , 48.237 , 65.7015, 87.3836]))
2025-10-07 07:09:33,413 | INFO | [TRAIN] Step 34375: (np.float64(85.447), np.float64(72.7096), np.float64(76.5308), array([95.5222, 50.8886, 75.4893, 85.8597]))

2025-10-07 07:09:33,413 | INFO | [TEST ] Step 37500: (np.float64(84.8917), np.float64(73.5617), np.float64(76.9607), array([95.0848, 53.7905, 73.0209, 86.4017]))
2025-10-07 07:09:33,413 | INFO | [TRAIN] Step 37500: (np.float64(85.3049), np.float64(70.0019), np.float64(74.5928), array([95.1416, 48.108 , 70.9078, 85.1693]))

2025-10-07 07:09:33,413 | INFO | [TEST ] Step 40625: (np.float64(84.7843), np.float64(71.5534), np.float64(75.5227), array([94.3513, 52.1613, 68.2783, 87.0597]))
2025-10-07 07:09:33,413 | INFO | [TRAIN] Step 40625: (np.float64(85.5723), np.float64(72.076), np.float64(76.1249), array([95.4741, 49.9759, 74.2297, 86.6432]))

2025-10-07 07:09:33,413 | INFO | [TEST ] Step 43750: (np.float64(85.0784), np.float64(73.4888), np.float64(76.9657), array([95.0826, 53.5254, 72.9713, 86.7593]))
2025-10-07 07:09:33,413 | INFO | [TRAIN] Step 43750: (np.float64(85.524), np.float64(72.8159), np.float64(76.6283), array([95.6772, 52.484 , 72.5642, 85.8597]))

2025-10-07 07:09:33,413 | INFO | [TEST ] Step 46875: (np.float64(84.8622), np.float64(75.2329), np.float64(78.1217), array([95.2301, 57.3645, 73.019 , 86.6561]))
2025-10-07 07:09:33,413 | INFO | [TRAIN] Step 46875: (np.float64(85.5508), np.float64(71.7328), np.float64(75.8782), array([95.3466, 50.3902, 72.44  , 86.0228]))

2025-10-07 07:09:33,413 | INFO | [TEST ] Step    -1: (np.float64(85.199), np.float64(76.0885), np.float64(78.8217), array([95.7256, 57.5479, 75.4986, 86.9435]))
2025-10-07 07:09:33,413 | INFO | [TRAIN] Step    -1: (np.float64(85.8768), np.float64(71.7571), np.float64(75.993), array([95.2218, 51.9519, 70.4383, 84.7716]))

2025-10-07 07:09:33,413 | INFO | The accuracy of the best round is: [np.float64(85.199), np.float64(76.0885), np.float64(78.8217), array([95.7256, 57.5479, 75.4986, 86.9435])]
2025-10-07 07:09:33,438 | INFO | MAIN - DONE.
2025-10-07 07:09:33,438 | INFO | MAIN - EXIT.
