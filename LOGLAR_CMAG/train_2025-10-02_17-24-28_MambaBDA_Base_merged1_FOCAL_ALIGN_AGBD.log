2025-10-02 17:24:31,087 | INFO | MAIN - START
2025-10-02 17:24:31,087 | INFO |  > FOCAL LOSS set to True
2025-10-02 17:24:31,087 | INFO |  > ALINGNMENT set to True
2025-10-02 17:24:31,087 | INFO |  > ATTENTION GATE set to -> Building: True, Damage: True
2025-10-02 17:24:31,089 | INFO | Command Line Args:
{
    "cfg": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/configs/vssm1/vssm_base_224.yaml",
    "opts": null,
    "pretrained_weight_path": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/pretrained_weight/vssm_base_0229_ckpt_epoch_237.pth",
    "dataset": "merged1",
    "type": "train",
    "train_dataset_path": "/mnt/storage1/alpgenc/change_detection/datasets/merged1",
    "train_data_list_path": "/mnt/storage1/alpgenc/change_detection/datasets/merged1/train_list.txt",
    "test_dataset_path": "/mnt/storage1/alpgenc/change_detection/datasets/merged1",
    "test_data_list_path": "/mnt/storage1/alpgenc/change_detection/datasets/merged1/test_list.txt",
    "shuffle": true,
    "batch_size": 8,
    "crop_size": 256,
    "start_iter": 0,
    "cuda": true,
    "max_iters": 800000,
    "model_type": "MambaBDA_Base",
    "model_param_path": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD",
    "resume": null,
    "learning_rate": 0.0001,
    "momentum": 0.9,
    "weight_decay": 0.005,
    "logfile": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/LOGLAR_CMAG/train_2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD.log",
    "extension": "png",
    "focal_loss": true,
    "enable_alignment": true,
    "enable_attn_gate_building": true,
    "enable_attn_gate_damage": true,
    "deterministic": false,
    "validations": 32,
    "measure_train_scores": true
}
2025-10-02 17:24:31,090 | INFO | Starting in RANDOM mode / not deterministic.
2025-10-02 17:24:31,099 | INFO |  > TRAIN EVALUATION params: TRAIN_BUF_MAXLEN = 128
2025-10-02 17:24:31,099 | INFO |  > ALIGNMENT params: alignment_args = AlignmentArgs(enabled=True, stages=(1, 2), mid_ch=64)
2025-10-02 17:24:31,099 | INFO |  > ATTENTION GATE params: attn_gate_args = AttentionGateArgs(enable_building_ag=True, enable_damage_ag=True)
2025-10-02 17:24:31,100 | INFO | ChangeMambaBDA class
2025-10-02 17:24:35,443 | INFO |  > FOCAL LOSS params: alpha = [0.6, 1.6, 1.1, 1.1], gamma = 1.5
2025-10-02 17:24:35,443 | INFO | ---------starting training-----------
2025-10-02 17:24:35,526 | INFO | VAL_STEP=3125, (number_of_validations = 32)
2025-10-02 17:25:16,356 | INFO | iter is 50 / 100000 [skipped    0] | loc. loss = 0.5641623139, classif. loss = 2.8233971596
2025-10-02 17:25:52,040 | INFO | iter is 100 / 100000 [skipped    1] | loc. loss = 0.4252930582, classif. loss = 3.4451973438
2025-10-02 17:26:28,077 | INFO | iter is 150 / 100000 [skipped    1] | loc. loss = 0.4998524785, classif. loss = 0.4232129157
2025-10-02 17:27:01,437 | INFO | iter is 200 / 100000 [skipped    1] | loc. loss = 0.3263368607, classif. loss = 0.6330118775
2025-10-02 17:27:34,182 | INFO | iter is 250 / 100000 [skipped    1] | loc. loss = 0.3416779339, classif. loss = 1.4716134071
2025-10-02 17:28:06,886 | INFO | iter is 300 / 100000 [skipped    1] | loc. loss = 0.4873349071, classif. loss = 0.6727976203
2025-10-02 17:28:38,688 | INFO | iter is 350 / 100000 [skipped    2] | loc. loss = 0.4008822739, classif. loss = 0.8469691277
2025-10-02 17:29:11,080 | INFO | iter is 400 / 100000 [skipped    2] | loc. loss = 0.3008994758, classif. loss = 1.4723827839
2025-10-02 17:29:43,291 | INFO | iter is 450 / 100000 [skipped    2] | loc. loss = 0.3455815315, classif. loss = 1.0512688160
2025-10-02 17:30:15,638 | INFO | iter is 500 / 100000 [skipped    2] | loc. loss = 0.3015503883, classif. loss = 0.6969921589
2025-10-02 17:30:47,469 | INFO | iter is 550 / 100000 [skipped    3] | loc. loss = 0.3890787363, classif. loss = 1.3893489838
2025-10-02 17:31:19,751 | INFO | iter is 600 / 100000 [skipped    3] | loc. loss = 0.3801242709, classif. loss = 2.3223068714
2025-10-02 17:31:52,002 | INFO | iter is 650 / 100000 [skipped    3] | loc. loss = 0.3749461174, classif. loss = 2.5055875778
2025-10-02 17:32:24,304 | INFO | iter is 700 / 100000 [skipped    3] | loc. loss = 0.4014718831, classif. loss = 0.5340154171
2025-10-02 17:32:56,758 | INFO | iter is 750 / 100000 [skipped    3] | loc. loss = 0.3239099383, classif. loss = 1.2907656431
2025-10-02 17:33:29,065 | INFO | iter is 800 / 100000 [skipped    3] | loc. loss = 0.2768096924, classif. loss = 0.7774865031
2025-10-02 17:34:01,443 | INFO | iter is 850 / 100000 [skipped    3] | loc. loss = 0.3613129854, classif. loss = 1.1514549255
2025-10-02 17:34:33,148 | INFO | iter is 900 / 100000 [skipped    4] | loc. loss = 0.3748150468, classif. loss = 2.2292366028
2025-10-02 17:35:05,524 | INFO | iter is 950 / 100000 [skipped    4] | loc. loss = 0.2725193501, classif. loss = 1.3477421999
2025-10-02 17:35:37,815 | INFO | iter is 1000 / 100000 [skipped    4] | loc. loss = 0.3043332994, classif. loss = 0.5577599406
2025-10-02 17:36:10,145 | INFO | iter is 1050 / 100000 [skipped    4] | loc. loss = 0.2664417624, classif. loss = 0.9523735046
2025-10-02 17:36:41,810 | INFO | iter is 1100 / 100000 [skipped    5] | loc. loss = 0.2901421785, classif. loss = 0.6380233765
2025-10-02 17:37:14,143 | INFO | iter is 1150 / 100000 [skipped    5] | loc. loss = 0.2213357240, classif. loss = 0.5566992760
2025-10-02 17:37:46,472 | INFO | iter is 1200 / 100000 [skipped    5] | loc. loss = 0.1998771131, classif. loss = 1.1412216425
2025-10-02 17:38:18,788 | INFO | iter is 1250 / 100000 [skipped    5] | loc. loss = 0.3541055918, classif. loss = 1.1889860630
2025-10-02 17:38:51,015 | INFO | iter is 1300 / 100000 [skipped    5] | loc. loss = 0.2361372411, classif. loss = 1.0920221806
2025-10-02 17:39:23,220 | INFO | iter is 1350 / 100000 [skipped    5] | loc. loss = 0.2012917399, classif. loss = 2.6086790562
2025-10-02 17:39:55,419 | INFO | iter is 1400 / 100000 [skipped    5] | loc. loss = 0.2807248533, classif. loss = 0.4145795703
2025-10-02 17:40:27,626 | INFO | iter is 1450 / 100000 [skipped    5] | loc. loss = 0.2895204425, classif. loss = 0.6304322481
2025-10-02 17:40:59,847 | INFO | iter is 1500 / 100000 [skipped    5] | loc. loss = 0.2847769856, classif. loss = 1.1887251139
2025-10-02 17:41:32,108 | INFO | iter is 1550 / 100000 [skipped    5] | loc. loss = 0.2107291669, classif. loss = 1.1345906258
2025-10-02 17:42:04,471 | INFO | iter is 1600 / 100000 [skipped    5] | loc. loss = 0.3370583057, classif. loss = 0.7529595494
2025-10-02 17:42:36,799 | INFO | iter is 1650 / 100000 [skipped    5] | loc. loss = 0.2928507030, classif. loss = 0.4523339272
2025-10-02 17:43:09,075 | INFO | iter is 1700 / 100000 [skipped    5] | loc. loss = 0.2408205867, classif. loss = 1.4309113026
2025-10-02 17:43:41,482 | INFO | iter is 1750 / 100000 [skipped    5] | loc. loss = 0.2979840636, classif. loss = 0.6078082323
2025-10-02 17:44:13,758 | INFO | iter is 1800 / 100000 [skipped    5] | loc. loss = 0.4553779364, classif. loss = 2.1239085197
2025-10-02 17:44:46,174 | INFO | iter is 1850 / 100000 [skipped    5] | loc. loss = 0.4268035889, classif. loss = 1.0591219664
2025-10-02 17:45:18,435 | INFO | iter is 1900 / 100000 [skipped    5] | loc. loss = 0.1818976104, classif. loss = 0.1285378933
2025-10-02 17:45:50,705 | INFO | iter is 1950 / 100000 [skipped    5] | loc. loss = 0.1894306690, classif. loss = 0.4797547460
2025-10-02 17:46:22,384 | INFO | iter is 2000 / 100000 [skipped    6] | loc. loss = 0.2061290890, classif. loss = 0.5707806349
2025-10-02 17:46:54,624 | INFO | iter is 2050 / 100000 [skipped    6] | loc. loss = 0.3379274607, classif. loss = 0.8252043724
2025-10-02 17:47:26,935 | INFO | iter is 2100 / 100000 [skipped    6] | loc. loss = 0.2212596387, classif. loss = 0.3316136599
2025-10-02 17:47:59,211 | INFO | iter is 2150 / 100000 [skipped    6] | loc. loss = 0.2767611742, classif. loss = 1.9455497265
2025-10-02 17:48:30,256 | INFO | iter is 2200 / 100000 [skipped    8] | loc. loss = 0.1974544674, classif. loss = 0.7658363581
2025-10-02 17:49:02,055 | INFO | iter is 2250 / 100000 [skipped    9] | loc. loss = 0.1860138178, classif. loss = 0.1028338447
2025-10-02 17:49:34,421 | INFO | iter is 2300 / 100000 [skipped    9] | loc. loss = 0.6260851622, classif. loss = 0.6373935342
2025-10-02 17:50:06,720 | INFO | iter is 2350 / 100000 [skipped    9] | loc. loss = 0.2805304527, classif. loss = 0.7177588940
2025-10-02 17:50:38,983 | INFO | iter is 2400 / 100000 [skipped    9] | loc. loss = 0.2572182119, classif. loss = 0.8374615908
2025-10-02 17:51:11,239 | INFO | iter is 2450 / 100000 [skipped    9] | loc. loss = 0.2549250126, classif. loss = 1.0246434212
2025-10-02 17:51:42,816 | INFO | iter is 2500 / 100000 [skipped   10] | loc. loss = 0.2276458442, classif. loss = 0.1992990673
2025-10-02 17:52:15,022 | INFO | iter is 2550 / 100000 [skipped   10] | loc. loss = 0.1601659060, classif. loss = 0.2013907880
2025-10-02 17:52:47,373 | INFO | iter is 2600 / 100000 [skipped   10] | loc. loss = 0.1874542385, classif. loss = 0.5469564795
2025-10-02 17:53:19,696 | INFO | iter is 2650 / 100000 [skipped   10] | loc. loss = 0.2858292460, classif. loss = 0.7786607742
2025-10-02 17:53:51,901 | INFO | iter is 2700 / 100000 [skipped   10] | loc. loss = 0.2172165364, classif. loss = 1.6018873453
2025-10-02 17:54:24,076 | INFO | iter is 2750 / 100000 [skipped   10] | loc. loss = 0.2164054066, classif. loss = 0.7452510595
2025-10-02 17:54:56,363 | INFO | iter is 2800 / 100000 [skipped   10] | loc. loss = 0.2485765964, classif. loss = 0.9923742414
2025-10-02 17:55:28,587 | INFO | iter is 2850 / 100000 [skipped   10] | loc. loss = 0.0839309767, classif. loss = 0.8941340446
2025-10-02 17:56:00,228 | INFO | iter is 2900 / 100000 [skipped   11] | loc. loss = 0.2068604678, classif. loss = 0.7371739149
2025-10-02 17:56:32,417 | INFO | iter is 2950 / 100000 [skipped   11] | loc. loss = 0.3389702141, classif. loss = 0.5295118093
2025-10-02 17:57:04,707 | INFO | iter is 3000 / 100000 [skipped   11] | loc. loss = 0.3009263277, classif. loss = 1.1252911091
2025-10-02 17:57:36,277 | INFO | iter is 3050 / 100000 [skipped   12] | loc. loss = 0.1418605149, classif. loss = 0.5342094898
2025-10-02 17:58:08,626 | INFO | iter is 3100 / 100000 [skipped   12] | loc. loss = 0.2377228290, classif. loss = 0.0448465161
2025-10-02 17:58:24,743 | INFO | ---------starting evaluation-----------
2025-10-02 17:58:25,341 | INFO | validation:    0/2126 (2025-10-02_17-58-25)
2025-10-02 17:58:53,592 | INFO | validation:  100/2126 (2025-10-02_17-58-53)
2025-10-02 17:59:22,279 | INFO | validation:  200/2126 (2025-10-02_17-59-22)
2025-10-02 17:59:48,626 | INFO | validation:  300/2126 (2025-10-02_17-59-48)
2025-10-02 18:00:17,756 | INFO | validation:  400/2126 (2025-10-02_18-00-17)
2025-10-02 18:00:47,904 | INFO | validation:  500/2126 (2025-10-02_18-00-47)
2025-10-02 18:01:18,350 | INFO | validation:  600/2126 (2025-10-02_18-01-18)
2025-10-02 18:01:44,774 | INFO | validation:  700/2126 (2025-10-02_18-01-44)
2025-10-02 18:02:13,965 | INFO | validation:  800/2126 (2025-10-02_18-02-13)
2025-10-02 18:02:41,313 | INFO | validation:  900/2126 (2025-10-02_18-02-41)
2025-10-02 18:03:13,608 | INFO | validation: 1000/2126 (2025-10-02_18-03-13)
2025-10-02 18:03:43,216 | INFO | validation: 1100/2126 (2025-10-02_18-03-43)
2025-10-02 18:04:12,158 | INFO | validation: 1200/2126 (2025-10-02_18-04-12)
2025-10-02 18:04:42,416 | INFO | validation: 1300/2126 (2025-10-02_18-04-42)
2025-10-02 18:05:10,329 | INFO | validation: 1400/2126 (2025-10-02_18-05-10)
2025-10-02 18:05:38,923 | INFO | validation: 1500/2126 (2025-10-02_18-05-38)
2025-10-02 18:06:07,850 | INFO | validation: 1600/2126 (2025-10-02_18-06-07)
2025-10-02 18:06:35,778 | INFO | validation: 1700/2126 (2025-10-02_18-06-35)
2025-10-02 18:07:05,045 | INFO | validation: 1800/2126 (2025-10-02_18-07-05)
2025-10-02 18:07:34,956 | INFO | validation: 1900/2126 (2025-10-02_18-07-34)
2025-10-02 18:08:02,218 | INFO | validation: 2000/2126 (2025-10-02_18-08-02)
2025-10-02 18:08:30,128 | INFO | validation: 2100/2126 (2025-10-02_18-08-30)
2025-10-02 18:08:38,509 | INFO | Confusion Matrix of Localization:
[[1293836222    5634211]
 [  11996747   40147284]]
2025-10-02 18:08:38,512 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99566423 0.00433577]
 [0.23006942 0.76993058]]
2025-10-02 18:08:38,512 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41133824  1642074   583339    90997]
 [       0  1429698  1092774   541361    32370]
 [       0   375589   536170  1881881   109291]
 [       0   178107   137600   130633  1535935]]
2025-10-02 18:08:38,513 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.9466882  0.03779206 0.01342545 0.00209428]
 [0.         0.46175848 0.35294004 0.17484674 0.01045474]
 [0.         0.12938268 0.18469953 0.64826928 0.0376485 ]
 [0.         0.08984979 0.06941519 0.06590054 0.77483447]]
2025-10-02 18:08:38,513 | INFO | lofF1 is 81.9955, clfF1 is 58.3566, oaF1 is 65.4483, sub class F1 score is [95.033  33.5989 62.3124 81.8976]
2025-10-02 18:08:38,771 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step3125.pth
2025-10-02 18:08:38,771 | INFO | ---------starting train set evaluation-----------
2025-10-02 18:08:39,266 | INFO | [TrainBuf] locF1 is 82.1143, clfF1 is 51.9061, oaF1 is 60.9685, sub class F1 score is [93.5853 34.2737 48.4363 60.4073]
2025-10-02 18:08:55,397 | INFO | iter is 3150 / 100000 [skipped   12] | loc. loss = 0.2723426819, classif. loss = 0.7661713362
2025-10-02 18:09:27,796 | INFO | iter is 3200 / 100000 [skipped   12] | loc. loss = 0.2228419483, classif. loss = 0.6100956202
2025-10-02 18:10:00,068 | INFO | iter is 3250 / 100000 [skipped   12] | loc. loss = 0.1773803979, classif. loss = 0.4097580910
2025-10-02 18:10:32,360 | INFO | iter is 3300 / 100000 [skipped   12] | loc. loss = 0.2489438057, classif. loss = 0.7953656316
2025-10-02 18:11:04,498 | INFO | iter is 3350 / 100000 [skipped   12] | loc. loss = 0.1891712546, classif. loss = 1.3502423763
2025-10-02 18:11:36,798 | INFO | iter is 3400 / 100000 [skipped   12] | loc. loss = 0.3730666637, classif. loss = 0.0995571837
2025-10-02 18:12:09,014 | INFO | iter is 3450 / 100000 [skipped   12] | loc. loss = 0.3463199139, classif. loss = 1.0401394367
2025-10-02 18:12:41,321 | INFO | iter is 3500 / 100000 [skipped   12] | loc. loss = 0.2547831535, classif. loss = 0.1966220140
2025-10-02 18:13:13,494 | INFO | iter is 3550 / 100000 [skipped   12] | loc. loss = 0.1753673106, classif. loss = 4.7046437263
2025-10-02 18:13:45,775 | INFO | iter is 3600 / 100000 [skipped   12] | loc. loss = 0.2588223517, classif. loss = 1.3410604000
2025-10-02 18:14:18,110 | INFO | iter is 3650 / 100000 [skipped   12] | loc. loss = 0.2310029417, classif. loss = 0.4372833967
2025-10-02 18:14:49,938 | INFO | iter is 3700 / 100000 [skipped   13] | loc. loss = 0.4733973145, classif. loss = 0.7066704631
2025-10-02 18:15:22,271 | INFO | iter is 3750 / 100000 [skipped   13] | loc. loss = 0.1916062534, classif. loss = 0.3047632277
2025-10-02 18:15:54,490 | INFO | iter is 3800 / 100000 [skipped   13] | loc. loss = 0.1838391274, classif. loss = 0.1656109542
2025-10-02 18:16:26,737 | INFO | iter is 3850 / 100000 [skipped   13] | loc. loss = 0.2745448947, classif. loss = 0.5472317338
2025-10-02 18:16:59,074 | INFO | iter is 3900 / 100000 [skipped   13] | loc. loss = 0.1800394803, classif. loss = 0.6455844045
2025-10-02 18:17:31,275 | INFO | iter is 3950 / 100000 [skipped   13] | loc. loss = 0.1912936717, classif. loss = 0.1005252376
2025-10-02 18:18:03,551 | INFO | iter is 4000 / 100000 [skipped   13] | loc. loss = 0.2892676592, classif. loss = 1.3702681065
2025-10-02 18:18:35,731 | INFO | iter is 4050 / 100000 [skipped   13] | loc. loss = 0.3065660596, classif. loss = 0.8824807405
2025-10-02 18:19:07,431 | INFO | iter is 4100 / 100000 [skipped   14] | loc. loss = 0.2696100771, classif. loss = 0.4034888744
2025-10-02 18:19:39,696 | INFO | iter is 4150 / 100000 [skipped   14] | loc. loss = 0.2074125558, classif. loss = 0.6543781757
2025-10-02 18:20:12,005 | INFO | iter is 4200 / 100000 [skipped   14] | loc. loss = 0.2072104067, classif. loss = 0.4847096205
2025-10-02 18:20:43,725 | INFO | iter is 4250 / 100000 [skipped   15] | loc. loss = 0.1700249314, classif. loss = 0.9054653049
2025-10-02 18:21:15,391 | INFO | iter is 4300 / 100000 [skipped   16] | loc. loss = 0.2306334376, classif. loss = 0.6900652647
2025-10-02 18:21:47,791 | INFO | iter is 4350 / 100000 [skipped   16] | loc. loss = 0.1542928964, classif. loss = 0.7695332766
2025-10-02 18:22:20,061 | INFO | iter is 4400 / 100000 [skipped   16] | loc. loss = 0.3015196919, classif. loss = 0.7483549118
2025-10-02 18:22:52,446 | INFO | iter is 4450 / 100000 [skipped   16] | loc. loss = 0.2681505084, classif. loss = 0.1910791844
2025-10-02 18:23:24,758 | INFO | iter is 4500 / 100000 [skipped   16] | loc. loss = 0.2159828246, classif. loss = 0.4236158431
2025-10-02 18:23:57,154 | INFO | iter is 4550 / 100000 [skipped   16] | loc. loss = 0.2004423141, classif. loss = 0.4768120050
2025-10-02 18:24:29,452 | INFO | iter is 4600 / 100000 [skipped   16] | loc. loss = 0.1867638826, classif. loss = 0.1779764593
2025-10-02 18:25:01,803 | INFO | iter is 4650 / 100000 [skipped   16] | loc. loss = 0.1816959381, classif. loss = 0.4884583056
2025-10-02 18:25:34,101 | INFO | iter is 4700 / 100000 [skipped   16] | loc. loss = 0.3747043908, classif. loss = 0.4315632582
2025-10-02 18:26:05,893 | INFO | iter is 4750 / 100000 [skipped   17] | loc. loss = 0.3503181040, classif. loss = 1.3590173721
2025-10-02 18:26:38,209 | INFO | iter is 4800 / 100000 [skipped   17] | loc. loss = 0.1986505985, classif. loss = 0.2467036992
2025-10-02 18:27:10,547 | INFO | iter is 4850 / 100000 [skipped   17] | loc. loss = 0.1221852154, classif. loss = 0.4886338711
2025-10-02 18:27:42,815 | INFO | iter is 4900 / 100000 [skipped   17] | loc. loss = 0.2107665688, classif. loss = 0.9340514541
2025-10-02 18:28:15,047 | INFO | iter is 4950 / 100000 [skipped   17] | loc. loss = 0.2261928618, classif. loss = 1.1768941879
2025-10-02 18:28:47,397 | INFO | iter is 5000 / 100000 [skipped   17] | loc. loss = 0.2812597454, classif. loss = 1.7058703899
2025-10-02 18:29:19,785 | INFO | iter is 5050 / 100000 [skipped   17] | loc. loss = 0.2165838480, classif. loss = 0.4476460218
2025-10-02 18:29:51,437 | INFO | iter is 5100 / 100000 [skipped   18] | loc. loss = 0.1386958510, classif. loss = 1.0159275532
2025-10-02 18:30:23,738 | INFO | iter is 5150 / 100000 [skipped   18] | loc. loss = 0.1880878210, classif. loss = 0.0612555221
2025-10-02 18:30:56,033 | INFO | iter is 5200 / 100000 [skipped   18] | loc. loss = 0.2032811046, classif. loss = 1.1899529696
2025-10-02 18:31:28,280 | INFO | iter is 5250 / 100000 [skipped   18] | loc. loss = 0.0909124911, classif. loss = 0.5575762391
2025-10-02 18:32:00,022 | INFO | iter is 5300 / 100000 [skipped   19] | loc. loss = 0.1747901887, classif. loss = 0.3031692505
2025-10-02 18:32:32,337 | INFO | iter is 5350 / 100000 [skipped   19] | loc. loss = 0.1055345088, classif. loss = 0.7220116854
2025-10-02 18:33:04,603 | INFO | iter is 5400 / 100000 [skipped   19] | loc. loss = 0.2379042208, classif. loss = 0.8934872746
2025-10-02 18:33:36,861 | INFO | iter is 5450 / 100000 [skipped   19] | loc. loss = 0.1608745158, classif. loss = 0.2623634040
2025-10-02 18:34:40,745 | INFO | iter is 5550 / 100000 [skipped   20] | loc. loss = 0.2933958769, classif. loss = 0.2235224843
2025-10-02 18:35:12,997 | INFO | iter is 5600 / 100000 [skipped   20] | loc. loss = 0.1215801165, classif. loss = 0.1082108840
2025-10-02 18:35:45,204 | INFO | iter is 5650 / 100000 [skipped   20] | loc. loss = 0.2202210724, classif. loss = 0.7126531005
2025-10-02 18:36:17,490 | INFO | iter is 5700 / 100000 [skipped   20] | loc. loss = 0.2668173015, classif. loss = 1.1256701946
2025-10-02 18:36:49,803 | INFO | iter is 5750 / 100000 [skipped   20] | loc. loss = 0.2265344113, classif. loss = 0.9741249681
2025-10-02 18:37:22,020 | INFO | iter is 5800 / 100000 [skipped   20] | loc. loss = 0.1372913420, classif. loss = 0.6822060943
2025-10-02 18:37:54,224 | INFO | iter is 5850 / 100000 [skipped   20] | loc. loss = 0.1990898103, classif. loss = 0.6710869074
2025-10-02 18:38:26,464 | INFO | iter is 5900 / 100000 [skipped   20] | loc. loss = 0.1215538532, classif. loss = 0.2673944831
2025-10-02 18:38:58,728 | INFO | iter is 5950 / 100000 [skipped   20] | loc. loss = 0.1683332771, classif. loss = 0.6062686443
2025-10-02 18:39:30,968 | INFO | iter is 6000 / 100000 [skipped   20] | loc. loss = 0.2882930636, classif. loss = 0.6907677650
2025-10-02 18:40:03,205 | INFO | iter is 6050 / 100000 [skipped   20] | loc. loss = 0.1448079497, classif. loss = 0.7881823778
2025-10-02 18:40:34,302 | INFO | iter is 6100 / 100000 [skipped   22] | loc. loss = 0.3284335732, classif. loss = 0.1892338991
2025-10-02 18:41:06,498 | INFO | iter is 6150 / 100000 [skipped   22] | loc. loss = 0.1884112209, classif. loss = 0.9126754999
2025-10-02 18:41:38,738 | INFO | iter is 6200 / 100000 [skipped   22] | loc. loss = 0.1780478060, classif. loss = 0.6537910700
2025-10-02 18:42:10,946 | INFO | iter is 6250 / 100000 [skipped   22] | loc. loss = 0.1003270522, classif. loss = 1.5466167927
2025-10-02 18:42:10,948 | INFO | ---------starting evaluation-----------
2025-10-02 18:42:11,429 | INFO | validation:    0/2126 (2025-10-02_18-42-11)
2025-10-02 18:42:39,340 | INFO | validation:  100/2126 (2025-10-02_18-42-39)
2025-10-02 18:43:07,874 | INFO | validation:  200/2126 (2025-10-02_18-43-07)
2025-10-02 18:43:34,070 | INFO | validation:  300/2126 (2025-10-02_18-43-34)
2025-10-02 18:44:02,938 | INFO | validation:  400/2126 (2025-10-02_18-44-02)
2025-10-02 18:44:32,825 | INFO | validation:  500/2126 (2025-10-02_18-44-32)
2025-10-02 18:45:03,056 | INFO | validation:  600/2126 (2025-10-02_18-45-03)
2025-10-02 18:45:29,245 | INFO | validation:  700/2126 (2025-10-02_18-45-29)
2025-10-02 18:45:58,119 | INFO | validation:  800/2126 (2025-10-02_18-45-58)
2025-10-02 18:46:25,301 | INFO | validation:  900/2126 (2025-10-02_18-46-25)
2025-10-02 18:46:57,514 | INFO | validation: 1000/2126 (2025-10-02_18-46-57)
2025-10-02 18:47:27,077 | INFO | validation: 1100/2126 (2025-10-02_18-47-27)
2025-10-02 18:47:55,967 | INFO | validation: 1200/2126 (2025-10-02_18-47-55)
2025-10-02 18:48:26,179 | INFO | validation: 1300/2126 (2025-10-02_18-48-26)
2025-10-02 18:48:54,034 | INFO | validation: 1400/2126 (2025-10-02_18-48-54)
2025-10-02 18:49:22,573 | INFO | validation: 1500/2126 (2025-10-02_18-49-22)
2025-10-02 18:49:51,446 | INFO | validation: 1600/2126 (2025-10-02_18-49-51)
2025-10-02 18:50:19,317 | INFO | validation: 1700/2126 (2025-10-02_18-50-19)
2025-10-02 18:50:48,517 | INFO | validation: 1800/2126 (2025-10-02_18-50-48)
2025-10-02 18:51:18,381 | INFO | validation: 1900/2126 (2025-10-02_18-51-18)
2025-10-02 18:51:45,589 | INFO | validation: 2000/2126 (2025-10-02_18-51-45)
2025-10-02 18:52:13,480 | INFO | validation: 2100/2126 (2025-10-02_18-52-13)
2025-10-02 18:52:21,848 | INFO | Confusion Matrix of Localization:
[[1291614836    7855597]
 [   8647767   43496264]]
2025-10-02 18:52:21,849 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99395477 0.00604523]
 [0.16584385 0.83415615]]
2025-10-02 18:52:21,849 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 39240508  4087077    99293    23356]
 [       0   941491  1836217   303014    15481]
 [       0   364714   994758  1454794    88665]
 [       0   257628   153877    67607  1503163]]
2025-10-02 18:52:21,849 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.03113847e-01 9.40634060e-02 2.28521209e-03
  5.37534504e-04]
 [0.00000000e+00 3.04079222e-01 5.93054461e-01 9.78663221e-02
  4.99999516e-03]
 [0.00000000e+00 1.25636469e-01 3.42673663e-01 5.01146600e-01
  3.05432682e-02]
 [0.00000000e+00 1.29965822e-01 7.76264645e-02 3.41057623e-02
  7.58301951e-01]]
2025-10-02 18:52:21,849 | INFO | lofF1 is 84.0541, clfF1 is 59.6718, oaF1 is 66.9865, sub class F1 score is [93.1475 36.1171 60.2694 83.21  ]
2025-10-02 18:52:22,107 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step6250.pth
2025-10-02 18:52:22,108 | INFO | ---------starting train set evaluation-----------
2025-10-02 18:52:22,607 | INFO | [TrainBuf] locF1 is 83.9217, clfF1 is 55.3525, oaF1 is 63.9233, sub class F1 score is [92.9587 37.1906 53.0845 63.3706]
2025-10-02 18:52:54,942 | INFO | iter is 6300 / 100000 [skipped   22] | loc. loss = 0.1684072316, classif. loss = 0.5872564316
2025-10-02 18:53:27,282 | INFO | iter is 6350 / 100000 [skipped   22] | loc. loss = 0.1674823314, classif. loss = 0.0839915425
2025-10-02 18:53:59,625 | INFO | iter is 6400 / 100000 [skipped   22] | loc. loss = 0.2302639782, classif. loss = 0.6018232107
2025-10-02 18:54:31,312 | INFO | iter is 6450 / 100000 [skipped   23] | loc. loss = 0.1164260954, classif. loss = 1.0747241974
2025-10-02 18:55:03,680 | INFO | iter is 6500 / 100000 [skipped   23] | loc. loss = 0.2768959701, classif. loss = 0.2734544575
2025-10-02 18:55:36,026 | INFO | iter is 6550 / 100000 [skipped   23] | loc. loss = 0.2224693298, classif. loss = 1.0290079117
2025-10-02 18:56:08,417 | INFO | iter is 6600 / 100000 [skipped   23] | loc. loss = 0.1491043419, classif. loss = 0.0770167857
2025-10-02 18:56:40,777 | INFO | iter is 6650 / 100000 [skipped   23] | loc. loss = 0.1760571599, classif. loss = 0.7653491497
2025-10-02 18:57:12,627 | INFO | iter is 6700 / 100000 [skipped   24] | loc. loss = 0.2038941979, classif. loss = 0.1649152637
2025-10-02 18:57:44,987 | INFO | iter is 6750 / 100000 [skipped   24] | loc. loss = 0.2136986852, classif. loss = 1.5144631863
2025-10-02 18:58:17,396 | INFO | iter is 6800 / 100000 [skipped   24] | loc. loss = 0.2092632055, classif. loss = 1.4647063017
2025-10-02 18:58:49,653 | INFO | iter is 6850 / 100000 [skipped   24] | loc. loss = 0.1588101089, classif. loss = 0.0266901497
2025-10-02 18:59:22,038 | INFO | iter is 6900 / 100000 [skipped   24] | loc. loss = 0.1226305366, classif. loss = 0.5417295694
2025-10-02 18:59:54,413 | INFO | iter is 6950 / 100000 [skipped   24] | loc. loss = 0.2857855558, classif. loss = 0.7187730670
2025-10-02 19:00:26,886 | INFO | iter is 7000 / 100000 [skipped   24] | loc. loss = 0.2735309005, classif. loss = 0.1092889905
2025-10-02 19:00:59,218 | INFO | iter is 7050 / 100000 [skipped   24] | loc. loss = 0.1672073901, classif. loss = 1.3241083622
2025-10-02 19:01:31,578 | INFO | iter is 7100 / 100000 [skipped   24] | loc. loss = 0.2474363446, classif. loss = 0.5180723667
2025-10-02 19:02:03,334 | INFO | iter is 7150 / 100000 [skipped   25] | loc. loss = 0.2321667075, classif. loss = 0.1081730574
2025-10-02 19:02:35,667 | INFO | iter is 7200 / 100000 [skipped   25] | loc. loss = 0.2033275962, classif. loss = 0.2026589811
2025-10-02 19:03:08,070 | INFO | iter is 7250 / 100000 [skipped   25] | loc. loss = 0.2029127330, classif. loss = 0.6425568461
2025-10-02 19:03:40,359 | INFO | iter is 7300 / 100000 [skipped   25] | loc. loss = 0.1497764736, classif. loss = 0.7040730715
2025-10-02 19:04:12,812 | INFO | iter is 7350 / 100000 [skipped   25] | loc. loss = 0.2306880951, classif. loss = 0.3822964728
2025-10-02 19:04:45,192 | INFO | iter is 7400 / 100000 [skipped   25] | loc. loss = 0.1734539270, classif. loss = 0.1624336094
2025-10-02 19:05:17,601 | INFO | iter is 7450 / 100000 [skipped   25] | loc. loss = 0.2306543589, classif. loss = 1.1353465319
2025-10-02 19:05:49,945 | INFO | iter is 7500 / 100000 [skipped   25] | loc. loss = 0.1886899769, classif. loss = 0.9960066080
2025-10-02 19:06:53,513 | INFO | iter is 7600 / 100000 [skipped   27] | loc. loss = 0.2283903062, classif. loss = 0.8725902438
2025-10-02 19:07:26,004 | INFO | iter is 7650 / 100000 [skipped   27] | loc. loss = 0.2072387189, classif. loss = 1.2387646437
2025-10-02 19:07:58,439 | INFO | iter is 7700 / 100000 [skipped   27] | loc. loss = 0.1634060740, classif. loss = 0.2611006796
2025-10-02 19:08:30,865 | INFO | iter is 7750 / 100000 [skipped   27] | loc. loss = 0.2210193872, classif. loss = 1.0275166035
2025-10-02 19:09:03,239 | INFO | iter is 7800 / 100000 [skipped   27] | loc. loss = 0.1442236155, classif. loss = 0.0388167277
2025-10-02 19:09:34,901 | INFO | iter is 7850 / 100000 [skipped   28] | loc. loss = 0.1948910654, classif. loss = 0.7169182301
2025-10-02 19:10:07,234 | INFO | iter is 7900 / 100000 [skipped   28] | loc. loss = 0.2222081870, classif. loss = 0.8471087217
2025-10-02 19:10:39,567 | INFO | iter is 7950 / 100000 [skipped   28] | loc. loss = 0.2667709291, classif. loss = 0.7096808553
2025-10-02 19:11:11,245 | INFO | iter is 8000 / 100000 [skipped   29] | loc. loss = 0.0899067447, classif. loss = 0.6016786695
2025-10-02 19:11:43,793 | INFO | iter is 8050 / 100000 [skipped   29] | loc. loss = 0.1373022050, classif. loss = 1.3750151396
2025-10-02 19:12:15,480 | INFO | iter is 8100 / 100000 [skipped   30] | loc. loss = 0.1832809597, classif. loss = 0.4477944076
2025-10-02 19:12:46,639 | INFO | iter is 8150 / 100000 [skipped   32] | loc. loss = 0.1720499843, classif. loss = 0.8987162709
2025-10-02 19:13:18,363 | INFO | iter is 8200 / 100000 [skipped   33] | loc. loss = 0.2800451219, classif. loss = 0.8172670007
2025-10-02 19:13:50,238 | INFO | iter is 8250 / 100000 [skipped   34] | loc. loss = 0.1866470873, classif. loss = 0.9276930690
2025-10-02 19:14:22,615 | INFO | iter is 8300 / 100000 [skipped   34] | loc. loss = 0.1847001612, classif. loss = 0.0542327613
2025-10-02 19:14:55,066 | INFO | iter is 8350 / 100000 [skipped   34] | loc. loss = 0.1330340058, classif. loss = 0.8443499207
2025-10-02 19:15:27,479 | INFO | iter is 8400 / 100000 [skipped   34] | loc. loss = 0.3290005922, classif. loss = 0.9348199368
2025-10-02 19:15:59,855 | INFO | iter is 8450 / 100000 [skipped   34] | loc. loss = 0.2802542150, classif. loss = 1.0174289942
2025-10-02 19:16:32,200 | INFO | iter is 8500 / 100000 [skipped   34] | loc. loss = 0.1454205513, classif. loss = 0.2874572277
2025-10-02 19:17:04,580 | INFO | iter is 8550 / 100000 [skipped   34] | loc. loss = 0.2219524980, classif. loss = 0.1292597055
2025-10-02 19:17:36,911 | INFO | iter is 8600 / 100000 [skipped   34] | loc. loss = 0.2358520031, classif. loss = 0.1679183543
2025-10-02 19:18:09,321 | INFO | iter is 8650 / 100000 [skipped   34] | loc. loss = 0.2697290778, classif. loss = 0.7811163664
2025-10-02 19:18:41,708 | INFO | iter is 8700 / 100000 [skipped   34] | loc. loss = 0.2856454849, classif. loss = 0.9640885592
2025-10-02 19:19:13,544 | INFO | iter is 8750 / 100000 [skipped   35] | loc. loss = 0.1452549398, classif. loss = 1.2441585064
2025-10-02 19:19:45,269 | INFO | iter is 8800 / 100000 [skipped   36] | loc. loss = 0.2606898546, classif. loss = 0.1736351401
2025-10-02 19:20:16,480 | INFO | iter is 8850 / 100000 [skipped   38] | loc. loss = 0.2438179553, classif. loss = 0.1688115299
2025-10-02 19:20:48,783 | INFO | iter is 8900 / 100000 [skipped   38] | loc. loss = 0.2890759110, classif. loss = 0.0881234109
2025-10-02 19:21:21,081 | INFO | iter is 8950 / 100000 [skipped   38] | loc. loss = 0.1921600401, classif. loss = 1.9044750929
2025-10-02 19:21:53,404 | INFO | iter is 9000 / 100000 [skipped   38] | loc. loss = 0.0842126608, classif. loss = 0.2857234478
2025-10-02 19:22:25,234 | INFO | iter is 9050 / 100000 [skipped   39] | loc. loss = 0.1814844608, classif. loss = 0.6109285355
2025-10-02 19:22:57,631 | INFO | iter is 9100 / 100000 [skipped   39] | loc. loss = 0.2335447371, classif. loss = 0.6044051647
2025-10-02 19:23:30,028 | INFO | iter is 9150 / 100000 [skipped   39] | loc. loss = 0.1144100204, classif. loss = 0.9971233010
2025-10-02 19:24:02,501 | INFO | iter is 9200 / 100000 [skipped   39] | loc. loss = 0.2326422483, classif. loss = 2.0783405304
2025-10-02 19:24:34,347 | INFO | iter is 9250 / 100000 [skipped   40] | loc. loss = 0.1547813416, classif. loss = 0.0208138525
2025-10-02 19:25:06,223 | INFO | iter is 9300 / 100000 [skipped   41] | loc. loss = 0.1122145355, classif. loss = 0.2457232624
2025-10-02 19:25:38,574 | INFO | iter is 9350 / 100000 [skipped   41] | loc. loss = 0.2605728507, classif. loss = 0.5353293419
2025-10-02 19:25:54,746 | INFO | ---------starting evaluation-----------
2025-10-02 19:25:55,225 | INFO | validation:    0/2126 (2025-10-02_19-25-55)
2025-10-02 19:26:23,157 | INFO | validation:  100/2126 (2025-10-02_19-26-23)
2025-10-02 19:26:51,722 | INFO | validation:  200/2126 (2025-10-02_19-26-51)
2025-10-02 19:27:17,942 | INFO | validation:  300/2126 (2025-10-02_19-27-17)
2025-10-02 19:27:46,829 | INFO | validation:  400/2126 (2025-10-02_19-27-46)
2025-10-02 19:28:16,761 | INFO | validation:  500/2126 (2025-10-02_19-28-16)
2025-10-02 19:28:47,010 | INFO | validation:  600/2126 (2025-10-02_19-28-47)
2025-10-02 19:29:13,229 | INFO | validation:  700/2126 (2025-10-02_19-29-13)
2025-10-02 19:29:42,114 | INFO | validation:  800/2126 (2025-10-02_19-29-42)
2025-10-02 19:30:09,338 | INFO | validation:  900/2126 (2025-10-02_19-30-09)
2025-10-02 19:30:41,597 | INFO | validation: 1000/2126 (2025-10-02_19-30-41)
2025-10-02 19:31:11,156 | INFO | validation: 1100/2126 (2025-10-02_19-31-11)
2025-10-02 19:31:40,051 | INFO | validation: 1200/2126 (2025-10-02_19-31-40)
2025-10-02 19:32:10,306 | INFO | validation: 1300/2126 (2025-10-02_19-32-10)
2025-10-02 19:32:38,194 | INFO | validation: 1400/2126 (2025-10-02_19-32-38)
2025-10-02 19:33:06,743 | INFO | validation: 1500/2126 (2025-10-02_19-33-06)
2025-10-02 19:33:35,627 | INFO | validation: 1600/2126 (2025-10-02_19-33-35)
2025-10-02 19:34:03,508 | INFO | validation: 1700/2126 (2025-10-02_19-34-03)
2025-10-02 19:34:32,757 | INFO | validation: 1800/2126 (2025-10-02_19-34-32)
2025-10-02 19:35:02,656 | INFO | validation: 1900/2126 (2025-10-02_19-35-02)
2025-10-02 19:35:29,882 | INFO | validation: 2000/2126 (2025-10-02_19-35-29)
2025-10-02 19:35:57,776 | INFO | validation: 2100/2126 (2025-10-02_19-35-57)
2025-10-02 19:36:06,156 | INFO | Confusion Matrix of Localization:
[[1292539920    6930513]
 [   8332024   43812007]]
2025-10-02 19:36:06,156 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99466666 0.00533334]
 [0.15978864 0.84021136]]
2025-10-02 19:36:06,156 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41694283  1281040   291115   183796]
 [       0  1190381  1352865   487996    64961]
 [       0   385037   348141  1968034   201719]
 [       0   119632    36060    79570  1747013]]
2025-10-02 19:36:06,157 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95958708 0.02948293 0.00669996 0.00423003]
 [0.         0.38446478 0.43694325 0.15761111 0.02098086]
 [0.         0.13263732 0.11992741 0.67794722 0.06948805]
 [0.         0.06035086 0.01819122 0.04014075 0.88131717]]
2025-10-02 19:36:06,157 | INFO | lofF1 is 85.1657, clfF1 is 67.1920, oaF1 is 72.5841, sub class F1 score is [96.026  44.2524 68.6965 83.5939]
2025-10-02 19:36:06,415 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step9375.pth
2025-10-02 19:36:06,415 | INFO | ---------starting train set evaluation-----------
2025-10-02 19:36:06,919 | INFO | [TrainBuf] locF1 is 85.8730, clfF1 is 61.7828, oaF1 is 69.0099, sub class F1 score is [94.3081 42.3442 59.0878 73.5324]
2025-10-02 19:36:23,190 | INFO | iter is 9400 / 100000 [skipped   41] | loc. loss = 0.2760265172, classif. loss = 0.4814901948
2025-10-02 19:36:55,492 | INFO | iter is 9450 / 100000 [skipped   41] | loc. loss = 0.1320987195, classif. loss = 0.5350229144
2025-10-02 19:37:27,897 | INFO | iter is 9500 / 100000 [skipped   41] | loc. loss = 0.2105503976, classif. loss = 0.4690492749
2025-10-02 19:38:00,214 | INFO | iter is 9550 / 100000 [skipped   41] | loc. loss = 0.2523069978, classif. loss = 0.2422392964
2025-10-02 19:38:32,641 | INFO | iter is 9600 / 100000 [skipped   41] | loc. loss = 0.1230746433, classif. loss = 0.8018519878
2025-10-02 19:39:04,967 | INFO | iter is 9650 / 100000 [skipped   41] | loc. loss = 0.1547748744, classif. loss = 0.4499356747
2025-10-02 19:39:37,430 | INFO | iter is 9700 / 100000 [skipped   41] | loc. loss = 0.2573622167, classif. loss = 0.5484310985
2025-10-02 19:40:09,727 | INFO | iter is 9750 / 100000 [skipped   41] | loc. loss = 0.1880198270, classif. loss = 0.8963240385
2025-10-02 19:40:42,152 | INFO | iter is 9800 / 100000 [skipped   41] | loc. loss = 0.2174568027, classif. loss = 0.2339027226
2025-10-02 19:41:14,491 | INFO | iter is 9850 / 100000 [skipped   41] | loc. loss = 0.1447059065, classif. loss = 0.3473655581
2025-10-02 19:41:46,959 | INFO | iter is 9900 / 100000 [skipped   41] | loc. loss = 0.3319392502, classif. loss = 1.1521413326
2025-10-02 19:42:19,283 | INFO | iter is 9950 / 100000 [skipped   41] | loc. loss = 0.1486423463, classif. loss = 1.2405960560
2025-10-02 19:42:51,803 | INFO | iter is 10000 / 100000 [skipped   41] | loc. loss = 0.2057571113, classif. loss = 0.6614714861
2025-10-02 19:43:24,123 | INFO | iter is 10050 / 100000 [skipped   41] | loc. loss = 0.1311977655, classif. loss = 0.0831370279
2025-10-02 19:43:56,484 | INFO | iter is 10100 / 100000 [skipped   41] | loc. loss = 0.2458705902, classif. loss = 0.3020721674
2025-10-02 19:44:28,879 | INFO | iter is 10150 / 100000 [skipped   41] | loc. loss = 0.2167608738, classif. loss = 0.3331474066
2025-10-02 19:45:00,592 | INFO | iter is 10200 / 100000 [skipped   42] | loc. loss = 0.2779982984, classif. loss = 0.3848257065
2025-10-02 19:45:32,915 | INFO | iter is 10250 / 100000 [skipped   42] | loc. loss = 0.3246014714, classif. loss = 0.7300869823
2025-10-02 19:46:05,357 | INFO | iter is 10300 / 100000 [skipped   42] | loc. loss = 0.1743308604, classif. loss = 0.7732632160
2025-10-02 19:46:37,744 | INFO | iter is 10350 / 100000 [skipped   42] | loc. loss = 0.1643451005, classif. loss = 0.3928863406
2025-10-02 19:47:10,112 | INFO | iter is 10400 / 100000 [skipped   42] | loc. loss = 0.1697814018, classif. loss = 1.5871460438
2025-10-02 19:47:42,473 | INFO | iter is 10450 / 100000 [skipped   42] | loc. loss = 0.1997634768, classif. loss = 0.5444386005
2025-10-02 19:48:14,805 | INFO | iter is 10500 / 100000 [skipped   42] | loc. loss = 0.1588129699, classif. loss = 0.3881181180
2025-10-02 19:48:47,221 | INFO | iter is 10550 / 100000 [skipped   42] | loc. loss = 0.1276124269, classif. loss = 0.8589621782
2025-10-02 19:49:19,561 | INFO | iter is 10600 / 100000 [skipped   42] | loc. loss = 0.0719697848, classif. loss = 0.4487983584
2025-10-02 19:49:51,982 | INFO | iter is 10650 / 100000 [skipped   42] | loc. loss = 0.1800971180, classif. loss = 0.9597141743
2025-10-02 19:50:24,337 | INFO | iter is 10700 / 100000 [skipped   42] | loc. loss = 0.2234036475, classif. loss = 1.0470635891
2025-10-02 19:50:56,659 | INFO | iter is 10750 / 100000 [skipped   42] | loc. loss = 0.2514023483, classif. loss = 0.5983796120
2025-10-02 19:51:28,386 | INFO | iter is 10800 / 100000 [skipped   43] | loc. loss = 0.2928877473, classif. loss = 0.2771178484
2025-10-02 19:52:00,722 | INFO | iter is 10850 / 100000 [skipped   43] | loc. loss = 0.2970420718, classif. loss = 3.7064342499
2025-10-02 19:52:33,132 | INFO | iter is 10900 / 100000 [skipped   43] | loc. loss = 0.1915326416, classif. loss = 0.1712457985
2025-10-02 19:53:05,535 | INFO | iter is 10950 / 100000 [skipped   43] | loc. loss = 0.2210733593, classif. loss = 0.9999805093
2025-10-02 19:53:37,937 | INFO | iter is 11000 / 100000 [skipped   43] | loc. loss = 0.1754054129, classif. loss = 0.1872906089
2025-10-02 19:54:10,328 | INFO | iter is 11050 / 100000 [skipped   43] | loc. loss = 0.2223137319, classif. loss = 0.8512090445
2025-10-02 19:54:42,712 | INFO | iter is 11100 / 100000 [skipped   43] | loc. loss = 0.0970431715, classif. loss = 1.0642378330
2025-10-02 19:55:15,157 | INFO | iter is 11150 / 100000 [skipped   43] | loc. loss = 0.2305507660, classif. loss = 1.2071046829
2025-10-02 19:55:47,521 | INFO | iter is 11200 / 100000 [skipped   43] | loc. loss = 0.3062665462, classif. loss = 1.5002186298
2025-10-02 19:56:19,890 | INFO | iter is 11250 / 100000 [skipped   43] | loc. loss = 0.2195076942, classif. loss = 0.6122416854
2025-10-02 19:56:52,275 | INFO | iter is 11300 / 100000 [skipped   43] | loc. loss = 0.1195584610, classif. loss = 0.0186037011
2025-10-02 19:57:24,641 | INFO | iter is 11350 / 100000 [skipped   43] | loc. loss = 0.1423637718, classif. loss = 0.1746278256
2025-10-02 19:57:57,115 | INFO | iter is 11400 / 100000 [skipped   43] | loc. loss = 0.1464636326, classif. loss = 0.8068251610
2025-10-02 19:58:29,493 | INFO | iter is 11450 / 100000 [skipped   43] | loc. loss = 0.2110789418, classif. loss = 0.1546664089
2025-10-02 19:59:01,964 | INFO | iter is 11500 / 100000 [skipped   43] | loc. loss = 0.0913506746, classif. loss = 0.3122070134
2025-10-02 19:59:34,364 | INFO | iter is 11550 / 100000 [skipped   43] | loc. loss = 0.1905647814, classif. loss = 0.5372694135
2025-10-02 20:00:06,761 | INFO | iter is 11600 / 100000 [skipped   43] | loc. loss = 0.1326570809, classif. loss = 1.5293872356
2025-10-02 20:00:39,141 | INFO | iter is 11650 / 100000 [skipped   43] | loc. loss = 0.3361409307, classif. loss = 0.5150150657
2025-10-02 20:01:11,627 | INFO | iter is 11700 / 100000 [skipped   43] | loc. loss = 0.2055368721, classif. loss = 0.5142618418
2025-10-02 20:01:44,010 | INFO | iter is 11750 / 100000 [skipped   43] | loc. loss = 0.2217987031, classif. loss = 0.1682108194
2025-10-02 20:02:16,438 | INFO | iter is 11800 / 100000 [skipped   43] | loc. loss = 0.1898870170, classif. loss = 1.0058617592
2025-10-02 20:02:48,839 | INFO | iter is 11850 / 100000 [skipped   43] | loc. loss = 0.1076295823, classif. loss = 0.0448977426
2025-10-02 20:03:21,290 | INFO | iter is 11900 / 100000 [skipped   43] | loc. loss = 0.1484640837, classif. loss = 0.6986595988
2025-10-02 20:03:53,051 | INFO | iter is 11950 / 100000 [skipped   44] | loc. loss = 0.1458373666, classif. loss = 0.1077512577
2025-10-02 20:04:25,499 | INFO | iter is 12000 / 100000 [skipped   44] | loc. loss = 0.1310783923, classif. loss = 0.5334196687
2025-10-02 20:04:57,254 | INFO | iter is 12050 / 100000 [skipped   45] | loc. loss = 0.2279109508, classif. loss = 0.5633763075
2025-10-02 20:05:29,719 | INFO | iter is 12100 / 100000 [skipped   45] | loc. loss = 0.2309099883, classif. loss = 0.5003027320
2025-10-02 20:06:02,041 | INFO | iter is 12150 / 100000 [skipped   45] | loc. loss = 0.2127254903, classif. loss = 0.5464757085
2025-10-02 20:06:34,455 | INFO | iter is 12200 / 100000 [skipped   45] | loc. loss = 0.2090518773, classif. loss = 0.6008443236
2025-10-02 20:07:06,287 | INFO | iter is 12250 / 100000 [skipped   46] | loc. loss = 0.2531184256, classif. loss = 1.0106458664
2025-10-02 20:07:38,597 | INFO | iter is 12300 / 100000 [skipped   46] | loc. loss = 0.1884796023, classif. loss = 1.2436295748
2025-10-02 20:08:10,904 | INFO | iter is 12350 / 100000 [skipped   46] | loc. loss = 0.2629116178, classif. loss = 0.6789835691
2025-10-02 20:08:43,257 | INFO | iter is 12400 / 100000 [skipped   46] | loc. loss = 0.2499266565, classif. loss = 0.5622186065
2025-10-02 20:09:15,660 | INFO | iter is 12450 / 100000 [skipped   46] | loc. loss = 0.1061245054, classif. loss = 1.1622900963
2025-10-02 20:09:48,004 | INFO | iter is 12500 / 100000 [skipped   46] | loc. loss = 0.1998331547, classif. loss = 0.2998643219
2025-10-02 20:09:48,005 | INFO | ---------starting evaluation-----------
2025-10-02 20:09:48,474 | INFO | validation:    0/2126 (2025-10-02_20-09-48)
2025-10-02 20:10:16,725 | INFO | validation:  100/2126 (2025-10-02_20-10-16)
2025-10-02 20:10:45,641 | INFO | validation:  200/2126 (2025-10-02_20-10-45)
2025-10-02 20:11:12,178 | INFO | validation:  300/2126 (2025-10-02_20-11-12)
2025-10-02 20:11:41,437 | INFO | validation:  400/2126 (2025-10-02_20-11-41)
2025-10-02 20:12:11,733 | INFO | validation:  500/2126 (2025-10-02_20-12-11)
2025-10-02 20:12:42,379 | INFO | validation:  600/2126 (2025-10-02_20-12-42)
2025-10-02 20:13:08,946 | INFO | validation:  700/2126 (2025-10-02_20-13-08)
2025-10-02 20:13:38,231 | INFO | validation:  800/2126 (2025-10-02_20-13-38)
2025-10-02 20:14:05,803 | INFO | validation:  900/2126 (2025-10-02_20-14-05)
2025-10-02 20:14:38,547 | INFO | validation: 1000/2126 (2025-10-02_20-14-38)
2025-10-02 20:15:08,539 | INFO | validation: 1100/2126 (2025-10-02_20-15-08)
2025-10-02 20:15:37,844 | INFO | validation: 1200/2126 (2025-10-02_20-15-37)
2025-10-02 20:16:08,522 | INFO | validation: 1300/2126 (2025-10-02_20-16-08)
2025-10-02 20:16:36,783 | INFO | validation: 1400/2126 (2025-10-02_20-16-36)
2025-10-02 20:17:05,766 | INFO | validation: 1500/2126 (2025-10-02_20-17-05)
2025-10-02 20:17:35,061 | INFO | validation: 1600/2126 (2025-10-02_20-17-35)
2025-10-02 20:18:03,326 | INFO | validation: 1700/2126 (2025-10-02_20-18-03)
2025-10-02 20:18:32,954 | INFO | validation: 1800/2126 (2025-10-02_20-18-32)
2025-10-02 20:19:03,252 | INFO | validation: 1900/2126 (2025-10-02_20-19-03)
2025-10-02 20:19:30,829 | INFO | validation: 2000/2126 (2025-10-02_20-19-30)
2025-10-02 20:19:59,107 | INFO | validation: 2100/2126 (2025-10-02_20-19-59)
2025-10-02 20:20:07,611 | INFO | Confusion Matrix of Localization:
[[1293420043    6050390]
 [   8526066   43617965]]
2025-10-02 20:20:07,611 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99534396 0.00465604]
 [0.16350991 0.83649009]]
2025-10-02 20:20:07,611 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41611377  1560365   171147   107345]
 [       0  1187970  1504648   354915    48670]
 [       0   404920   399343  1949115   149553]
 [       0   137073    40164   104437  1700601]]
2025-10-02 20:20:07,612 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95767901 0.03591154 0.00393892 0.00247053]
 [0.         0.38368608 0.48596555 0.11462911 0.01571925]
 [0.         0.13948661 0.13756545 0.67143001 0.05151793]
 [0.         0.06914934 0.02026157 0.05268542 0.85790367]]
2025-10-02 20:20:07,612 | INFO | lofF1 is 85.6830, clfF1 is 68.7828, oaF1 is 73.8529, sub class F1 score is [95.8881 45.5904 71.1026 85.2764]
2025-10-02 20:20:07,874 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step12500.pth
2025-10-02 20:20:07,874 | INFO | ---------starting train set evaluation-----------
2025-10-02 20:20:08,367 | INFO | [TrainBuf] locF1 is 86.0328, clfF1 is 62.2790, oaF1 is 69.4052, sub class F1 score is [93.9024 37.0268 66.3504 86.9657]
2025-10-02 20:20:40,688 | INFO | iter is 12550 / 100000 [skipped   46] | loc. loss = 0.3584029675, classif. loss = 0.2949636281
2025-10-02 20:21:12,979 | INFO | iter is 12600 / 100000 [skipped   46] | loc. loss = 0.2396466136, classif. loss = 0.5555518866
2025-10-02 20:21:45,369 | INFO | iter is 12650 / 100000 [skipped   46] | loc. loss = 0.2284522057, classif. loss = 0.9001006484
2025-10-02 20:22:17,742 | INFO | iter is 12700 / 100000 [skipped   46] | loc. loss = 0.2175447792, classif. loss = 0.4710031152
2025-10-02 20:22:50,043 | INFO | iter is 12750 / 100000 [skipped   46] | loc. loss = 0.2202925682, classif. loss = 0.0676997900
2025-10-02 20:23:21,711 | INFO | iter is 12800 / 100000 [skipped   47] | loc. loss = 0.1377187967, classif. loss = 0.1068982705
2025-10-02 20:23:54,135 | INFO | iter is 12850 / 100000 [skipped   47] | loc. loss = 0.1407325268, classif. loss = 0.4013304114
2025-10-02 20:24:26,480 | INFO | iter is 12900 / 100000 [skipped   47] | loc. loss = 0.0840816349, classif. loss = 0.0430685356
2025-10-02 20:24:58,883 | INFO | iter is 12950 / 100000 [skipped   47] | loc. loss = 0.1529379785, classif. loss = 0.1417715251
2025-10-02 20:25:30,694 | INFO | iter is 13000 / 100000 [skipped   48] | loc. loss = 0.1281576604, classif. loss = 0.5294235349
2025-10-02 20:26:03,051 | INFO | iter is 13050 / 100000 [skipped   48] | loc. loss = 0.1245230213, classif. loss = 0.0814183056
2025-10-02 20:26:35,409 | INFO | iter is 13100 / 100000 [skipped   48] | loc. loss = 0.1485979557, classif. loss = 0.5254858732
2025-10-02 20:27:07,213 | INFO | iter is 13150 / 100000 [skipped   49] | loc. loss = 0.1601781994, classif. loss = 0.2745133340
2025-10-02 20:27:39,567 | INFO | iter is 13200 / 100000 [skipped   49] | loc. loss = 0.2700865269, classif. loss = 0.2098644376
2025-10-02 20:28:11,931 | INFO | iter is 13250 / 100000 [skipped   49] | loc. loss = 0.1430031061, classif. loss = 1.2899243832
2025-10-02 20:28:44,275 | INFO | iter is 13300 / 100000 [skipped   49] | loc. loss = 0.2436835915, classif. loss = 0.1020156443
2025-10-02 20:29:16,611 | INFO | iter is 13350 / 100000 [skipped   49] | loc. loss = 0.3208363056, classif. loss = 1.4096765518
2025-10-02 20:29:48,928 | INFO | iter is 13400 / 100000 [skipped   49] | loc. loss = 0.2675711215, classif. loss = 0.6592354774
2025-10-02 20:30:21,350 | INFO | iter is 13450 / 100000 [skipped   49] | loc. loss = 0.0625744686, classif. loss = 0.7774195075
2025-10-02 20:30:53,594 | INFO | iter is 13500 / 100000 [skipped   49] | loc. loss = 0.2145571560, classif. loss = 0.0210490022
2025-10-02 20:31:25,346 | INFO | iter is 13550 / 100000 [skipped   50] | loc. loss = 0.1519755274, classif. loss = 0.1104001552
2025-10-02 20:31:57,630 | INFO | iter is 13600 / 100000 [skipped   50] | loc. loss = 0.0971272737, classif. loss = 0.2500422001
2025-10-02 20:32:30,050 | INFO | iter is 13650 / 100000 [skipped   50] | loc. loss = 0.3344174027, classif. loss = 0.3904578984
2025-10-02 20:33:02,426 | INFO | iter is 13700 / 100000 [skipped   50] | loc. loss = 0.0926154628, classif. loss = 0.3552368283
2025-10-02 20:33:34,792 | INFO | iter is 13750 / 100000 [skipped   50] | loc. loss = 0.2892964482, classif. loss = 0.0204582140
2025-10-02 20:34:07,181 | INFO | iter is 13800 / 100000 [skipped   50] | loc. loss = 0.2188263834, classif. loss = 0.4896180630
2025-10-02 20:34:39,612 | INFO | iter is 13850 / 100000 [skipped   50] | loc. loss = 0.0838429779, classif. loss = 0.1246639192
2025-10-02 20:35:12,020 | INFO | iter is 13900 / 100000 [skipped   50] | loc. loss = 0.3403765559, classif. loss = 1.2032943964
2025-10-02 20:35:44,445 | INFO | iter is 13950 / 100000 [skipped   50] | loc. loss = 0.3170190156, classif. loss = 0.0453966409
2025-10-02 20:36:16,935 | INFO | iter is 14000 / 100000 [skipped   50] | loc. loss = 0.1952131689, classif. loss = 0.0375720039
2025-10-02 20:36:49,271 | INFO | iter is 14050 / 100000 [skipped   50] | loc. loss = 0.1863770485, classif. loss = 0.8751966953
2025-10-02 20:37:21,705 | INFO | iter is 14100 / 100000 [skipped   50] | loc. loss = 0.3298237920, classif. loss = 1.0051977634
2025-10-02 20:37:54,050 | INFO | iter is 14150 / 100000 [skipped   50] | loc. loss = 0.1927999556, classif. loss = 0.0678979531
2025-10-02 20:38:26,501 | INFO | iter is 14200 / 100000 [skipped   50] | loc. loss = 0.1457515806, classif. loss = 0.4693528116
2025-10-02 20:38:58,814 | INFO | iter is 14250 / 100000 [skipped   50] | loc. loss = 0.2010595948, classif. loss = 0.4211694002
2025-10-02 20:39:31,278 | INFO | iter is 14300 / 100000 [skipped   50] | loc. loss = 0.1382983327, classif. loss = 0.1088470817
2025-10-02 20:40:03,685 | INFO | iter is 14350 / 100000 [skipped   50] | loc. loss = 0.2817473412, classif. loss = 0.7183228135
2025-10-02 20:40:36,091 | INFO | iter is 14400 / 100000 [skipped   50] | loc. loss = 0.4524286687, classif. loss = 0.5715738535
2025-10-02 20:41:08,423 | INFO | iter is 14450 / 100000 [skipped   50] | loc. loss = 0.2446516007, classif. loss = 0.6836169362
2025-10-02 20:41:40,846 | INFO | iter is 14500 / 100000 [skipped   50] | loc. loss = 0.2417418659, classif. loss = 0.6531423926
2025-10-02 20:42:12,529 | INFO | iter is 14550 / 100000 [skipped   51] | loc. loss = 0.2641374171, classif. loss = 1.1075451374
2025-10-02 20:42:44,979 | INFO | iter is 14600 / 100000 [skipped   51] | loc. loss = 0.1952286214, classif. loss = 1.1034969091
2025-10-02 20:43:17,367 | INFO | iter is 14650 / 100000 [skipped   51] | loc. loss = 0.1282656640, classif. loss = 0.5097224712
2025-10-02 20:43:49,851 | INFO | iter is 14700 / 100000 [skipped   51] | loc. loss = 0.1558311582, classif. loss = 1.5812441111
2025-10-02 20:44:22,198 | INFO | iter is 14750 / 100000 [skipped   51] | loc. loss = 0.1685010791, classif. loss = 0.5728299618
2025-10-02 20:44:54,657 | INFO | iter is 14800 / 100000 [skipped   51] | loc. loss = 0.2773494720, classif. loss = 0.8713984489
2025-10-02 20:45:27,005 | INFO | iter is 14850 / 100000 [skipped   51] | loc. loss = 0.2239264101, classif. loss = 0.5323185921
2025-10-02 20:45:59,398 | INFO | iter is 14900 / 100000 [skipped   51] | loc. loss = 0.2017721236, classif. loss = 0.4018939137
2025-10-02 20:46:31,731 | INFO | iter is 14950 / 100000 [skipped   51] | loc. loss = 0.2726515234, classif. loss = 0.7310004234
2025-10-02 20:47:04,182 | INFO | iter is 15000 / 100000 [skipped   51] | loc. loss = 0.1627310514, classif. loss = 1.2390201092
2025-10-02 20:47:35,968 | INFO | iter is 15050 / 100000 [skipped   52] | loc. loss = 0.2028316110, classif. loss = 0.5446878076
2025-10-02 20:48:08,288 | INFO | iter is 15100 / 100000 [skipped   52] | loc. loss = 0.2261004150, classif. loss = 0.2915881872
2025-10-02 20:48:40,659 | INFO | iter is 15150 / 100000 [skipped   52] | loc. loss = 0.1419771910, classif. loss = 0.4273348451
2025-10-02 20:49:13,000 | INFO | iter is 15200 / 100000 [skipped   52] | loc. loss = 0.2633171082, classif. loss = 1.1643068790
2025-10-02 20:49:44,755 | INFO | iter is 15250 / 100000 [skipped   53] | loc. loss = 0.1713948399, classif. loss = 0.5636764765
2025-10-02 20:50:17,099 | INFO | iter is 15300 / 100000 [skipped   53] | loc. loss = 0.1520476937, classif. loss = 0.1336718351
2025-10-02 20:50:49,466 | INFO | iter is 15350 / 100000 [skipped   53] | loc. loss = 0.2290754914, classif. loss = 0.1098526418
2025-10-02 20:51:21,806 | INFO | iter is 15400 / 100000 [skipped   53] | loc. loss = 0.2477909625, classif. loss = 0.0759692565
2025-10-02 20:51:54,146 | INFO | iter is 15450 / 100000 [skipped   53] | loc. loss = 0.2277048528, classif. loss = 0.7820965052
2025-10-02 20:52:26,506 | INFO | iter is 15500 / 100000 [skipped   53] | loc. loss = 0.2524200678, classif. loss = 0.7737171650
2025-10-02 20:52:58,903 | INFO | iter is 15550 / 100000 [skipped   53] | loc. loss = 0.1256405264, classif. loss = 0.5949970484
2025-10-02 20:53:31,269 | INFO | iter is 15600 / 100000 [skipped   53] | loc. loss = 0.2299232483, classif. loss = 2.1675326824
2025-10-02 20:53:47,450 | INFO | ---------starting evaluation-----------
2025-10-02 20:53:47,919 | INFO | validation:    0/2126 (2025-10-02_20-53-47)
2025-10-02 20:54:15,878 | INFO | validation:  100/2126 (2025-10-02_20-54-15)
2025-10-02 20:54:44,442 | INFO | validation:  200/2126 (2025-10-02_20-54-44)
2025-10-02 20:55:10,696 | INFO | validation:  300/2126 (2025-10-02_20-55-10)
2025-10-02 20:55:39,620 | INFO | validation:  400/2126 (2025-10-02_20-55-39)
2025-10-02 20:56:09,549 | INFO | validation:  500/2126 (2025-10-02_20-56-09)
2025-10-02 20:56:39,839 | INFO | validation:  600/2126 (2025-10-02_20-56-39)
2025-10-02 20:57:06,093 | INFO | validation:  700/2126 (2025-10-02_20-57-06)
2025-10-02 20:57:35,007 | INFO | validation:  800/2126 (2025-10-02_20-57-35)
2025-10-02 20:58:02,247 | INFO | validation:  900/2126 (2025-10-02_20-58-02)
2025-10-02 20:58:34,540 | INFO | validation: 1000/2126 (2025-10-02_20-58-34)
2025-10-02 20:59:04,151 | INFO | validation: 1100/2126 (2025-10-02_20-59-04)
2025-10-02 20:59:33,096 | INFO | validation: 1200/2126 (2025-10-02_20-59-33)
2025-10-02 21:00:03,382 | INFO | validation: 1300/2126 (2025-10-02_21-00-03)
2025-10-02 21:00:31,305 | INFO | validation: 1400/2126 (2025-10-02_21-00-31)
2025-10-02 21:00:59,904 | INFO | validation: 1500/2126 (2025-10-02_21-00-59)
2025-10-02 21:01:28,847 | INFO | validation: 1600/2126 (2025-10-02_21-01-28)
2025-10-02 21:01:56,761 | INFO | validation: 1700/2126 (2025-10-02_21-01-56)
2025-10-02 21:02:26,057 | INFO | validation: 1800/2126 (2025-10-02_21-02-26)
2025-10-02 21:02:56,011 | INFO | validation: 1900/2126 (2025-10-02_21-02-56)
2025-10-02 21:03:23,285 | INFO | validation: 2000/2126 (2025-10-02_21-03-23)
2025-10-02 21:03:51,226 | INFO | validation: 2100/2126 (2025-10-02_21-03-51)
2025-10-02 21:03:59,617 | INFO | Confusion Matrix of Localization:
[[1291901843    7568590]
 [   6731518   45412513]]
2025-10-02 21:03:59,617 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99417564 0.00582436]
 [0.1290947  0.8709053 ]]
2025-10-02 21:03:59,618 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 39594118  3330098   394614   131404]
 [       0   676461  1752292   632110    35340]
 [       0   115383   443733  2228226   115589]
 [       0   122881    51655   180279  1627460]]
2025-10-02 21:03:59,618 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.91125212 0.07664166 0.00908198 0.00302424]
 [0.         0.21848083 0.56594868 0.20415651 0.01141398]
 [0.         0.03974707 0.15285689 0.76757801 0.03981803]
 [0.         0.06198989 0.02605844 0.0909455  0.82100617]]
2025-10-02 21:03:59,618 | INFO | lofF1 is 86.3971, clfF1 is 65.0060, oaF1 is 71.4233, sub class F1 score is [94.3177 40.4034 70.3114 83.6296]
2025-10-02 21:03:59,618 | INFO | ---------starting train set evaluation-----------
2025-10-02 21:04:00,112 | INFO | [TrainBuf] locF1 is 86.2867, clfF1 is 68.3672, oaF1 is 73.7431, sub class F1 score is [94.9525 58.3624 53.2956 82.7923]
2025-10-02 21:04:16,366 | INFO | iter is 15650 / 100000 [skipped   53] | loc. loss = 0.1302880049, classif. loss = 0.9068261385
2025-10-02 21:04:48,726 | INFO | iter is 15700 / 100000 [skipped   53] | loc. loss = 0.1917627156, classif. loss = 0.6570073366
2025-10-02 21:05:20,596 | INFO | iter is 15750 / 100000 [skipped   54] | loc. loss = 0.1771432906, classif. loss = 0.0631746724
2025-10-02 21:05:52,970 | INFO | iter is 15800 / 100000 [skipped   54] | loc. loss = 0.1326778233, classif. loss = 0.4570894539
2025-10-02 21:06:25,412 | INFO | iter is 15850 / 100000 [skipped   54] | loc. loss = 0.1753759235, classif. loss = 0.4496993124
2025-10-02 21:06:57,733 | INFO | iter is 15900 / 100000 [skipped   54] | loc. loss = 0.3323450983, classif. loss = 0.7017802000
2025-10-02 21:07:30,253 | INFO | iter is 15950 / 100000 [skipped   54] | loc. loss = 0.1066843569, classif. loss = 1.0236954689
2025-10-02 21:08:02,628 | INFO | iter is 16000 / 100000 [skipped   54] | loc. loss = 0.1874567419, classif. loss = 1.0322706699
2025-10-02 21:08:34,962 | INFO | iter is 16050 / 100000 [skipped   54] | loc. loss = 0.1508218646, classif. loss = 0.6604757905
2025-10-02 21:09:07,374 | INFO | iter is 16100 / 100000 [skipped   54] | loc. loss = 0.0857848451, classif. loss = 0.0073709171
2025-10-02 21:09:39,710 | INFO | iter is 16150 / 100000 [skipped   54] | loc. loss = 0.2320770621, classif. loss = 0.6478835344
2025-10-02 21:10:12,150 | INFO | iter is 16200 / 100000 [skipped   54] | loc. loss = 0.0973286256, classif. loss = 0.4615851641
2025-10-02 21:10:44,567 | INFO | iter is 16250 / 100000 [skipped   54] | loc. loss = 0.1225813851, classif. loss = 0.6154508591
2025-10-02 21:11:16,958 | INFO | iter is 16300 / 100000 [skipped   54] | loc. loss = 0.2247442603, classif. loss = 0.4475194216
2025-10-02 21:11:49,243 | INFO | iter is 16350 / 100000 [skipped   54] | loc. loss = 0.0969152972, classif. loss = 0.0620791018
2025-10-02 21:12:21,651 | INFO | iter is 16400 / 100000 [skipped   54] | loc. loss = 0.2235623598, classif. loss = 1.3493883610
2025-10-02 21:12:54,058 | INFO | iter is 16450 / 100000 [skipped   54] | loc. loss = 0.0798553079, classif. loss = 0.6874659061
2025-10-02 21:13:26,532 | INFO | iter is 16500 / 100000 [skipped   54] | loc. loss = 0.1741011292, classif. loss = 0.7090578079
2025-10-02 21:13:58,916 | INFO | iter is 16550 / 100000 [skipped   54] | loc. loss = 0.2039099932, classif. loss = 1.7471305132
2025-10-02 21:14:31,403 | INFO | iter is 16600 / 100000 [skipped   54] | loc. loss = 0.0851674378, classif. loss = 0.3287532330
2025-10-02 21:15:03,777 | INFO | iter is 16650 / 100000 [skipped   54] | loc. loss = 0.2451249957, classif. loss = 1.0432697535
2025-10-02 21:15:34,937 | INFO | iter is 16700 / 100000 [skipped   56] | loc. loss = 0.1799310297, classif. loss = 0.2029365003
2025-10-02 21:16:07,308 | INFO | iter is 16750 / 100000 [skipped   56] | loc. loss = 0.2545992434, classif. loss = 0.7649350166
2025-10-02 21:16:39,733 | INFO | iter is 16800 / 100000 [skipped   56] | loc. loss = 0.2629323602, classif. loss = 0.6160620451
2025-10-02 21:17:12,232 | INFO | iter is 16850 / 100000 [skipped   56] | loc. loss = 0.2132739574, classif. loss = 0.7058531046
2025-10-02 21:17:44,579 | INFO | iter is 16900 / 100000 [skipped   56] | loc. loss = 0.1646728069, classif. loss = 0.3281150460
2025-10-02 21:18:17,010 | INFO | iter is 16950 / 100000 [skipped   56] | loc. loss = 0.2127993554, classif. loss = 1.8965606689
2025-10-02 21:18:48,841 | INFO | iter is 17000 / 100000 [skipped   57] | loc. loss = 0.1248552054, classif. loss = 0.2940107286
2025-10-02 21:19:21,232 | INFO | iter is 17050 / 100000 [skipped   57] | loc. loss = 0.1866673529, classif. loss = 0.3810507655
2025-10-02 21:19:53,619 | INFO | iter is 17100 / 100000 [skipped   57] | loc. loss = 0.2435674667, classif. loss = 0.6435046792
2025-10-02 21:20:25,982 | INFO | iter is 17150 / 100000 [skipped   57] | loc. loss = 0.1265252978, classif. loss = 0.9089342356
2025-10-02 21:20:58,381 | INFO | iter is 17200 / 100000 [skipped   57] | loc. loss = 0.2091822922, classif. loss = 1.5527678728
2025-10-02 21:21:30,734 | INFO | iter is 17250 / 100000 [skipped   57] | loc. loss = 0.1790551692, classif. loss = 0.8384193778
2025-10-02 21:22:03,186 | INFO | iter is 17300 / 100000 [skipped   57] | loc. loss = 0.1688137203, classif. loss = 0.7895164490
2025-10-02 21:22:35,568 | INFO | iter is 17350 / 100000 [skipped   57] | loc. loss = 0.3214728236, classif. loss = 1.1369874477
2025-10-02 21:23:08,033 | INFO | iter is 17400 / 100000 [skipped   57] | loc. loss = 0.2096502483, classif. loss = 0.4579558969
2025-10-02 21:23:40,400 | INFO | iter is 17450 / 100000 [skipped   57] | loc. loss = 0.1449768990, classif. loss = 1.2328503132
2025-10-02 21:24:12,219 | INFO | iter is 17500 / 100000 [skipped   58] | loc. loss = 0.2021120042, classif. loss = 0.7378149033
2025-10-02 21:24:44,586 | INFO | iter is 17550 / 100000 [skipped   58] | loc. loss = 0.1404338777, classif. loss = 0.9307551384
2025-10-02 21:25:16,986 | INFO | iter is 17600 / 100000 [skipped   58] | loc. loss = 0.2489380985, classif. loss = 0.8347342014
2025-10-02 21:25:49,366 | INFO | iter is 17650 / 100000 [skipped   58] | loc. loss = 0.1893679798, classif. loss = 0.3065923452
2025-10-02 21:26:21,244 | INFO | iter is 17700 / 100000 [skipped   59] | loc. loss = 0.1301239133, classif. loss = 0.0679679886
2025-10-02 21:26:53,539 | INFO | iter is 17750 / 100000 [skipped   59] | loc. loss = 0.2604535520, classif. loss = 1.0376410484
2025-10-02 21:27:26,040 | INFO | iter is 17800 / 100000 [skipped   59] | loc. loss = 0.2743967772, classif. loss = 0.6603056192
2025-10-02 21:27:57,910 | INFO | iter is 17850 / 100000 [skipped   60] | loc. loss = 0.1919458807, classif. loss = 0.0525695533
2025-10-02 21:28:30,287 | INFO | iter is 17900 / 100000 [skipped   60] | loc. loss = 0.2182352543, classif. loss = 0.0388488136
2025-10-02 21:29:02,830 | INFO | iter is 17950 / 100000 [skipped   60] | loc. loss = 0.1445554197, classif. loss = 0.1149455756
2025-10-02 21:29:35,350 | INFO | iter is 18000 / 100000 [skipped   60] | loc. loss = 0.1252688468, classif. loss = 0.5392732024
2025-10-02 21:30:07,766 | INFO | iter is 18050 / 100000 [skipped   60] | loc. loss = 0.1852061152, classif. loss = 0.8703244925
2025-10-02 21:30:39,032 | INFO | iter is 18100 / 100000 [skipped   62] | loc. loss = 0.1735902727, classif. loss = 0.1646626741
2025-10-02 21:31:11,391 | INFO | iter is 18150 / 100000 [skipped   62] | loc. loss = 0.2079531848, classif. loss = 0.8530606627
2025-10-02 21:31:43,875 | INFO | iter is 18200 / 100000 [skipped   62] | loc. loss = 0.1665163636, classif. loss = 0.6456878185
2025-10-02 21:32:16,263 | INFO | iter is 18250 / 100000 [skipped   62] | loc. loss = 0.1528025717, classif. loss = 1.0544058084
2025-10-02 21:32:48,769 | INFO | iter is 18300 / 100000 [skipped   62] | loc. loss = 0.1535059214, classif. loss = 0.8937505484
2025-10-02 21:33:20,628 | INFO | iter is 18350 / 100000 [skipped   63] | loc. loss = 0.2406632602, classif. loss = 0.2316341996
2025-10-02 21:33:53,092 | INFO | iter is 18400 / 100000 [skipped   63] | loc. loss = 0.1646429300, classif. loss = 0.0861453563
2025-10-02 21:34:25,520 | INFO | iter is 18450 / 100000 [skipped   63] | loc. loss = 0.1620303392, classif. loss = 1.4059703350
2025-10-02 21:34:57,894 | INFO | iter is 18500 / 100000 [skipped   63] | loc. loss = 0.1312972158, classif. loss = 2.4977324009
2025-10-02 21:35:30,379 | INFO | iter is 18550 / 100000 [skipped   63] | loc. loss = 0.2275629640, classif. loss = 0.8513964415
2025-10-02 21:36:02,761 | INFO | iter is 18600 / 100000 [skipped   63] | loc. loss = 0.3206252158, classif. loss = 0.3286659718
2025-10-02 21:36:35,163 | INFO | iter is 18650 / 100000 [skipped   63] | loc. loss = 0.2471252084, classif. loss = 0.4437575936
2025-10-02 21:37:07,498 | INFO | iter is 18700 / 100000 [skipped   63] | loc. loss = 0.2392151058, classif. loss = 0.1058920473
2025-10-02 21:37:39,913 | INFO | iter is 18750 / 100000 [skipped   63] | loc. loss = 0.2058161497, classif. loss = 0.5807471275
2025-10-02 21:37:39,915 | INFO | ---------starting evaluation-----------
2025-10-02 21:37:40,388 | INFO | validation:    0/2126 (2025-10-02_21-37-40)
2025-10-02 21:38:08,649 | INFO | validation:  100/2126 (2025-10-02_21-38-08)
2025-10-02 21:38:37,562 | INFO | validation:  200/2126 (2025-10-02_21-38-37)
2025-10-02 21:39:04,095 | INFO | validation:  300/2126 (2025-10-02_21-39-04)
2025-10-02 21:39:33,342 | INFO | validation:  400/2126 (2025-10-02_21-39-33)
2025-10-02 21:40:03,627 | INFO | validation:  500/2126 (2025-10-02_21-40-03)
2025-10-02 21:40:34,263 | INFO | validation:  600/2126 (2025-10-02_21-40-34)
2025-10-02 21:41:00,791 | INFO | validation:  700/2126 (2025-10-02_21-41-00)
2025-10-02 21:41:30,048 | INFO | validation:  800/2126 (2025-10-02_21-41-30)
2025-10-02 21:41:57,590 | INFO | validation:  900/2126 (2025-10-02_21-41-57)
2025-10-02 21:42:30,270 | INFO | validation: 1000/2126 (2025-10-02_21-42-30)
2025-10-02 21:43:00,221 | INFO | validation: 1100/2126 (2025-10-02_21-43-00)
2025-10-02 21:43:29,494 | INFO | validation: 1200/2126 (2025-10-02_21-43-29)
2025-10-02 21:44:00,161 | INFO | validation: 1300/2126 (2025-10-02_21-44-00)
2025-10-02 21:44:28,417 | INFO | validation: 1400/2126 (2025-10-02_21-44-28)
2025-10-02 21:44:57,344 | INFO | validation: 1500/2126 (2025-10-02_21-44-57)
2025-10-02 21:45:26,617 | INFO | validation: 1600/2126 (2025-10-02_21-45-26)
2025-10-02 21:45:54,843 | INFO | validation: 1700/2126 (2025-10-02_21-45-54)
2025-10-02 21:46:24,445 | INFO | validation: 1800/2126 (2025-10-02_21-46-24)
2025-10-02 21:46:54,724 | INFO | validation: 1900/2126 (2025-10-02_21-46-54)
2025-10-02 21:47:22,291 | INFO | validation: 2000/2126 (2025-10-02_21-47-22)
2025-10-02 21:47:50,539 | INFO | validation: 2100/2126 (2025-10-02_21-47-50)
2025-10-02 21:47:59,032 | INFO | Confusion Matrix of Localization:
[[1293077928    6392505]
 [   8074600   44069431]]
2025-10-02 21:47:59,032 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99508068 0.00491932]
 [0.15485186 0.84514814]]
2025-10-02 21:47:59,033 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42145793  1058216   176953    69272]
 [       0  1256100  1339388   451097    49618]
 [       0   384604   437265  1880143   200919]
 [       0   180105    35869    78333  1687968]]
2025-10-02 21:47:59,033 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.9699785  0.02435467 0.00407254 0.00159428]
 [0.         0.40569045 0.4325905  0.14569361 0.01602544]
 [0.         0.13248816 0.1506288  0.64767058 0.06921246]
 [0.         0.09085773 0.01809487 0.03951672 0.85153069]]
2025-10-02 21:47:59,033 | INFO | lofF1 is 85.9003, clfF1 is 67.7240, oaF1 is 73.1769, sub class F1 score is [96.4249 44.8936 68.5001 84.6088]
2025-10-02 21:47:59,033 | INFO | ---------starting train set evaluation-----------
2025-10-02 21:47:59,531 | INFO | [TrainBuf] locF1 is 86.5694, clfF1 is 69.3706, oaF1 is 74.5302, sub class F1 score is [94.9507 50.2833 66.4738 81.9759]
2025-10-02 21:48:31,875 | INFO | iter is 18800 / 100000 [skipped   63] | loc. loss = 0.1434304118, classif. loss = 0.5015242100
2025-10-02 21:49:04,351 | INFO | iter is 18850 / 100000 [skipped   63] | loc. loss = 0.2476738244, classif. loss = 0.6203212738
2025-10-02 21:49:36,698 | INFO | iter is 18900 / 100000 [skipped   63] | loc. loss = 0.1977134645, classif. loss = 0.4569798112
2025-10-02 21:50:09,126 | INFO | iter is 18950 / 100000 [skipped   63] | loc. loss = 0.2017439753, classif. loss = 0.8442485332
2025-10-02 21:50:41,459 | INFO | iter is 19000 / 100000 [skipped   63] | loc. loss = 0.3170938492, classif. loss = 1.0400453806
2025-10-02 21:51:13,915 | INFO | iter is 19050 / 100000 [skipped   63] | loc. loss = 0.0846100524, classif. loss = 1.7093912363
2025-10-02 21:51:46,312 | INFO | iter is 19100 / 100000 [skipped   63] | loc. loss = 0.2040309608, classif. loss = 0.1292757690
2025-10-02 21:52:18,784 | INFO | iter is 19150 / 100000 [skipped   63] | loc. loss = 0.3795022964, classif. loss = 3.5186402798
2025-10-02 21:52:51,113 | INFO | iter is 19200 / 100000 [skipped   63] | loc. loss = 0.0914061219, classif. loss = 0.2712243795
2025-10-02 21:53:23,563 | INFO | iter is 19250 / 100000 [skipped   63] | loc. loss = 0.1592303365, classif. loss = 0.1286746264
2025-10-02 21:53:55,873 | INFO | iter is 19300 / 100000 [skipped   63] | loc. loss = 0.1139191091, classif. loss = 1.4624454975
2025-10-02 21:54:28,291 | INFO | iter is 19350 / 100000 [skipped   63] | loc. loss = 0.2014515996, classif. loss = 0.5055487156
2025-10-02 21:55:00,633 | INFO | iter is 19400 / 100000 [skipped   63] | loc. loss = 0.1279003322, classif. loss = 0.0195564851
2025-10-02 21:55:33,071 | INFO | iter is 19450 / 100000 [skipped   63] | loc. loss = 0.2594142556, classif. loss = 0.5281126499
2025-10-02 21:56:05,417 | INFO | iter is 19500 / 100000 [skipped   63] | loc. loss = 0.4591188133, classif. loss = 1.2106058598
2025-10-02 21:56:37,923 | INFO | iter is 19550 / 100000 [skipped   63] | loc. loss = 0.2397244573, classif. loss = 0.6237287521
2025-10-02 21:57:10,282 | INFO | iter is 19600 / 100000 [skipped   63] | loc. loss = 0.2384007573, classif. loss = 1.0965386629
2025-10-02 21:57:42,591 | INFO | iter is 19650 / 100000 [skipped   63] | loc. loss = 0.2400068492, classif. loss = 0.9332107306
2025-10-02 21:58:14,983 | INFO | iter is 19700 / 100000 [skipped   63] | loc. loss = 0.2109860182, classif. loss = 0.9423059225
2025-10-02 21:58:47,321 | INFO | iter is 19750 / 100000 [skipped   63] | loc. loss = 0.1706050783, classif. loss = 0.3236559331
2025-10-02 21:59:19,669 | INFO | iter is 19800 / 100000 [skipped   63] | loc. loss = 0.1645094454, classif. loss = 0.4716316462
2025-10-02 21:59:52,128 | INFO | iter is 19850 / 100000 [skipped   63] | loc. loss = 0.1291452199, classif. loss = 0.5055043101
2025-10-02 22:00:24,506 | INFO | iter is 19900 / 100000 [skipped   63] | loc. loss = 0.2837782800, classif. loss = 0.0964279920
2025-10-02 22:00:56,978 | INFO | iter is 19950 / 100000 [skipped   63] | loc. loss = 0.2399281263, classif. loss = 1.0275530815
2025-10-02 22:01:28,652 | INFO | iter is 20000 / 100000 [skipped   64] | loc. loss = 0.1431989670, classif. loss = 0.7477381825
2025-10-02 22:02:00,986 | INFO | iter is 20050 / 100000 [skipped   64] | loc. loss = 0.1147061214, classif. loss = 0.4435676038
2025-10-02 22:02:32,736 | INFO | iter is 20100 / 100000 [skipped   65] | loc. loss = 0.2842721939, classif. loss = 0.3574966192
2025-10-02 22:03:04,550 | INFO | iter is 20150 / 100000 [skipped   66] | loc. loss = 0.2456246912, classif. loss = 0.1857192367
2025-10-02 22:03:37,078 | INFO | iter is 20200 / 100000 [skipped   66] | loc. loss = 0.1841129661, classif. loss = 0.9829033017
2025-10-02 22:04:09,419 | INFO | iter is 20250 / 100000 [skipped   66] | loc. loss = 0.3215225935, classif. loss = 0.8752882481
2025-10-02 22:04:41,855 | INFO | iter is 20300 / 100000 [skipped   66] | loc. loss = 0.2095281631, classif. loss = 0.0408757813
2025-10-02 22:05:14,232 | INFO | iter is 20350 / 100000 [skipped   66] | loc. loss = 0.1118121445, classif. loss = 0.6180592179
2025-10-02 22:05:46,658 | INFO | iter is 20400 / 100000 [skipped   66] | loc. loss = 0.2122442126, classif. loss = 1.2888716459
2025-10-02 22:06:19,016 | INFO | iter is 20450 / 100000 [skipped   66] | loc. loss = 0.1697601080, classif. loss = 0.0730035156
2025-10-02 22:06:51,489 | INFO | iter is 20500 / 100000 [skipped   66] | loc. loss = 0.1493159384, classif. loss = 0.2635779381
2025-10-02 22:07:23,841 | INFO | iter is 20550 / 100000 [skipped   66] | loc. loss = 0.2194035351, classif. loss = 0.6053903103
2025-10-02 22:07:56,242 | INFO | iter is 20600 / 100000 [skipped   66] | loc. loss = 0.1153280437, classif. loss = 0.2435152829
2025-10-02 22:08:28,557 | INFO | iter is 20650 / 100000 [skipped   66] | loc. loss = 0.0950213000, classif. loss = 0.1742271781
2025-10-02 22:09:01,001 | INFO | iter is 20700 / 100000 [skipped   66] | loc. loss = 0.0892810225, classif. loss = 0.8268454075
2025-10-02 22:09:33,350 | INFO | iter is 20750 / 100000 [skipped   66] | loc. loss = 0.2376815528, classif. loss = 2.3992998600
2025-10-02 22:10:05,707 | INFO | iter is 20800 / 100000 [skipped   66] | loc. loss = 0.1707747132, classif. loss = 1.6385842562
2025-10-02 22:10:38,108 | INFO | iter is 20850 / 100000 [skipped   66] | loc. loss = 0.2472267747, classif. loss = 1.1541258097
2025-10-02 22:11:09,982 | INFO | iter is 20900 / 100000 [skipped   67] | loc. loss = 0.0931416526, classif. loss = 0.6638388634
2025-10-02 22:11:42,330 | INFO | iter is 20950 / 100000 [skipped   67] | loc. loss = 0.2305222154, classif. loss = 0.6742085814
2025-10-02 22:12:14,676 | INFO | iter is 21000 / 100000 [skipped   67] | loc. loss = 0.2560160160, classif. loss = 0.6003976464
2025-10-02 22:12:46,501 | INFO | iter is 21050 / 100000 [skipped   68] | loc. loss = 0.2083355933, classif. loss = 0.6624915600
2025-10-02 22:13:18,979 | INFO | iter is 21100 / 100000 [skipped   68] | loc. loss = 0.1629539132, classif. loss = 0.5588869452
2025-10-02 22:13:51,548 | INFO | iter is 21150 / 100000 [skipped   68] | loc. loss = 0.1217938960, classif. loss = 1.0611267090
2025-10-02 22:14:23,975 | INFO | iter is 21200 / 100000 [skipped   68] | loc. loss = 0.1787015200, classif. loss = 0.9960231781
2025-10-02 22:14:56,461 | INFO | iter is 21250 / 100000 [skipped   68] | loc. loss = 0.1100002974, classif. loss = 1.3452575207
2025-10-02 22:15:28,265 | INFO | iter is 21300 / 100000 [skipped   69] | loc. loss = 0.2273795009, classif. loss = 1.2619174719
2025-10-02 22:16:00,652 | INFO | iter is 21350 / 100000 [skipped   69] | loc. loss = 0.1980570555, classif. loss = 0.1542755663
2025-10-02 22:16:33,124 | INFO | iter is 21400 / 100000 [skipped   69] | loc. loss = 0.2670114636, classif. loss = 0.1249063015
2025-10-02 22:17:04,915 | INFO | iter is 21450 / 100000 [skipped   70] | loc. loss = 0.0884908363, classif. loss = 0.3992397785
2025-10-02 22:17:37,406 | INFO | iter is 21500 / 100000 [skipped   70] | loc. loss = 0.1265152246, classif. loss = 0.1210539937
2025-10-02 22:18:09,166 | INFO | iter is 21550 / 100000 [skipped   71] | loc. loss = 0.1479453146, classif. loss = 1.2966717482
2025-10-02 22:18:40,881 | INFO | iter is 21600 / 100000 [skipped   72] | loc. loss = 0.2296078503, classif. loss = 0.1435211152
2025-10-02 22:19:13,318 | INFO | iter is 21650 / 100000 [skipped   72] | loc. loss = 0.1068910956, classif. loss = 1.5882208347
2025-10-02 22:19:45,725 | INFO | iter is 21700 / 100000 [skipped   72] | loc. loss = 0.2402546853, classif. loss = 0.0686536729
2025-10-02 22:20:18,204 | INFO | iter is 21750 / 100000 [skipped   72] | loc. loss = 0.1174543425, classif. loss = 0.3967957497
2025-10-02 22:20:50,530 | INFO | iter is 21800 / 100000 [skipped   72] | loc. loss = 0.1528319418, classif. loss = 0.1766176224
2025-10-02 22:21:22,898 | INFO | iter is 21850 / 100000 [skipped   72] | loc. loss = 0.1427593529, classif. loss = 0.0720618963
2025-10-02 22:21:39,083 | INFO | ---------starting evaluation-----------
2025-10-02 22:21:39,553 | INFO | validation:    0/2126 (2025-10-02_22-21-39)
2025-10-02 22:22:07,789 | INFO | validation:  100/2126 (2025-10-02_22-22-07)
2025-10-02 22:22:36,704 | INFO | validation:  200/2126 (2025-10-02_22-22-36)
2025-10-02 22:23:03,241 | INFO | validation:  300/2126 (2025-10-02_22-23-03)
2025-10-02 22:23:32,499 | INFO | validation:  400/2126 (2025-10-02_22-23-32)
2025-10-02 22:24:02,807 | INFO | validation:  500/2126 (2025-10-02_22-24-02)
2025-10-02 22:24:33,450 | INFO | validation:  600/2126 (2025-10-02_22-24-33)
2025-10-02 22:24:59,985 | INFO | validation:  700/2126 (2025-10-02_22-24-59)
2025-10-02 22:25:29,273 | INFO | validation:  800/2126 (2025-10-02_22-25-29)
2025-10-02 22:25:56,820 | INFO | validation:  900/2126 (2025-10-02_22-25-56)
2025-10-02 22:26:29,502 | INFO | validation: 1000/2126 (2025-10-02_22-26-29)
2025-10-02 22:26:59,449 | INFO | validation: 1100/2126 (2025-10-02_22-26-59)
2025-10-02 22:27:28,696 | INFO | validation: 1200/2126 (2025-10-02_22-27-28)
2025-10-02 22:27:59,324 | INFO | validation: 1300/2126 (2025-10-02_22-27-59)
2025-10-02 22:28:27,543 | INFO | validation: 1400/2126 (2025-10-02_22-28-27)
2025-10-02 22:28:56,454 | INFO | validation: 1500/2126 (2025-10-02_22-28-56)
2025-10-02 22:29:25,710 | INFO | validation: 1600/2126 (2025-10-02_22-29-25)
2025-10-02 22:29:53,929 | INFO | validation: 1700/2126 (2025-10-02_22-29-53)
2025-10-02 22:30:23,523 | INFO | validation: 1800/2126 (2025-10-02_22-30-23)
2025-10-02 22:30:53,808 | INFO | validation: 1900/2126 (2025-10-02_22-30-53)
2025-10-02 22:31:21,355 | INFO | validation: 2000/2126 (2025-10-02_22-31-21)
2025-10-02 22:31:49,590 | INFO | validation: 2100/2126 (2025-10-02_22-31-49)
2025-10-02 22:31:58,080 | INFO | Confusion Matrix of Localization:
[[1289943110    9527323]
 [   5344100   46799931]]
2025-10-02 22:31:58,081 | INFO | Confusion Matrix of Localization - Normalized:
[[0.9926683  0.0073317 ]
 [0.10248728 0.89751272]]
2025-10-02 22:31:58,081 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41163432  1571902   548376   166524]
 [       0   985708  1288351   774451    47693]
 [       0   173515   220828  2334640   173948]
 [       0    63797    17101   139322  1762055]]
2025-10-02 22:31:58,081 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.94736963 0.03617707 0.01262078 0.00383252]
 [0.         0.31836026 0.41610676 0.25012927 0.01540371]
 [0.         0.05977235 0.0760707  0.80423544 0.05992151]
 [0.         0.03218373 0.00862696 0.07028389 0.88890542]]
2025-10-02 22:31:58,081 | INFO | lofF1 is 86.2900, clfF1 is 66.0707, oaF1 is 72.1365, sub class F1 score is [95.911  41.5974 69.6937 85.278 ]
2025-10-02 22:31:58,082 | INFO | ---------starting train set evaluation-----------
2025-10-02 22:31:58,599 | INFO | [TrainBuf] locF1 is 87.5923, clfF1 is 75.8433, oaF1 is 79.3680, sub class F1 score is [96.0573 62.5701 76.2128 75.6048]
2025-10-02 22:32:14,886 | INFO | iter is 21900 / 100000 [skipped   72] | loc. loss = 0.1837248057, classif. loss = 0.8102793097
2025-10-02 22:32:46,701 | INFO | iter is 21950 / 100000 [skipped   73] | loc. loss = 0.1143635139, classif. loss = 0.5926461220
2025-10-02 22:33:19,077 | INFO | iter is 22000 / 100000 [skipped   73] | loc. loss = 0.1693637669, classif. loss = 0.5267080069
2025-10-02 22:33:51,521 | INFO | iter is 22050 / 100000 [skipped   73] | loc. loss = 0.1321580261, classif. loss = 0.3994295299
2025-10-02 22:34:23,921 | INFO | iter is 22100 / 100000 [skipped   73] | loc. loss = 0.1197789982, classif. loss = 0.0158465505
2025-10-02 22:34:56,308 | INFO | iter is 22150 / 100000 [skipped   73] | loc. loss = 0.2030868977, classif. loss = 0.6050603390
2025-10-02 22:35:28,714 | INFO | iter is 22200 / 100000 [skipped   73] | loc. loss = 0.2156946510, classif. loss = 0.0441649780
2025-10-02 22:36:01,113 | INFO | iter is 22250 / 100000 [skipped   73] | loc. loss = 0.1741681099, classif. loss = 1.0677797794
2025-10-02 22:36:33,536 | INFO | iter is 22300 / 100000 [skipped   73] | loc. loss = 0.1350502670, classif. loss = 0.1798278838
2025-10-02 22:37:05,962 | INFO | iter is 22350 / 100000 [skipped   73] | loc. loss = 0.1566177607, classif. loss = 0.6781749129
2025-10-02 22:37:38,340 | INFO | iter is 22400 / 100000 [skipped   73] | loc. loss = 0.1350271851, classif. loss = 2.1963493824
2025-10-02 22:38:10,757 | INFO | iter is 22450 / 100000 [skipped   73] | loc. loss = 0.1382521093, classif. loss = 1.4078935385
2025-10-02 22:38:42,420 | INFO | iter is 22500 / 100000 [skipped   74] | loc. loss = 0.1991679817, classif. loss = 0.6383703947
2025-10-02 22:39:14,795 | INFO | iter is 22550 / 100000 [skipped   74] | loc. loss = 0.2190937251, classif. loss = 0.3554706573
2025-10-02 22:39:46,570 | INFO | iter is 22600 / 100000 [skipped   75] | loc. loss = 0.4134851396, classif. loss = 0.4870949090
2025-10-02 22:40:18,934 | INFO | iter is 22650 / 100000 [skipped   75] | loc. loss = 0.1026002839, classif. loss = 0.6076675653
2025-10-02 22:40:51,274 | INFO | iter is 22700 / 100000 [skipped   75] | loc. loss = 0.2429479808, classif. loss = 1.2241888046
2025-10-02 22:41:23,671 | INFO | iter is 22750 / 100000 [skipped   75] | loc. loss = 0.2553296089, classif. loss = 0.7210814953
2025-10-02 22:41:55,987 | INFO | iter is 22800 / 100000 [skipped   75] | loc. loss = 0.1809725463, classif. loss = 0.5844357014
2025-10-02 22:42:28,396 | INFO | iter is 22850 / 100000 [skipped   75] | loc. loss = 0.1496477127, classif. loss = 0.0706489235
2025-10-02 22:43:00,733 | INFO | iter is 22900 / 100000 [skipped   75] | loc. loss = 0.2383784354, classif. loss = 0.4732279778
2025-10-02 22:43:33,102 | INFO | iter is 22950 / 100000 [skipped   75] | loc. loss = 0.1845881939, classif. loss = 0.5499602556
2025-10-02 22:44:04,879 | INFO | iter is 23000 / 100000 [skipped   76] | loc. loss = 0.2304851562, classif. loss = 0.7351028919
2025-10-02 22:44:36,639 | INFO | iter is 23050 / 100000 [skipped   77] | loc. loss = 0.2726561427, classif. loss = 0.8043810725
2025-10-02 22:45:09,078 | INFO | iter is 23100 / 100000 [skipped   77] | loc. loss = 0.1937716603, classif. loss = 0.9148889780
2025-10-02 22:45:41,554 | INFO | iter is 23150 / 100000 [skipped   77] | loc. loss = 0.3456962407, classif. loss = 0.2296522558
2025-10-02 22:46:13,350 | INFO | iter is 23200 / 100000 [skipped   78] | loc. loss = 0.1552848518, classif. loss = 1.0999338627
2025-10-02 22:46:45,758 | INFO | iter is 23250 / 100000 [skipped   78] | loc. loss = 0.1019491032, classif. loss = 0.5577948689
2025-10-02 22:47:18,141 | INFO | iter is 23300 / 100000 [skipped   78] | loc. loss = 0.3209618926, classif. loss = 0.6062239408
2025-10-02 22:47:50,564 | INFO | iter is 23350 / 100000 [skipped   78] | loc. loss = 0.2804426551, classif. loss = 1.0836634636
2025-10-02 22:48:23,033 | INFO | iter is 23400 / 100000 [skipped   78] | loc. loss = 0.1532834470, classif. loss = 0.2649461031
2025-10-02 22:48:55,470 | INFO | iter is 23450 / 100000 [skipped   78] | loc. loss = 0.2438306808, classif. loss = 0.8248927593
2025-10-02 22:49:27,994 | INFO | iter is 23500 / 100000 [skipped   78] | loc. loss = 0.1497640759, classif. loss = 0.0411051959
2025-10-02 22:50:00,411 | INFO | iter is 23550 / 100000 [skipped   78] | loc. loss = 0.2543213964, classif. loss = 0.4330543578
2025-10-02 22:50:32,274 | INFO | iter is 23600 / 100000 [skipped   79] | loc. loss = 0.2247945666, classif. loss = 0.7469072342
2025-10-02 22:51:04,105 | INFO | iter is 23650 / 100000 [skipped   80] | loc. loss = 0.3024734557, classif. loss = 0.6580109596
2025-10-02 22:51:36,055 | INFO | iter is 23700 / 100000 [skipped   81] | loc. loss = 0.1726371199, classif. loss = 0.1253688931
2025-10-02 22:52:08,472 | INFO | iter is 23750 / 100000 [skipped   81] | loc. loss = 0.1352952123, classif. loss = 0.4302456379
2025-10-02 22:52:40,981 | INFO | iter is 23800 / 100000 [skipped   81] | loc. loss = 0.1853638291, classif. loss = 0.8619899154
2025-10-02 22:53:13,367 | INFO | iter is 23850 / 100000 [skipped   81] | loc. loss = 0.0738304704, classif. loss = 0.2075911164
2025-10-02 22:53:45,768 | INFO | iter is 23900 / 100000 [skipped   81] | loc. loss = 0.1942810565, classif. loss = 0.1475710571
2025-10-02 22:54:18,280 | INFO | iter is 23950 / 100000 [skipped   81] | loc. loss = 0.0986649916, classif. loss = 0.0012841342
2025-10-02 22:54:50,151 | INFO | iter is 24000 / 100000 [skipped   82] | loc. loss = 0.3328776360, classif. loss = 0.7095188498
2025-10-02 22:55:22,551 | INFO | iter is 24050 / 100000 [skipped   82] | loc. loss = 0.1319639087, classif. loss = 0.4502097070
2025-10-02 22:55:54,940 | INFO | iter is 24100 / 100000 [skipped   82] | loc. loss = 0.1888093054, classif. loss = 0.6797415018
2025-10-02 22:56:27,324 | INFO | iter is 24150 / 100000 [skipped   82] | loc. loss = 0.1842737794, classif. loss = 0.2308371663
2025-10-02 22:56:59,774 | INFO | iter is 24200 / 100000 [skipped   82] | loc. loss = 0.1367509514, classif. loss = 0.5791023970
2025-10-02 22:57:31,495 | INFO | iter is 24250 / 100000 [skipped   83] | loc. loss = 0.1212187558, classif. loss = 0.3837096989
2025-10-02 22:58:03,852 | INFO | iter is 24300 / 100000 [skipped   83] | loc. loss = 0.2511885464, classif. loss = 1.8974349499
2025-10-02 22:58:36,323 | INFO | iter is 24350 / 100000 [skipped   83] | loc. loss = 0.1089181602, classif. loss = 0.0201351289
2025-10-02 22:59:08,764 | INFO | iter is 24400 / 100000 [skipped   83] | loc. loss = 0.1675828248, classif. loss = 0.5265526175
2025-10-02 22:59:41,110 | INFO | iter is 24450 / 100000 [skipped   83] | loc. loss = 0.1565409750, classif. loss = 0.2227523476
2025-10-02 23:00:13,460 | INFO | iter is 24500 / 100000 [skipped   83] | loc. loss = 0.1442948431, classif. loss = 0.5988422632
2025-10-02 23:00:45,790 | INFO | iter is 24550 / 100000 [skipped   83] | loc. loss = 0.3158038855, classif. loss = 0.3532879949
2025-10-02 23:01:17,526 | INFO | iter is 24600 / 100000 [skipped   84] | loc. loss = 0.1406527311, classif. loss = 0.4175170660
2025-10-02 23:01:49,931 | INFO | iter is 24650 / 100000 [skipped   84] | loc. loss = 0.1314973086, classif. loss = 0.0037413654
2025-10-02 23:02:22,367 | INFO | iter is 24700 / 100000 [skipped   84] | loc. loss = 0.1180104166, classif. loss = 0.7229468822
2025-10-02 23:02:54,768 | INFO | iter is 24750 / 100000 [skipped   84] | loc. loss = 0.2248012424, classif. loss = 0.1509414911
2025-10-02 23:03:27,164 | INFO | iter is 24800 / 100000 [skipped   84] | loc. loss = 0.2297801524, classif. loss = 0.0276994035
2025-10-02 23:03:59,578 | INFO | iter is 24850 / 100000 [skipped   84] | loc. loss = 0.1625889242, classif. loss = 1.5328677893
2025-10-02 23:04:32,006 | INFO | iter is 24900 / 100000 [skipped   84] | loc. loss = 0.2339027524, classif. loss = 0.9464898705
2025-10-02 23:05:04,362 | INFO | iter is 24950 / 100000 [skipped   84] | loc. loss = 0.2070565820, classif. loss = 1.2418265343
2025-10-02 23:05:36,726 | INFO | iter is 25000 / 100000 [skipped   84] | loc. loss = 0.2023338377, classif. loss = 0.0827014372
2025-10-02 23:05:36,727 | INFO | ---------starting evaluation-----------
2025-10-02 23:05:37,203 | INFO | validation:    0/2126 (2025-10-02_23-05-37)
2025-10-02 23:06:05,160 | INFO | validation:  100/2126 (2025-10-02_23-06-05)
2025-10-02 23:06:33,760 | INFO | validation:  200/2126 (2025-10-02_23-06-33)
2025-10-02 23:07:00,022 | INFO | validation:  300/2126 (2025-10-02_23-07-00)
2025-10-02 23:07:28,965 | INFO | validation:  400/2126 (2025-10-02_23-07-28)
2025-10-02 23:07:58,956 | INFO | validation:  500/2126 (2025-10-02_23-07-58)
2025-10-02 23:08:29,274 | INFO | validation:  600/2126 (2025-10-02_23-08-29)
2025-10-02 23:08:55,550 | INFO | validation:  700/2126 (2025-10-02_23-08-55)
2025-10-02 23:09:24,524 | INFO | validation:  800/2126 (2025-10-02_23-09-24)
2025-10-02 23:09:51,821 | INFO | validation:  900/2126 (2025-10-02_23-09-51)
2025-10-02 23:10:24,139 | INFO | validation: 1000/2126 (2025-10-02_23-10-24)
2025-10-02 23:10:53,776 | INFO | validation: 1100/2126 (2025-10-02_23-10-53)
2025-10-02 23:11:22,749 | INFO | validation: 1200/2126 (2025-10-02_23-11-22)
2025-10-02 23:11:53,039 | INFO | validation: 1300/2126 (2025-10-02_23-11-53)
2025-10-02 23:12:20,970 | INFO | validation: 1400/2126 (2025-10-02_23-12-20)
2025-10-02 23:12:49,606 | INFO | validation: 1500/2126 (2025-10-02_23-12-49)
2025-10-02 23:13:18,554 | INFO | validation: 1600/2126 (2025-10-02_23-13-18)
2025-10-02 23:13:46,506 | INFO | validation: 1700/2126 (2025-10-02_23-13-46)
2025-10-02 23:14:15,818 | INFO | validation: 1800/2126 (2025-10-02_23-14-15)
2025-10-02 23:14:45,762 | INFO | validation: 1900/2126 (2025-10-02_23-14-45)
2025-10-02 23:15:13,038 | INFO | validation: 2000/2126 (2025-10-02_23-15-13)
2025-10-02 23:15:40,990 | INFO | validation: 2100/2126 (2025-10-02_23-15-40)
2025-10-02 23:15:49,395 | INFO | Confusion Matrix of Localization:
[[1291744234    7726199]
 [   6497343   45646688]]
2025-10-02 23:15:49,395 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99405435 0.00594565]
 [0.12460377 0.87539623]]
2025-10-02 23:15:49,395 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40601357  2276104   392577   180196]
 [       0   834229  1583583   559715   118676]
 [       0   162145   457599  1955683   327504]
 [       0    89255    28300    55476  1809244]]
2025-10-02 23:15:49,395 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.93443356 0.05238416 0.0090351  0.00414718]
 [0.         0.26943614 0.51145968 0.18077465 0.03832953]
 [0.         0.05585562 0.15763344 0.67369255 0.11281839]
 [0.         0.04502655 0.01427653 0.02798603 0.9127109 ]]
2025-10-02 23:15:49,395 | INFO | lofF1 is 86.5201, clfF1 is 65.3715, oaF1 is 71.7161, sub class F1 score is [95.3786 42.5592 66.6742 81.9052]
2025-10-02 23:15:49,396 | INFO | ---------starting train set evaluation-----------
2025-10-02 23:15:49,892 | INFO | [TrainBuf] locF1 is 86.7981, clfF1 is 75.2463, oaF1 is 78.7119, sub class F1 score is [95.506  62.4154 75.6629 74.3494]
2025-10-02 23:16:22,290 | INFO | iter is 25050 / 100000 [skipped   84] | loc. loss = 0.1864971220, classif. loss = 0.7514805198
2025-10-02 23:16:54,709 | INFO | iter is 25100 / 100000 [skipped   84] | loc. loss = 0.2305940241, classif. loss = 0.5214245319
2025-10-02 23:17:27,097 | INFO | iter is 25150 / 100000 [skipped   84] | loc. loss = 0.3325374424, classif. loss = 0.8940222263
2025-10-02 23:17:59,560 | INFO | iter is 25200 / 100000 [skipped   84] | loc. loss = 0.1322685033, classif. loss = 0.6483522654
2025-10-02 23:18:31,965 | INFO | iter is 25250 / 100000 [skipped   84] | loc. loss = 0.2742509246, classif. loss = 0.6497768164
2025-10-02 23:19:04,389 | INFO | iter is 25300 / 100000 [skipped   84] | loc. loss = 0.1696090102, classif. loss = 0.2516322136
2025-10-02 23:19:36,730 | INFO | iter is 25350 / 100000 [skipped   84] | loc. loss = 0.2494927198, classif. loss = 0.2316207439
2025-10-02 23:20:09,109 | INFO | iter is 25400 / 100000 [skipped   84] | loc. loss = 0.0676341429, classif. loss = 0.3922995329
2025-10-02 23:20:41,447 | INFO | iter is 25450 / 100000 [skipped   84] | loc. loss = 0.1138986051, classif. loss = 1.1212146282
2025-10-02 23:21:13,839 | INFO | iter is 25500 / 100000 [skipped   84] | loc. loss = 0.1391330510, classif. loss = 0.8451193571
2025-10-02 23:21:46,242 | INFO | iter is 25550 / 100000 [skipped   84] | loc. loss = 0.1848812997, classif. loss = 0.8940912485
2025-10-02 23:22:18,704 | INFO | iter is 25600 / 100000 [skipped   84] | loc. loss = 0.1247355193, classif. loss = 0.5103752613
2025-10-02 23:22:51,067 | INFO | iter is 25650 / 100000 [skipped   84] | loc. loss = 0.1194076538, classif. loss = 0.9007072449
2025-10-02 23:23:23,475 | INFO | iter is 25700 / 100000 [skipped   84] | loc. loss = 0.1711399108, classif. loss = 0.6636381745
2025-10-02 23:23:55,854 | INFO | iter is 25750 / 100000 [skipped   84] | loc. loss = 0.1835393608, classif. loss = 0.3035414815
2025-10-02 23:24:28,310 | INFO | iter is 25800 / 100000 [skipped   84] | loc. loss = 0.0875355601, classif. loss = 1.0828390121
2025-10-02 23:25:00,643 | INFO | iter is 25850 / 100000 [skipped   84] | loc. loss = 0.1232798100, classif. loss = 0.0980753154
2025-10-02 23:25:33,051 | INFO | iter is 25900 / 100000 [skipped   84] | loc. loss = 0.1988638639, classif. loss = 0.4813414216
2025-10-02 23:26:05,560 | INFO | iter is 25950 / 100000 [skipped   84] | loc. loss = 0.1520112455, classif. loss = 0.6272268891
2025-10-02 23:26:37,965 | INFO | iter is 26000 / 100000 [skipped   84] | loc. loss = 0.2486121058, classif. loss = 0.9155078530
2025-10-02 23:27:10,292 | INFO | iter is 26050 / 100000 [skipped   84] | loc. loss = 0.1633251607, classif. loss = 0.1094945967
2025-10-02 23:27:42,156 | INFO | iter is 26100 / 100000 [skipped   85] | loc. loss = 0.1626760364, classif. loss = 1.0967905521
2025-10-02 23:28:14,567 | INFO | iter is 26150 / 100000 [skipped   85] | loc. loss = 0.1361920536, classif. loss = 1.0818161964
2025-10-02 23:28:47,006 | INFO | iter is 26200 / 100000 [skipped   85] | loc. loss = 0.2823923528, classif. loss = 0.1821535975
2025-10-02 23:29:19,400 | INFO | iter is 26250 / 100000 [skipped   85] | loc. loss = 0.1314031333, classif. loss = 0.0264616795
2025-10-02 23:29:51,736 | INFO | iter is 26300 / 100000 [skipped   85] | loc. loss = 0.2336264551, classif. loss = 0.4584177434
2025-10-02 23:30:24,107 | INFO | iter is 26350 / 100000 [skipped   85] | loc. loss = 0.1312567741, classif. loss = 0.9065689445
2025-10-02 23:30:56,453 | INFO | iter is 26400 / 100000 [skipped   85] | loc. loss = 0.1364729404, classif. loss = 0.6173745394
2025-10-02 23:31:28,772 | INFO | iter is 26450 / 100000 [skipped   85] | loc. loss = 0.2919774354, classif. loss = 1.2958303690
2025-10-02 23:32:01,062 | INFO | iter is 26500 / 100000 [skipped   85] | loc. loss = 0.2539334595, classif. loss = 0.5522283316
2025-10-02 23:32:33,453 | INFO | iter is 26550 / 100000 [skipped   85] | loc. loss = 0.0442444719, classif. loss = 0.0168333724
2025-10-02 23:33:05,203 | INFO | iter is 26600 / 100000 [skipped   86] | loc. loss = 0.3968324661, classif. loss = 0.7389386892
2025-10-02 23:33:37,601 | INFO | iter is 26650 / 100000 [skipped   86] | loc. loss = 0.2489853054, classif. loss = 0.0879947692
2025-10-02 23:34:09,995 | INFO | iter is 26700 / 100000 [skipped   86] | loc. loss = 0.1335083544, classif. loss = 0.9235281348
2025-10-02 23:34:42,375 | INFO | iter is 26750 / 100000 [skipped   86] | loc. loss = 0.1411074698, classif. loss = 0.5291998386
2025-10-02 23:35:13,576 | INFO | iter is 26800 / 100000 [skipped   88] | loc. loss = 0.2098068595, classif. loss = 1.7178899050
2025-10-02 23:35:45,899 | INFO | iter is 26850 / 100000 [skipped   88] | loc. loss = 0.2358755022, classif. loss = 0.3245851398
2025-10-02 23:36:18,232 | INFO | iter is 26900 / 100000 [skipped   88] | loc. loss = 0.1807182729, classif. loss = 0.2248378545
2025-10-02 23:36:50,575 | INFO | iter is 26950 / 100000 [skipped   88] | loc. loss = 0.2187482268, classif. loss = 0.0254285038
2025-10-02 23:37:23,016 | INFO | iter is 27000 / 100000 [skipped   88] | loc. loss = 0.1573766470, classif. loss = 2.3760967255
2025-10-02 23:37:55,285 | INFO | iter is 27050 / 100000 [skipped   88] | loc. loss = 0.1857954711, classif. loss = 0.1510919631
2025-10-02 23:38:27,700 | INFO | iter is 27100 / 100000 [skipped   88] | loc. loss = 0.1702070683, classif. loss = 0.3151932955
2025-10-02 23:39:00,062 | INFO | iter is 27150 / 100000 [skipped   88] | loc. loss = 0.1484970152, classif. loss = 0.2292427123
2025-10-02 23:39:32,448 | INFO | iter is 27200 / 100000 [skipped   88] | loc. loss = 0.1562218964, classif. loss = 0.8454153538
2025-10-02 23:40:04,902 | INFO | iter is 27250 / 100000 [skipped   88] | loc. loss = 0.1236756891, classif. loss = 0.6342160702
2025-10-02 23:40:37,372 | INFO | iter is 27300 / 100000 [skipped   88] | loc. loss = 0.3025238514, classif. loss = 0.9506784081
2025-10-02 23:41:09,781 | INFO | iter is 27350 / 100000 [skipped   88] | loc. loss = 0.1723598838, classif. loss = 0.2835730910
2025-10-02 23:41:42,259 | INFO | iter is 27400 / 100000 [skipped   88] | loc. loss = 0.1785607934, classif. loss = 0.6402471066
2025-10-02 23:42:14,687 | INFO | iter is 27450 / 100000 [skipped   88] | loc. loss = 0.1491523981, classif. loss = 0.4083233774
2025-10-02 23:42:47,147 | INFO | iter is 27500 / 100000 [skipped   88] | loc. loss = 0.0875301287, classif. loss = 0.0197676327
2025-10-02 23:43:19,558 | INFO | iter is 27550 / 100000 [skipped   88] | loc. loss = 0.2309608012, classif. loss = 0.0728083327
2025-10-02 23:43:51,951 | INFO | iter is 27600 / 100000 [skipped   88] | loc. loss = 0.0986069515, classif. loss = 0.6298126578
2025-10-02 23:44:24,435 | INFO | iter is 27650 / 100000 [skipped   88] | loc. loss = 0.1196739599, classif. loss = 0.0952546299
2025-10-02 23:44:56,745 | INFO | iter is 27700 / 100000 [skipped   88] | loc. loss = 0.2387734652, classif. loss = 0.7894905806
2025-10-02 23:45:29,201 | INFO | iter is 27750 / 100000 [skipped   88] | loc. loss = 0.1451319307, classif. loss = 0.6673088074
2025-10-02 23:46:01,606 | INFO | iter is 27800 / 100000 [skipped   88] | loc. loss = 0.1518347859, classif. loss = 0.8140288591
2025-10-02 23:46:34,044 | INFO | iter is 27850 / 100000 [skipped   88] | loc. loss = 0.1611535847, classif. loss = 0.0281876158
2025-10-02 23:47:06,424 | INFO | iter is 27900 / 100000 [skipped   88] | loc. loss = 0.2640118003, classif. loss = 0.0350346752
2025-10-02 23:47:38,758 | INFO | iter is 27950 / 100000 [skipped   88] | loc. loss = 0.1308377683, classif. loss = 0.2363909334
2025-10-02 23:48:10,618 | INFO | iter is 28000 / 100000 [skipped   89] | loc. loss = 0.1506322920, classif. loss = 0.1558329761
2025-10-02 23:48:41,753 | INFO | iter is 28050 / 100000 [skipped   91] | loc. loss = 0.0703686476, classif. loss = 0.0727367699
2025-10-02 23:49:14,146 | INFO | iter is 28100 / 100000 [skipped   91] | loc. loss = 0.1860599965, classif. loss = 0.5912202597
2025-10-02 23:49:30,376 | INFO | ---------starting evaluation-----------
2025-10-02 23:49:30,846 | INFO | validation:    0/2126 (2025-10-02_23-49-30)
2025-10-02 23:49:58,799 | INFO | validation:  100/2126 (2025-10-02_23-49-58)
2025-10-02 23:50:27,407 | INFO | validation:  200/2126 (2025-10-02_23-50-27)
2025-10-02 23:50:53,664 | INFO | validation:  300/2126 (2025-10-02_23-50-53)
2025-10-02 23:51:22,575 | INFO | validation:  400/2126 (2025-10-02_23-51-22)
2025-10-02 23:51:52,504 | INFO | validation:  500/2126 (2025-10-02_23-51-52)
2025-10-02 23:52:22,780 | INFO | validation:  600/2126 (2025-10-02_23-52-22)
2025-10-02 23:52:49,041 | INFO | validation:  700/2126 (2025-10-02_23-52-49)
2025-10-02 23:53:17,980 | INFO | validation:  800/2126 (2025-10-02_23-53-17)
2025-10-02 23:53:45,256 | INFO | validation:  900/2126 (2025-10-02_23-53-45)
2025-10-02 23:54:17,550 | INFO | validation: 1000/2126 (2025-10-02_23-54-17)
2025-10-02 23:54:47,160 | INFO | validation: 1100/2126 (2025-10-02_23-54-47)
2025-10-02 23:55:16,093 | INFO | validation: 1200/2126 (2025-10-02_23-55-16)
2025-10-02 23:55:46,375 | INFO | validation: 1300/2126 (2025-10-02_23-55-46)
2025-10-02 23:56:14,329 | INFO | validation: 1400/2126 (2025-10-02_23-56-14)
2025-10-02 23:56:42,950 | INFO | validation: 1500/2126 (2025-10-02_23-56-42)
2025-10-02 23:57:11,911 | INFO | validation: 1600/2126 (2025-10-02_23-57-11)
2025-10-02 23:57:39,876 | INFO | validation: 1700/2126 (2025-10-02_23-57-39)
2025-10-02 23:58:09,174 | INFO | validation: 1800/2126 (2025-10-02_23-58-09)
2025-10-02 23:58:39,134 | INFO | validation: 1900/2126 (2025-10-02_23-58-39)
2025-10-02 23:59:06,400 | INFO | validation: 2000/2126 (2025-10-02_23-59-06)
2025-10-02 23:59:34,337 | INFO | validation: 2100/2126 (2025-10-02_23-59-34)
2025-10-02 23:59:42,724 | INFO | Confusion Matrix of Localization:
[[1293532332    5938101]
 [   7158331   44985700]]
2025-10-02 23:59:42,724 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99543037 0.00456963]
 [0.13727997 0.86272003]]
2025-10-02 23:59:42,724 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41544219  1636985   161250   107780]
 [       0   953766  1756561   351181    34695]
 [       0   162241   636112  1987101   117477]
 [       0    77820    70754   109349  1724352]]
2025-10-02 23:59:42,724 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95613338 0.03767494 0.00371114 0.00248054]
 [0.         0.30804376 0.56732747 0.11342312 0.01120566]
 [0.         0.05588869 0.2191275  0.68451541 0.04046841]
 [0.         0.03925792 0.03569333 0.05516339 0.86988536]]
2025-10-02 23:59:42,725 | INFO | lofF1 is 87.2934, clfF1 is 71.1381, oaF1 is 75.9847, sub class F1 score is [96.4034 48.8163 72.1034 86.944 ]
2025-10-02 23:59:42,986 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step28125.pth
2025-10-02 23:59:42,987 | INFO | ---------starting train set evaluation-----------
2025-10-02 23:59:43,483 | INFO | [TrainBuf] locF1 is 88.7119, clfF1 is 68.3596, oaF1 is 74.4653, sub class F1 score is [95.1857 48.7057 70.7832 74.911 ]
2025-10-02 23:59:59,661 | INFO | iter is 28150 / 100000 [skipped   91] | loc. loss = 0.1308808178, classif. loss = 1.2279310226
2025-10-03 00:00:32,076 | INFO | iter is 28200 / 100000 [skipped   91] | loc. loss = 0.2682299912, classif. loss = 1.1747028828
2025-10-03 00:01:04,582 | INFO | iter is 28250 / 100000 [skipped   91] | loc. loss = 0.1346392781, classif. loss = 0.0158988722
2025-10-03 00:01:37,002 | INFO | iter is 28300 / 100000 [skipped   91] | loc. loss = 0.1527877152, classif. loss = 0.3612447381
2025-10-03 00:02:09,473 | INFO | iter is 28350 / 100000 [skipped   91] | loc. loss = 0.2779168189, classif. loss = 1.2908196449
2025-10-03 00:02:41,861 | INFO | iter is 28400 / 100000 [skipped   91] | loc. loss = 0.5099850893, classif. loss = 2.0305390358
2025-10-03 00:03:14,270 | INFO | iter is 28450 / 100000 [skipped   91] | loc. loss = 0.1516048610, classif. loss = 0.5175318718
2025-10-03 00:03:46,078 | INFO | iter is 28500 / 100000 [skipped   92] | loc. loss = 0.2461469173, classif. loss = 0.2227174640
2025-10-03 00:04:18,515 | INFO | iter is 28550 / 100000 [skipped   92] | loc. loss = 0.1046480387, classif. loss = 1.2644690275
2025-10-03 00:04:50,795 | INFO | iter is 28600 / 100000 [skipped   92] | loc. loss = 0.1772610694, classif. loss = 0.5903601050
2025-10-03 00:05:23,170 | INFO | iter is 28650 / 100000 [skipped   92] | loc. loss = 0.1766788960, classif. loss = 0.3937035203
2025-10-03 00:05:55,522 | INFO | iter is 28700 / 100000 [skipped   92] | loc. loss = 0.1469244808, classif. loss = 0.0753893852
2025-10-03 00:06:27,830 | INFO | iter is 28750 / 100000 [skipped   92] | loc. loss = 0.2179299891, classif. loss = 0.1009028554
2025-10-03 00:06:59,608 | INFO | iter is 28800 / 100000 [skipped   93] | loc. loss = 0.2002615184, classif. loss = 0.5444576144
2025-10-03 00:07:32,080 | INFO | iter is 28850 / 100000 [skipped   93] | loc. loss = 0.1202193946, classif. loss = 0.2462580055
2025-10-03 00:08:04,457 | INFO | iter is 28900 / 100000 [skipped   93] | loc. loss = 0.2137069106, classif. loss = 0.0430837348
2025-10-03 00:08:36,937 | INFO | iter is 28950 / 100000 [skipped   93] | loc. loss = 0.2119723707, classif. loss = 0.1357359886
2025-10-03 00:09:09,360 | INFO | iter is 29000 / 100000 [skipped   93] | loc. loss = 0.1511064172, classif. loss = 0.4736088514
2025-10-03 00:09:41,918 | INFO | iter is 29050 / 100000 [skipped   93] | loc. loss = 0.1307611018, classif. loss = 0.0408505648
2025-10-03 00:10:14,323 | INFO | iter is 29100 / 100000 [skipped   93] | loc. loss = 0.1433646381, classif. loss = 0.4874065518
2025-10-03 00:10:46,178 | INFO | iter is 29150 / 100000 [skipped   94] | loc. loss = 0.2241967618, classif. loss = 0.6147202253
2025-10-03 00:11:18,609 | INFO | iter is 29200 / 100000 [skipped   94] | loc. loss = 0.1665648222, classif. loss = 0.1621235907
2025-10-03 00:11:51,063 | INFO | iter is 29250 / 100000 [skipped   94] | loc. loss = 0.1349166930, classif. loss = 0.3732640743
2025-10-03 00:12:23,440 | INFO | iter is 29300 / 100000 [skipped   94] | loc. loss = 0.1065263748, classif. loss = 0.2008515745
2025-10-03 00:12:55,313 | INFO | iter is 29350 / 100000 [skipped   95] | loc. loss = 0.1861953586, classif. loss = 0.2244141102
2025-10-03 00:13:27,129 | INFO | iter is 29400 / 100000 [skipped   96] | loc. loss = 0.0966609716, classif. loss = 0.6940029860
2025-10-03 00:13:59,492 | INFO | iter is 29450 / 100000 [skipped   96] | loc. loss = 0.2302123308, classif. loss = 0.6796262860
2025-10-03 00:14:31,949 | INFO | iter is 29500 / 100000 [skipped   96] | loc. loss = 0.2604483962, classif. loss = 0.7315670848
2025-10-03 00:15:04,451 | INFO | iter is 29550 / 100000 [skipped   96] | loc. loss = 0.0863621607, classif. loss = 0.4483568072
2025-10-03 00:15:36,922 | INFO | iter is 29600 / 100000 [skipped   96] | loc. loss = 0.1662367284, classif. loss = 1.2469284534
2025-10-03 00:16:08,779 | INFO | iter is 29650 / 100000 [skipped   97] | loc. loss = 0.1574140787, classif. loss = 0.0143215191
2025-10-03 00:16:41,168 | INFO | iter is 29700 / 100000 [skipped   97] | loc. loss = 0.0899457633, classif. loss = 0.2129924297
2025-10-03 00:17:13,546 | INFO | iter is 29750 / 100000 [skipped   97] | loc. loss = 0.1686095744, classif. loss = 0.1205809116
2025-10-03 00:17:45,897 | INFO | iter is 29800 / 100000 [skipped   97] | loc. loss = 0.1626400203, classif. loss = 0.1687519550
2025-10-03 00:18:18,339 | INFO | iter is 29850 / 100000 [skipped   97] | loc. loss = 0.1857441664, classif. loss = 0.3143619895
2025-10-03 00:18:50,648 | INFO | iter is 29900 / 100000 [skipped   97] | loc. loss = 0.0992790088, classif. loss = 0.2480571866
2025-10-03 00:19:22,959 | INFO | iter is 29950 / 100000 [skipped   97] | loc. loss = 0.2086638361, classif. loss = 0.7477970123
2025-10-03 00:19:55,421 | INFO | iter is 30000 / 100000 [skipped   97] | loc. loss = 0.1284995228, classif. loss = 0.6437656283
2025-10-03 00:20:27,929 | INFO | iter is 30050 / 100000 [skipped   97] | loc. loss = 0.1624344736, classif. loss = 0.5421693325
2025-10-03 00:21:00,293 | INFO | iter is 30100 / 100000 [skipped   97] | loc. loss = 0.1929436624, classif. loss = 0.5866895318
2025-10-03 00:21:32,714 | INFO | iter is 30150 / 100000 [skipped   97] | loc. loss = 0.1243382618, classif. loss = 0.0451902375
2025-10-03 00:22:05,075 | INFO | iter is 30200 / 100000 [skipped   97] | loc. loss = 0.0969457403, classif. loss = 0.0316236094
2025-10-03 00:22:37,450 | INFO | iter is 30250 / 100000 [skipped   97] | loc. loss = 0.1507851928, classif. loss = 0.6261203289
2025-10-03 00:23:09,906 | INFO | iter is 30300 / 100000 [skipped   97] | loc. loss = 0.1543027014, classif. loss = 0.7081473470
2025-10-03 00:23:42,281 | INFO | iter is 30350 / 100000 [skipped   97] | loc. loss = 0.1699120998, classif. loss = 1.2552666664
2025-10-03 00:24:13,485 | INFO | iter is 30400 / 100000 [skipped   99] | loc. loss = 0.1175838709, classif. loss = 0.6560292244
2025-10-03 00:24:45,835 | INFO | iter is 30450 / 100000 [skipped   99] | loc. loss = 0.1569678485, classif. loss = 0.9025714397
2025-10-03 00:25:18,258 | INFO | iter is 30500 / 100000 [skipped   99] | loc. loss = 0.2545240521, classif. loss = 0.4085464478
2025-10-03 00:25:50,645 | INFO | iter is 30550 / 100000 [skipped   99] | loc. loss = 0.1811923832, classif. loss = 0.0959461555
2025-10-03 00:26:23,103 | INFO | iter is 30600 / 100000 [skipped   99] | loc. loss = 0.1325258613, classif. loss = 0.0676011965
2025-10-03 00:26:55,527 | INFO | iter is 30650 / 100000 [skipped   99] | loc. loss = 0.2092619985, classif. loss = 0.7001994252
2025-10-03 00:27:27,800 | INFO | iter is 30700 / 100000 [skipped   99] | loc. loss = 0.2435034513, classif. loss = 0.1703856289
2025-10-03 00:28:00,223 | INFO | iter is 30750 / 100000 [skipped   99] | loc. loss = 0.1315809041, classif. loss = 0.1684100926
2025-10-03 00:28:32,501 | INFO | iter is 30800 / 100000 [skipped   99] | loc. loss = 0.1532343924, classif. loss = 0.3342991471
2025-10-03 00:29:04,843 | INFO | iter is 30850 / 100000 [skipped   99] | loc. loss = 0.1805646122, classif. loss = 0.0961647332
2025-10-03 00:29:37,208 | INFO | iter is 30900 / 100000 [skipped   99] | loc. loss = 0.2274774313, classif. loss = 0.0938579291
2025-10-03 00:30:09,009 | INFO | iter is 30950 / 100000 [skipped  100] | loc. loss = 0.1065514609, classif. loss = 0.0806675553
2025-10-03 00:30:40,765 | INFO | iter is 31000 / 100000 [skipped  101] | loc. loss = 0.2531024814, classif. loss = 0.1000048295
2025-10-03 00:31:13,102 | INFO | iter is 31050 / 100000 [skipped  101] | loc. loss = 0.1417872161, classif. loss = 0.9994688630
2025-10-03 00:31:45,493 | INFO | iter is 31100 / 100000 [skipped  101] | loc. loss = 0.2087822855, classif. loss = 0.8883428574
2025-10-03 00:32:17,840 | INFO | iter is 31150 / 100000 [skipped  101] | loc. loss = 0.1686653644, classif. loss = 0.7250500321
2025-10-03 00:32:50,119 | INFO | iter is 31200 / 100000 [skipped  101] | loc. loss = 0.1661976427, classif. loss = 1.2227122784
2025-10-03 00:33:22,482 | INFO | iter is 31250 / 100000 [skipped  101] | loc. loss = 0.1335496902, classif. loss = 0.2542436719
2025-10-03 00:33:22,484 | INFO | ---------starting evaluation-----------
2025-10-03 00:33:22,949 | INFO | validation:    0/2126 (2025-10-03_00-33-22)
2025-10-03 00:33:50,907 | INFO | validation:  100/2126 (2025-10-03_00-33-50)
2025-10-03 00:34:19,507 | INFO | validation:  200/2126 (2025-10-03_00-34-19)
2025-10-03 00:34:45,772 | INFO | validation:  300/2126 (2025-10-03_00-34-45)
2025-10-03 00:35:14,723 | INFO | validation:  400/2126 (2025-10-03_00-35-14)
2025-10-03 00:35:44,669 | INFO | validation:  500/2126 (2025-10-03_00-35-44)
2025-10-03 00:36:14,945 | INFO | validation:  600/2126 (2025-10-03_00-36-14)
2025-10-03 00:36:41,214 | INFO | validation:  700/2126 (2025-10-03_00-36-41)
2025-10-03 00:37:10,169 | INFO | validation:  800/2126 (2025-10-03_00-37-10)
2025-10-03 00:37:37,418 | INFO | validation:  900/2126 (2025-10-03_00-37-37)
2025-10-03 00:38:09,709 | INFO | validation: 1000/2126 (2025-10-03_00-38-09)
2025-10-03 00:38:39,315 | INFO | validation: 1100/2126 (2025-10-03_00-38-39)
2025-10-03 00:39:08,262 | INFO | validation: 1200/2126 (2025-10-03_00-39-08)
2025-10-03 00:39:38,531 | INFO | validation: 1300/2126 (2025-10-03_00-39-38)
2025-10-03 00:40:06,447 | INFO | validation: 1400/2126 (2025-10-03_00-40-06)
2025-10-03 00:40:35,064 | INFO | validation: 1500/2126 (2025-10-03_00-40-35)
2025-10-03 00:41:03,988 | INFO | validation: 1600/2126 (2025-10-03_00-41-03)
2025-10-03 00:41:31,921 | INFO | validation: 1700/2126 (2025-10-03_00-41-31)
2025-10-03 00:42:01,189 | INFO | validation: 1800/2126 (2025-10-03_00-42-01)
2025-10-03 00:42:31,115 | INFO | validation: 1900/2126 (2025-10-03_00-42-31)
2025-10-03 00:42:58,387 | INFO | validation: 2000/2126 (2025-10-03_00-42-58)
2025-10-03 00:43:26,323 | INFO | validation: 2100/2126 (2025-10-03_00-43-26)
2025-10-03 00:43:34,708 | INFO | Confusion Matrix of Localization:
[[1292627611    6842822]
 [   7300719   44843312]]
2025-10-03 00:43:34,708 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99473415 0.00526585]
 [0.14001064 0.85998936]]
2025-10-03 00:43:34,708 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40745189  2342774   314363    47908]
 [       0   920614  1691222   468169    16198]
 [       0   197147   494235  2104371   107178]
 [       0   124221   106911   145389  1605754]]
2025-10-03 00:43:34,709 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.93774383 0.05391856 0.00723501 0.00110259]
 [0.         0.29733645 0.54622452 0.15120746 0.00523157]
 [0.         0.06791309 0.17025379 0.72491251 0.03692062]
 [0.         0.06266588 0.05393349 0.07334452 0.81005612]]
2025-10-03 00:43:34,709 | INFO | lofF1 is 86.3782, clfF1 is 67.6252, oaF1 is 73.2511, sub class F1 score is [95.3802 43.7497 70.9113 85.4281]
2025-10-03 00:43:34,709 | INFO | ---------starting train set evaluation-----------
2025-10-03 00:43:35,206 | INFO | [TrainBuf] locF1 is 88.1291, clfF1 is 69.5930, oaF1 is 75.1539, sub class F1 score is [95.6356 53.2732 60.5274 85.2655]
2025-10-03 00:44:07,741 | INFO | iter is 31300 / 100000 [skipped  101] | loc. loss = 0.1732090861, classif. loss = 0.3842613995
2025-10-03 00:44:40,173 | INFO | iter is 31350 / 100000 [skipped  101] | loc. loss = 0.2111850530, classif. loss = 2.4227306843
2025-10-03 00:45:12,611 | INFO | iter is 31400 / 100000 [skipped  101] | loc. loss = 0.1406245232, classif. loss = 0.9699018598
2025-10-03 00:45:45,048 | INFO | iter is 31450 / 100000 [skipped  101] | loc. loss = 0.1651721299, classif. loss = 1.6909112930
2025-10-03 00:46:17,384 | INFO | iter is 31500 / 100000 [skipped  101] | loc. loss = 0.2514237463, classif. loss = 0.1006508023
2025-10-03 00:46:49,785 | INFO | iter is 31550 / 100000 [skipped  101] | loc. loss = 0.1448389590, classif. loss = 0.4053773880
2025-10-03 00:47:22,228 | INFO | iter is 31600 / 100000 [skipped  101] | loc. loss = 0.1318623573, classif. loss = 0.3219353557
2025-10-03 00:47:54,665 | INFO | iter is 31650 / 100000 [skipped  101] | loc. loss = 0.2160939276, classif. loss = 0.3983962834
2025-10-03 00:48:27,111 | INFO | iter is 31700 / 100000 [skipped  101] | loc. loss = 0.1038760394, classif. loss = 0.3355264664
2025-10-03 00:48:59,491 | INFO | iter is 31750 / 100000 [skipped  101] | loc. loss = 0.2383282185, classif. loss = 0.7149116993
2025-10-03 00:49:31,285 | INFO | iter is 31800 / 100000 [skipped  102] | loc. loss = 0.0404874831, classif. loss = 0.0344887301
2025-10-03 00:50:03,679 | INFO | iter is 31850 / 100000 [skipped  102] | loc. loss = 0.1108055934, classif. loss = 0.3430758417
2025-10-03 00:50:36,062 | INFO | iter is 31900 / 100000 [skipped  102] | loc. loss = 0.2685912848, classif. loss = 0.8782927394
2025-10-03 00:51:08,497 | INFO | iter is 31950 / 100000 [skipped  102] | loc. loss = 0.2573390007, classif. loss = 0.9178291559
2025-10-03 00:51:40,870 | INFO | iter is 32000 / 100000 [skipped  102] | loc. loss = 0.1840696335, classif. loss = 0.1783706397
2025-10-03 00:52:12,653 | INFO | iter is 32050 / 100000 [skipped  103] | loc. loss = 0.0732909963, classif. loss = 1.0717337132
2025-10-03 00:52:44,996 | INFO | iter is 32100 / 100000 [skipped  103] | loc. loss = 0.2109221816, classif. loss = 0.1503719985
2025-10-03 00:53:17,434 | INFO | iter is 32150 / 100000 [skipped  103] | loc. loss = 0.1156229824, classif. loss = 0.0601400882
2025-10-03 00:53:49,824 | INFO | iter is 32200 / 100000 [skipped  103] | loc. loss = 0.1039379239, classif. loss = 0.3059317768
2025-10-03 00:54:22,340 | INFO | iter is 32250 / 100000 [skipped  103] | loc. loss = 0.2987771630, classif. loss = 0.6549197435
2025-10-03 00:54:54,721 | INFO | iter is 32300 / 100000 [skipped  103] | loc. loss = 0.6123931408, classif. loss = 0.2535682619
2025-10-03 00:55:26,566 | INFO | iter is 32350 / 100000 [skipped  104] | loc. loss = 0.1523770988, classif. loss = 0.1816939712
2025-10-03 00:55:58,391 | INFO | iter is 32400 / 100000 [skipped  105] | loc. loss = 0.1277598143, classif. loss = 0.4128635526
2025-10-03 00:56:30,742 | INFO | iter is 32450 / 100000 [skipped  105] | loc. loss = 0.1906827539, classif. loss = 0.9099038839
2025-10-03 00:57:03,190 | INFO | iter is 32500 / 100000 [skipped  105] | loc. loss = 0.2266330421, classif. loss = 0.6527599692
2025-10-03 00:57:35,543 | INFO | iter is 32550 / 100000 [skipped  105] | loc. loss = 0.1840906590, classif. loss = 0.6511102319
2025-10-03 00:58:07,969 | INFO | iter is 32600 / 100000 [skipped  105] | loc. loss = 0.2166346014, classif. loss = 0.6005728841
2025-10-03 00:58:40,346 | INFO | iter is 32650 / 100000 [skipped  105] | loc. loss = 0.1955946088, classif. loss = 0.3609774709
2025-10-03 00:59:12,790 | INFO | iter is 32700 / 100000 [skipped  105] | loc. loss = 0.2139831632, classif. loss = 0.5893463492
2025-10-03 00:59:45,117 | INFO | iter is 32750 / 100000 [skipped  105] | loc. loss = 0.1857627630, classif. loss = 1.0552604198
2025-10-03 01:00:16,994 | INFO | iter is 32800 / 100000 [skipped  106] | loc. loss = 0.1510314941, classif. loss = 0.1288472712
2025-10-03 01:00:49,376 | INFO | iter is 32850 / 100000 [skipped  106] | loc. loss = 0.1373524964, classif. loss = 1.0770823956
2025-10-03 01:01:21,818 | INFO | iter is 32900 / 100000 [skipped  106] | loc. loss = 0.1591630876, classif. loss = 0.2809873223
2025-10-03 01:01:54,243 | INFO | iter is 32950 / 100000 [skipped  106] | loc. loss = 0.1664125025, classif. loss = 1.3194797039
2025-10-03 01:02:26,747 | INFO | iter is 33000 / 100000 [skipped  106] | loc. loss = 0.1632231176, classif. loss = 1.1119298935
2025-10-03 01:02:58,488 | INFO | iter is 33050 / 100000 [skipped  107] | loc. loss = 0.1417833269, classif. loss = 0.6209851503
2025-10-03 01:03:30,863 | INFO | iter is 33100 / 100000 [skipped  107] | loc. loss = 0.1445294321, classif. loss = 0.5189893246
2025-10-03 01:04:02,610 | INFO | iter is 33150 / 100000 [skipped  108] | loc. loss = 0.1436983943, classif. loss = 0.2190550417
2025-10-03 01:04:35,103 | INFO | iter is 33200 / 100000 [skipped  108] | loc. loss = 0.1607948989, classif. loss = 0.3735957146
2025-10-03 01:05:07,453 | INFO | iter is 33250 / 100000 [skipped  108] | loc. loss = 0.2847867012, classif. loss = 0.8845077753
2025-10-03 01:05:39,968 | INFO | iter is 33300 / 100000 [skipped  108] | loc. loss = 0.1888314486, classif. loss = 0.1426005363
2025-10-03 01:06:12,327 | INFO | iter is 33350 / 100000 [skipped  108] | loc. loss = 0.1839158535, classif. loss = 1.3299123049
2025-10-03 01:06:44,647 | INFO | iter is 33400 / 100000 [skipped  108] | loc. loss = 0.1268970966, classif. loss = 0.5973682404
2025-10-03 01:07:17,043 | INFO | iter is 33450 / 100000 [skipped  108] | loc. loss = 0.2162624896, classif. loss = 1.3143389225
2025-10-03 01:07:49,464 | INFO | iter is 33500 / 100000 [skipped  108] | loc. loss = 0.2037422508, classif. loss = 1.4247004986
2025-10-03 01:08:21,803 | INFO | iter is 33550 / 100000 [skipped  108] | loc. loss = 0.1050507277, classif. loss = 1.9173235893
2025-10-03 01:08:54,292 | INFO | iter is 33600 / 100000 [skipped  108] | loc. loss = 0.1728322804, classif. loss = 0.3155233562
2025-10-03 01:09:25,994 | INFO | iter is 33650 / 100000 [skipped  109] | loc. loss = 0.2900609970, classif. loss = 0.3537016213
2025-10-03 01:09:58,471 | INFO | iter is 33700 / 100000 [skipped  109] | loc. loss = 0.1157136261, classif. loss = 0.5601806641
2025-10-03 01:10:30,879 | INFO | iter is 33750 / 100000 [skipped  109] | loc. loss = 0.1993204802, classif. loss = 0.5849268436
2025-10-03 01:11:03,292 | INFO | iter is 33800 / 100000 [skipped  109] | loc. loss = 0.1872880161, classif. loss = 1.1624224186
2025-10-03 01:11:35,609 | INFO | iter is 33850 / 100000 [skipped  109] | loc. loss = 0.0562114716, classif. loss = 0.5121589899
2025-10-03 01:12:08,035 | INFO | iter is 33900 / 100000 [skipped  109] | loc. loss = 0.2001238465, classif. loss = 1.6651334763
2025-10-03 01:12:40,384 | INFO | iter is 33950 / 100000 [skipped  109] | loc. loss = 0.2530483305, classif. loss = 0.5624665022
2025-10-03 01:13:13,024 | INFO | iter is 34000 / 100000 [skipped  109] | loc. loss = 0.1576258093, classif. loss = 0.2584082186
2025-10-03 01:13:45,460 | INFO | iter is 34050 / 100000 [skipped  109] | loc. loss = 0.2182819247, classif. loss = 0.6611281633
2025-10-03 01:14:17,925 | INFO | iter is 34100 / 100000 [skipped  109] | loc. loss = 0.0669455081, classif. loss = 0.7971452475
2025-10-03 01:14:50,290 | INFO | iter is 34150 / 100000 [skipped  109] | loc. loss = 0.2239184082, classif. loss = 0.0199548528
2025-10-03 01:15:22,712 | INFO | iter is 34200 / 100000 [skipped  109] | loc. loss = 0.3558201194, classif. loss = 1.0543317795
2025-10-03 01:15:55,085 | INFO | iter is 34250 / 100000 [skipped  109] | loc. loss = 0.1534350365, classif. loss = 1.0359470844
2025-10-03 01:16:27,410 | INFO | iter is 34300 / 100000 [skipped  109] | loc. loss = 0.1530351192, classif. loss = 0.4868302047
2025-10-03 01:16:59,772 | INFO | iter is 34350 / 100000 [skipped  109] | loc. loss = 0.1675048321, classif. loss = 0.0459067076
2025-10-03 01:17:15,945 | INFO | ---------starting evaluation-----------
2025-10-03 01:17:16,414 | INFO | validation:    0/2126 (2025-10-03_01-17-16)
2025-10-03 01:17:44,295 | INFO | validation:  100/2126 (2025-10-03_01-17-44)
2025-10-03 01:18:12,818 | INFO | validation:  200/2126 (2025-10-03_01-18-12)
2025-10-03 01:18:39,023 | INFO | validation:  300/2126 (2025-10-03_01-18-39)
2025-10-03 01:19:07,937 | INFO | validation:  400/2126 (2025-10-03_01-19-07)
2025-10-03 01:19:37,877 | INFO | validation:  500/2126 (2025-10-03_01-19-37)
2025-10-03 01:20:08,163 | INFO | validation:  600/2126 (2025-10-03_01-20-08)
2025-10-03 01:20:34,426 | INFO | validation:  700/2126 (2025-10-03_01-20-34)
2025-10-03 01:21:03,357 | INFO | validation:  800/2126 (2025-10-03_01-21-03)
2025-10-03 01:21:30,580 | INFO | validation:  900/2126 (2025-10-03_01-21-30)
2025-10-03 01:22:02,860 | INFO | validation: 1000/2126 (2025-10-03_01-22-02)
2025-10-03 01:22:32,451 | INFO | validation: 1100/2126 (2025-10-03_01-22-32)
2025-10-03 01:23:01,368 | INFO | validation: 1200/2126 (2025-10-03_01-23-01)
2025-10-03 01:23:31,628 | INFO | validation: 1300/2126 (2025-10-03_01-23-31)
2025-10-03 01:23:59,533 | INFO | validation: 1400/2126 (2025-10-03_01-23-59)
2025-10-03 01:24:28,115 | INFO | validation: 1500/2126 (2025-10-03_01-24-28)
2025-10-03 01:24:57,046 | INFO | validation: 1600/2126 (2025-10-03_01-24-57)
2025-10-03 01:25:24,960 | INFO | validation: 1700/2126 (2025-10-03_01-25-24)
2025-10-03 01:25:54,217 | INFO | validation: 1800/2126 (2025-10-03_01-25-54)
2025-10-03 01:26:24,151 | INFO | validation: 1900/2126 (2025-10-03_01-26-24)
2025-10-03 01:26:51,400 | INFO | validation: 2000/2126 (2025-10-03_01-26-51)
2025-10-03 01:27:19,320 | INFO | validation: 2100/2126 (2025-10-03_01-27-19)
2025-10-03 01:27:27,702 | INFO | Confusion Matrix of Localization:
[[1292494051    6976382]
 [   6644298   45499733]]
2025-10-03 01:27:27,703 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99463137 0.00536863]
 [0.12742202 0.87257798]]
2025-10-03 01:27:27,703 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41896142  1243452   213243    97397]
 [       0  1242829  1349778   464012    39584]
 [       0   260747   368161  2102710   171313]
 [       0   116851    29564    95920  1739940]]
2025-10-03 01:27:27,703 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96423283 0.02861784 0.00490775 0.00224158]
 [0.         0.40140424 0.43594622 0.14986485 0.01278469]
 [0.         0.08982198 0.12682389 0.72434033 0.0590138 ]
 [0.         0.05894793 0.01491418 0.04838885 0.87774905]]
2025-10-03 01:27:27,703 | INFO | lofF1 is 86.9808, clfF1 is 68.6680, oaF1 is 74.1619, sub class F1 score is [96.3497 44.3484 72.773  86.3385]
2025-10-03 01:27:27,704 | INFO | ---------starting train set evaluation-----------
2025-10-03 01:27:28,207 | INFO | [TrainBuf] locF1 is 88.4606, clfF1 is 71.6559, oaF1 is 76.6973, sub class F1 score is [95.6527 52.4851 70.6325 82.2569]
2025-10-03 01:27:44,517 | INFO | iter is 34400 / 100000 [skipped  109] | loc. loss = 0.2861699164, classif. loss = 0.4562202692
2025-10-03 01:28:17,025 | INFO | iter is 34450 / 100000 [skipped  109] | loc. loss = 0.1741149724, classif. loss = 0.6685701609
2025-10-03 01:28:49,507 | INFO | iter is 34500 / 100000 [skipped  109] | loc. loss = 0.1743077338, classif. loss = 0.4826685190
2025-10-03 01:29:21,365 | INFO | iter is 34550 / 100000 [skipped  110] | loc. loss = 0.1982610226, classif. loss = 0.5454409122
2025-10-03 01:29:53,802 | INFO | iter is 34600 / 100000 [skipped  110] | loc. loss = 0.1665366143, classif. loss = 0.6721289754
2025-10-03 01:30:24,977 | INFO | iter is 34650 / 100000 [skipped  112] | loc. loss = 0.1687288731, classif. loss = 0.7945448160
2025-10-03 01:30:57,449 | INFO | iter is 34700 / 100000 [skipped  112] | loc. loss = 0.2096454799, classif. loss = 1.4482458830
2025-10-03 01:31:29,827 | INFO | iter is 34750 / 100000 [skipped  112] | loc. loss = 0.2188334614, classif. loss = 0.4974420667
2025-10-03 01:32:02,234 | INFO | iter is 34800 / 100000 [skipped  112] | loc. loss = 0.1547260582, classif. loss = 0.2209395170
2025-10-03 01:32:34,736 | INFO | iter is 34850 / 100000 [skipped  112] | loc. loss = 0.1318948418, classif. loss = 1.3834633827
2025-10-03 01:33:06,514 | INFO | iter is 34900 / 100000 [skipped  113] | loc. loss = 0.2813216746, classif. loss = 0.4701219797
2025-10-03 01:33:38,948 | INFO | iter is 34950 / 100000 [skipped  113] | loc. loss = 0.1810463369, classif. loss = 0.2600306273
2025-10-03 01:34:11,333 | INFO | iter is 35000 / 100000 [skipped  113] | loc. loss = 0.2924109399, classif. loss = 1.2037518024
2025-10-03 01:34:43,083 | INFO | iter is 35050 / 100000 [skipped  114] | loc. loss = 0.2372624874, classif. loss = 0.7898639441
2025-10-03 01:35:15,396 | INFO | iter is 35100 / 100000 [skipped  114] | loc. loss = 0.1624531150, classif. loss = 0.3486080766
2025-10-03 01:35:47,274 | INFO | iter is 35150 / 100000 [skipped  115] | loc. loss = 0.1685965061, classif. loss = 0.8320260048
2025-10-03 01:36:19,628 | INFO | iter is 35200 / 100000 [skipped  115] | loc. loss = 0.1612271667, classif. loss = 0.0660079792
2025-10-03 01:36:52,071 | INFO | iter is 35250 / 100000 [skipped  115] | loc. loss = 0.1331116855, classif. loss = 0.4778732359
2025-10-03 01:37:24,390 | INFO | iter is 35300 / 100000 [skipped  115] | loc. loss = 0.2252725661, classif. loss = 0.1359189749
2025-10-03 01:37:56,783 | INFO | iter is 35350 / 100000 [skipped  115] | loc. loss = 0.1943434626, classif. loss = 0.3992400467
2025-10-03 01:38:29,191 | INFO | iter is 35400 / 100000 [skipped  115] | loc. loss = 0.1279717088, classif. loss = 0.0546610802
2025-10-03 01:39:01,528 | INFO | iter is 35450 / 100000 [skipped  115] | loc. loss = 0.2375817597, classif. loss = 0.8614801764
2025-10-03 01:39:33,856 | INFO | iter is 35500 / 100000 [skipped  115] | loc. loss = 0.1166540086, classif. loss = 0.5519211292
2025-10-03 01:40:06,159 | INFO | iter is 35550 / 100000 [skipped  115] | loc. loss = 0.1491338015, classif. loss = 0.6202734113
2025-10-03 01:40:38,560 | INFO | iter is 35600 / 100000 [skipped  115] | loc. loss = 0.1322877556, classif. loss = 0.4495368004
2025-10-03 01:41:10,940 | INFO | iter is 35650 / 100000 [skipped  115] | loc. loss = 0.1260337383, classif. loss = 0.2906077206
2025-10-03 01:41:43,326 | INFO | iter is 35700 / 100000 [skipped  115] | loc. loss = 0.1807730794, classif. loss = 0.0456918254
2025-10-03 01:42:15,734 | INFO | iter is 35750 / 100000 [skipped  115] | loc. loss = 0.1291710585, classif. loss = 0.2135906518
2025-10-03 01:42:48,114 | INFO | iter is 35800 / 100000 [skipped  115] | loc. loss = 0.1221789643, classif. loss = 0.0585919693
2025-10-03 01:43:20,461 | INFO | iter is 35850 / 100000 [skipped  115] | loc. loss = 0.3513681889, classif. loss = 2.1124908924
2025-10-03 01:43:52,249 | INFO | iter is 35900 / 100000 [skipped  116] | loc. loss = 0.2381834686, classif. loss = 0.7703155875
2025-10-03 01:44:24,540 | INFO | iter is 35950 / 100000 [skipped  116] | loc. loss = 0.4831087291, classif. loss = 3.8073656559
2025-10-03 01:44:56,921 | INFO | iter is 36000 / 100000 [skipped  116] | loc. loss = 0.2463676333, classif. loss = 0.8562700748
2025-10-03 01:45:28,673 | INFO | iter is 36050 / 100000 [skipped  117] | loc. loss = 0.2054005265, classif. loss = 0.6123560667
2025-10-03 01:46:01,161 | INFO | iter is 36100 / 100000 [skipped  117] | loc. loss = 0.2321859300, classif. loss = 0.5493317842
2025-10-03 01:46:33,551 | INFO | iter is 36150 / 100000 [skipped  117] | loc. loss = 0.0659576431, classif. loss = 0.0060355901
2025-10-03 01:47:05,970 | INFO | iter is 36200 / 100000 [skipped  117] | loc. loss = 0.2315380573, classif. loss = 0.6474648714
2025-10-03 01:47:38,399 | INFO | iter is 36250 / 100000 [skipped  117] | loc. loss = 0.2859115303, classif. loss = 0.5022578835
2025-10-03 01:48:10,788 | INFO | iter is 36300 / 100000 [skipped  117] | loc. loss = 0.1329093724, classif. loss = 0.2801151574
2025-10-03 01:48:43,092 | INFO | iter is 36350 / 100000 [skipped  117] | loc. loss = 0.1107978374, classif. loss = 0.1923900545
2025-10-03 01:49:15,592 | INFO | iter is 36400 / 100000 [skipped  117] | loc. loss = 0.2536702454, classif. loss = 0.1135678291
2025-10-03 01:49:47,400 | INFO | iter is 36450 / 100000 [skipped  118] | loc. loss = 0.1038946733, classif. loss = 0.0296138227
2025-10-03 01:50:19,898 | INFO | iter is 36500 / 100000 [skipped  118] | loc. loss = 0.1491436809, classif. loss = 0.1149423048
2025-10-03 01:50:52,294 | INFO | iter is 36550 / 100000 [skipped  118] | loc. loss = 0.1549892128, classif. loss = 0.2145071626
2025-10-03 01:51:24,658 | INFO | iter is 36600 / 100000 [skipped  118] | loc. loss = 0.1062590182, classif. loss = 1.7486398220
2025-10-03 01:51:57,146 | INFO | iter is 36650 / 100000 [skipped  118] | loc. loss = 0.1180474386, classif. loss = 0.6806293726
2025-10-03 01:52:29,565 | INFO | iter is 36700 / 100000 [skipped  118] | loc. loss = 0.2890249789, classif. loss = 0.3031150103
2025-10-03 01:53:01,916 | INFO | iter is 36750 / 100000 [skipped  118] | loc. loss = 0.1995448470, classif. loss = 0.4231456220
2025-10-03 01:53:34,330 | INFO | iter is 36800 / 100000 [skipped  118] | loc. loss = 0.1391260028, classif. loss = 0.0777551532
2025-10-03 01:54:06,660 | INFO | iter is 36850 / 100000 [skipped  118] | loc. loss = 0.2125140578, classif. loss = 0.8792843819
2025-10-03 01:54:38,528 | INFO | iter is 36900 / 100000 [skipped  119] | loc. loss = 0.1092016175, classif. loss = 0.4778822660
2025-10-03 01:55:10,232 | INFO | iter is 36950 / 100000 [skipped  120] | loc. loss = 0.1393310726, classif. loss = 0.4601339102
2025-10-03 01:55:41,997 | INFO | iter is 37000 / 100000 [skipped  121] | loc. loss = 0.1303540617, classif. loss = 0.5965898037
2025-10-03 01:56:14,381 | INFO | iter is 37050 / 100000 [skipped  121] | loc. loss = 0.2003592551, classif. loss = 0.1222815216
2025-10-03 01:56:46,794 | INFO | iter is 37100 / 100000 [skipped  121] | loc. loss = 0.2173472196, classif. loss = 0.1583355665
2025-10-03 01:57:19,088 | INFO | iter is 37150 / 100000 [skipped  121] | loc. loss = 0.2126804739, classif. loss = 0.3411830366
2025-10-03 01:57:51,461 | INFO | iter is 37200 / 100000 [skipped  121] | loc. loss = 0.2469173074, classif. loss = 0.7994679809
2025-10-03 01:58:23,801 | INFO | iter is 37250 / 100000 [skipped  121] | loc. loss = 0.0773670971, classif. loss = 1.2995271683
2025-10-03 01:58:56,187 | INFO | iter is 37300 / 100000 [skipped  121] | loc. loss = 0.2151898295, classif. loss = 0.0827733576
2025-10-03 01:59:28,512 | INFO | iter is 37350 / 100000 [skipped  121] | loc. loss = 0.1863531768, classif. loss = 0.1601613909
2025-10-03 02:00:00,949 | INFO | iter is 37400 / 100000 [skipped  121] | loc. loss = 0.2213244736, classif. loss = 1.2203748226
2025-10-03 02:00:33,333 | INFO | iter is 37450 / 100000 [skipped  121] | loc. loss = 0.1894465089, classif. loss = 0.4246419668
2025-10-03 02:01:05,762 | INFO | iter is 37500 / 100000 [skipped  121] | loc. loss = 0.1861343533, classif. loss = 1.0168492794
2025-10-03 02:01:05,763 | INFO | ---------starting evaluation-----------
2025-10-03 02:01:06,229 | INFO | validation:    0/2126 (2025-10-03_02-01-06)
2025-10-03 02:01:34,236 | INFO | validation:  100/2126 (2025-10-03_02-01-34)
2025-10-03 02:02:02,897 | INFO | validation:  200/2126 (2025-10-03_02-02-02)
2025-10-03 02:02:29,199 | INFO | validation:  300/2126 (2025-10-03_02-02-29)
2025-10-03 02:02:58,198 | INFO | validation:  400/2126 (2025-10-03_02-02-58)
2025-10-03 02:03:28,243 | INFO | validation:  500/2126 (2025-10-03_02-03-28)
2025-10-03 02:03:58,617 | INFO | validation:  600/2126 (2025-10-03_02-03-58)
2025-10-03 02:04:24,935 | INFO | validation:  700/2126 (2025-10-03_02-04-24)
2025-10-03 02:04:53,918 | INFO | validation:  800/2126 (2025-10-03_02-04-53)
2025-10-03 02:05:21,214 | INFO | validation:  900/2126 (2025-10-03_02-05-21)
2025-10-03 02:05:53,577 | INFO | validation: 1000/2126 (2025-10-03_02-05-53)
2025-10-03 02:06:23,259 | INFO | validation: 1100/2126 (2025-10-03_02-06-23)
2025-10-03 02:06:52,243 | INFO | validation: 1200/2126 (2025-10-03_02-06-52)
2025-10-03 02:07:22,574 | INFO | validation: 1300/2126 (2025-10-03_02-07-22)
2025-10-03 02:07:50,545 | INFO | validation: 1400/2126 (2025-10-03_02-07-50)
2025-10-03 02:08:19,200 | INFO | validation: 1500/2126 (2025-10-03_02-08-19)
2025-10-03 02:08:48,195 | INFO | validation: 1600/2126 (2025-10-03_02-08-48)
2025-10-03 02:09:16,179 | INFO | validation: 1700/2126 (2025-10-03_02-09-16)
2025-10-03 02:09:45,516 | INFO | validation: 1800/2126 (2025-10-03_02-09-45)
2025-10-03 02:10:15,515 | INFO | validation: 1900/2126 (2025-10-03_02-10-15)
2025-10-03 02:10:42,827 | INFO | validation: 2000/2126 (2025-10-03_02-10-42)
2025-10-03 02:11:10,820 | INFO | validation: 2100/2126 (2025-10-03_02-11-10)
2025-10-03 02:11:19,229 | INFO | Confusion Matrix of Localization:
[[1292279027    7191406]
 [   6214551   45929480]]
2025-10-03 02:11:19,230 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99446589 0.00553411]
 [0.11918049 0.88081951]]
2025-10-03 02:11:19,230 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41517642  1341483   443204   147905]
 [       0  1024770  1369771   640665    60997]
 [       0   192362   382073  2116615   211881]
 [       0    98717    40048    82416  1761094]]
2025-10-03 02:11:19,230 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95552171 0.03087401 0.01020027 0.00340401]
 [0.         0.33097636 0.44240349 0.20691957 0.01970058]
 [0.         0.06626475 0.13161629 0.72913032 0.07298864]
 [0.         0.04979985 0.02020305 0.04157647 0.88842063]]
2025-10-03 02:11:19,230 | INFO | lofF1 is 87.2646, clfF1 is 67.1525, oaF1 is 73.1861, sub class F1 score is [96.2352 43.9764 68.4343 84.5836]
2025-10-03 02:11:19,231 | INFO | ---------starting train set evaluation-----------
2025-10-03 02:11:19,723 | INFO | [TrainBuf] locF1 is 87.3409, clfF1 is 72.6411, oaF1 is 77.0511, sub class F1 score is [95.3975 54.9526 68.1573 85.373 ]
2025-10-03 02:11:52,239 | INFO | iter is 37550 / 100000 [skipped  121] | loc. loss = 0.1447344869, classif. loss = 0.7106023431
2025-10-03 02:12:24,677 | INFO | iter is 37600 / 100000 [skipped  121] | loc. loss = 0.2600468993, classif. loss = 0.3137464523
2025-10-03 02:12:56,512 | INFO | iter is 37650 / 100000 [skipped  122] | loc. loss = 0.0444799028, classif. loss = 0.2188736498
2025-10-03 02:13:28,330 | INFO | iter is 37700 / 100000 [skipped  123] | loc. loss = 0.1867582798, classif. loss = 0.4841593206
2025-10-03 02:13:59,576 | INFO | iter is 37750 / 100000 [skipped  125] | loc. loss = 0.1283683330, classif. loss = 0.4380697608
2025-10-03 02:14:31,929 | INFO | iter is 37800 / 100000 [skipped  125] | loc. loss = 0.1658069640, classif. loss = 0.3545570076
2025-10-03 02:15:04,318 | INFO | iter is 37850 / 100000 [skipped  125] | loc. loss = 0.2012792379, classif. loss = 0.5109745264
2025-10-03 02:15:36,682 | INFO | iter is 37900 / 100000 [skipped  125] | loc. loss = 0.0986611843, classif. loss = 0.4045281410
2025-10-03 02:16:09,183 | INFO | iter is 37950 / 100000 [skipped  125] | loc. loss = 0.1377587616, classif. loss = 1.3311883211
2025-10-03 02:16:41,579 | INFO | iter is 38000 / 100000 [skipped  125] | loc. loss = 0.0487693585, classif. loss = 0.3426066041
2025-10-03 02:17:13,902 | INFO | iter is 38050 / 100000 [skipped  125] | loc. loss = 0.2001501024, classif. loss = 0.7335755825
2025-10-03 02:17:46,328 | INFO | iter is 38100 / 100000 [skipped  125] | loc. loss = 0.1817314178, classif. loss = 0.6715162992
2025-10-03 02:18:18,741 | INFO | iter is 38150 / 100000 [skipped  125] | loc. loss = 0.1862107813, classif. loss = 0.3034821749
2025-10-03 02:18:51,067 | INFO | iter is 38200 / 100000 [skipped  125] | loc. loss = 0.1349084377, classif. loss = 0.6133956909
2025-10-03 02:19:22,941 | INFO | iter is 38250 / 100000 [skipped  126] | loc. loss = 0.0959515572, classif. loss = 0.0207983367
2025-10-03 02:19:54,674 | INFO | iter is 38300 / 100000 [skipped  127] | loc. loss = 0.2099456489, classif. loss = 0.8090533018
2025-10-03 02:20:27,101 | INFO | iter is 38350 / 100000 [skipped  127] | loc. loss = 0.1921813041, classif. loss = 0.8484072685
2025-10-03 02:20:58,883 | INFO | iter is 38400 / 100000 [skipped  128] | loc. loss = 0.1409904361, classif. loss = 0.1847534627
2025-10-03 02:21:31,433 | INFO | iter is 38450 / 100000 [skipped  128] | loc. loss = 0.1989412308, classif. loss = 0.5620446801
2025-10-03 02:22:03,873 | INFO | iter is 38500 / 100000 [skipped  128] | loc. loss = 0.1594274193, classif. loss = 0.0865125582
2025-10-03 02:22:36,368 | INFO | iter is 38550 / 100000 [skipped  128] | loc. loss = 0.2086370736, classif. loss = 0.0421273969
2025-10-03 02:23:08,714 | INFO | iter is 38600 / 100000 [skipped  128] | loc. loss = 0.1697664261, classif. loss = 0.3062300384
2025-10-03 02:23:41,058 | INFO | iter is 38650 / 100000 [skipped  128] | loc. loss = 0.3572027683, classif. loss = 1.2459506989
2025-10-03 02:24:13,318 | INFO | iter is 38700 / 100000 [skipped  128] | loc. loss = 0.1394994855, classif. loss = 0.0640032515
2025-10-03 02:24:45,692 | INFO | iter is 38750 / 100000 [skipped  128] | loc. loss = 0.1495651007, classif. loss = 0.7041828632
2025-10-03 02:25:18,065 | INFO | iter is 38800 / 100000 [skipped  128] | loc. loss = 0.2280826271, classif. loss = 1.1404166222
2025-10-03 02:25:50,487 | INFO | iter is 38850 / 100000 [skipped  128] | loc. loss = 0.1734390259, classif. loss = 0.6226252317
2025-10-03 02:26:22,888 | INFO | iter is 38900 / 100000 [skipped  128] | loc. loss = 0.2183110416, classif. loss = 1.0807700157
2025-10-03 02:26:55,336 | INFO | iter is 38950 / 100000 [skipped  128] | loc. loss = 0.2069091797, classif. loss = 0.7902897596
2025-10-03 02:27:27,744 | INFO | iter is 39000 / 100000 [skipped  128] | loc. loss = 0.2055521905, classif. loss = 0.1065702587
2025-10-03 02:28:00,160 | INFO | iter is 39050 / 100000 [skipped  128] | loc. loss = 0.2230823040, classif. loss = 0.3848816752
2025-10-03 02:28:32,501 | INFO | iter is 39100 / 100000 [skipped  128] | loc. loss = 0.1034760103, classif. loss = 0.0605729036
2025-10-03 02:29:04,916 | INFO | iter is 39150 / 100000 [skipped  128] | loc. loss = 0.2775102258, classif. loss = 0.9111400843
2025-10-03 02:29:37,200 | INFO | iter is 39200 / 100000 [skipped  128] | loc. loss = 0.1683826149, classif. loss = 0.2445702404
2025-10-03 02:30:09,620 | INFO | iter is 39250 / 100000 [skipped  128] | loc. loss = 0.2117288709, classif. loss = 0.5403903127
2025-10-03 02:30:41,952 | INFO | iter is 39300 / 100000 [skipped  128] | loc. loss = 0.1580056995, classif. loss = 0.5901845694
2025-10-03 02:31:14,362 | INFO | iter is 39350 / 100000 [skipped  128] | loc. loss = 0.2229872644, classif. loss = 0.1036299765
2025-10-03 02:31:46,140 | INFO | iter is 39400 / 100000 [skipped  129] | loc. loss = 0.1974207163, classif. loss = 0.0252978727
2025-10-03 02:32:17,914 | INFO | iter is 39450 / 100000 [skipped  130] | loc. loss = 0.1975608468, classif. loss = 0.5570611954
2025-10-03 02:32:50,221 | INFO | iter is 39500 / 100000 [skipped  130] | loc. loss = 0.0748764649, classif. loss = 0.0594838783
2025-10-03 02:33:22,583 | INFO | iter is 39550 / 100000 [skipped  130] | loc. loss = 0.1780461669, classif. loss = 0.0641713589
2025-10-03 02:33:54,936 | INFO | iter is 39600 / 100000 [skipped  130] | loc. loss = 0.1920472682, classif. loss = 0.6865884066
2025-10-03 02:34:27,385 | INFO | iter is 39650 / 100000 [skipped  130] | loc. loss = 0.2790287733, classif. loss = 0.3857559562
2025-10-03 02:34:59,715 | INFO | iter is 39700 / 100000 [skipped  130] | loc. loss = 0.1392342597, classif. loss = 0.6584815979
2025-10-03 02:35:32,113 | INFO | iter is 39750 / 100000 [skipped  130] | loc. loss = 0.2053913474, classif. loss = 1.0971753597
2025-10-03 02:36:04,516 | INFO | iter is 39800 / 100000 [skipped  130] | loc. loss = 0.3044319749, classif. loss = 1.0997574329
2025-10-03 02:37:08,035 | INFO | iter is 39900 / 100000 [skipped  132] | loc. loss = 0.1466634423, classif. loss = 0.7199233770
2025-10-03 02:37:40,411 | INFO | iter is 39950 / 100000 [skipped  132] | loc. loss = 0.1286322922, classif. loss = 0.2289351225
2025-10-03 02:38:12,247 | INFO | iter is 40000 / 100000 [skipped  133] | loc. loss = 0.0929862857, classif. loss = 2.1253483295
2025-10-03 02:38:43,992 | INFO | iter is 40050 / 100000 [skipped  134] | loc. loss = 0.1059770733, classif. loss = 0.0619943030
2025-10-03 02:39:16,366 | INFO | iter is 40100 / 100000 [skipped  134] | loc. loss = 0.0770073235, classif. loss = 0.4571356177
2025-10-03 02:39:48,800 | INFO | iter is 40150 / 100000 [skipped  134] | loc. loss = 0.0554145500, classif. loss = 0.1778359711
2025-10-03 02:40:21,194 | INFO | iter is 40200 / 100000 [skipped  134] | loc. loss = 0.1457344741, classif. loss = 0.4550441802
2025-10-03 02:40:53,606 | INFO | iter is 40250 / 100000 [skipped  134] | loc. loss = 0.2608255446, classif. loss = 0.1557006836
2025-10-03 02:41:26,079 | INFO | iter is 40300 / 100000 [skipped  134] | loc. loss = 0.0800284371, classif. loss = 1.0575852394
2025-10-03 02:41:58,370 | INFO | iter is 40350 / 100000 [skipped  134] | loc. loss = 0.2320996225, classif. loss = 0.0197277926
2025-10-03 02:42:30,786 | INFO | iter is 40400 / 100000 [skipped  134] | loc. loss = 0.1706661284, classif. loss = 0.5828854442
2025-10-03 02:43:03,148 | INFO | iter is 40450 / 100000 [skipped  134] | loc. loss = 0.1386880875, classif. loss = 0.2977628112
2025-10-03 02:43:35,468 | INFO | iter is 40500 / 100000 [skipped  134] | loc. loss = 0.1612217873, classif. loss = 1.2206883430
2025-10-03 02:44:07,909 | INFO | iter is 40550 / 100000 [skipped  134] | loc. loss = 0.1818263829, classif. loss = 0.5568104982
2025-10-03 02:44:40,208 | INFO | iter is 40600 / 100000 [skipped  134] | loc. loss = 0.1933842152, classif. loss = 0.7664600015
2025-10-03 02:44:55,786 | INFO | ---------starting evaluation-----------
2025-10-03 02:44:56,252 | INFO | validation:    0/2126 (2025-10-03_02-44-56)
2025-10-03 02:45:24,214 | INFO | validation:  100/2126 (2025-10-03_02-45-24)
2025-10-03 02:45:52,813 | INFO | validation:  200/2126 (2025-10-03_02-45-52)
2025-10-03 02:46:19,082 | INFO | validation:  300/2126 (2025-10-03_02-46-19)
2025-10-03 02:46:48,016 | INFO | validation:  400/2126 (2025-10-03_02-46-48)
2025-10-03 02:47:17,984 | INFO | validation:  500/2126 (2025-10-03_02-47-17)
2025-10-03 02:47:48,284 | INFO | validation:  600/2126 (2025-10-03_02-47-48)
2025-10-03 02:48:14,545 | INFO | validation:  700/2126 (2025-10-03_02-48-14)
2025-10-03 02:48:43,484 | INFO | validation:  800/2126 (2025-10-03_02-48-43)
2025-10-03 02:49:10,738 | INFO | validation:  900/2126 (2025-10-03_02-49-10)
2025-10-03 02:49:43,055 | INFO | validation: 1000/2126 (2025-10-03_02-49-43)
2025-10-03 02:50:12,671 | INFO | validation: 1100/2126 (2025-10-03_02-50-12)
2025-10-03 02:50:41,608 | INFO | validation: 1200/2126 (2025-10-03_02-50-41)
2025-10-03 02:51:11,911 | INFO | validation: 1300/2126 (2025-10-03_02-51-11)
2025-10-03 02:51:39,842 | INFO | validation: 1400/2126 (2025-10-03_02-51-39)
2025-10-03 02:52:08,450 | INFO | validation: 1500/2126 (2025-10-03_02-52-08)
2025-10-03 02:52:37,395 | INFO | validation: 1600/2126 (2025-10-03_02-52-37)
2025-10-03 02:53:05,337 | INFO | validation: 1700/2126 (2025-10-03_02-53-05)
2025-10-03 02:53:34,622 | INFO | validation: 1800/2126 (2025-10-03_02-53-34)
2025-10-03 02:54:04,562 | INFO | validation: 1900/2126 (2025-10-03_02-54-04)
2025-10-03 02:54:31,828 | INFO | validation: 2000/2126 (2025-10-03_02-54-31)
2025-10-03 02:54:59,777 | INFO | validation: 2100/2126 (2025-10-03_02-54-59)
2025-10-03 02:55:08,174 | INFO | Confusion Matrix of Localization:
[[1294209193    5261240]
 [   8110683   44033348]]
2025-10-03 02:55:08,174 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99595124 0.00404876]
 [0.15554384 0.84445616]]
2025-10-03 02:55:08,174 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41720989  1272755   260692   195798]
 [       0  1155628  1526104   339156    75315]
 [       0   264019   591944  1853408   193560]
 [       0    89440    38325    72970  1781540]]
2025-10-03 02:55:08,174 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96020171 0.02929225 0.00599978 0.00450626]
 [0.         0.37324039 0.49289533 0.10953933 0.02432496]
 [0.         0.09094911 0.20391253 0.63846092 0.06667744]
 [0.         0.04511987 0.01933385 0.03681124 0.89873504]]
2025-10-03 02:55:08,174 | INFO | lofF1 is 86.8177, clfF1 is 68.6329, oaF1 is 74.0884, sub class F1 score is [96.264  46.7748 68.2761 84.2637]
2025-10-03 02:55:08,175 | INFO | ---------starting train set evaluation-----------
2025-10-03 02:55:08,668 | INFO | [TrainBuf] locF1 is 87.8200, clfF1 is 66.2511, oaF1 is 72.7217, sub class F1 score is [94.546  56.0068 54.2893 73.9388]
2025-10-03 02:55:24,872 | INFO | iter is 40650 / 100000 [skipped  135] | loc. loss = 0.2224866748, classif. loss = 0.8994168043
2025-10-03 02:55:57,351 | INFO | iter is 40700 / 100000 [skipped  135] | loc. loss = 0.1116869375, classif. loss = 0.3176111877
2025-10-03 02:56:29,762 | INFO | iter is 40750 / 100000 [skipped  135] | loc. loss = 0.1854613572, classif. loss = 1.0033328533
2025-10-03 02:57:02,213 | INFO | iter is 40800 / 100000 [skipped  135] | loc. loss = 0.1471046209, classif. loss = 0.0505888388
2025-10-03 02:57:34,536 | INFO | iter is 40850 / 100000 [skipped  135] | loc. loss = 0.1771285385, classif. loss = 0.3481807113
2025-10-03 02:58:06,883 | INFO | iter is 40900 / 100000 [skipped  135] | loc. loss = 0.1473399848, classif. loss = 1.0477786064
2025-10-03 02:58:39,356 | INFO | iter is 40950 / 100000 [skipped  135] | loc. loss = 0.2528254390, classif. loss = 1.1540691853
2025-10-03 02:59:11,721 | INFO | iter is 41000 / 100000 [skipped  135] | loc. loss = 0.2426771522, classif. loss = 0.2198567390
2025-10-03 02:59:44,108 | INFO | iter is 41050 / 100000 [skipped  135] | loc. loss = 0.2331859618, classif. loss = 0.2547090054
2025-10-03 03:00:16,494 | INFO | iter is 41100 / 100000 [skipped  135] | loc. loss = 0.1563403159, classif. loss = 0.1551461518
2025-10-03 03:00:48,837 | INFO | iter is 41150 / 100000 [skipped  135] | loc. loss = 0.1826198101, classif. loss = 0.7419387102
2025-10-03 03:01:21,345 | INFO | iter is 41200 / 100000 [skipped  135] | loc. loss = 0.1715254337, classif. loss = 1.4434279203
2025-10-03 03:01:52,481 | INFO | iter is 41250 / 100000 [skipped  137] | loc. loss = 0.2513450086, classif. loss = 0.8732696176
2025-10-03 03:02:24,258 | INFO | iter is 41300 / 100000 [skipped  138] | loc. loss = 0.1197890490, classif. loss = 1.5275788307
2025-10-03 03:02:56,620 | INFO | iter is 41350 / 100000 [skipped  138] | loc. loss = 0.2097954005, classif. loss = 0.7857676744
2025-10-03 03:03:28,468 | INFO | iter is 41400 / 100000 [skipped  139] | loc. loss = 0.2333762050, classif. loss = 0.1149777472
2025-10-03 03:04:00,265 | INFO | iter is 41450 / 100000 [skipped  140] | loc. loss = 0.1619002372, classif. loss = 0.0221529230
2025-10-03 03:04:32,674 | INFO | iter is 41500 / 100000 [skipped  140] | loc. loss = 0.0863048360, classif. loss = 0.4902654886
2025-10-03 03:05:05,018 | INFO | iter is 41550 / 100000 [skipped  140] | loc. loss = 0.2893517017, classif. loss = 0.6700431705
2025-10-03 03:05:37,465 | INFO | iter is 41600 / 100000 [skipped  140] | loc. loss = 0.2261852324, classif. loss = 0.9473748207
2025-10-03 03:06:09,259 | INFO | iter is 41650 / 100000 [skipped  141] | loc. loss = 0.2799527943, classif. loss = 0.7624908090
2025-10-03 03:06:41,672 | INFO | iter is 41700 / 100000 [skipped  141] | loc. loss = 0.1973564625, classif. loss = 0.1689175367
2025-10-03 03:07:13,986 | INFO | iter is 41750 / 100000 [skipped  141] | loc. loss = 0.1250235736, classif. loss = 0.4522785544
2025-10-03 03:07:46,343 | INFO | iter is 41800 / 100000 [skipped  141] | loc. loss = 0.1147093922, classif. loss = 0.7492792606
2025-10-03 03:08:18,705 | INFO | iter is 41850 / 100000 [skipped  141] | loc. loss = 0.2730988860, classif. loss = 0.2899116278
2025-10-03 03:08:51,081 | INFO | iter is 41900 / 100000 [skipped  141] | loc. loss = 0.2117590755, classif. loss = 0.1014329046
2025-10-03 03:09:23,486 | INFO | iter is 41950 / 100000 [skipped  141] | loc. loss = 0.3140513897, classif. loss = 0.1650881618
2025-10-03 03:09:55,849 | INFO | iter is 42000 / 100000 [skipped  141] | loc. loss = 0.2109000385, classif. loss = 0.0054789088
2025-10-03 03:10:28,255 | INFO | iter is 42050 / 100000 [skipped  141] | loc. loss = 0.1920318156, classif. loss = 0.0095163910
2025-10-03 03:11:00,691 | INFO | iter is 42100 / 100000 [skipped  141] | loc. loss = 0.1965383440, classif. loss = 0.0891169682
2025-10-03 03:11:32,490 | INFO | iter is 42150 / 100000 [skipped  142] | loc. loss = 0.2035412788, classif. loss = 0.0782610029
2025-10-03 03:12:04,881 | INFO | iter is 42200 / 100000 [skipped  142] | loc. loss = 0.1304334104, classif. loss = 0.3158304691
2025-10-03 03:12:37,223 | INFO | iter is 42250 / 100000 [skipped  142] | loc. loss = 0.1998019516, classif. loss = 1.5052533150
2025-10-03 03:13:09,635 | INFO | iter is 42300 / 100000 [skipped  142] | loc. loss = 0.1822209507, classif. loss = 0.3217656016
2025-10-03 03:13:41,981 | INFO | iter is 42350 / 100000 [skipped  142] | loc. loss = 0.1756775081, classif. loss = 1.0744171143
2025-10-03 03:14:14,352 | INFO | iter is 42400 / 100000 [skipped  142] | loc. loss = 0.1585444957, classif. loss = 0.0027783825
2025-10-03 03:14:45,516 | INFO | iter is 42450 / 100000 [skipped  144] | loc. loss = 0.1664105356, classif. loss = 0.0268663745
2025-10-03 03:15:17,981 | INFO | iter is 42500 / 100000 [skipped  144] | loc. loss = 0.1015284434, classif. loss = 0.5304054618
2025-10-03 03:15:50,392 | INFO | iter is 42550 / 100000 [skipped  144] | loc. loss = 0.1811934859, classif. loss = 0.1332521439
2025-10-03 03:16:22,741 | INFO | iter is 42600 / 100000 [skipped  144] | loc. loss = 0.1448199451, classif. loss = 1.0846945047
2025-10-03 03:16:55,127 | INFO | iter is 42650 / 100000 [skipped  144] | loc. loss = 0.0984814614, classif. loss = 1.1600942612
2025-10-03 03:17:26,219 | INFO | iter is 42700 / 100000 [skipped  146] | loc. loss = 0.2939261496, classif. loss = 0.5579971671
2025-10-03 03:17:58,553 | INFO | iter is 42750 / 100000 [skipped  146] | loc. loss = 0.2202945948, classif. loss = 1.0466974974
2025-10-03 03:18:30,951 | INFO | iter is 42800 / 100000 [skipped  146] | loc. loss = 0.2839985192, classif. loss = 0.1198512241
2025-10-03 03:19:03,260 | INFO | iter is 42850 / 100000 [skipped  146] | loc. loss = 0.2184686214, classif. loss = 0.7748799324
2025-10-03 03:19:35,735 | INFO | iter is 42900 / 100000 [skipped  146] | loc. loss = 0.2103188783, classif. loss = 0.3681047261
2025-10-03 03:20:08,078 | INFO | iter is 42950 / 100000 [skipped  146] | loc. loss = 0.1483578831, classif. loss = 0.5861557126
2025-10-03 03:20:39,919 | INFO | iter is 43000 / 100000 [skipped  147] | loc. loss = 0.1266319007, classif. loss = 0.4860467613
2025-10-03 03:21:12,332 | INFO | iter is 43050 / 100000 [skipped  147] | loc. loss = 0.1579392999, classif. loss = 0.4052386284
2025-10-03 03:21:44,793 | INFO | iter is 43100 / 100000 [skipped  147] | loc. loss = 0.1012602076, classif. loss = 0.0275321975
2025-10-03 03:22:17,196 | INFO | iter is 43150 / 100000 [skipped  147] | loc. loss = 0.1807405353, classif. loss = 0.1640960872
2025-10-03 03:22:49,688 | INFO | iter is 43200 / 100000 [skipped  147] | loc. loss = 0.1507957876, classif. loss = 0.9925216436
2025-10-03 03:23:22,095 | INFO | iter is 43250 / 100000 [skipped  147] | loc. loss = 0.3889380097, classif. loss = 0.3532376289
2025-10-03 03:23:54,616 | INFO | iter is 43300 / 100000 [skipped  147] | loc. loss = 0.1816047579, classif. loss = 0.8588292599
2025-10-03 03:24:27,073 | INFO | iter is 43350 / 100000 [skipped  147] | loc. loss = 0.2837386727, classif. loss = 0.4621795118
2025-10-03 03:24:59,585 | INFO | iter is 43400 / 100000 [skipped  147] | loc. loss = 0.1784877926, classif. loss = 0.3602102101
2025-10-03 03:25:31,440 | INFO | iter is 43450 / 100000 [skipped  148] | loc. loss = 0.1343402565, classif. loss = 0.4016132951
2025-10-03 03:26:03,886 | INFO | iter is 43500 / 100000 [skipped  148] | loc. loss = 0.1256801784, classif. loss = 0.0129309511
2025-10-03 03:26:36,187 | INFO | iter is 43550 / 100000 [skipped  148] | loc. loss = 0.1679749191, classif. loss = 0.4030609131
2025-10-03 03:27:08,550 | INFO | iter is 43600 / 100000 [skipped  148] | loc. loss = 0.1743761599, classif. loss = 0.4162557423
2025-10-03 03:27:40,355 | INFO | iter is 43650 / 100000 [skipped  149] | loc. loss = 0.1535201967, classif. loss = 0.3919562101
2025-10-03 03:28:12,837 | INFO | iter is 43700 / 100000 [skipped  149] | loc. loss = 0.1363682300, classif. loss = 0.4080465436
2025-10-03 03:28:45,272 | INFO | iter is 43750 / 100000 [skipped  149] | loc. loss = 0.1397795677, classif. loss = 0.0226277672
2025-10-03 03:28:45,273 | INFO | ---------starting evaluation-----------
2025-10-03 03:28:45,738 | INFO | validation:    0/2126 (2025-10-03_03-28-45)
2025-10-03 03:29:14,003 | INFO | validation:  100/2126 (2025-10-03_03-29-14)
2025-10-03 03:29:42,958 | INFO | validation:  200/2126 (2025-10-03_03-29-42)
2025-10-03 03:30:09,483 | INFO | validation:  300/2126 (2025-10-03_03-30-09)
2025-10-03 03:30:38,753 | INFO | validation:  400/2126 (2025-10-03_03-30-38)
2025-10-03 03:31:09,061 | INFO | validation:  500/2126 (2025-10-03_03-31-09)
2025-10-03 03:31:39,687 | INFO | validation:  600/2126 (2025-10-03_03-31-39)
2025-10-03 03:32:06,246 | INFO | validation:  700/2126 (2025-10-03_03-32-06)
2025-10-03 03:32:35,526 | INFO | validation:  800/2126 (2025-10-03_03-32-35)
2025-10-03 03:33:03,075 | INFO | validation:  900/2126 (2025-10-03_03-33-03)
2025-10-03 03:33:35,786 | INFO | validation: 1000/2126 (2025-10-03_03-33-35)
2025-10-03 03:34:05,736 | INFO | validation: 1100/2126 (2025-10-03_03-34-05)
2025-10-03 03:34:34,995 | INFO | validation: 1200/2126 (2025-10-03_03-34-34)
2025-10-03 03:35:05,652 | INFO | validation: 1300/2126 (2025-10-03_03-35-05)
2025-10-03 03:35:33,898 | INFO | validation: 1400/2126 (2025-10-03_03-35-33)
2025-10-03 03:36:02,833 | INFO | validation: 1500/2126 (2025-10-03_03-36-02)
2025-10-03 03:36:32,114 | INFO | validation: 1600/2126 (2025-10-03_03-36-32)
2025-10-03 03:37:00,340 | INFO | validation: 1700/2126 (2025-10-03_03-37-00)
2025-10-03 03:37:29,904 | INFO | validation: 1800/2126 (2025-10-03_03-37-29)
2025-10-03 03:38:00,195 | INFO | validation: 1900/2126 (2025-10-03_03-38-00)
2025-10-03 03:38:27,761 | INFO | validation: 2000/2126 (2025-10-03_03-38-27)
2025-10-03 03:38:56,039 | INFO | validation: 2100/2126 (2025-10-03_03-38-56)
2025-10-03 03:39:04,533 | INFO | Confusion Matrix of Localization:
[[1293665553    5804880]
 [   7124465   45019566]]
2025-10-03 03:39:04,533 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99553289 0.00446711]
 [0.1366305  0.8633695 ]]
2025-10-03 03:39:04,533 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41804600  1383382   207331    54921]
 [       0  1019897  1547631   502428    26247]
 [       0   233420   392646  2141952   134913]
 [       0   129113    41872   128852  1682438]]
2025-10-03 03:39:04,533 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.962126   0.03183831 0.00477169 0.001264  ]
 [0.         0.3294025  0.49984804 0.16227231 0.00847716]
 [0.         0.08040839 0.13525847 0.73785839 0.04647475]
 [0.         0.06513375 0.0211232  0.06500208 0.84874097]]
2025-10-03 03:39:04,533 | INFO | lofF1 is 87.4434, clfF1 is 70.7895, oaF1 is 75.7856, sub class F1 score is [96.5049 47.9014 72.8122 86.7059]
2025-10-03 03:39:04,534 | INFO | ---------starting train set evaluation-----------
2025-10-03 03:39:05,031 | INFO | [TrainBuf] locF1 is 89.0408, clfF1 is 79.6322, oaF1 is 82.4548, sub class F1 score is [97.2156 68.5366 74.5874 83.7053]
2025-10-03 03:39:37,492 | INFO | iter is 43800 / 100000 [skipped  149] | loc. loss = 0.1956290156, classif. loss = 0.8796980381
2025-10-03 03:40:09,877 | INFO | iter is 43850 / 100000 [skipped  149] | loc. loss = 0.0979556292, classif. loss = 0.4171842933
2025-10-03 03:40:42,369 | INFO | iter is 43900 / 100000 [skipped  149] | loc. loss = 0.1522306800, classif. loss = 0.3588384390
2025-10-03 03:41:14,713 | INFO | iter is 43950 / 100000 [skipped  149] | loc. loss = 0.1016931683, classif. loss = 1.0693325996
2025-10-03 03:41:47,093 | INFO | iter is 44000 / 100000 [skipped  149] | loc. loss = 0.1518509388, classif. loss = 0.4931619465
2025-10-03 03:42:19,468 | INFO | iter is 44050 / 100000 [skipped  149] | loc. loss = 0.1014471948, classif. loss = 0.4516531825
2025-10-03 03:42:51,919 | INFO | iter is 44100 / 100000 [skipped  149] | loc. loss = 0.2290095687, classif. loss = 1.6814097166
2025-10-03 03:43:24,329 | INFO | iter is 44150 / 100000 [skipped  149] | loc. loss = 0.2318709195, classif. loss = 0.7102222443
2025-10-03 03:43:56,749 | INFO | iter is 44200 / 100000 [skipped  149] | loc. loss = 0.2118752599, classif. loss = 0.2234669328
2025-10-03 03:44:29,155 | INFO | iter is 44250 / 100000 [skipped  149] | loc. loss = 0.0959172249, classif. loss = 0.3445873857
2025-10-03 03:45:01,085 | INFO | iter is 44300 / 100000 [skipped  150] | loc. loss = 0.2764016986, classif. loss = 1.0303418636
2025-10-03 03:45:32,966 | INFO | iter is 44350 / 100000 [skipped  151] | loc. loss = 0.2146855295, classif. loss = 0.0988322645
2025-10-03 03:46:05,444 | INFO | iter is 44400 / 100000 [skipped  151] | loc. loss = 0.1462200582, classif. loss = 0.6100803614
2025-10-03 03:46:37,854 | INFO | iter is 44450 / 100000 [skipped  151] | loc. loss = 0.1400954127, classif. loss = 0.0498047583
2025-10-03 03:47:10,407 | INFO | iter is 44500 / 100000 [skipped  151] | loc. loss = 0.0808602199, classif. loss = 0.0797122046
2025-10-03 03:47:42,879 | INFO | iter is 44550 / 100000 [skipped  151] | loc. loss = 0.3012294173, classif. loss = 0.1834208965
2025-10-03 03:48:15,396 | INFO | iter is 44600 / 100000 [skipped  151] | loc. loss = 0.1074108183, classif. loss = 0.0373533294
2025-10-03 03:48:47,836 | INFO | iter is 44650 / 100000 [skipped  151] | loc. loss = 0.2198108137, classif. loss = 0.9787790775
2025-10-03 03:49:20,370 | INFO | iter is 44700 / 100000 [skipped  151] | loc. loss = 0.1537311673, classif. loss = 0.4553829432
2025-10-03 03:49:52,805 | INFO | iter is 44750 / 100000 [skipped  151] | loc. loss = 0.1695048958, classif. loss = 0.3665584922
2025-10-03 03:50:24,650 | INFO | iter is 44800 / 100000 [skipped  152] | loc. loss = 0.1765189767, classif. loss = 0.7192852497
2025-10-03 03:50:56,395 | INFO | iter is 44850 / 100000 [skipped  153] | loc. loss = 0.1085222736, classif. loss = 0.8675923347
2025-10-03 03:51:28,822 | INFO | iter is 44900 / 100000 [skipped  153] | loc. loss = 0.1567064673, classif. loss = 0.5277214050
2025-10-03 03:52:01,166 | INFO | iter is 44950 / 100000 [skipped  153] | loc. loss = 0.2985873520, classif. loss = 0.1629744023
2025-10-03 03:52:33,611 | INFO | iter is 45000 / 100000 [skipped  153] | loc. loss = 0.1522898227, classif. loss = 0.9531329870
2025-10-03 03:53:05,422 | INFO | iter is 45050 / 100000 [skipped  154] | loc. loss = 0.1424496025, classif. loss = 0.0172033645
2025-10-03 03:53:37,859 | INFO | iter is 45100 / 100000 [skipped  154] | loc. loss = 0.1569201052, classif. loss = 1.2593262196
2025-10-03 03:54:10,267 | INFO | iter is 45150 / 100000 [skipped  154] | loc. loss = 0.2417757362, classif. loss = 0.6878273487
2025-10-03 03:54:42,619 | INFO | iter is 45200 / 100000 [skipped  154] | loc. loss = 0.1834536642, classif. loss = 0.0518399924
2025-10-03 03:55:15,059 | INFO | iter is 45250 / 100000 [skipped  154] | loc. loss = 0.0912210047, classif. loss = 0.1007610261
2025-10-03 03:55:47,423 | INFO | iter is 45300 / 100000 [skipped  154] | loc. loss = 0.1608050764, classif. loss = 0.0272841323
2025-10-03 03:56:19,829 | INFO | iter is 45350 / 100000 [skipped  154] | loc. loss = 0.1659224480, classif. loss = 0.8698791265
2025-10-03 03:57:24,031 | INFO | iter is 45450 / 100000 [skipped  155] | loc. loss = 0.1364709139, classif. loss = 0.0761714354
2025-10-03 03:57:55,807 | INFO | iter is 45500 / 100000 [skipped  156] | loc. loss = 0.2021520436, classif. loss = 0.0955827609
2025-10-03 03:58:28,253 | INFO | iter is 45550 / 100000 [skipped  156] | loc. loss = 0.0835360736, classif. loss = 0.2393989563
2025-10-03 03:59:00,660 | INFO | iter is 45600 / 100000 [skipped  156] | loc. loss = 0.1828486621, classif. loss = 0.4564333260
2025-10-03 03:59:33,085 | INFO | iter is 45650 / 100000 [skipped  156] | loc. loss = 0.3359534442, classif. loss = 0.6695660949
2025-10-03 04:00:05,595 | INFO | iter is 45700 / 100000 [skipped  156] | loc. loss = 0.3456312418, classif. loss = 0.4285352528
2025-10-03 04:00:37,967 | INFO | iter is 45750 / 100000 [skipped  156] | loc. loss = 0.1929116547, classif. loss = 0.2705458105
2025-10-03 04:01:10,316 | INFO | iter is 45800 / 100000 [skipped  156] | loc. loss = 0.2355890423, classif. loss = 0.0990848243
2025-10-03 04:01:41,519 | INFO | iter is 45850 / 100000 [skipped  158] | loc. loss = 0.1488670856, classif. loss = 0.6740022898
2025-10-03 04:02:13,880 | INFO | iter is 45900 / 100000 [skipped  158] | loc. loss = 0.2097171843, classif. loss = 0.4882288575
2025-10-03 04:02:46,252 | INFO | iter is 45950 / 100000 [skipped  158] | loc. loss = 0.0624505244, classif. loss = 0.3034539223
2025-10-03 04:03:18,535 | INFO | iter is 46000 / 100000 [skipped  158] | loc. loss = 0.2359634936, classif. loss = 0.0456277207
2025-10-03 04:03:50,285 | INFO | iter is 46050 / 100000 [skipped  159] | loc. loss = 0.1921548247, classif. loss = 0.4018873274
2025-10-03 04:04:22,653 | INFO | iter is 46100 / 100000 [skipped  159] | loc. loss = 0.0802731663, classif. loss = 1.5117399693
2025-10-03 04:04:55,041 | INFO | iter is 46150 / 100000 [skipped  159] | loc. loss = 0.2546034455, classif. loss = 0.5095709562
2025-10-03 04:05:27,388 | INFO | iter is 46200 / 100000 [skipped  159] | loc. loss = 0.2232601345, classif. loss = 0.5785117149
2025-10-03 04:05:59,824 | INFO | iter is 46250 / 100000 [skipped  159] | loc. loss = 0.1581387520, classif. loss = 0.2569098175
2025-10-03 04:06:32,283 | INFO | iter is 46300 / 100000 [skipped  159] | loc. loss = 0.1477658153, classif. loss = 0.3695589304
2025-10-03 04:07:04,656 | INFO | iter is 46350 / 100000 [skipped  159] | loc. loss = 0.1974586248, classif. loss = 1.4543930292
2025-10-03 04:07:37,055 | INFO | iter is 46400 / 100000 [skipped  159] | loc. loss = 0.2356660664, classif. loss = 0.3772770166
2025-10-03 04:08:09,487 | INFO | iter is 46450 / 100000 [skipped  159] | loc. loss = 0.1383455843, classif. loss = 0.0553627238
2025-10-03 04:08:41,898 | INFO | iter is 46500 / 100000 [skipped  159] | loc. loss = 0.2118781507, classif. loss = 0.9615107775
2025-10-03 04:09:14,338 | INFO | iter is 46550 / 100000 [skipped  159] | loc. loss = 0.1488800943, classif. loss = 0.8928064108
2025-10-03 04:09:46,780 | INFO | iter is 46600 / 100000 [skipped  159] | loc. loss = 0.3238478005, classif. loss = 0.0358978882
2025-10-03 04:10:18,552 | INFO | iter is 46650 / 100000 [skipped  160] | loc. loss = 0.1519319862, classif. loss = 0.0156391840
2025-10-03 04:10:50,955 | INFO | iter is 46700 / 100000 [skipped  160] | loc. loss = 0.1672398299, classif. loss = 0.0732662529
2025-10-03 04:11:23,421 | INFO | iter is 46750 / 100000 [skipped  160] | loc. loss = 0.0723292232, classif. loss = 2.5650517941
2025-10-03 04:11:55,784 | INFO | iter is 46800 / 100000 [skipped  160] | loc. loss = 0.1773816347, classif. loss = 0.6699987054
2025-10-03 04:12:28,131 | INFO | iter is 46850 / 100000 [skipped  160] | loc. loss = 0.2518240809, classif. loss = 0.6831554174
2025-10-03 04:12:44,381 | INFO | ---------starting evaluation-----------
2025-10-03 04:12:44,851 | INFO | validation:    0/2126 (2025-10-03_04-12-44)
2025-10-03 04:13:12,890 | INFO | validation:  100/2126 (2025-10-03_04-13-12)
2025-10-03 04:13:41,553 | INFO | validation:  200/2126 (2025-10-03_04-13-41)
2025-10-03 04:14:07,876 | INFO | validation:  300/2126 (2025-10-03_04-14-07)
2025-10-03 04:14:36,885 | INFO | validation:  400/2126 (2025-10-03_04-14-36)
2025-10-03 04:15:06,907 | INFO | validation:  500/2126 (2025-10-03_04-15-06)
2025-10-03 04:15:37,300 | INFO | validation:  600/2126 (2025-10-03_04-15-37)
2025-10-03 04:16:03,615 | INFO | validation:  700/2126 (2025-10-03_04-16-03)
2025-10-03 04:16:32,627 | INFO | validation:  800/2126 (2025-10-03_04-16-32)
2025-10-03 04:16:59,960 | INFO | validation:  900/2126 (2025-10-03_04-16-59)
2025-10-03 04:17:32,372 | INFO | validation: 1000/2126 (2025-10-03_04-17-32)
2025-10-03 04:18:02,081 | INFO | validation: 1100/2126 (2025-10-03_04-18-02)
2025-10-03 04:18:31,123 | INFO | validation: 1200/2126 (2025-10-03_04-18-31)
2025-10-03 04:19:01,512 | INFO | validation: 1300/2126 (2025-10-03_04-19-01)
2025-10-03 04:19:29,501 | INFO | validation: 1400/2126 (2025-10-03_04-19-29)
2025-10-03 04:19:58,197 | INFO | validation: 1500/2126 (2025-10-03_04-19-58)
2025-10-03 04:20:27,232 | INFO | validation: 1600/2126 (2025-10-03_04-20-27)
2025-10-03 04:20:55,256 | INFO | validation: 1700/2126 (2025-10-03_04-20-55)
2025-10-03 04:21:24,621 | INFO | validation: 1800/2126 (2025-10-03_04-21-24)
2025-10-03 04:21:54,643 | INFO | validation: 1900/2126 (2025-10-03_04-21-54)
2025-10-03 04:22:21,990 | INFO | validation: 2000/2126 (2025-10-03_04-22-21)
2025-10-03 04:22:50,010 | INFO | validation: 2100/2126 (2025-10-03_04-22-50)
2025-10-03 04:22:58,431 | INFO | Confusion Matrix of Localization:
[[1293772717    5697716]
 [   7157251   44986780]]
2025-10-03 04:22:58,431 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99561536 0.00438464]
 [0.13725926 0.86274074]]
2025-10-03 04:22:58,432 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40993113  1975659   314502   166960]
 [       0   922710  1721972   416918    34603]
 [       0   238548   583663  1968714   112006]
 [       0    73980    52828   151348  1704119]]
2025-10-03 04:22:58,432 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.94344976 0.04546947 0.00723821 0.00384256]
 [0.         0.29801341 0.55615604 0.13465461 0.01117595]
 [0.         0.08217488 0.20105989 0.67818147 0.03858376]
 [0.         0.03732076 0.02665019 0.07635066 0.8596784 ]]
2025-10-03 04:22:58,432 | INFO | lofF1 is 87.4986, clfF1 is 68.5210, oaF1 is 74.2143, sub class F1 score is [95.6904 46.3498 68.4245 85.2067]
2025-10-03 04:22:58,432 | INFO | ---------starting train set evaluation-----------
2025-10-03 04:22:58,931 | INFO | [TrainBuf] locF1 is 88.3385, clfF1 is 70.4424, oaF1 is 75.8112, sub class F1 score is [95.545  52.1827 67.0621 81.6811]
2025-10-03 04:23:15,192 | INFO | iter is 46900 / 100000 [skipped  160] | loc. loss = 0.1661068648, classif. loss = 0.3872974813
2025-10-03 04:23:47,605 | INFO | iter is 46950 / 100000 [skipped  160] | loc. loss = 0.1469822824, classif. loss = 0.9343549609
2025-10-03 04:24:20,031 | INFO | iter is 47000 / 100000 [skipped  160] | loc. loss = 0.0655980036, classif. loss = 1.4882332087
2025-10-03 04:24:52,389 | INFO | iter is 47050 / 100000 [skipped  160] | loc. loss = 0.2126895934, classif. loss = 0.0769864619
2025-10-03 04:25:24,809 | INFO | iter is 47100 / 100000 [skipped  160] | loc. loss = 0.1272234321, classif. loss = 0.1071071625
2025-10-03 04:25:57,247 | INFO | iter is 47150 / 100000 [skipped  160] | loc. loss = 0.1370921731, classif. loss = 0.0297709517
2025-10-03 04:26:29,797 | INFO | iter is 47200 / 100000 [skipped  160] | loc. loss = 0.2137031853, classif. loss = 0.2621852756
2025-10-03 04:27:02,223 | INFO | iter is 47250 / 100000 [skipped  160] | loc. loss = 0.0701427460, classif. loss = 0.5846211910
2025-10-03 04:27:34,707 | INFO | iter is 47300 / 100000 [skipped  160] | loc. loss = 0.1902057230, classif. loss = 0.5544523597
2025-10-03 04:28:07,102 | INFO | iter is 47350 / 100000 [skipped  160] | loc. loss = 0.1212161407, classif. loss = 0.3035620153
2025-10-03 04:28:39,543 | INFO | iter is 47400 / 100000 [skipped  160] | loc. loss = 0.0936609581, classif. loss = 0.9278167486
2025-10-03 04:29:11,940 | INFO | iter is 47450 / 100000 [skipped  160] | loc. loss = 0.1613520682, classif. loss = 0.5881203413
2025-10-03 04:29:44,287 | INFO | iter is 47500 / 100000 [skipped  160] | loc. loss = 0.1162606478, classif. loss = 0.3168617487
2025-10-03 04:30:15,504 | INFO | iter is 47550 / 100000 [skipped  162] | loc. loss = 0.0557221621, classif. loss = 0.8364107013
2025-10-03 04:30:47,880 | INFO | iter is 47600 / 100000 [skipped  162] | loc. loss = 0.2001883388, classif. loss = 0.7094291449
2025-10-03 04:31:20,358 | INFO | iter is 47650 / 100000 [skipped  162] | loc. loss = 0.1653762758, classif. loss = 0.2599626184
2025-10-03 04:31:52,789 | INFO | iter is 47700 / 100000 [skipped  162] | loc. loss = 0.1899424642, classif. loss = 0.4601824284
2025-10-03 04:32:25,181 | INFO | iter is 47750 / 100000 [skipped  162] | loc. loss = 0.1488390118, classif. loss = 0.0165357888
2025-10-03 04:32:57,508 | INFO | iter is 47800 / 100000 [skipped  162] | loc. loss = 0.0830157474, classif. loss = 0.3570463657
2025-10-03 04:33:29,891 | INFO | iter is 47850 / 100000 [skipped  162] | loc. loss = 0.3555936217, classif. loss = 0.8362959027
2025-10-03 04:34:02,295 | INFO | iter is 47900 / 100000 [skipped  162] | loc. loss = 0.2513501048, classif. loss = 0.3289324641
2025-10-03 04:34:34,745 | INFO | iter is 47950 / 100000 [skipped  162] | loc. loss = 0.1698720157, classif. loss = 0.7738861442
2025-10-03 04:35:07,079 | INFO | iter is 48000 / 100000 [skipped  162] | loc. loss = 0.2170807421, classif. loss = 0.5265238285
2025-10-03 04:35:39,429 | INFO | iter is 48050 / 100000 [skipped  162] | loc. loss = 0.2215973586, classif. loss = 2.2667717934
2025-10-03 04:36:11,851 | INFO | iter is 48100 / 100000 [skipped  162] | loc. loss = 0.2044744194, classif. loss = 0.6094200611
2025-10-03 04:36:44,270 | INFO | iter is 48150 / 100000 [skipped  162] | loc. loss = 0.1243114546, classif. loss = 0.0335588083
2025-10-03 04:37:16,731 | INFO | iter is 48200 / 100000 [skipped  162] | loc. loss = 0.1887244433, classif. loss = 0.5816358328
2025-10-03 04:37:49,204 | INFO | iter is 48250 / 100000 [skipped  162] | loc. loss = 0.1809046268, classif. loss = 0.8675367832
2025-10-03 04:38:21,618 | INFO | iter is 48300 / 100000 [skipped  162] | loc. loss = 0.1446046531, classif. loss = 0.5313446522
2025-10-03 04:38:54,023 | INFO | iter is 48350 / 100000 [skipped  162] | loc. loss = 0.2312188745, classif. loss = 0.1894071847
2025-10-03 04:39:26,446 | INFO | iter is 48400 / 100000 [skipped  162] | loc. loss = 0.1851661801, classif. loss = 0.1102917269
2025-10-03 04:39:58,919 | INFO | iter is 48450 / 100000 [skipped  162] | loc. loss = 0.0715698004, classif. loss = 0.0519109629
2025-10-03 04:40:30,132 | INFO | iter is 48500 / 100000 [skipped  164] | loc. loss = 0.1768886298, classif. loss = 0.9843155146
2025-10-03 04:41:02,592 | INFO | iter is 48550 / 100000 [skipped  164] | loc. loss = 0.1702367067, classif. loss = 0.0502356142
2025-10-03 04:41:35,031 | INFO | iter is 48600 / 100000 [skipped  164] | loc. loss = 0.1808332503, classif. loss = 0.7260894775
2025-10-03 04:42:07,470 | INFO | iter is 48650 / 100000 [skipped  164] | loc. loss = 0.2087213397, classif. loss = 2.4126372337
2025-10-03 04:42:39,950 | INFO | iter is 48700 / 100000 [skipped  164] | loc. loss = 0.1608267277, classif. loss = 0.9146072268
2025-10-03 04:43:11,816 | INFO | iter is 48750 / 100000 [skipped  165] | loc. loss = 0.1419207305, classif. loss = 1.8930292130
2025-10-03 04:43:43,584 | INFO | iter is 48800 / 100000 [skipped  166] | loc. loss = 0.2879360020, classif. loss = 0.6961202621
2025-10-03 04:44:15,943 | INFO | iter is 48850 / 100000 [skipped  166] | loc. loss = 0.2038848400, classif. loss = 0.5765711069
2025-10-03 04:44:48,387 | INFO | iter is 48900 / 100000 [skipped  166] | loc. loss = 0.2004023641, classif. loss = 0.1203138679
2025-10-03 04:45:20,778 | INFO | iter is 48950 / 100000 [skipped  166] | loc. loss = 0.1888144910, classif. loss = 1.0029556751
2025-10-03 04:45:53,213 | INFO | iter is 49000 / 100000 [skipped  166] | loc. loss = 0.2155063450, classif. loss = 1.6400554180
2025-10-03 04:46:25,542 | INFO | iter is 49050 / 100000 [skipped  166] | loc. loss = 0.2552561164, classif. loss = 0.6483008862
2025-10-03 04:46:57,974 | INFO | iter is 49100 / 100000 [skipped  166] | loc. loss = 0.0995141938, classif. loss = 0.2707061172
2025-10-03 04:47:30,320 | INFO | iter is 49150 / 100000 [skipped  166] | loc. loss = 0.1071569026, classif. loss = 1.0043911934
2025-10-03 04:48:02,722 | INFO | iter is 49200 / 100000 [skipped  166] | loc. loss = 0.1360239089, classif. loss = 1.3396512270
2025-10-03 04:48:35,052 | INFO | iter is 49250 / 100000 [skipped  166] | loc. loss = 0.1491527557, classif. loss = 0.0039452869
2025-10-03 04:49:07,522 | INFO | iter is 49300 / 100000 [skipped  166] | loc. loss = 0.1647958159, classif. loss = 0.0939349085
2025-10-03 04:49:39,252 | INFO | iter is 49350 / 100000 [skipped  167] | loc. loss = 0.1903788745, classif. loss = 0.1112904698
2025-10-03 04:50:11,718 | INFO | iter is 49400 / 100000 [skipped  167] | loc. loss = 0.0684998482, classif. loss = 0.4383948147
2025-10-03 04:50:44,076 | INFO | iter is 49450 / 100000 [skipped  167] | loc. loss = 0.0924296156, classif. loss = 0.0939417332
2025-10-03 04:51:16,575 | INFO | iter is 49500 / 100000 [skipped  167] | loc. loss = 0.1694869101, classif. loss = 0.3192079365
2025-10-03 04:51:49,001 | INFO | iter is 49550 / 100000 [skipped  167] | loc. loss = 0.1586794853, classif. loss = 0.5829256177
2025-10-03 04:52:20,819 | INFO | iter is 49600 / 100000 [skipped  168] | loc. loss = 0.2664481401, classif. loss = 0.8235506415
2025-10-03 04:52:53,266 | INFO | iter is 49650 / 100000 [skipped  168] | loc. loss = 0.2213142067, classif. loss = 0.8569281697
2025-10-03 04:53:25,682 | INFO | iter is 49700 / 100000 [skipped  168] | loc. loss = 0.2036628127, classif. loss = 0.4616302848
2025-10-03 04:53:58,073 | INFO | iter is 49750 / 100000 [skipped  168] | loc. loss = 0.2243595570, classif. loss = 0.5553101301
2025-10-03 04:54:30,484 | INFO | iter is 49800 / 100000 [skipped  168] | loc. loss = 0.1631634682, classif. loss = 0.0579149574
2025-10-03 04:55:02,878 | INFO | iter is 49850 / 100000 [skipped  168] | loc. loss = 0.1134482175, classif. loss = 0.7634382844
2025-10-03 04:55:35,307 | INFO | iter is 49900 / 100000 [skipped  168] | loc. loss = 0.2862785459, classif. loss = 0.4377033114
2025-10-03 04:56:07,735 | INFO | iter is 49950 / 100000 [skipped  168] | loc. loss = 0.0861271918, classif. loss = 0.2342941165
2025-10-03 04:56:39,528 | INFO | iter is 50000 / 100000 [skipped  169] | loc. loss = 0.0971202701, classif. loss = 0.5101652741
2025-10-03 04:56:39,530 | INFO | ---------starting evaluation-----------
2025-10-03 04:56:39,986 | INFO | validation:    0/2126 (2025-10-03_04-56-39)
2025-10-03 04:57:08,030 | INFO | validation:  100/2126 (2025-10-03_04-57-08)
2025-10-03 04:57:36,688 | INFO | validation:  200/2126 (2025-10-03_04-57-36)
2025-10-03 04:58:03,002 | INFO | validation:  300/2126 (2025-10-03_04-58-03)
2025-10-03 04:58:31,987 | INFO | validation:  400/2126 (2025-10-03_04-58-31)
2025-10-03 04:59:01,990 | INFO | validation:  500/2126 (2025-10-03_04-59-01)
2025-10-03 04:59:32,320 | INFO | validation:  600/2126 (2025-10-03_04-59-32)
2025-10-03 04:59:58,606 | INFO | validation:  700/2126 (2025-10-03_04-59-58)
2025-10-03 05:00:27,617 | INFO | validation:  800/2126 (2025-10-03_05-00-27)
2025-10-03 05:00:54,910 | INFO | validation:  900/2126 (2025-10-03_05-00-54)
2025-10-03 05:01:27,264 | INFO | validation: 1000/2126 (2025-10-03_05-01-27)
2025-10-03 05:01:56,952 | INFO | validation: 1100/2126 (2025-10-03_05-01-56)
2025-10-03 05:02:25,951 | INFO | validation: 1200/2126 (2025-10-03_05-02-25)
2025-10-03 05:02:56,309 | INFO | validation: 1300/2126 (2025-10-03_05-02-56)
2025-10-03 05:03:24,291 | INFO | validation: 1400/2126 (2025-10-03_05-03-24)
2025-10-03 05:03:52,941 | INFO | validation: 1500/2126 (2025-10-03_05-03-52)
2025-10-03 05:04:21,920 | INFO | validation: 1600/2126 (2025-10-03_05-04-21)
2025-10-03 05:04:49,882 | INFO | validation: 1700/2126 (2025-10-03_05-04-49)
2025-10-03 05:05:19,220 | INFO | validation: 1800/2126 (2025-10-03_05-05-19)
2025-10-03 05:05:49,218 | INFO | validation: 1900/2126 (2025-10-03_05-05-49)
2025-10-03 05:06:16,546 | INFO | validation: 2000/2126 (2025-10-03_05-06-16)
2025-10-03 05:06:44,552 | INFO | validation: 2100/2126 (2025-10-03_05-06-44)
2025-10-03 05:06:52,962 | INFO | Confusion Matrix of Localization:
[[1293474095    5996338]
 [   7291337   44852694]]
2025-10-03 05:06:52,962 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99538555 0.00461445]
 [0.13983071 0.86016929]]
2025-10-03 05:06:52,962 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40912729  1640000   574674   322831]
 [       0   870085  1469649   694555    61914]
 [       0   139329   247572  2274675   241355]
 [       0    56413    27245    70788  1827829]]
2025-10-03 05:06:52,962 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.94159974 0.03774433 0.01322603 0.0074299 ]
 [0.         0.28101678 0.47466171 0.22432476 0.01999675]
 [0.         0.04799597 0.08528346 0.78357873 0.08314183]
 [0.         0.02845872 0.01374431 0.03571048 0.92208649]]
2025-10-03 05:06:52,963 | INFO | lofF1 is 87.0985, clfF1 is 67.8537, oaF1 is 73.6271, sub class F1 score is [95.7821 45.3548 69.8007 82.4051]
2025-10-03 05:06:52,963 | INFO | ---------starting train set evaluation-----------
2025-10-03 05:06:53,462 | INFO | [TrainBuf] locF1 is 88.2386, clfF1 is 74.2614, oaF1 is 78.4546, sub class F1 score is [96.3025 52.5521 75.9835 88.5713]
2025-10-03 05:07:25,934 | INFO | iter is 50050 / 100000 [skipped  169] | loc. loss = 0.2991635799, classif. loss = 0.2120909393
2025-10-03 05:07:58,391 | INFO | iter is 50100 / 100000 [skipped  169] | loc. loss = 0.2800765932, classif. loss = 0.4361699522
2025-10-03 05:08:30,810 | INFO | iter is 50150 / 100000 [skipped  169] | loc. loss = 0.1981805563, classif. loss = 2.0329260826
2025-10-03 05:09:03,260 | INFO | iter is 50200 / 100000 [skipped  169] | loc. loss = 0.4140501022, classif. loss = 0.1406220496
2025-10-03 05:09:35,636 | INFO | iter is 50250 / 100000 [skipped  169] | loc. loss = 0.1865613908, classif. loss = 0.5973240137
2025-10-03 05:10:07,432 | INFO | iter is 50300 / 100000 [skipped  170] | loc. loss = 0.1253412515, classif. loss = 0.3925863206
2025-10-03 05:10:39,808 | INFO | iter is 50350 / 100000 [skipped  170] | loc. loss = 0.1620306522, classif. loss = 0.7296269536
2025-10-03 05:11:12,218 | INFO | iter is 50400 / 100000 [skipped  170] | loc. loss = 0.1577595472, classif. loss = 0.4959535599
2025-10-03 05:11:44,581 | INFO | iter is 50450 / 100000 [skipped  170] | loc. loss = 0.1506619155, classif. loss = 0.4690570235
2025-10-03 05:12:16,372 | INFO | iter is 50500 / 100000 [skipped  171] | loc. loss = 0.1493003666, classif. loss = 0.7130864859
2025-10-03 05:12:48,729 | INFO | iter is 50550 / 100000 [skipped  171] | loc. loss = 0.2033896297, classif. loss = 0.3744847178
2025-10-03 05:13:20,427 | INFO | iter is 50600 / 100000 [skipped  172] | loc. loss = 0.1689676046, classif. loss = 0.3528702259
2025-10-03 05:13:52,773 | INFO | iter is 50650 / 100000 [skipped  172] | loc. loss = 0.1497385949, classif. loss = 0.4844027162
2025-10-03 05:14:25,193 | INFO | iter is 50700 / 100000 [skipped  172] | loc. loss = 0.1405161023, classif. loss = 1.3316496611
2025-10-03 05:14:57,593 | INFO | iter is 50750 / 100000 [skipped  172] | loc. loss = 0.0997411981, classif. loss = 0.2598551512
2025-10-03 05:15:30,044 | INFO | iter is 50800 / 100000 [skipped  172] | loc. loss = 0.2542558014, classif. loss = 2.2401618958
2025-10-03 05:16:02,484 | INFO | iter is 50850 / 100000 [skipped  172] | loc. loss = 0.0971070528, classif. loss = 0.5047640204
2025-10-03 05:16:34,908 | INFO | iter is 50900 / 100000 [skipped  172] | loc. loss = 0.1429387927, classif. loss = 0.3498596549
2025-10-03 05:17:07,368 | INFO | iter is 50950 / 100000 [skipped  172] | loc. loss = 0.1680402458, classif. loss = 0.5637403727
2025-10-03 05:17:39,750 | INFO | iter is 51000 / 100000 [skipped  172] | loc. loss = 0.1558206826, classif. loss = 0.1037603244
2025-10-03 05:18:12,139 | INFO | iter is 51050 / 100000 [skipped  172] | loc. loss = 0.1270956993, classif. loss = 0.2884295285
2025-10-03 05:18:43,883 | INFO | iter is 51100 / 100000 [skipped  173] | loc. loss = 0.1214672327, classif. loss = 0.0884845704
2025-10-03 05:19:16,306 | INFO | iter is 51150 / 100000 [skipped  173] | loc. loss = 0.2335531116, classif. loss = 0.2360681444
2025-10-03 05:19:48,669 | INFO | iter is 51200 / 100000 [skipped  173] | loc. loss = 0.1268822700, classif. loss = 0.2105981708
2025-10-03 05:20:21,067 | INFO | iter is 51250 / 100000 [skipped  173] | loc. loss = 0.0875279009, classif. loss = 0.0426835045
2025-10-03 05:20:53,414 | INFO | iter is 51300 / 100000 [skipped  173] | loc. loss = 0.0970171615, classif. loss = 0.4843548536
2025-10-03 05:21:25,845 | INFO | iter is 51350 / 100000 [skipped  173] | loc. loss = 0.1999078542, classif. loss = 0.0291721523
2025-10-03 05:21:58,250 | INFO | iter is 51400 / 100000 [skipped  173] | loc. loss = 0.1107197255, classif. loss = 0.6755948067
2025-10-03 05:22:30,688 | INFO | iter is 51450 / 100000 [skipped  173] | loc. loss = 0.1450812817, classif. loss = 0.7434803247
2025-10-03 05:23:03,106 | INFO | iter is 51500 / 100000 [skipped  173] | loc. loss = 0.1831585467, classif. loss = 0.3886013925
2025-10-03 05:23:35,495 | INFO | iter is 51550 / 100000 [skipped  173] | loc. loss = 0.2449716032, classif. loss = 1.6273775101
2025-10-03 05:24:07,345 | INFO | iter is 51600 / 100000 [skipped  174] | loc. loss = 0.1245914251, classif. loss = 0.4846588373
2025-10-03 05:24:39,706 | INFO | iter is 51650 / 100000 [skipped  174] | loc. loss = 0.1345511228, classif. loss = 0.0870051831
2025-10-03 05:25:12,133 | INFO | iter is 51700 / 100000 [skipped  174] | loc. loss = 0.2296508253, classif. loss = 0.5690772533
2025-10-03 05:25:44,508 | INFO | iter is 51750 / 100000 [skipped  174] | loc. loss = 0.5272594094, classif. loss = 1.9106315374
2025-10-03 05:26:16,926 | INFO | iter is 51800 / 100000 [skipped  174] | loc. loss = 0.1675357074, classif. loss = 0.9265133142
2025-10-03 05:26:49,237 | INFO | iter is 51850 / 100000 [skipped  174] | loc. loss = 0.0498975478, classif. loss = 0.2650201917
2025-10-03 05:27:21,674 | INFO | iter is 51900 / 100000 [skipped  174] | loc. loss = 0.1817221493, classif. loss = 0.3680189848
2025-10-03 05:27:54,055 | INFO | iter is 51950 / 100000 [skipped  174] | loc. loss = 0.0826243684, classif. loss = 1.0445606709
2025-10-03 05:28:26,504 | INFO | iter is 52000 / 100000 [skipped  174] | loc. loss = 0.1612888873, classif. loss = 1.0911254883
2025-10-03 05:28:58,246 | INFO | iter is 52050 / 100000 [skipped  175] | loc. loss = 0.2253868431, classif. loss = 0.4152559042
2025-10-03 05:29:30,624 | INFO | iter is 52100 / 100000 [skipped  175] | loc. loss = 0.1601651311, classif. loss = 0.2488080710
2025-10-03 05:30:03,059 | INFO | iter is 52150 / 100000 [skipped  175] | loc. loss = 0.1092281044, classif. loss = 0.3305077255
2025-10-03 05:30:35,432 | INFO | iter is 52200 / 100000 [skipped  175] | loc. loss = 0.0476371422, classif. loss = 2.3688640594
2025-10-03 05:31:07,909 | INFO | iter is 52250 / 100000 [skipped  175] | loc. loss = 0.1216524988, classif. loss = 0.7199041843
2025-10-03 05:31:40,228 | INFO | iter is 52300 / 100000 [skipped  175] | loc. loss = 0.1165404320, classif. loss = 0.9463832378
2025-10-03 05:32:12,671 | INFO | iter is 52350 / 100000 [skipped  175] | loc. loss = 0.1441772580, classif. loss = 1.2259883881
2025-10-03 05:32:44,989 | INFO | iter is 52400 / 100000 [skipped  175] | loc. loss = 0.0769373998, classif. loss = 0.9955846667
2025-10-03 05:33:16,735 | INFO | iter is 52450 / 100000 [skipped  176] | loc. loss = 0.2389709651, classif. loss = 0.1322353184
2025-10-03 05:33:49,088 | INFO | iter is 52500 / 100000 [skipped  176] | loc. loss = 0.2340602428, classif. loss = 0.3782004714
2025-10-03 05:34:21,504 | INFO | iter is 52550 / 100000 [skipped  176] | loc. loss = 0.2204221189, classif. loss = 0.8208711743
2025-10-03 05:34:53,952 | INFO | iter is 52600 / 100000 [skipped  176] | loc. loss = 0.2145802677, classif. loss = 1.2264534235
2025-10-03 05:35:26,343 | INFO | iter is 52650 / 100000 [skipped  176] | loc. loss = 0.1948440522, classif. loss = 0.9367421865
2025-10-03 05:35:58,637 | INFO | iter is 52700 / 100000 [skipped  176] | loc. loss = 0.2340188622, classif. loss = 0.1177452281
2025-10-03 05:36:31,072 | INFO | iter is 52750 / 100000 [skipped  176] | loc. loss = 0.2397069782, classif. loss = 1.0987486839
2025-10-03 05:37:03,477 | INFO | iter is 52800 / 100000 [skipped  176] | loc. loss = 0.1708368063, classif. loss = 0.0354875959
2025-10-03 05:37:35,905 | INFO | iter is 52850 / 100000 [skipped  176] | loc. loss = 0.1434205770, classif. loss = 0.3889420331
2025-10-03 05:38:08,342 | INFO | iter is 52900 / 100000 [skipped  176] | loc. loss = 0.0924264863, classif. loss = 0.6456038952
2025-10-03 05:38:40,755 | INFO | iter is 52950 / 100000 [skipped  176] | loc. loss = 0.0765772611, classif. loss = 0.2856525481
2025-10-03 05:39:13,126 | INFO | iter is 53000 / 100000 [skipped  176] | loc. loss = 0.1728545874, classif. loss = 0.8614200354
2025-10-03 05:39:45,536 | INFO | iter is 53050 / 100000 [skipped  176] | loc. loss = 0.1411470473, classif. loss = 0.2897921801
2025-10-03 05:40:17,897 | INFO | iter is 53100 / 100000 [skipped  176] | loc. loss = 0.1166255549, classif. loss = 0.7171688080
2025-10-03 05:40:34,133 | INFO | ---------starting evaluation-----------
2025-10-03 05:40:34,593 | INFO | validation:    0/2126 (2025-10-03_05-40-34)
2025-10-03 05:41:02,560 | INFO | validation:  100/2126 (2025-10-03_05-41-02)
2025-10-03 05:41:31,149 | INFO | validation:  200/2126 (2025-10-03_05-41-31)
2025-10-03 05:41:57,401 | INFO | validation:  300/2126 (2025-10-03_05-41-57)
2025-10-03 05:42:26,311 | INFO | validation:  400/2126 (2025-10-03_05-42-26)
2025-10-03 05:42:56,222 | INFO | validation:  500/2126 (2025-10-03_05-42-56)
2025-10-03 05:43:26,486 | INFO | validation:  600/2126 (2025-10-03_05-43-26)
2025-10-03 05:43:52,719 | INFO | validation:  700/2126 (2025-10-03_05-43-52)
2025-10-03 05:44:21,630 | INFO | validation:  800/2126 (2025-10-03_05-44-21)
2025-10-03 05:44:48,851 | INFO | validation:  900/2126 (2025-10-03_05-44-48)
2025-10-03 05:45:21,124 | INFO | validation: 1000/2126 (2025-10-03_05-45-21)
2025-10-03 05:45:50,725 | INFO | validation: 1100/2126 (2025-10-03_05-45-50)
2025-10-03 05:46:19,664 | INFO | validation: 1200/2126 (2025-10-03_05-46-19)
2025-10-03 05:46:49,922 | INFO | validation: 1300/2126 (2025-10-03_05-46-49)
2025-10-03 05:47:17,847 | INFO | validation: 1400/2126 (2025-10-03_05-47-17)
2025-10-03 05:47:46,424 | INFO | validation: 1500/2126 (2025-10-03_05-47-46)
2025-10-03 05:48:15,344 | INFO | validation: 1600/2126 (2025-10-03_05-48-15)
2025-10-03 05:48:43,236 | INFO | validation: 1700/2126 (2025-10-03_05-48-43)
2025-10-03 05:49:12,467 | INFO | validation: 1800/2126 (2025-10-03_05-49-12)
2025-10-03 05:49:42,370 | INFO | validation: 1900/2126 (2025-10-03_05-49-42)
2025-10-03 05:50:09,600 | INFO | validation: 2000/2126 (2025-10-03_05-50-09)
2025-10-03 05:50:37,513 | INFO | validation: 2100/2126 (2025-10-03_05-50-37)
2025-10-03 05:50:45,889 | INFO | Confusion Matrix of Localization:
[[1292616500    6853933]
 [   6146473   45997558]]
2025-10-03 05:50:45,889 | INFO | Confusion Matrix of Localization - Normalized:
[[0.9947256  0.0052744 ]
 [0.11787491 0.88212509]]
2025-10-03 05:50:45,890 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42206129  1068443   107933    67729]
 [       0  1300066  1365392   399115    31630]
 [       0   283920   535383  1923632   159996]
 [       0   128626    51285   106791  1695573]]
2025-10-03 05:50:45,890 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.97136713 0.02459004 0.00248406 0.00155877]
 [0.         0.41989043 0.44098917 0.12890466 0.01021574]
 [0.         0.0978046  0.18442843 0.66265164 0.05511533]
 [0.         0.06488807 0.02587179 0.05387295 0.85536719]]
2025-10-03 05:50:45,890 | INFO | lofF1 is 87.6181, clfF1 is 68.3754, oaF1 is 74.1482, sub class F1 score is [96.6158 44.6447 70.7165 86.1308]
2025-10-03 05:50:45,890 | INFO | ---------starting train set evaluation-----------
2025-10-03 05:50:46,382 | INFO | [TrainBuf] locF1 is 87.9299, clfF1 is 69.8253, oaF1 is 75.2567, sub class F1 score is [95.3638 56.5056 61.0612 78.5836]
2025-10-03 05:51:01,969 | INFO | iter is 53150 / 100000 [skipped  177] | loc. loss = 0.1254001856, classif. loss = 0.1530937105
2025-10-03 05:51:34,366 | INFO | iter is 53200 / 100000 [skipped  177] | loc. loss = 0.1126250476, classif. loss = 0.4830301702
2025-10-03 05:52:06,754 | INFO | iter is 53250 / 100000 [skipped  177] | loc. loss = 0.2040288448, classif. loss = 0.2025044560
2025-10-03 05:52:39,126 | INFO | iter is 53300 / 100000 [skipped  177] | loc. loss = 0.1616834104, classif. loss = 0.8141130209
2025-10-03 05:53:11,510 | INFO | iter is 53350 / 100000 [skipped  177] | loc. loss = 0.1528705359, classif. loss = 0.1302617490
2025-10-03 05:53:43,790 | INFO | iter is 53400 / 100000 [skipped  177] | loc. loss = 0.1917088628, classif. loss = 0.0094436007
2025-10-03 05:54:16,195 | INFO | iter is 53450 / 100000 [skipped  177] | loc. loss = 0.0815410912, classif. loss = 0.1728150547
2025-10-03 05:54:48,555 | INFO | iter is 53500 / 100000 [skipped  177] | loc. loss = 0.1082278863, classif. loss = 1.5273478031
2025-10-03 05:55:20,974 | INFO | iter is 53550 / 100000 [skipped  177] | loc. loss = 0.1487363875, classif. loss = 1.1199276447
2025-10-03 05:55:53,339 | INFO | iter is 53600 / 100000 [skipped  177] | loc. loss = 0.2423129380, classif. loss = 0.9060413241
2025-10-03 05:56:25,780 | INFO | iter is 53650 / 100000 [skipped  177] | loc. loss = 0.1666473001, classif. loss = 0.9049745202
2025-10-03 05:56:58,116 | INFO | iter is 53700 / 100000 [skipped  177] | loc. loss = 0.2239059210, classif. loss = 0.0968231782
2025-10-03 05:57:30,493 | INFO | iter is 53750 / 100000 [skipped  177] | loc. loss = 0.1178964823, classif. loss = 0.4405849576
2025-10-03 05:58:02,815 | INFO | iter is 53800 / 100000 [skipped  177] | loc. loss = 0.1152553558, classif. loss = 0.1271339506
2025-10-03 05:58:35,171 | INFO | iter is 53850 / 100000 [skipped  177] | loc. loss = 0.1493341029, classif. loss = 0.1779227257
2025-10-03 05:59:07,585 | INFO | iter is 53900 / 100000 [skipped  177] | loc. loss = 0.1878111660, classif. loss = 0.6870650649
2025-10-03 05:59:39,876 | INFO | iter is 53950 / 100000 [skipped  177] | loc. loss = 0.1748144478, classif. loss = 0.5277709365
2025-10-03 06:00:12,233 | INFO | iter is 54000 / 100000 [skipped  177] | loc. loss = 0.1512380242, classif. loss = 0.1425333917
2025-10-03 06:00:44,068 | INFO | iter is 54050 / 100000 [skipped  178] | loc. loss = 0.1292717308, classif. loss = 1.3833401203
2025-10-03 06:01:16,399 | INFO | iter is 54100 / 100000 [skipped  178] | loc. loss = 0.2047169805, classif. loss = 1.4893126488
2025-10-03 06:01:48,858 | INFO | iter is 54150 / 100000 [skipped  178] | loc. loss = 0.1306635141, classif. loss = 0.3926014900
2025-10-03 06:02:20,579 | INFO | iter is 54200 / 100000 [skipped  179] | loc. loss = 0.1508519202, classif. loss = 0.0168136470
2025-10-03 06:02:53,030 | INFO | iter is 54250 / 100000 [skipped  179] | loc. loss = 0.1469522268, classif. loss = 0.0137540204
2025-10-03 06:03:25,355 | INFO | iter is 54300 / 100000 [skipped  179] | loc. loss = 0.1236678511, classif. loss = 0.0436991937
2025-10-03 06:03:57,759 | INFO | iter is 54350 / 100000 [skipped  179] | loc. loss = 0.1381868273, classif. loss = 0.3138473630
2025-10-03 06:04:30,122 | INFO | iter is 54400 / 100000 [skipped  179] | loc. loss = 0.1524280459, classif. loss = 0.9120745063
2025-10-03 06:05:02,534 | INFO | iter is 54450 / 100000 [skipped  179] | loc. loss = 0.1627725959, classif. loss = 0.1899040043
2025-10-03 06:05:34,844 | INFO | iter is 54500 / 100000 [skipped  179] | loc. loss = 0.0151292011, classif. loss = 0.0100077949
2025-10-03 06:06:07,226 | INFO | iter is 54550 / 100000 [skipped  179] | loc. loss = 0.2066369653, classif. loss = 0.0239316486
2025-10-03 06:06:39,582 | INFO | iter is 54600 / 100000 [skipped  179] | loc. loss = 0.1787402928, classif. loss = 0.4704211056
2025-10-03 06:07:11,996 | INFO | iter is 54650 / 100000 [skipped  179] | loc. loss = 0.2030257583, classif. loss = 0.3196998835
2025-10-03 06:07:44,423 | INFO | iter is 54700 / 100000 [skipped  179] | loc. loss = 0.2069295198, classif. loss = 0.4838407040
2025-10-03 06:08:16,765 | INFO | iter is 54750 / 100000 [skipped  179] | loc. loss = 0.1071594656, classif. loss = 0.4070822895
2025-10-03 06:08:49,186 | INFO | iter is 54800 / 100000 [skipped  179] | loc. loss = 0.0976264551, classif. loss = 0.7510733604
2025-10-03 06:09:21,606 | INFO | iter is 54850 / 100000 [skipped  179] | loc. loss = 0.1006962955, classif. loss = 1.0927157402
2025-10-03 06:09:53,424 | INFO | iter is 54900 / 100000 [skipped  180] | loc. loss = 0.1587437391, classif. loss = 0.2977762818
2025-10-03 06:10:25,689 | INFO | iter is 54950 / 100000 [skipped  180] | loc. loss = 0.1817733645, classif. loss = 0.7560024261
2025-10-03 06:10:57,513 | INFO | iter is 55000 / 100000 [skipped  181] | loc. loss = 0.1241858006, classif. loss = 0.1061081290
2025-10-03 06:11:29,831 | INFO | iter is 55050 / 100000 [skipped  181] | loc. loss = 0.1889612228, classif. loss = 0.0846609771
2025-10-03 06:12:02,119 | INFO | iter is 55100 / 100000 [skipped  181] | loc. loss = 0.1604437232, classif. loss = 1.3197246790
2025-10-03 06:12:34,444 | INFO | iter is 55150 / 100000 [skipped  181] | loc. loss = 0.1064319015, classif. loss = 1.2982323170
2025-10-03 06:13:06,835 | INFO | iter is 55200 / 100000 [skipped  181] | loc. loss = 0.1320327669, classif. loss = 0.4429527819
2025-10-03 06:13:38,552 | INFO | iter is 55250 / 100000 [skipped  182] | loc. loss = 0.2175770551, classif. loss = 0.2345418632
2025-10-03 06:14:10,950 | INFO | iter is 55300 / 100000 [skipped  182] | loc. loss = 0.1197984815, classif. loss = 0.2548602521
2025-10-03 06:14:42,716 | INFO | iter is 55350 / 100000 [skipped  183] | loc. loss = 0.3234670162, classif. loss = 0.4684483111
2025-10-03 06:15:14,532 | INFO | iter is 55400 / 100000 [skipped  184] | loc. loss = 0.2445173562, classif. loss = 0.0667461157
2025-10-03 06:15:46,900 | INFO | iter is 55450 / 100000 [skipped  184] | loc. loss = 0.2176978141, classif. loss = 0.6023966670
2025-10-03 06:16:19,203 | INFO | iter is 55500 / 100000 [skipped  184] | loc. loss = 0.1475913078, classif. loss = 0.4449892342
2025-10-03 06:16:51,553 | INFO | iter is 55550 / 100000 [skipped  184] | loc. loss = 0.1937659383, classif. loss = 0.7738184333
2025-10-03 06:17:23,907 | INFO | iter is 55600 / 100000 [skipped  184] | loc. loss = 0.1059046090, classif. loss = 0.5326960087
2025-10-03 06:17:56,277 | INFO | iter is 55650 / 100000 [skipped  184] | loc. loss = 0.1407279670, classif. loss = 0.5661792755
2025-10-03 06:18:28,655 | INFO | iter is 55700 / 100000 [skipped  184] | loc. loss = 0.0911733061, classif. loss = 0.4833969772
2025-10-03 06:19:00,955 | INFO | iter is 55750 / 100000 [skipped  184] | loc. loss = 0.2926546037, classif. loss = 0.1354498565
2025-10-03 06:19:33,322 | INFO | iter is 55800 / 100000 [skipped  184] | loc. loss = 0.2667817771, classif. loss = 0.6546330452
2025-10-03 06:20:05,714 | INFO | iter is 55850 / 100000 [skipped  184] | loc. loss = 0.1945326626, classif. loss = 0.5100316405
2025-10-03 06:20:38,166 | INFO | iter is 55900 / 100000 [skipped  184] | loc. loss = 0.1178924218, classif. loss = 0.4889421463
2025-10-03 06:21:10,534 | INFO | iter is 55950 / 100000 [skipped  184] | loc. loss = 0.2416046858, classif. loss = 0.5475485325
2025-10-03 06:21:42,959 | INFO | iter is 56000 / 100000 [skipped  184] | loc. loss = 0.1242952943, classif. loss = 0.1315987706
2025-10-03 06:22:14,753 | INFO | iter is 56050 / 100000 [skipped  185] | loc. loss = 0.2296550572, classif. loss = 0.4174965322
2025-10-03 06:22:47,155 | INFO | iter is 56100 / 100000 [skipped  185] | loc. loss = 0.2995949388, classif. loss = 0.3057600558
2025-10-03 06:23:19,453 | INFO | iter is 56150 / 100000 [skipped  185] | loc. loss = 0.1396798790, classif. loss = 0.3278918862
2025-10-03 06:23:51,844 | INFO | iter is 56200 / 100000 [skipped  185] | loc. loss = 0.1004089415, classif. loss = 0.3260580003
2025-10-03 06:24:23,688 | INFO | iter is 56250 / 100000 [skipped  186] | loc. loss = 0.1359675974, classif. loss = 0.8596834540
2025-10-03 06:24:23,690 | INFO | ---------starting evaluation-----------
2025-10-03 06:24:24,160 | INFO | validation:    0/2126 (2025-10-03_06-24-24)
2025-10-03 06:24:52,152 | INFO | validation:  100/2126 (2025-10-03_06-24-52)
2025-10-03 06:25:20,776 | INFO | validation:  200/2126 (2025-10-03_06-25-20)
2025-10-03 06:25:47,071 | INFO | validation:  300/2126 (2025-10-03_06-25-47)
2025-10-03 06:26:16,034 | INFO | validation:  400/2126 (2025-10-03_06-26-16)
2025-10-03 06:26:46,032 | INFO | validation:  500/2126 (2025-10-03_06-26-46)
2025-10-03 06:27:16,386 | INFO | validation:  600/2126 (2025-10-03_06-27-16)
2025-10-03 06:27:42,675 | INFO | validation:  700/2126 (2025-10-03_06-27-42)
2025-10-03 06:28:11,652 | INFO | validation:  800/2126 (2025-10-03_06-28-11)
2025-10-03 06:28:38,934 | INFO | validation:  900/2126 (2025-10-03_06-28-38)
2025-10-03 06:29:11,275 | INFO | validation: 1000/2126 (2025-10-03_06-29-11)
2025-10-03 06:29:40,920 | INFO | validation: 1100/2126 (2025-10-03_06-29-40)
2025-10-03 06:30:09,898 | INFO | validation: 1200/2126 (2025-10-03_06-30-09)
2025-10-03 06:30:40,218 | INFO | validation: 1300/2126 (2025-10-03_06-30-40)
2025-10-03 06:31:08,174 | INFO | validation: 1400/2126 (2025-10-03_06-31-08)
2025-10-03 06:31:36,839 | INFO | validation: 1500/2126 (2025-10-03_06-31-36)
2025-10-03 06:32:05,830 | INFO | validation: 1600/2126 (2025-10-03_06-32-05)
2025-10-03 06:32:33,825 | INFO | validation: 1700/2126 (2025-10-03_06-32-33)
2025-10-03 06:33:03,169 | INFO | validation: 1800/2126 (2025-10-03_06-33-03)
2025-10-03 06:33:33,168 | INFO | validation: 1900/2126 (2025-10-03_06-33-33)
2025-10-03 06:34:00,498 | INFO | validation: 2000/2126 (2025-10-03_06-34-00)
2025-10-03 06:34:28,482 | INFO | validation: 2100/2126 (2025-10-03_06-34-28)
2025-10-03 06:34:36,899 | INFO | Confusion Matrix of Localization:
[[1293507939    5962494]
 [   6840762   45303269]]
2025-10-03 06:34:36,899 | INFO | Confusion Matrix of Localization - Normalized:
[[0.9954116  0.0045884 ]
 [0.13118974 0.86881026]]
2025-10-03 06:34:36,899 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41559656  1513319   206667   170592]
 [       0   960158  1516712   559605    59728]
 [       0   220357   329470  2138700   214404]
 [       0    66903    24560    89458  1801354]]
2025-10-03 06:34:36,899 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95648866 0.03482879 0.00475641 0.00392615]
 [0.         0.31010822 0.48986194 0.18073912 0.01929072]
 [0.         0.07590845 0.11349564 0.73673814 0.07385777]
 [0.         0.03375061 0.0123898  0.04512896 0.90873063]]
2025-10-03 06:34:36,899 | INFO | lofF1 is 87.6189, clfF1 is 69.8516, oaF1 is 75.1818, sub class F1 score is [96.362  46.8102 72.5307 85.2036]
2025-10-03 06:34:36,900 | INFO | ---------starting train set evaluation-----------
2025-10-03 06:34:37,396 | INFO | [TrainBuf] locF1 is 89.0297, clfF1 is 73.0427, oaF1 is 77.8388, sub class F1 score is [96.7072 63.4802 63.8485 76.8816]
2025-10-03 06:35:09,860 | INFO | iter is 56300 / 100000 [skipped  186] | loc. loss = 0.2974260151, classif. loss = 0.4346204698
2025-10-03 06:35:42,307 | INFO | iter is 56350 / 100000 [skipped  186] | loc. loss = 0.2047305405, classif. loss = 0.1563744247
2025-10-03 06:36:14,836 | INFO | iter is 56400 / 100000 [skipped  186] | loc. loss = 0.1143759191, classif. loss = 0.5385493040
2025-10-03 06:36:47,254 | INFO | iter is 56450 / 100000 [skipped  186] | loc. loss = 0.5020847321, classif. loss = 5.2304215431
2025-10-03 06:37:19,694 | INFO | iter is 56500 / 100000 [skipped  186] | loc. loss = 0.2464649677, classif. loss = 0.5595490932
2025-10-03 06:37:52,109 | INFO | iter is 56550 / 100000 [skipped  186] | loc. loss = 0.1314231008, classif. loss = 0.0719566867
2025-10-03 06:38:24,492 | INFO | iter is 56600 / 100000 [skipped  186] | loc. loss = 0.1222717166, classif. loss = 0.6867379546
2025-10-03 06:38:56,280 | INFO | iter is 56650 / 100000 [skipped  187] | loc. loss = 0.1577756107, classif. loss = 0.5668243170
2025-10-03 06:39:28,637 | INFO | iter is 56700 / 100000 [skipped  187] | loc. loss = 0.1376004964, classif. loss = 0.6312103271
2025-10-03 06:40:01,060 | INFO | iter is 56750 / 100000 [skipped  187] | loc. loss = 0.0874520987, classif. loss = 0.6409782767
2025-10-03 06:40:33,412 | INFO | iter is 56800 / 100000 [skipped  187] | loc. loss = 0.1841742247, classif. loss = 1.2272906303
2025-10-03 06:41:05,737 | INFO | iter is 56850 / 100000 [skipped  187] | loc. loss = 0.1094447598, classif. loss = 0.4012164176
2025-10-03 06:41:38,219 | INFO | iter is 56900 / 100000 [skipped  187] | loc. loss = 0.1539727151, classif. loss = 0.7980463505
2025-10-03 06:42:09,941 | INFO | iter is 56950 / 100000 [skipped  188] | loc. loss = 0.1370385140, classif. loss = 2.3501703739
2025-10-03 06:42:42,366 | INFO | iter is 57000 / 100000 [skipped  188] | loc. loss = 0.2029390186, classif. loss = 0.9378007650
2025-10-03 06:43:14,730 | INFO | iter is 57050 / 100000 [skipped  188] | loc. loss = 0.2473241091, classif. loss = 0.8300993443
2025-10-03 06:43:47,178 | INFO | iter is 57100 / 100000 [skipped  188] | loc. loss = 0.0868603885, classif. loss = 0.0112165539
2025-10-03 06:44:19,557 | INFO | iter is 57150 / 100000 [skipped  188] | loc. loss = 0.2358459532, classif. loss = 0.6014998555
2025-10-03 06:44:51,324 | INFO | iter is 57200 / 100000 [skipped  189] | loc. loss = 0.1376035810, classif. loss = 0.5670161247
2025-10-03 06:45:23,630 | INFO | iter is 57250 / 100000 [skipped  189] | loc. loss = 0.1127689108, classif. loss = 0.7034075260
2025-10-03 06:45:55,906 | INFO | iter is 57300 / 100000 [skipped  189] | loc. loss = 0.2076373696, classif. loss = 0.2064469755
2025-10-03 06:46:28,258 | INFO | iter is 57350 / 100000 [skipped  189] | loc. loss = 0.2448797822, classif. loss = 0.4847404957
2025-10-03 06:47:00,643 | INFO | iter is 57400 / 100000 [skipped  189] | loc. loss = 0.2944340706, classif. loss = 1.0814185143
2025-10-03 06:47:32,989 | INFO | iter is 57450 / 100000 [skipped  189] | loc. loss = 0.1698603928, classif. loss = 0.3033226132
2025-10-03 06:48:05,292 | INFO | iter is 57500 / 100000 [skipped  189] | loc. loss = 0.2367011756, classif. loss = 0.4603076577
2025-10-03 06:48:37,071 | INFO | iter is 57550 / 100000 [skipped  190] | loc. loss = 0.1788993329, classif. loss = 0.3728794456
2025-10-03 06:49:09,399 | INFO | iter is 57600 / 100000 [skipped  190] | loc. loss = 0.2627442479, classif. loss = 0.4573269486
2025-10-03 06:49:41,758 | INFO | iter is 57650 / 100000 [skipped  190] | loc. loss = 0.1665319204, classif. loss = 0.3630495071
2025-10-03 06:50:14,240 | INFO | iter is 57700 / 100000 [skipped  190] | loc. loss = 0.2110317945, classif. loss = 0.4775148034
2025-10-03 06:50:45,996 | INFO | iter is 57750 / 100000 [skipped  191] | loc. loss = 0.1813407093, classif. loss = 0.5538300872
2025-10-03 06:51:18,381 | INFO | iter is 57800 / 100000 [skipped  191] | loc. loss = 0.2744594216, classif. loss = 0.2011672258
2025-10-03 06:51:50,729 | INFO | iter is 57850 / 100000 [skipped  191] | loc. loss = 0.2119438052, classif. loss = 0.1259226501
2025-10-03 06:52:23,138 | INFO | iter is 57900 / 100000 [skipped  191] | loc. loss = 0.2075516880, classif. loss = 0.2900663614
2025-10-03 06:52:55,533 | INFO | iter is 57950 / 100000 [skipped  191] | loc. loss = 0.2004540265, classif. loss = 0.0696007237
2025-10-03 06:53:27,874 | INFO | iter is 58000 / 100000 [skipped  191] | loc. loss = 0.0905534402, classif. loss = 1.0337880850
2025-10-03 06:54:00,340 | INFO | iter is 58050 / 100000 [skipped  191] | loc. loss = 0.1180022880, classif. loss = 0.6071501374
2025-10-03 06:54:32,701 | INFO | iter is 58100 / 100000 [skipped  191] | loc. loss = 0.1270379275, classif. loss = 0.0827232674
2025-10-03 06:55:05,117 | INFO | iter is 58150 / 100000 [skipped  191] | loc. loss = 0.0559302121, classif. loss = 0.7356923819
2025-10-03 06:55:37,516 | INFO | iter is 58200 / 100000 [skipped  191] | loc. loss = 0.0462358296, classif. loss = 0.0164487325
2025-10-03 06:56:09,994 | INFO | iter is 58250 / 100000 [skipped  191] | loc. loss = 0.1023220420, classif. loss = 0.7128075957
2025-10-03 06:56:42,398 | INFO | iter is 58300 / 100000 [skipped  191] | loc. loss = 0.2109108120, classif. loss = 1.0643725395
2025-10-03 06:57:14,789 | INFO | iter is 58350 / 100000 [skipped  191] | loc. loss = 0.1721060574, classif. loss = 0.1382858306
2025-10-03 06:57:47,126 | INFO | iter is 58400 / 100000 [skipped  191] | loc. loss = 0.2811339200, classif. loss = 1.0314695835
2025-10-03 06:58:19,522 | INFO | iter is 58450 / 100000 [skipped  191] | loc. loss = 0.0898149312, classif. loss = 0.5098342299
2025-10-03 06:58:51,986 | INFO | iter is 58500 / 100000 [skipped  191] | loc. loss = 0.1398432553, classif. loss = 0.0730715841
2025-10-03 06:59:24,384 | INFO | iter is 58550 / 100000 [skipped  191] | loc. loss = 0.1608136594, classif. loss = 0.2050546110
2025-10-03 06:59:56,757 | INFO | iter is 58600 / 100000 [skipped  191] | loc. loss = 0.1793609858, classif. loss = 0.3163945973
2025-10-03 07:00:29,213 | INFO | iter is 58650 / 100000 [skipped  191] | loc. loss = 0.1884424537, classif. loss = 0.5304764509
2025-10-03 07:01:00,942 | INFO | iter is 58700 / 100000 [skipped  192] | loc. loss = 0.1135751829, classif. loss = 0.4700049758
2025-10-03 07:01:33,340 | INFO | iter is 58750 / 100000 [skipped  192] | loc. loss = 0.1601652056, classif. loss = 0.1047908366
2025-10-03 07:02:05,141 | INFO | iter is 58800 / 100000 [skipped  193] | loc. loss = 0.1071221977, classif. loss = 0.4470753670
2025-10-03 07:02:37,483 | INFO | iter is 58850 / 100000 [skipped  193] | loc. loss = 0.1720276028, classif. loss = 0.8875796795
2025-10-03 07:03:09,799 | INFO | iter is 58900 / 100000 [skipped  193] | loc. loss = 0.1872362942, classif. loss = 2.4571843147
2025-10-03 07:03:42,258 | INFO | iter is 58950 / 100000 [skipped  193] | loc. loss = 0.2878330648, classif. loss = 0.0424913950
2025-10-03 07:04:14,052 | INFO | iter is 59000 / 100000 [skipped  194] | loc. loss = 0.2172926366, classif. loss = 1.0052750111
2025-10-03 07:04:46,552 | INFO | iter is 59050 / 100000 [skipped  194] | loc. loss = 0.0752227902, classif. loss = 0.3428068757
2025-10-03 07:05:18,870 | INFO | iter is 59100 / 100000 [skipped  194] | loc. loss = 0.0942426324, classif. loss = 0.5137251019
2025-10-03 07:05:51,318 | INFO | iter is 59150 / 100000 [skipped  194] | loc. loss = 0.1514389217, classif. loss = 0.8097991347
2025-10-03 07:06:23,677 | INFO | iter is 59200 / 100000 [skipped  194] | loc. loss = 0.1275052726, classif. loss = 0.0442933664
2025-10-03 07:06:56,084 | INFO | iter is 59250 / 100000 [skipped  194] | loc. loss = 0.1045738012, classif. loss = 0.6318765283
2025-10-03 07:07:27,971 | INFO | iter is 59300 / 100000 [skipped  195] | loc. loss = 0.1290851384, classif. loss = 0.3059998155
2025-10-03 07:08:00,409 | INFO | iter is 59350 / 100000 [skipped  195] | loc. loss = 0.1290030926, classif. loss = 0.2545899153
2025-10-03 07:08:16,612 | INFO | ---------starting evaluation-----------
2025-10-03 07:08:17,072 | INFO | validation:    0/2126 (2025-10-03_07-08-17)
2025-10-03 07:08:45,123 | INFO | validation:  100/2126 (2025-10-03_07-08-45)
2025-10-03 07:09:13,750 | INFO | validation:  200/2126 (2025-10-03_07-09-13)
2025-10-03 07:09:40,107 | INFO | validation:  300/2126 (2025-10-03_07-09-40)
2025-10-03 07:10:09,079 | INFO | validation:  400/2126 (2025-10-03_07-10-09)
2025-10-03 07:10:39,120 | INFO | validation:  500/2126 (2025-10-03_07-10-39)
2025-10-03 07:11:09,424 | INFO | validation:  600/2126 (2025-10-03_07-11-09)
2025-10-03 07:11:35,759 | INFO | validation:  700/2126 (2025-10-03_07-11-35)
2025-10-03 07:12:04,749 | INFO | validation:  800/2126 (2025-10-03_07-12-04)
2025-10-03 07:12:32,047 | INFO | validation:  900/2126 (2025-10-03_07-12-32)
2025-10-03 07:13:04,424 | INFO | validation: 1000/2126 (2025-10-03_07-13-04)
2025-10-03 07:13:34,103 | INFO | validation: 1100/2126 (2025-10-03_07-13-34)
2025-10-03 07:14:03,133 | INFO | validation: 1200/2126 (2025-10-03_07-14-03)
2025-10-03 07:14:33,469 | INFO | validation: 1300/2126 (2025-10-03_07-14-33)
2025-10-03 07:15:01,430 | INFO | validation: 1400/2126 (2025-10-03_07-15-01)
2025-10-03 07:15:30,097 | INFO | validation: 1500/2126 (2025-10-03_07-15-30)
2025-10-03 07:15:59,148 | INFO | validation: 1600/2126 (2025-10-03_07-15-59)
2025-10-03 07:16:27,164 | INFO | validation: 1700/2126 (2025-10-03_07-16-27)
2025-10-03 07:16:56,467 | INFO | validation: 1800/2126 (2025-10-03_07-16-56)
2025-10-03 07:17:26,486 | INFO | validation: 1900/2126 (2025-10-03_07-17-26)
2025-10-03 07:17:53,808 | INFO | validation: 2000/2126 (2025-10-03_07-17-53)
2025-10-03 07:18:21,795 | INFO | validation: 2100/2126 (2025-10-03_07-18-21)
2025-10-03 07:18:30,197 | INFO | Confusion Matrix of Localization:
[[1293260686    6209747]
 [   6721350   45422681]]
2025-10-03 07:18:30,198 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99522132 0.00477868]
 [0.1288997  0.8711003 ]]
2025-10-03 07:18:30,198 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42547394   763228    26170   113442]
 [       0  1369581  1533590   138364    54668]
 [       0   377442  1186443  1106483   232563]
 [       0   118356    31702    58008  1774209]]
2025-10-03 07:18:30,198 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.79221286e-01 1.75655671e-02 6.02298252e-04
  2.61084900e-03]
 [0.00000000e+00 4.42342120e-01 4.95313130e-01 4.46882843e-02
  1.76564650e-02]
 [0.00000000e+00 1.30021003e-01 4.08705202e-01 3.81160627e-01
  8.01131684e-02]
 [0.00000000e+00 5.97071547e-02 1.59927356e-02 2.92633464e-02
  8.95036763e-01]]
2025-10-03 07:18:30,198 | INFO | lofF1 is 87.5395, clfF1 is 63.7767, oaF1 is 70.9055, sub class F1 score is [96.8494 46.3939 52.2918 85.3568]
2025-10-03 07:18:30,198 | INFO | ---------starting train set evaluation-----------
2025-10-03 07:18:30,691 | INFO | [TrainBuf] locF1 is 88.8477, clfF1 is 75.2812, oaF1 is 79.3512, sub class F1 score is [96.8421 67.4958 67.0081 76.5186]
2025-10-03 07:18:46,870 | INFO | iter is 59400 / 100000 [skipped  195] | loc. loss = 0.1809946150, classif. loss = 0.7771095037
2025-10-03 07:19:18,698 | INFO | iter is 59450 / 100000 [skipped  196] | loc. loss = 0.1728950143, classif. loss = 0.4514397383
2025-10-03 07:19:51,133 | INFO | iter is 59500 / 100000 [skipped  196] | loc. loss = 0.1729969531, classif. loss = 0.8652945757
2025-10-03 07:20:23,518 | INFO | iter is 59550 / 100000 [skipped  196] | loc. loss = 0.1716911793, classif. loss = 0.1385263801
2025-10-03 07:20:55,878 | INFO | iter is 59600 / 100000 [skipped  196] | loc. loss = 0.1229123771, classif. loss = 0.2033743858
2025-10-03 07:21:28,243 | INFO | iter is 59650 / 100000 [skipped  196] | loc. loss = 0.2123630345, classif. loss = 0.5340700150
2025-10-03 07:22:00,585 | INFO | iter is 59700 / 100000 [skipped  196] | loc. loss = 0.2039899081, classif. loss = 1.5604177713
2025-10-03 07:22:32,930 | INFO | iter is 59750 / 100000 [skipped  196] | loc. loss = 0.0859697834, classif. loss = 0.0774381682
2025-10-03 07:23:05,360 | INFO | iter is 59800 / 100000 [skipped  196] | loc. loss = 0.4224995673, classif. loss = 0.0301697217
2025-10-03 07:23:37,716 | INFO | iter is 59850 / 100000 [skipped  196] | loc. loss = 0.1430386305, classif. loss = 0.0886403695
2025-10-03 07:24:10,136 | INFO | iter is 59900 / 100000 [skipped  196] | loc. loss = 0.2828413844, classif. loss = 0.1008566469
2025-10-03 07:24:41,950 | INFO | iter is 59950 / 100000 [skipped  197] | loc. loss = 0.1015987098, classif. loss = 0.5233495235
2025-10-03 07:25:14,364 | INFO | iter is 60000 / 100000 [skipped  197] | loc. loss = 0.1819787174, classif. loss = 0.0836227089
2025-10-03 07:25:46,878 | INFO | iter is 60050 / 100000 [skipped  197] | loc. loss = 0.1673118025, classif. loss = 0.5353819132
2025-10-03 07:26:19,346 | INFO | iter is 60100 / 100000 [skipped  197] | loc. loss = 0.1570847034, classif. loss = 1.8397792578
2025-10-03 07:26:51,079 | INFO | iter is 60150 / 100000 [skipped  198] | loc. loss = 0.2372074425, classif. loss = 1.0974721909
2025-10-03 07:27:23,534 | INFO | iter is 60200 / 100000 [skipped  198] | loc. loss = 0.1299280971, classif. loss = 1.4148064852
2025-10-03 07:27:55,847 | INFO | iter is 60250 / 100000 [skipped  198] | loc. loss = 0.2017249167, classif. loss = 0.2383737862
2025-10-03 07:28:27,715 | INFO | iter is 60300 / 100000 [skipped  199] | loc. loss = 0.1769907624, classif. loss = 0.1020221561
2025-10-03 07:29:00,120 | INFO | iter is 60350 / 100000 [skipped  199] | loc. loss = 0.1059988514, classif. loss = 0.4658063650
2025-10-03 07:29:32,526 | INFO | iter is 60400 / 100000 [skipped  199] | loc. loss = 0.1281862855, classif. loss = 0.8342881203
2025-10-03 07:30:04,978 | INFO | iter is 60450 / 100000 [skipped  199] | loc. loss = 0.1808084846, classif. loss = 0.0548787117
2025-10-03 07:30:37,343 | INFO | iter is 60500 / 100000 [skipped  199] | loc. loss = 0.1841518283, classif. loss = 0.1351379305
2025-10-03 07:31:09,738 | INFO | iter is 60550 / 100000 [skipped  199] | loc. loss = 0.1840798110, classif. loss = 0.6982033253
2025-10-03 07:31:42,099 | INFO | iter is 60600 / 100000 [skipped  199] | loc. loss = 0.1156252399, classif. loss = 0.3695451021
2025-10-03 07:32:14,502 | INFO | iter is 60650 / 100000 [skipped  199] | loc. loss = 0.0937527791, classif. loss = 0.3006094694
2025-10-03 07:32:46,911 | INFO | iter is 60700 / 100000 [skipped  199] | loc. loss = 0.3937940598, classif. loss = 0.4136185050
2025-10-03 07:33:19,388 | INFO | iter is 60750 / 100000 [skipped  199] | loc. loss = 0.1154934540, classif. loss = 0.0468006693
2025-10-03 07:33:51,700 | INFO | iter is 60800 / 100000 [skipped  199] | loc. loss = 0.1378009617, classif. loss = 0.2367431223
2025-10-03 07:34:24,136 | INFO | iter is 60850 / 100000 [skipped  199] | loc. loss = 0.6100503206, classif. loss = 0.6506901979
2025-10-03 07:34:56,471 | INFO | iter is 60900 / 100000 [skipped  199] | loc. loss = 0.1545132101, classif. loss = 0.6263507605
2025-10-03 07:35:28,927 | INFO | iter is 60950 / 100000 [skipped  199] | loc. loss = 0.1651401818, classif. loss = 0.2408036292
2025-10-03 07:36:01,292 | INFO | iter is 61000 / 100000 [skipped  199] | loc. loss = 0.2236038297, classif. loss = 0.3664521575
2025-10-03 07:36:33,738 | INFO | iter is 61050 / 100000 [skipped  199] | loc. loss = 0.0579767227, classif. loss = 0.0210453831
2025-10-03 07:37:06,145 | INFO | iter is 61100 / 100000 [skipped  199] | loc. loss = 0.1477537602, classif. loss = 0.6467025280
2025-10-03 07:37:38,593 | INFO | iter is 61150 / 100000 [skipped  199] | loc. loss = 0.2473368049, classif. loss = 1.1137462854
2025-10-03 07:38:10,987 | INFO | iter is 61200 / 100000 [skipped  199] | loc. loss = 0.0905395597, classif. loss = 0.0202910267
2025-10-03 07:38:42,857 | INFO | iter is 61250 / 100000 [skipped  200] | loc. loss = 0.1517503113, classif. loss = 0.6341724396
2025-10-03 07:39:15,282 | INFO | iter is 61300 / 100000 [skipped  200] | loc. loss = 0.1694180220, classif. loss = 0.8594858646
2025-10-03 07:39:47,749 | INFO | iter is 61350 / 100000 [skipped  200] | loc. loss = 0.1600201279, classif. loss = 0.6688913703
2025-10-03 07:40:19,528 | INFO | iter is 61400 / 100000 [skipped  201] | loc. loss = 0.2179312706, classif. loss = 0.8287262917
2025-10-03 07:40:51,908 | INFO | iter is 61450 / 100000 [skipped  201] | loc. loss = 0.2303240001, classif. loss = 0.6398812532
2025-10-03 07:41:24,265 | INFO | iter is 61500 / 100000 [skipped  201] | loc. loss = 0.1733973622, classif. loss = 0.6924996972
2025-10-03 07:41:56,628 | INFO | iter is 61550 / 100000 [skipped  201] | loc. loss = 0.0778573155, classif. loss = 0.7429043651
2025-10-03 07:42:29,086 | INFO | iter is 61600 / 100000 [skipped  201] | loc. loss = 0.1708741337, classif. loss = 0.6045765281
2025-10-03 07:43:01,403 | INFO | iter is 61650 / 100000 [skipped  201] | loc. loss = 0.1114551499, classif. loss = 0.0364980251
2025-10-03 07:43:33,791 | INFO | iter is 61700 / 100000 [skipped  201] | loc. loss = 0.1811440736, classif. loss = 0.5242727399
2025-10-03 07:44:06,175 | INFO | iter is 61750 / 100000 [skipped  201] | loc. loss = 0.2781194150, classif. loss = 1.4163755178
2025-10-03 07:44:38,480 | INFO | iter is 61800 / 100000 [skipped  201] | loc. loss = 0.1075059772, classif. loss = 0.3182645440
2025-10-03 07:45:10,827 | INFO | iter is 61850 / 100000 [skipped  201] | loc. loss = 0.1566503048, classif. loss = 0.0771468058
2025-10-03 07:45:41,993 | INFO | iter is 61900 / 100000 [skipped  203] | loc. loss = 0.1943543553, classif. loss = 0.3855123222
2025-10-03 07:46:14,329 | INFO | iter is 61950 / 100000 [skipped  203] | loc. loss = 0.1073530465, classif. loss = 0.6674492359
2025-10-03 07:46:46,686 | INFO | iter is 62000 / 100000 [skipped  203] | loc. loss = 0.1405070126, classif. loss = 0.4346604943
2025-10-03 07:47:18,944 | INFO | iter is 62050 / 100000 [skipped  203] | loc. loss = 0.1633063555, classif. loss = 0.1174385026
2025-10-03 07:47:51,225 | INFO | iter is 62100 / 100000 [skipped  203] | loc. loss = 0.1114467531, classif. loss = 0.6468539238
2025-10-03 07:48:22,993 | INFO | iter is 62150 / 100000 [skipped  204] | loc. loss = 0.2182556391, classif. loss = 0.0574059859
2025-10-03 07:48:55,304 | INFO | iter is 62200 / 100000 [skipped  204] | loc. loss = 0.1502683461, classif. loss = 0.6500931978
2025-10-03 07:49:27,678 | INFO | iter is 62250 / 100000 [skipped  204] | loc. loss = 0.1570884883, classif. loss = 0.3069190979
2025-10-03 07:49:59,424 | INFO | iter is 62300 / 100000 [skipped  205] | loc. loss = 0.1311223656, classif. loss = 0.3168050349
2025-10-03 07:50:31,803 | INFO | iter is 62350 / 100000 [skipped  205] | loc. loss = 0.1759092063, classif. loss = 0.0461314172
2025-10-03 07:51:04,134 | INFO | iter is 62400 / 100000 [skipped  205] | loc. loss = 0.2119554877, classif. loss = 0.7305383682
2025-10-03 07:51:36,586 | INFO | iter is 62450 / 100000 [skipped  205] | loc. loss = 0.2278687209, classif. loss = 0.3989306390
2025-10-03 07:52:09,014 | INFO | iter is 62500 / 100000 [skipped  205] | loc. loss = 0.3083446622, classif. loss = 0.8081896305
2025-10-03 07:52:09,015 | INFO | ---------starting evaluation-----------
2025-10-03 07:52:09,475 | INFO | validation:    0/2126 (2025-10-03_07-52-09)
2025-10-03 07:52:37,518 | INFO | validation:  100/2126 (2025-10-03_07-52-37)
2025-10-03 07:53:06,229 | INFO | validation:  200/2126 (2025-10-03_07-53-06)
2025-10-03 07:53:32,589 | INFO | validation:  300/2126 (2025-10-03_07-53-32)
2025-10-03 07:54:01,637 | INFO | validation:  400/2126 (2025-10-03_07-54-01)
2025-10-03 07:54:31,732 | INFO | validation:  500/2126 (2025-10-03_07-54-31)
2025-10-03 07:55:02,151 | INFO | validation:  600/2126 (2025-10-03_07-55-02)
2025-10-03 07:55:28,538 | INFO | validation:  700/2126 (2025-10-03_07-55-28)
2025-10-03 07:55:57,619 | INFO | validation:  800/2126 (2025-10-03_07-55-57)
2025-10-03 07:56:25,001 | INFO | validation:  900/2126 (2025-10-03_07-56-25)
2025-10-03 07:56:57,437 | INFO | validation: 1000/2126 (2025-10-03_07-56-57)
2025-10-03 07:57:27,174 | INFO | validation: 1100/2126 (2025-10-03_07-57-27)
2025-10-03 07:57:56,236 | INFO | validation: 1200/2126 (2025-10-03_07-57-56)
2025-10-03 07:58:26,680 | INFO | validation: 1300/2126 (2025-10-03_07-58-26)
2025-10-03 07:58:54,730 | INFO | validation: 1400/2126 (2025-10-03_07-58-54)
2025-10-03 07:59:23,453 | INFO | validation: 1500/2126 (2025-10-03_07-59-23)
2025-10-03 07:59:52,504 | INFO | validation: 1600/2126 (2025-10-03_07-59-52)
2025-10-03 08:00:20,553 | INFO | validation: 1700/2126 (2025-10-03_08-00-20)
2025-10-03 08:00:49,970 | INFO | validation: 1800/2126 (2025-10-03_08-00-49)
2025-10-03 08:01:20,019 | INFO | validation: 1900/2126 (2025-10-03_08-01-20)
2025-10-03 08:01:47,411 | INFO | validation: 2000/2126 (2025-10-03_08-01-47)
2025-10-03 08:02:15,475 | INFO | validation: 2100/2126 (2025-10-03_08-02-15)
2025-10-03 08:02:23,897 | INFO | Confusion Matrix of Localization:
[[1292177771    7292662]
 [   6142645   46001386]]
2025-10-03 08:02:23,897 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99438797 0.00561203]
 [0.1178015  0.8821985 ]]
2025-10-03 08:02:23,897 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40639125  2244083   450789   116237]
 [       0   719978  1919254   409041    47930]
 [       0   122081   637527  1967718   175605]
 [       0    70764    55641    92010  1763860]]
2025-10-03 08:02:23,897 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.93530279 0.0516472  0.01037483 0.00267518]
 [0.         0.23253579 0.61987344 0.13211052 0.01548025]
 [0.         0.04205439 0.21961493 0.67783836 0.06049231]
 [0.         0.03569838 0.02806926 0.04641637 0.88981599]]
2025-10-03 08:02:23,897 | INFO | lofF1 is 87.2576, clfF1 is 69.5003, oaF1 is 74.8275, sub class F1 score is [95.619  48.2667 67.5903 86.3387]
2025-10-03 08:02:23,898 | INFO | ---------starting train set evaluation-----------
2025-10-03 08:02:24,391 | INFO | [TrainBuf] locF1 is 88.6470, clfF1 is 82.0703, oaF1 is 84.0433, sub class F1 score is [96.945  66.4836 82.5529 88.7406]
2025-10-03 08:02:56,887 | INFO | iter is 62550 / 100000 [skipped  205] | loc. loss = 0.2311328351, classif. loss = 0.1384803206
2025-10-03 08:03:29,273 | INFO | iter is 62600 / 100000 [skipped  205] | loc. loss = 0.1061869562, classif. loss = 0.0344984531
2025-10-03 08:04:01,168 | INFO | iter is 62650 / 100000 [skipped  206] | loc. loss = 0.1767941415, classif. loss = 0.3870902061
2025-10-03 08:04:33,483 | INFO | iter is 62700 / 100000 [skipped  206] | loc. loss = 0.0691677481, classif. loss = 0.4018725753
2025-10-03 08:05:05,921 | INFO | iter is 62750 / 100000 [skipped  206] | loc. loss = 0.1214829683, classif. loss = 0.4256331325
2025-10-03 08:05:38,265 | INFO | iter is 62800 / 100000 [skipped  206] | loc. loss = 0.2128377259, classif. loss = 0.5008918047
2025-10-03 08:06:10,565 | INFO | iter is 62850 / 100000 [skipped  206] | loc. loss = 0.1566317081, classif. loss = 0.5651865005
2025-10-03 08:06:43,046 | INFO | iter is 62900 / 100000 [skipped  206] | loc. loss = 0.1190421879, classif. loss = 0.2330663800
2025-10-03 08:07:14,808 | INFO | iter is 62950 / 100000 [skipped  207] | loc. loss = 0.1693997979, classif. loss = 0.3052953482
2025-10-03 08:07:47,211 | INFO | iter is 63000 / 100000 [skipped  207] | loc. loss = 0.2263504118, classif. loss = 0.4941143394
2025-10-03 08:08:19,543 | INFO | iter is 63050 / 100000 [skipped  207] | loc. loss = 0.1724404395, classif. loss = 0.9707549214
2025-10-03 08:08:52,026 | INFO | iter is 63100 / 100000 [skipped  207] | loc. loss = 0.1452344656, classif. loss = 0.2291335464
2025-10-03 08:09:23,785 | INFO | iter is 63150 / 100000 [skipped  208] | loc. loss = 0.1446225345, classif. loss = 0.0477261394
2025-10-03 08:09:56,264 | INFO | iter is 63200 / 100000 [skipped  208] | loc. loss = 0.1041443944, classif. loss = 0.0953615308
2025-10-03 08:10:28,612 | INFO | iter is 63250 / 100000 [skipped  208] | loc. loss = 0.0969895273, classif. loss = 0.5366705060
2025-10-03 08:11:01,034 | INFO | iter is 63300 / 100000 [skipped  208] | loc. loss = 0.1305127293, classif. loss = 2.2924480438
2025-10-03 08:11:33,467 | INFO | iter is 63350 / 100000 [skipped  208] | loc. loss = 0.2475063205, classif. loss = 0.5028510690
2025-10-03 08:12:05,839 | INFO | iter is 63400 / 100000 [skipped  208] | loc. loss = 0.1369833946, classif. loss = 0.8840847015
2025-10-03 08:12:37,552 | INFO | iter is 63450 / 100000 [skipped  209] | loc. loss = 0.2077274323, classif. loss = 0.8785083294
2025-10-03 08:13:09,864 | INFO | iter is 63500 / 100000 [skipped  209] | loc. loss = 0.1953054965, classif. loss = 0.7729014754
2025-10-03 08:13:42,224 | INFO | iter is 63550 / 100000 [skipped  209] | loc. loss = 0.3474698365, classif. loss = 0.8512548208
2025-10-03 08:14:14,610 | INFO | iter is 63600 / 100000 [skipped  209] | loc. loss = 0.1449681818, classif. loss = 0.2010671198
2025-10-03 08:14:46,925 | INFO | iter is 63650 / 100000 [skipped  209] | loc. loss = 0.1412135363, classif. loss = 0.2778762281
2025-10-03 08:15:19,258 | INFO | iter is 63700 / 100000 [skipped  209] | loc. loss = 0.1140191481, classif. loss = 0.5826535225
2025-10-03 08:15:51,575 | INFO | iter is 63750 / 100000 [skipped  209] | loc. loss = 0.1444778889, classif. loss = 0.9328139424
2025-10-03 08:16:23,975 | INFO | iter is 63800 / 100000 [skipped  209] | loc. loss = 0.2330446094, classif. loss = 0.0063576112
2025-10-03 08:16:55,734 | INFO | iter is 63850 / 100000 [skipped  210] | loc. loss = 0.1035420001, classif. loss = 0.9751700759
2025-10-03 08:17:26,943 | INFO | iter is 63900 / 100000 [skipped  212] | loc. loss = 0.1805982590, classif. loss = 0.2173130512
2025-10-03 08:17:59,300 | INFO | iter is 63950 / 100000 [skipped  212] | loc. loss = 0.1234762669, classif. loss = 0.0333160609
2025-10-03 08:18:31,776 | INFO | iter is 64000 / 100000 [skipped  212] | loc. loss = 0.1935271025, classif. loss = 0.4300494790
2025-10-03 08:19:04,121 | INFO | iter is 64050 / 100000 [skipped  212] | loc. loss = 0.1421301514, classif. loss = 0.6961249113
2025-10-03 08:19:36,481 | INFO | iter is 64100 / 100000 [skipped  212] | loc. loss = 0.1459859908, classif. loss = 0.5250027180
2025-10-03 08:20:08,936 | INFO | iter is 64150 / 100000 [skipped  212] | loc. loss = 0.0991441682, classif. loss = 0.7061588168
2025-10-03 08:20:39,543 | INFO | iter is 64200 / 100000 [skipped  215] | loc. loss = 0.1186114028, classif. loss = 0.6797641516
2025-10-03 08:21:11,896 | INFO | iter is 64250 / 100000 [skipped  215] | loc. loss = 0.1286839694, classif. loss = 0.3660777807
2025-10-03 08:21:44,289 | INFO | iter is 64300 / 100000 [skipped  215] | loc. loss = 0.1308130473, classif. loss = 0.4873935878
2025-10-03 08:22:16,661 | INFO | iter is 64350 / 100000 [skipped  215] | loc. loss = 0.1758584380, classif. loss = 0.4599747062
2025-10-03 08:22:48,911 | INFO | iter is 64400 / 100000 [skipped  215] | loc. loss = 0.1618420631, classif. loss = 0.2294094115
2025-10-03 08:23:21,336 | INFO | iter is 64450 / 100000 [skipped  215] | loc. loss = 0.1215991974, classif. loss = 0.6143336892
2025-10-03 08:23:53,743 | INFO | iter is 64500 / 100000 [skipped  215] | loc. loss = 0.1393052042, classif. loss = 0.0579992309
2025-10-03 08:24:26,133 | INFO | iter is 64550 / 100000 [skipped  215] | loc. loss = 0.2020452023, classif. loss = 0.0937645659
2025-10-03 08:24:58,580 | INFO | iter is 64600 / 100000 [skipped  215] | loc. loss = 0.1551178098, classif. loss = 0.6975164413
2025-10-03 08:25:30,884 | INFO | iter is 64650 / 100000 [skipped  215] | loc. loss = 0.1868582368, classif. loss = 0.4315812290
2025-10-03 08:26:03,314 | INFO | iter is 64700 / 100000 [skipped  215] | loc. loss = 0.6407328844, classif. loss = 0.0715626925
2025-10-03 08:26:35,060 | INFO | iter is 64750 / 100000 [skipped  216] | loc. loss = 0.1052852869, classif. loss = 0.9550809264
2025-10-03 08:27:07,407 | INFO | iter is 64800 / 100000 [skipped  216] | loc. loss = 0.1115944386, classif. loss = 0.2037303001
2025-10-03 08:27:39,901 | INFO | iter is 64850 / 100000 [skipped  216] | loc. loss = 0.1963460296, classif. loss = 0.3821461201
2025-10-03 08:28:12,281 | INFO | iter is 64900 / 100000 [skipped  216] | loc. loss = 0.1218691617, classif. loss = 0.0573383979
2025-10-03 08:28:44,692 | INFO | iter is 64950 / 100000 [skipped  216] | loc. loss = 0.1785220802, classif. loss = 0.3196297288
2025-10-03 08:29:17,136 | INFO | iter is 65000 / 100000 [skipped  216] | loc. loss = 0.2054004371, classif. loss = 0.4894812107
2025-10-03 08:29:49,543 | INFO | iter is 65050 / 100000 [skipped  216] | loc. loss = 0.2911286950, classif. loss = 0.6475611329
2025-10-03 08:30:21,952 | INFO | iter is 65100 / 100000 [skipped  216] | loc. loss = 0.2430605590, classif. loss = 0.7053114772
2025-10-03 08:30:54,442 | INFO | iter is 65150 / 100000 [skipped  216] | loc. loss = 0.0674264729, classif. loss = 0.6142066717
2025-10-03 08:31:26,933 | INFO | iter is 65200 / 100000 [skipped  216] | loc. loss = 0.1579892337, classif. loss = 0.7470581532
2025-10-03 08:31:59,450 | INFO | iter is 65250 / 100000 [skipped  216] | loc. loss = 0.1297352761, classif. loss = 0.2600486279
2025-10-03 08:32:31,869 | INFO | iter is 65300 / 100000 [skipped  216] | loc. loss = 0.0970064029, classif. loss = 0.6057643890
2025-10-03 08:33:04,258 | INFO | iter is 65350 / 100000 [skipped  216] | loc. loss = 0.1883842498, classif. loss = 0.6550957561
2025-10-03 08:33:36,604 | INFO | iter is 65400 / 100000 [skipped  216] | loc. loss = 0.1052640751, classif. loss = 0.7786687613
2025-10-03 08:34:08,975 | INFO | iter is 65450 / 100000 [skipped  216] | loc. loss = 0.4853322804, classif. loss = 0.6602298021
2025-10-03 08:34:41,345 | INFO | iter is 65500 / 100000 [skipped  216] | loc. loss = 0.2992647290, classif. loss = 0.6072418690
2025-10-03 08:35:13,716 | INFO | iter is 65550 / 100000 [skipped  216] | loc. loss = 0.1053493544, classif. loss = 0.7348062396
2025-10-03 08:35:46,153 | INFO | iter is 65600 / 100000 [skipped  216] | loc. loss = 0.2280430943, classif. loss = 0.6002186537
2025-10-03 08:36:02,362 | INFO | ---------starting evaluation-----------
2025-10-03 08:36:02,827 | INFO | validation:    0/2126 (2025-10-03_08-36-02)
2025-10-03 08:36:30,795 | INFO | validation:  100/2126 (2025-10-03_08-36-30)
2025-10-03 08:36:59,402 | INFO | validation:  200/2126 (2025-10-03_08-36-59)
2025-10-03 08:37:25,659 | INFO | validation:  300/2126 (2025-10-03_08-37-25)
2025-10-03 08:37:54,592 | INFO | validation:  400/2126 (2025-10-03_08-37-54)
2025-10-03 08:38:24,544 | INFO | validation:  500/2126 (2025-10-03_08-38-24)
2025-10-03 08:38:54,839 | INFO | validation:  600/2126 (2025-10-03_08-38-54)
2025-10-03 08:39:21,093 | INFO | validation:  700/2126 (2025-10-03_08-39-21)
2025-10-03 08:39:50,028 | INFO | validation:  800/2126 (2025-10-03_08-39-50)
2025-10-03 08:40:17,277 | INFO | validation:  900/2126 (2025-10-03_08-40-17)
2025-10-03 08:40:49,595 | INFO | validation: 1000/2126 (2025-10-03_08-40-49)
2025-10-03 08:41:19,233 | INFO | validation: 1100/2126 (2025-10-03_08-41-19)
2025-10-03 08:41:48,203 | INFO | validation: 1200/2126 (2025-10-03_08-41-48)
2025-10-03 08:42:18,504 | INFO | validation: 1300/2126 (2025-10-03_08-42-18)
2025-10-03 08:42:46,454 | INFO | validation: 1400/2126 (2025-10-03_08-42-46)
2025-10-03 08:43:15,095 | INFO | validation: 1500/2126 (2025-10-03_08-43-15)
2025-10-03 08:43:44,062 | INFO | validation: 1600/2126 (2025-10-03_08-43-44)
2025-10-03 08:44:12,013 | INFO | validation: 1700/2126 (2025-10-03_08-44-12)
2025-10-03 08:44:41,344 | INFO | validation: 1800/2126 (2025-10-03_08-44-41)
2025-10-03 08:45:11,292 | INFO | validation: 1900/2126 (2025-10-03_08-45-11)
2025-10-03 08:45:38,564 | INFO | validation: 2000/2126 (2025-10-03_08-45-38)
2025-10-03 08:46:06,520 | INFO | validation: 2100/2126 (2025-10-03_08-46-06)
2025-10-03 08:46:14,915 | INFO | Confusion Matrix of Localization:
[[1293358843    6111590]
 [   6647231   45496800]]
2025-10-03 08:46:14,915 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99529686 0.00470314]
 [0.12747827 0.87252173]]
2025-10-03 08:46:14,915 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41963084  1337284    58265    91601]
 [       0  1017942  1759296   278843    40122]
 [       0   262133   846197  1638558   156043]
 [       0    99478    46042    85364  1751391]]
2025-10-03 08:46:14,915 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96577349 0.03077737 0.00134096 0.00210818]
 [0.         0.32877108 0.56821081 0.09005966 0.01295845]
 [0.         0.09029942 0.29149746 0.56444952 0.0537536 ]
 [0.         0.05018375 0.02322685 0.04306365 0.88352575]]
2025-10-03 08:46:14,915 | INFO | lofF1 is 87.7026, clfF1 is 70.0457, oaF1 is 75.3428, sub class F1 score is [96.6971 49.6624 66.0182 87.1028]
2025-10-03 08:46:14,916 | INFO | ---------starting train set evaluation-----------
2025-10-03 08:46:15,438 | INFO | [TrainBuf] locF1 is 88.8227, clfF1 is 73.9846, oaF1 is 78.4360, sub class F1 score is [96.2468 57.4155 68.6343 85.5544]
2025-10-03 08:46:31,066 | INFO | iter is 65650 / 100000 [skipped  217] | loc. loss = 0.1203888953, classif. loss = 0.3108479381
2025-10-03 08:47:03,590 | INFO | iter is 65700 / 100000 [skipped  217] | loc. loss = 0.1776444018, classif. loss = 0.0292759072
2025-10-03 08:47:36,021 | INFO | iter is 65750 / 100000 [skipped  217] | loc. loss = 0.2230538130, classif. loss = 0.7627311349
2025-10-03 08:48:08,540 | INFO | iter is 65800 / 100000 [skipped  217] | loc. loss = 0.2628700733, classif. loss = 0.4186187387
2025-10-03 08:48:40,950 | INFO | iter is 65850 / 100000 [skipped  217] | loc. loss = 0.2139713764, classif. loss = 0.4809759259
2025-10-03 08:49:13,379 | INFO | iter is 65900 / 100000 [skipped  217] | loc. loss = 0.0787740797, classif. loss = 0.6025137901
2025-10-03 08:49:45,809 | INFO | iter is 65950 / 100000 [skipped  217] | loc. loss = 0.1788233668, classif. loss = 0.6885166168
2025-10-03 08:50:18,294 | INFO | iter is 66000 / 100000 [skipped  217] | loc. loss = 0.1011296138, classif. loss = 0.4250824153
2025-10-03 08:50:50,753 | INFO | iter is 66050 / 100000 [skipped  217] | loc. loss = 0.2650214434, classif. loss = 1.0568730831
2025-10-03 08:51:23,228 | INFO | iter is 66100 / 100000 [skipped  217] | loc. loss = 0.1519051790, classif. loss = 0.6830716133
2025-10-03 08:51:55,645 | INFO | iter is 66150 / 100000 [skipped  217] | loc. loss = 0.1630093902, classif. loss = 0.7737724185
2025-10-03 08:52:28,152 | INFO | iter is 66200 / 100000 [skipped  217] | loc. loss = 0.2078776211, classif. loss = 0.4350788295
2025-10-03 08:53:00,533 | INFO | iter is 66250 / 100000 [skipped  217] | loc. loss = 0.2184312642, classif. loss = 1.2049136162
2025-10-03 08:53:32,892 | INFO | iter is 66300 / 100000 [skipped  217] | loc. loss = 0.1435393691, classif. loss = 0.4801568985
2025-10-03 08:54:05,328 | INFO | iter is 66350 / 100000 [skipped  217] | loc. loss = 0.2133624703, classif. loss = 0.4444741011
2025-10-03 08:54:37,800 | INFO | iter is 66400 / 100000 [skipped  217] | loc. loss = 0.2206206024, classif. loss = 0.1296863556
2025-10-03 08:55:10,274 | INFO | iter is 66450 / 100000 [skipped  217] | loc. loss = 0.0747861564, classif. loss = 1.7012283802
2025-10-03 08:55:42,715 | INFO | iter is 66500 / 100000 [skipped  217] | loc. loss = 0.1411421746, classif. loss = 0.0839748606
2025-10-03 08:56:15,208 | INFO | iter is 66550 / 100000 [skipped  217] | loc. loss = 0.0961824805, classif. loss = 0.0352242365
2025-10-03 08:56:47,026 | INFO | iter is 66600 / 100000 [skipped  218] | loc. loss = 0.1406590343, classif. loss = 0.9172950983
2025-10-03 08:57:19,428 | INFO | iter is 66650 / 100000 [skipped  218] | loc. loss = 0.1786315590, classif. loss = 0.7824426889
2025-10-03 08:57:51,919 | INFO | iter is 66700 / 100000 [skipped  218] | loc. loss = 0.1613672525, classif. loss = 0.6480460167
2025-10-03 08:58:23,630 | INFO | iter is 66750 / 100000 [skipped  219] | loc. loss = 0.1051042825, classif. loss = 0.4303091466
2025-10-03 08:58:56,003 | INFO | iter is 66800 / 100000 [skipped  219] | loc. loss = 0.1757000685, classif. loss = 0.0131160617
2025-10-03 08:59:28,290 | INFO | iter is 66850 / 100000 [skipped  219] | loc. loss = 0.1340537071, classif. loss = 0.7897168398
2025-10-03 09:00:00,069 | INFO | iter is 66900 / 100000 [skipped  220] | loc. loss = 0.1080982164, classif. loss = 1.4040877819
2025-10-03 09:00:32,424 | INFO | iter is 66950 / 100000 [skipped  220] | loc. loss = 0.3062677979, classif. loss = 0.5803349614
2025-10-03 09:01:04,833 | INFO | iter is 67000 / 100000 [skipped  220] | loc. loss = 0.1800864041, classif. loss = 0.6783525348
2025-10-03 09:01:37,159 | INFO | iter is 67050 / 100000 [skipped  220] | loc. loss = 0.1879396439, classif. loss = 0.6217041016
2025-10-03 09:02:09,502 | INFO | iter is 67100 / 100000 [skipped  220] | loc. loss = 0.1265006512, classif. loss = 0.1049006432
2025-10-03 09:02:41,887 | INFO | iter is 67150 / 100000 [skipped  220] | loc. loss = 0.0585101955, classif. loss = 0.5024523139
2025-10-03 09:03:14,263 | INFO | iter is 67200 / 100000 [skipped  220] | loc. loss = 0.1690372080, classif. loss = 0.6414693594
2025-10-03 09:03:46,606 | INFO | iter is 67250 / 100000 [skipped  220] | loc. loss = 0.2019026577, classif. loss = 1.3083912134
2025-10-03 09:04:18,926 | INFO | iter is 67300 / 100000 [skipped  220] | loc. loss = 0.1597345620, classif. loss = 0.2150717378
2025-10-03 09:04:51,349 | INFO | iter is 67350 / 100000 [skipped  220] | loc. loss = 0.1047425643, classif. loss = 0.6012848616
2025-10-03 09:05:23,801 | INFO | iter is 67400 / 100000 [skipped  220] | loc. loss = 0.1687467992, classif. loss = 0.4989823103
2025-10-03 09:05:56,181 | INFO | iter is 67450 / 100000 [skipped  220] | loc. loss = 0.1889371425, classif. loss = 0.5399127603
2025-10-03 09:06:28,549 | INFO | iter is 67500 / 100000 [skipped  220] | loc. loss = 0.1018672064, classif. loss = 0.4407366514
2025-10-03 09:07:00,393 | INFO | iter is 67550 / 100000 [skipped  221] | loc. loss = 0.1342926621, classif. loss = 1.0400251150
2025-10-03 09:07:32,764 | INFO | iter is 67600 / 100000 [skipped  221] | loc. loss = 0.0372637697, classif. loss = 0.4722094536
2025-10-03 09:08:05,181 | INFO | iter is 67650 / 100000 [skipped  221] | loc. loss = 0.1591593921, classif. loss = 0.2759261727
2025-10-03 09:08:37,558 | INFO | iter is 67700 / 100000 [skipped  221] | loc. loss = 0.2538450658, classif. loss = 0.0790054649
2025-10-03 09:09:10,033 | INFO | iter is 67750 / 100000 [skipped  221] | loc. loss = 0.1647206098, classif. loss = 0.7893437147
2025-10-03 09:09:42,459 | INFO | iter is 67800 / 100000 [skipped  221] | loc. loss = 0.1463819742, classif. loss = 0.4308760464
2025-10-03 09:10:14,921 | INFO | iter is 67850 / 100000 [skipped  221] | loc. loss = 0.1071502566, classif. loss = 0.0167107005
2025-10-03 09:10:47,252 | INFO | iter is 67900 / 100000 [skipped  221] | loc. loss = 0.1959257424, classif. loss = 0.0524628386
2025-10-03 09:11:19,711 | INFO | iter is 67950 / 100000 [skipped  221] | loc. loss = 0.2817576528, classif. loss = 3.8286185265
2025-10-03 09:11:52,110 | INFO | iter is 68000 / 100000 [skipped  221] | loc. loss = 0.1234964281, classif. loss = 0.6901130080
2025-10-03 09:12:23,983 | INFO | iter is 68050 / 100000 [skipped  222] | loc. loss = 0.0815249085, classif. loss = 0.5039911270
2025-10-03 09:12:56,396 | INFO | iter is 68100 / 100000 [skipped  222] | loc. loss = 0.1111555845, classif. loss = 0.4792164266
2025-10-03 09:13:28,874 | INFO | iter is 68150 / 100000 [skipped  222] | loc. loss = 0.1474885643, classif. loss = 0.0827910081
2025-10-03 09:14:00,630 | INFO | iter is 68200 / 100000 [skipped  223] | loc. loss = 0.2428583652, classif. loss = 0.6011587381
2025-10-03 09:14:33,119 | INFO | iter is 68250 / 100000 [skipped  223] | loc. loss = 0.0836051702, classif. loss = 0.7137507200
2025-10-03 09:15:04,933 | INFO | iter is 68300 / 100000 [skipped  224] | loc. loss = 0.1784702241, classif. loss = 0.0264403112
2025-10-03 09:15:37,343 | INFO | iter is 68350 / 100000 [skipped  224] | loc. loss = 0.1620946378, classif. loss = 0.1744606495
2025-10-03 09:16:09,701 | INFO | iter is 68400 / 100000 [skipped  224] | loc. loss = 0.5014651418, classif. loss = 0.3270815015
2025-10-03 09:16:41,486 | INFO | iter is 68450 / 100000 [skipped  225] | loc. loss = 0.0816939250, classif. loss = 0.3502508998
2025-10-03 09:17:13,405 | INFO | iter is 68500 / 100000 [skipped  226] | loc. loss = 0.1499025226, classif. loss = 0.1728258133
2025-10-03 09:17:45,773 | INFO | iter is 68550 / 100000 [skipped  226] | loc. loss = 0.1824556887, classif. loss = 0.0195479300
2025-10-03 09:18:18,230 | INFO | iter is 68600 / 100000 [skipped  226] | loc. loss = 0.0691574737, classif. loss = 0.0329130962
2025-10-03 09:18:50,536 | INFO | iter is 68650 / 100000 [skipped  226] | loc. loss = 0.1530257761, classif. loss = 0.0543057919
2025-10-03 09:19:23,030 | INFO | iter is 68700 / 100000 [skipped  226] | loc. loss = 0.1697092801, classif. loss = 0.3979044557
2025-10-03 09:19:55,362 | INFO | iter is 68750 / 100000 [skipped  226] | loc. loss = 0.1244726479, classif. loss = 0.5205534101
2025-10-03 09:19:55,363 | INFO | ---------starting evaluation-----------
2025-10-03 09:19:55,821 | INFO | validation:    0/2126 (2025-10-03_09-19-55)
2025-10-03 09:20:24,120 | INFO | validation:  100/2126 (2025-10-03_09-20-24)
2025-10-03 09:20:53,105 | INFO | validation:  200/2126 (2025-10-03_09-20-53)
2025-10-03 09:21:19,665 | INFO | validation:  300/2126 (2025-10-03_09-21-19)
2025-10-03 09:21:48,966 | INFO | validation:  400/2126 (2025-10-03_09-21-48)
2025-10-03 09:22:19,301 | INFO | validation:  500/2126 (2025-10-03_09-22-19)
2025-10-03 09:22:49,981 | INFO | validation:  600/2126 (2025-10-03_09-22-49)
2025-10-03 09:23:16,556 | INFO | validation:  700/2126 (2025-10-03_09-23-16)
2025-10-03 09:23:45,874 | INFO | validation:  800/2126 (2025-10-03_09-23-45)
2025-10-03 09:24:13,454 | INFO | validation:  900/2126 (2025-10-03_09-24-13)
2025-10-03 09:24:46,191 | INFO | validation: 1000/2126 (2025-10-03_09-24-46)
2025-10-03 09:25:16,197 | INFO | validation: 1100/2126 (2025-10-03_09-25-16)
2025-10-03 09:25:45,492 | INFO | validation: 1200/2126 (2025-10-03_09-25-45)
2025-10-03 09:26:16,159 | INFO | validation: 1300/2126 (2025-10-03_09-26-16)
2025-10-03 09:26:44,424 | INFO | validation: 1400/2126 (2025-10-03_09-26-44)
2025-10-03 09:27:13,376 | INFO | validation: 1500/2126 (2025-10-03_09-27-13)
2025-10-03 09:27:42,686 | INFO | validation: 1600/2126 (2025-10-03_09-27-42)
2025-10-03 09:28:10,962 | INFO | validation: 1700/2126 (2025-10-03_09-28-10)
2025-10-03 09:28:40,604 | INFO | validation: 1800/2126 (2025-10-03_09-28-40)
2025-10-03 09:29:10,924 | INFO | validation: 1900/2126 (2025-10-03_09-29-10)
2025-10-03 09:29:38,531 | INFO | validation: 2000/2126 (2025-10-03_09-29-38)
2025-10-03 09:30:06,811 | INFO | validation: 2100/2126 (2025-10-03_09-30-06)
2025-10-03 09:30:15,311 | INFO | Confusion Matrix of Localization:
[[1293382039    6088394]
 [   6408680   45735351]]
2025-10-03 09:30:15,311 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99531471 0.00468529]
 [0.12290342 0.87709658]]
2025-10-03 09:30:15,311 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41645587  1509106   186660   108881]
 [       0   947451  1781278   331879    35595]
 [       0   155735   662900  1860889   223407]
 [       0    68447    45714    84355  1783759]]
2025-10-03 09:30:15,312 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95846635 0.03473183 0.00429595 0.00250588]
 [0.         0.30600416 0.57531047 0.10718903 0.01149634]
 [0.         0.0536475  0.22835541 0.64103797 0.07695911]
 [0.         0.03452952 0.02306138 0.04255464 0.89985446]]
2025-10-03 09:30:15,312 | INFO | lofF1 is 87.9799, clfF1 is 71.0722, oaF1 is 76.1445, sub class F1 score is [96.5499 50.2108 69.3493 86.2987]
2025-10-03 09:30:15,571 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step68750.pth
2025-10-03 09:30:15,571 | INFO | ---------starting train set evaluation-----------
2025-10-03 09:30:16,061 | INFO | [TrainBuf] locF1 is 89.1188, clfF1 is 76.0375, oaF1 is 79.9619, sub class F1 score is [97.5307 65.6967 64.3193 86.3292]
2025-10-03 09:30:48,534 | INFO | iter is 68800 / 100000 [skipped  226] | loc. loss = 0.1703818589, classif. loss = 0.7143957615
2025-10-03 09:31:20,932 | INFO | iter is 68850 / 100000 [skipped  226] | loc. loss = 0.1047983170, classif. loss = 0.0974086821
2025-10-03 09:31:53,402 | INFO | iter is 68900 / 100000 [skipped  226] | loc. loss = 0.1634717733, classif. loss = 0.4508653879
2025-10-03 09:32:25,726 | INFO | iter is 68950 / 100000 [skipped  226] | loc. loss = 0.1755954623, classif. loss = 0.4758648276
2025-10-03 09:32:57,571 | INFO | iter is 69000 / 100000 [skipped  227] | loc. loss = 0.2605539858, classif. loss = 0.4747103453
2025-10-03 09:33:29,922 | INFO | iter is 69050 / 100000 [skipped  227] | loc. loss = 0.2288407981, classif. loss = 0.5081444383
2025-10-03 09:34:02,343 | INFO | iter is 69100 / 100000 [skipped  227] | loc. loss = 0.1495073736, classif. loss = 0.0908052251
2025-10-03 09:34:34,775 | INFO | iter is 69150 / 100000 [skipped  227] | loc. loss = 0.2734445930, classif. loss = 0.5610230565
2025-10-03 09:35:07,272 | INFO | iter is 69200 / 100000 [skipped  227] | loc. loss = 0.2065550536, classif. loss = 0.0281846859
2025-10-03 09:35:39,615 | INFO | iter is 69250 / 100000 [skipped  227] | loc. loss = 0.1613926142, classif. loss = 1.7692804337
2025-10-03 09:36:11,445 | INFO | iter is 69300 / 100000 [skipped  228] | loc. loss = 0.1074843034, classif. loss = 0.0975313932
2025-10-03 09:36:43,791 | INFO | iter is 69350 / 100000 [skipped  228] | loc. loss = 0.2564879656, classif. loss = 0.2226583362
2025-10-03 09:37:16,208 | INFO | iter is 69400 / 100000 [skipped  228] | loc. loss = 0.2090773731, classif. loss = 0.5074685812
2025-10-03 09:37:48,610 | INFO | iter is 69450 / 100000 [skipped  228] | loc. loss = 0.1315631568, classif. loss = 0.5549131632
2025-10-03 09:38:20,417 | INFO | iter is 69500 / 100000 [skipped  229] | loc. loss = 0.0451159477, classif. loss = 0.0003337958
2025-10-03 09:38:52,775 | INFO | iter is 69550 / 100000 [skipped  229] | loc. loss = 0.1160106063, classif. loss = 0.5045654774
2025-10-03 09:39:25,228 | INFO | iter is 69600 / 100000 [skipped  229] | loc. loss = 0.2610162199, classif. loss = 0.3641232848
2025-10-03 09:39:57,615 | INFO | iter is 69650 / 100000 [skipped  229] | loc. loss = 0.4988403022, classif. loss = 0.4604698420
2025-10-03 09:40:28,753 | INFO | iter is 69700 / 100000 [skipped  231] | loc. loss = 0.0878689289, classif. loss = 0.6300606728
2025-10-03 09:41:00,466 | INFO | iter is 69750 / 100000 [skipped  232] | loc. loss = 0.2509623766, classif. loss = 0.3953589797
2025-10-03 09:41:32,881 | INFO | iter is 69800 / 100000 [skipped  232] | loc. loss = 0.0721343905, classif. loss = 0.0498275012
2025-10-03 09:42:05,279 | INFO | iter is 69850 / 100000 [skipped  232] | loc. loss = 0.1572690010, classif. loss = 0.1366892606
2025-10-03 09:42:37,728 | INFO | iter is 69900 / 100000 [skipped  232] | loc. loss = 0.0824975222, classif. loss = 0.4925138950
2025-10-03 09:43:10,062 | INFO | iter is 69950 / 100000 [skipped  232] | loc. loss = 0.1570298970, classif. loss = 0.3115621507
2025-10-03 09:43:42,415 | INFO | iter is 70000 / 100000 [skipped  232] | loc. loss = 0.0923069939, classif. loss = 0.0658856481
2025-10-03 09:44:14,799 | INFO | iter is 70050 / 100000 [skipped  232] | loc. loss = 0.1327351481, classif. loss = 0.7148368359
2025-10-03 09:44:47,162 | INFO | iter is 70100 / 100000 [skipped  232] | loc. loss = 0.2631421387, classif. loss = 0.7253671885
2025-10-03 09:45:19,465 | INFO | iter is 70150 / 100000 [skipped  232] | loc. loss = 0.0892716497, classif. loss = 0.5956008434
2025-10-03 09:45:51,880 | INFO | iter is 70200 / 100000 [skipped  232] | loc. loss = 0.1261694282, classif. loss = 0.2728524506
2025-10-03 09:46:24,233 | INFO | iter is 70250 / 100000 [skipped  232] | loc. loss = 0.1296538860, classif. loss = 0.5773797035
2025-10-03 09:46:55,969 | INFO | iter is 70300 / 100000 [skipped  233] | loc. loss = 0.1643857658, classif. loss = 0.5845338106
2025-10-03 09:47:28,413 | INFO | iter is 70350 / 100000 [skipped  233] | loc. loss = 0.1309888363, classif. loss = 0.3255601227
2025-10-03 09:48:00,835 | INFO | iter is 70400 / 100000 [skipped  233] | loc. loss = 0.2508161664, classif. loss = 0.6538587213
2025-10-03 09:48:33,178 | INFO | iter is 70450 / 100000 [skipped  233] | loc. loss = 0.0941942483, classif. loss = 0.8006541729
2025-10-03 09:49:05,663 | INFO | iter is 70500 / 100000 [skipped  233] | loc. loss = 0.2284771502, classif. loss = 0.7590219975
2025-10-03 09:49:37,954 | INFO | iter is 70550 / 100000 [skipped  233] | loc. loss = 0.1476242393, classif. loss = 0.0119490726
2025-10-03 09:50:10,359 | INFO | iter is 70600 / 100000 [skipped  233] | loc. loss = 0.1495991349, classif. loss = 0.5185621977
2025-10-03 09:50:42,701 | INFO | iter is 70650 / 100000 [skipped  233] | loc. loss = 0.1841184944, classif. loss = 0.5662376285
2025-10-03 09:51:15,094 | INFO | iter is 70700 / 100000 [skipped  233] | loc. loss = 0.0729577467, classif. loss = 0.3962665498
2025-10-03 09:51:47,488 | INFO | iter is 70750 / 100000 [skipped  233] | loc. loss = 0.1322485805, classif. loss = 0.0277077388
2025-10-03 09:52:19,357 | INFO | iter is 70800 / 100000 [skipped  234] | loc. loss = 0.2079630792, classif. loss = 0.5777122378
2025-10-03 09:52:51,817 | INFO | iter is 70850 / 100000 [skipped  234] | loc. loss = 0.2129795849, classif. loss = 0.6406655908
2025-10-03 09:53:56,024 | INFO | iter is 70950 / 100000 [skipped  235] | loc. loss = 0.1020583287, classif. loss = 0.0616132244
2025-10-03 09:54:28,333 | INFO | iter is 71000 / 100000 [skipped  235] | loc. loss = 0.1555477083, classif. loss = 0.4580052495
2025-10-03 09:55:00,793 | INFO | iter is 71050 / 100000 [skipped  235] | loc. loss = 0.1500678360, classif. loss = 0.0929633677
2025-10-03 09:55:33,167 | INFO | iter is 71100 / 100000 [skipped  235] | loc. loss = 0.1166132912, classif. loss = 0.6243487597
2025-10-03 09:56:05,712 | INFO | iter is 71150 / 100000 [skipped  235] | loc. loss = 0.1452749968, classif. loss = 0.2664174736
2025-10-03 09:56:38,124 | INFO | iter is 71200 / 100000 [skipped  235] | loc. loss = 0.1218949482, classif. loss = 0.1869346499
2025-10-03 09:57:10,578 | INFO | iter is 71250 / 100000 [skipped  235] | loc. loss = 0.1746957451, classif. loss = 1.1347631216
2025-10-03 09:57:42,901 | INFO | iter is 71300 / 100000 [skipped  235] | loc. loss = 0.2179445475, classif. loss = 0.3702206910
2025-10-03 09:58:15,235 | INFO | iter is 71350 / 100000 [skipped  235] | loc. loss = 0.1604164541, classif. loss = 0.5414834023
2025-10-03 09:58:47,542 | INFO | iter is 71400 / 100000 [skipped  235] | loc. loss = 0.0895399749, classif. loss = 1.3535155058
2025-10-03 09:59:19,985 | INFO | iter is 71450 / 100000 [skipped  235] | loc. loss = 0.2063799948, classif. loss = 1.6727019548
2025-10-03 09:59:51,818 | INFO | iter is 71500 / 100000 [skipped  236] | loc. loss = 0.1599663049, classif. loss = 0.3918567002
2025-10-03 10:00:24,077 | INFO | iter is 71550 / 100000 [skipped  236] | loc. loss = 0.1716674417, classif. loss = 0.5430887341
2025-10-03 10:00:56,333 | INFO | iter is 71600 / 100000 [skipped  236] | loc. loss = 0.2471245378, classif. loss = 2.7127163410
2025-10-03 10:01:28,665 | INFO | iter is 71650 / 100000 [skipped  236] | loc. loss = 0.1371083409, classif. loss = 0.0786854401
2025-10-03 10:02:01,060 | INFO | iter is 71700 / 100000 [skipped  236] | loc. loss = 0.0464699417, classif. loss = 0.0837284252
2025-10-03 10:02:33,406 | INFO | iter is 71750 / 100000 [skipped  236] | loc. loss = 0.0835306346, classif. loss = 0.5199419260
2025-10-03 10:03:05,847 | INFO | iter is 71800 / 100000 [skipped  236] | loc. loss = 0.0844427943, classif. loss = 0.1313308924
2025-10-03 10:03:37,580 | INFO | iter is 71850 / 100000 [skipped  237] | loc. loss = 0.1108428836, classif. loss = 0.0058282423
2025-10-03 10:03:53,818 | INFO | ---------starting evaluation-----------
2025-10-03 10:03:54,286 | INFO | validation:    0/2126 (2025-10-03_10-03-54)
2025-10-03 10:04:22,466 | INFO | validation:  100/2126 (2025-10-03_10-04-22)
2025-10-03 10:04:51,299 | INFO | validation:  200/2126 (2025-10-03_10-04-51)
2025-10-03 10:05:17,752 | INFO | validation:  300/2126 (2025-10-03_10-05-17)
2025-10-03 10:05:46,934 | INFO | validation:  400/2126 (2025-10-03_10-05-46)
2025-10-03 10:06:17,159 | INFO | validation:  500/2126 (2025-10-03_10-06-17)
2025-10-03 10:06:47,724 | INFO | validation:  600/2126 (2025-10-03_10-06-47)
2025-10-03 10:07:14,176 | INFO | validation:  700/2126 (2025-10-03_10-07-14)
2025-10-03 10:07:43,374 | INFO | validation:  800/2126 (2025-10-03_10-07-43)
2025-10-03 10:08:10,839 | INFO | validation:  900/2126 (2025-10-03_10-08-10)
2025-10-03 10:08:43,451 | INFO | validation: 1000/2126 (2025-10-03_10-08-43)
2025-10-03 10:09:13,344 | INFO | validation: 1100/2126 (2025-10-03_10-09-13)
2025-10-03 10:09:42,532 | INFO | validation: 1200/2126 (2025-10-03_10-09-42)
2025-10-03 10:10:13,097 | INFO | validation: 1300/2126 (2025-10-03_10-10-13)
2025-10-03 10:10:41,251 | INFO | validation: 1400/2126 (2025-10-03_10-10-41)
2025-10-03 10:11:10,105 | INFO | validation: 1500/2126 (2025-10-03_10-11-10)
2025-10-03 10:11:39,299 | INFO | validation: 1600/2126 (2025-10-03_10-11-39)
2025-10-03 10:12:07,514 | INFO | validation: 1700/2126 (2025-10-03_10-12-07)
2025-10-03 10:12:37,050 | INFO | validation: 1800/2126 (2025-10-03_10-12-37)
2025-10-03 10:13:07,278 | INFO | validation: 1900/2126 (2025-10-03_10-13-07)
2025-10-03 10:13:34,772 | INFO | validation: 2000/2126 (2025-10-03_10-13-34)
2025-10-03 10:14:02,940 | INFO | validation: 2100/2126 (2025-10-03_10-14-02)
2025-10-03 10:14:11,408 | INFO | Confusion Matrix of Localization:
[[1293572471    5897962]
 [   6767535   45376496]]
2025-10-03 10:14:11,409 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99546126 0.00453874]
 [0.12978542 0.87021458]]
2025-10-03 10:14:11,409 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41363809  1749955   222742   113728]
 [       0   965386  1657738   419480    53599]
 [       0   299636   675364  1714294   213637]
 [       0    88637    38238    60994  1794406]]
2025-10-03 10:14:11,409 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95198127 0.04027493 0.00512637 0.00261743]
 [0.         0.31179674 0.53540998 0.13548207 0.0173112 ]
 [0.         0.10321844 0.232649   0.59053901 0.07359355]
 [0.         0.04471478 0.01928996 0.0307697  0.90522556]]
2025-10-03 10:14:11,409 | INFO | lofF1 is 87.7532, clfF1 is 67.4675, oaF1 is 73.5532, sub class F1 score is [96.0077 45.9366 64.4418 86.3184]
2025-10-03 10:14:11,410 | INFO | ---------starting train set evaluation-----------
2025-10-03 10:14:11,905 | INFO | [TrainBuf] locF1 is 88.5311, clfF1 is 80.5302, oaF1 is 82.9305, sub class F1 score is [96.7433 69.585  76.2575 84.3896]
2025-10-03 10:14:28,113 | INFO | iter is 71900 / 100000 [skipped  237] | loc. loss = 0.1885530055, classif. loss = 0.0245220810
2025-10-03 10:15:00,504 | INFO | iter is 71950 / 100000 [skipped  237] | loc. loss = 0.2224725783, classif. loss = 0.0157240331
2025-10-03 10:15:32,860 | INFO | iter is 72000 / 100000 [skipped  237] | loc. loss = 0.1682363898, classif. loss = 0.8255687952
2025-10-03 10:16:05,265 | INFO | iter is 72050 / 100000 [skipped  237] | loc. loss = 0.1607367098, classif. loss = 0.2593256235
2025-10-03 10:16:37,645 | INFO | iter is 72100 / 100000 [skipped  237] | loc. loss = 0.1078340560, classif. loss = 0.6871798038
2025-10-03 10:17:10,014 | INFO | iter is 72150 / 100000 [skipped  237] | loc. loss = 0.1125797778, classif. loss = 0.6976389885
2025-10-03 10:17:42,407 | INFO | iter is 72200 / 100000 [skipped  237] | loc. loss = 0.1494030654, classif. loss = 0.6386727095
2025-10-03 10:18:14,839 | INFO | iter is 72250 / 100000 [skipped  237] | loc. loss = 0.1881967336, classif. loss = 0.4267560542
2025-10-03 10:18:47,122 | INFO | iter is 72300 / 100000 [skipped  237] | loc. loss = 0.2667829692, classif. loss = 0.1391893327
2025-10-03 10:19:19,472 | INFO | iter is 72350 / 100000 [skipped  237] | loc. loss = 0.2031168938, classif. loss = 0.5900163651
2025-10-03 10:19:51,851 | INFO | iter is 72400 / 100000 [skipped  237] | loc. loss = 0.1824204028, classif. loss = 0.5204737782
2025-10-03 10:20:23,622 | INFO | iter is 72450 / 100000 [skipped  238] | loc. loss = 0.2126958072, classif. loss = 1.3231794834
2025-10-03 10:20:56,001 | INFO | iter is 72500 / 100000 [skipped  238] | loc. loss = 0.1898300499, classif. loss = 0.8329413533
2025-10-03 10:21:27,752 | INFO | iter is 72550 / 100000 [skipped  239] | loc. loss = 0.1099532396, classif. loss = 0.5636996031
2025-10-03 10:22:00,172 | INFO | iter is 72600 / 100000 [skipped  239] | loc. loss = 0.1491251588, classif. loss = 0.7090513110
2025-10-03 10:22:32,549 | INFO | iter is 72650 / 100000 [skipped  239] | loc. loss = 0.1535885036, classif. loss = 0.0698024929
2025-10-03 10:23:04,991 | INFO | iter is 72700 / 100000 [skipped  239] | loc. loss = 0.0710293874, classif. loss = 0.1250468940
2025-10-03 10:23:37,332 | INFO | iter is 72750 / 100000 [skipped  239] | loc. loss = 0.1109159067, classif. loss = 0.4320212603
2025-10-03 10:24:09,748 | INFO | iter is 72800 / 100000 [skipped  239] | loc. loss = 0.1003725752, classif. loss = 0.9570289850
2025-10-03 10:24:42,134 | INFO | iter is 72850 / 100000 [skipped  239] | loc. loss = 0.1385049969, classif. loss = 0.3788504899
2025-10-03 10:25:14,535 | INFO | iter is 72900 / 100000 [skipped  239] | loc. loss = 0.0899313241, classif. loss = 0.5925824046
2025-10-03 10:25:46,941 | INFO | iter is 72950 / 100000 [skipped  239] | loc. loss = 0.0441727005, classif. loss = 0.0214668699
2025-10-03 10:26:18,735 | INFO | iter is 73000 / 100000 [skipped  240] | loc. loss = 0.1205036342, classif. loss = 0.6372534037
2025-10-03 10:26:50,552 | INFO | iter is 73050 / 100000 [skipped  241] | loc. loss = 0.1746575832, classif. loss = 0.4592062235
2025-10-03 10:27:22,937 | INFO | iter is 73100 / 100000 [skipped  241] | loc. loss = 0.0899148434, classif. loss = 0.0465542078
2025-10-03 10:27:55,296 | INFO | iter is 73150 / 100000 [skipped  241] | loc. loss = 0.1080447584, classif. loss = 0.1454603076
2025-10-03 10:28:27,677 | INFO | iter is 73200 / 100000 [skipped  241] | loc. loss = 0.1490867436, classif. loss = 0.7275862694
2025-10-03 10:28:59,986 | INFO | iter is 73250 / 100000 [skipped  241] | loc. loss = 0.1308750212, classif. loss = 0.0647285134
2025-10-03 10:29:32,367 | INFO | iter is 73300 / 100000 [skipped  241] | loc. loss = 0.1204450056, classif. loss = 0.2067511082
2025-10-03 10:30:04,785 | INFO | iter is 73350 / 100000 [skipped  241] | loc. loss = 0.0749669224, classif. loss = 0.3127093911
2025-10-03 10:30:37,087 | INFO | iter is 73400 / 100000 [skipped  241] | loc. loss = 0.1592821926, classif. loss = 5.3600158691
2025-10-03 10:31:09,524 | INFO | iter is 73450 / 100000 [skipped  241] | loc. loss = 0.1825004071, classif. loss = 0.3343237340
2025-10-03 10:31:41,927 | INFO | iter is 73500 / 100000 [skipped  241] | loc. loss = 0.1488121599, classif. loss = 0.6113110185
2025-10-03 10:32:14,236 | INFO | iter is 73550 / 100000 [skipped  241] | loc. loss = 0.2505891025, classif. loss = 0.6749283075
2025-10-03 10:32:46,543 | INFO | iter is 73600 / 100000 [skipped  241] | loc. loss = 0.1666782349, classif. loss = 0.0057984251
2025-10-03 10:33:18,955 | INFO | iter is 73650 / 100000 [skipped  241] | loc. loss = 0.2208848298, classif. loss = 0.2804459929
2025-10-03 10:33:51,375 | INFO | iter is 73700 / 100000 [skipped  241] | loc. loss = 0.1078750119, classif. loss = 0.0172757283
2025-10-03 10:34:23,127 | INFO | iter is 73750 / 100000 [skipped  242] | loc. loss = 0.1548818797, classif. loss = 0.4595072567
2025-10-03 10:34:55,634 | INFO | iter is 73800 / 100000 [skipped  242] | loc. loss = 0.1912562400, classif. loss = 0.1871359497
2025-10-03 10:35:28,036 | INFO | iter is 73850 / 100000 [skipped  242] | loc. loss = 0.1628980786, classif. loss = 0.7350223064
2025-10-03 10:36:00,433 | INFO | iter is 73900 / 100000 [skipped  242] | loc. loss = 0.1128934175, classif. loss = 0.9592218399
2025-10-03 10:36:32,900 | INFO | iter is 73950 / 100000 [skipped  242] | loc. loss = 0.1356355697, classif. loss = 0.3973452449
2025-10-03 10:37:05,267 | INFO | iter is 74000 / 100000 [skipped  242] | loc. loss = 0.1721876115, classif. loss = 0.4026986957
2025-10-03 10:37:37,112 | INFO | iter is 74050 / 100000 [skipped  243] | loc. loss = 0.1250426471, classif. loss = 0.0548007563
2025-10-03 10:38:08,857 | INFO | iter is 74100 / 100000 [skipped  244] | loc. loss = 0.2350461930, classif. loss = 1.1325978041
2025-10-03 10:38:41,192 | INFO | iter is 74150 / 100000 [skipped  244] | loc. loss = 0.2577323318, classif. loss = 0.5481117964
2025-10-03 10:39:13,434 | INFO | iter is 74200 / 100000 [skipped  244] | loc. loss = 0.2769107521, classif. loss = 0.7341175675
2025-10-03 10:39:45,822 | INFO | iter is 74250 / 100000 [skipped  244] | loc. loss = 0.1511246860, classif. loss = 0.1937520355
2025-10-03 10:40:18,103 | INFO | iter is 74300 / 100000 [skipped  244] | loc. loss = 0.1367852837, classif. loss = 0.5282905102
2025-10-03 10:40:50,445 | INFO | iter is 74350 / 100000 [skipped  244] | loc. loss = 0.1335396022, classif. loss = 1.5493688583
2025-10-03 10:41:22,830 | INFO | iter is 74400 / 100000 [skipped  244] | loc. loss = 0.1855519116, classif. loss = 0.3378399312
2025-10-03 10:41:54,570 | INFO | iter is 74450 / 100000 [skipped  245] | loc. loss = 0.1859960556, classif. loss = 0.1086269692
2025-10-03 10:42:26,911 | INFO | iter is 74500 / 100000 [skipped  245] | loc. loss = 0.1076088399, classif. loss = 0.5377976894
2025-10-03 10:42:58,678 | INFO | iter is 74550 / 100000 [skipped  246] | loc. loss = 0.1280166507, classif. loss = 0.4133383036
2025-10-03 10:43:31,189 | INFO | iter is 74600 / 100000 [skipped  246] | loc. loss = 0.0951578692, classif. loss = 0.4817736149
2025-10-03 10:44:03,560 | INFO | iter is 74650 / 100000 [skipped  246] | loc. loss = 0.2211430818, classif. loss = 1.0832821131
2025-10-03 10:44:35,972 | INFO | iter is 74700 / 100000 [skipped  246] | loc. loss = 0.1983724236, classif. loss = 0.3278427720
2025-10-03 10:45:08,290 | INFO | iter is 74750 / 100000 [skipped  246] | loc. loss = 0.2289236486, classif. loss = 0.5254635811
2025-10-03 10:45:40,630 | INFO | iter is 74800 / 100000 [skipped  246] | loc. loss = 0.1716629416, classif. loss = 0.6302130222
2025-10-03 10:46:11,828 | INFO | iter is 74850 / 100000 [skipped  248] | loc. loss = 0.0923234820, classif. loss = 0.7818076611
2025-10-03 10:46:44,124 | INFO | iter is 74900 / 100000 [skipped  248] | loc. loss = 0.3174112439, classif. loss = 0.5687389374
2025-10-03 10:47:16,518 | INFO | iter is 74950 / 100000 [skipped  248] | loc. loss = 0.0488281362, classif. loss = 1.2742582560
2025-10-03 10:47:48,926 | INFO | iter is 75000 / 100000 [skipped  248] | loc. loss = 0.1238238364, classif. loss = 0.0394902751
2025-10-03 10:47:48,927 | INFO | ---------starting evaluation-----------
2025-10-03 10:47:49,380 | INFO | validation:    0/2126 (2025-10-03_10-47-49)
2025-10-03 10:48:17,452 | INFO | validation:  100/2126 (2025-10-03_10-48-17)
2025-10-03 10:48:46,150 | INFO | validation:  200/2126 (2025-10-03_10-48-46)
2025-10-03 10:49:12,509 | INFO | validation:  300/2126 (2025-10-03_10-49-12)
2025-10-03 10:49:41,571 | INFO | validation:  400/2126 (2025-10-03_10-49-41)
2025-10-03 10:50:11,647 | INFO | validation:  500/2126 (2025-10-03_10-50-11)
2025-10-03 10:50:42,112 | INFO | validation:  600/2126 (2025-10-03_10-50-42)
2025-10-03 10:51:08,436 | INFO | validation:  700/2126 (2025-10-03_10-51-08)
2025-10-03 10:51:37,517 | INFO | validation:  800/2126 (2025-10-03_10-51-37)
2025-10-03 10:52:04,878 | INFO | validation:  900/2126 (2025-10-03_10-52-04)
2025-10-03 10:52:37,329 | INFO | validation: 1000/2126 (2025-10-03_10-52-37)
2025-10-03 10:53:07,032 | INFO | validation: 1100/2126 (2025-10-03_10-53-07)
2025-10-03 10:53:36,109 | INFO | validation: 1200/2126 (2025-10-03_10-53-36)
2025-10-03 10:54:06,480 | INFO | validation: 1300/2126 (2025-10-03_10-54-06)
2025-10-03 10:54:34,513 | INFO | validation: 1400/2126 (2025-10-03_10-54-34)
2025-10-03 10:55:03,264 | INFO | validation: 1500/2126 (2025-10-03_10-55-03)
2025-10-03 10:55:32,313 | INFO | validation: 1600/2126 (2025-10-03_10-55-32)
2025-10-03 10:56:00,367 | INFO | validation: 1700/2126 (2025-10-03_10-56-00)
2025-10-03 10:56:29,809 | INFO | validation: 1800/2126 (2025-10-03_10-56-29)
2025-10-03 10:56:59,880 | INFO | validation: 1900/2126 (2025-10-03_10-56-59)
2025-10-03 10:57:27,250 | INFO | validation: 2000/2126 (2025-10-03_10-57-27)
2025-10-03 10:57:55,269 | INFO | validation: 2100/2126 (2025-10-03_10-57-55)
2025-10-03 10:58:03,690 | INFO | Confusion Matrix of Localization:
[[1294181523    5288910]
 [   7235175   44908856]]
2025-10-03 10:58:03,690 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99592995 0.00407005]
 [0.13875366 0.86124634]]
2025-10-03 10:58:03,690 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42055660  1143792   119494   131288]
 [       0  1081113  1713486   250466    51138]
 [       0   190595   779000  1768430   164906]
 [       0    87134    36404    94307  1764430]]
2025-10-03 10:58:03,690 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96790411 0.02632419 0.00275013 0.00302157]
 [0.         0.34917381 0.55341526 0.08089457 0.01651636]
 [0.         0.06565606 0.26834947 0.60918775 0.05680672]
 [0.         0.04395657 0.01836476 0.04757513 0.89010354]]
2025-10-03 10:58:03,690 | INFO | lofF1 is 87.7625, clfF1 is 71.1731, oaF1 is 76.1499, sub class F1 score is [96.8302 50.6283 68.8691 86.1951]
2025-10-03 10:58:03,945 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step75000.pth
2025-10-03 10:58:03,945 | INFO | ---------starting train set evaluation-----------
2025-10-03 10:58:04,435 | INFO | [TrainBuf] locF1 is 88.1051, clfF1 is 76.9878, oaF1 is 80.3230, sub class F1 score is [96.8997 57.7868 81.3614 83.053 ]
2025-10-03 10:58:36,783 | INFO | iter is 75050 / 100000 [skipped  248] | loc. loss = 0.0878663138, classif. loss = 0.0122334296
2025-10-03 10:59:09,218 | INFO | iter is 75100 / 100000 [skipped  248] | loc. loss = 0.0512921661, classif. loss = 0.0019819683
2025-10-03 10:59:41,543 | INFO | iter is 75150 / 100000 [skipped  248] | loc. loss = 0.1311003119, classif. loss = 0.8168280721
2025-10-03 11:00:13,944 | INFO | iter is 75200 / 100000 [skipped  248] | loc. loss = 0.0888904184, classif. loss = 0.2468490005
2025-10-03 11:00:46,293 | INFO | iter is 75250 / 100000 [skipped  248] | loc. loss = 0.1576091349, classif. loss = 0.0267330520
2025-10-03 11:01:18,723 | INFO | iter is 75300 / 100000 [skipped  248] | loc. loss = 0.1626085043, classif. loss = 0.3149231970
2025-10-03 11:01:51,014 | INFO | iter is 75350 / 100000 [skipped  248] | loc. loss = 0.1868644953, classif. loss = 0.1433900595
2025-10-03 11:02:23,429 | INFO | iter is 75400 / 100000 [skipped  248] | loc. loss = 0.1586649567, classif. loss = 0.5180732608
2025-10-03 11:02:55,192 | INFO | iter is 75450 / 100000 [skipped  249] | loc. loss = 0.1272294223, classif. loss = 0.0199453123
2025-10-03 11:03:27,499 | INFO | iter is 75500 / 100000 [skipped  249] | loc. loss = 0.0970840603, classif. loss = 0.7646220326
2025-10-03 11:03:59,801 | INFO | iter is 75550 / 100000 [skipped  249] | loc. loss = 0.0851536542, classif. loss = 0.0840655118
2025-10-03 11:04:31,554 | INFO | iter is 75600 / 100000 [skipped  250] | loc. loss = 0.1541022956, classif. loss = 0.6550551653
2025-10-03 11:05:03,893 | INFO | iter is 75650 / 100000 [skipped  250] | loc. loss = 0.1307714432, classif. loss = 1.0559502840
2025-10-03 11:05:36,191 | INFO | iter is 75700 / 100000 [skipped  250] | loc. loss = 0.2042224705, classif. loss = 0.3217521310
2025-10-03 11:06:08,617 | INFO | iter is 75750 / 100000 [skipped  250] | loc. loss = 0.3722718060, classif. loss = 0.0629668236
2025-10-03 11:06:40,957 | INFO | iter is 75800 / 100000 [skipped  250] | loc. loss = 0.1488866210, classif. loss = 0.2236209512
2025-10-03 11:07:13,350 | INFO | iter is 75850 / 100000 [skipped  250] | loc. loss = 0.1306323856, classif. loss = 1.3004465103
2025-10-03 11:07:45,604 | INFO | iter is 75900 / 100000 [skipped  250] | loc. loss = 0.1324382424, classif. loss = 0.3878017664
2025-10-03 11:08:17,943 | INFO | iter is 75950 / 100000 [skipped  250] | loc. loss = 0.1364340186, classif. loss = 0.9394413233
2025-10-03 11:08:50,385 | INFO | iter is 76000 / 100000 [skipped  250] | loc. loss = 0.0748780817, classif. loss = 1.7390229702
2025-10-03 11:09:22,774 | INFO | iter is 76050 / 100000 [skipped  250] | loc. loss = 0.2481719851, classif. loss = 0.7236291170
2025-10-03 11:09:55,115 | INFO | iter is 76100 / 100000 [skipped  250] | loc. loss = 0.2530984282, classif. loss = 0.1388352811
2025-10-03 11:10:27,468 | INFO | iter is 76150 / 100000 [skipped  250] | loc. loss = 0.2083610445, classif. loss = 0.4625995457
2025-10-03 11:10:59,828 | INFO | iter is 76200 / 100000 [skipped  250] | loc. loss = 0.1358227730, classif. loss = 0.8228465319
2025-10-03 11:11:32,242 | INFO | iter is 76250 / 100000 [skipped  250] | loc. loss = 0.1827683300, classif. loss = 0.6459289193
2025-10-03 11:12:04,660 | INFO | iter is 76300 / 100000 [skipped  250] | loc. loss = 0.1379093379, classif. loss = 0.1696014404
2025-10-03 11:12:36,433 | INFO | iter is 76350 / 100000 [skipped  251] | loc. loss = 0.1109084934, classif. loss = 0.4139077067
2025-10-03 11:13:08,874 | INFO | iter is 76400 / 100000 [skipped  251] | loc. loss = 0.3230584860, classif. loss = 0.4949356318
2025-10-03 11:13:41,288 | INFO | iter is 76450 / 100000 [skipped  251] | loc. loss = 0.1441531628, classif. loss = 1.1642059088
2025-10-03 11:14:13,733 | INFO | iter is 76500 / 100000 [skipped  251] | loc. loss = 0.2015449703, classif. loss = 0.6768403649
2025-10-03 11:14:46,065 | INFO | iter is 76550 / 100000 [skipped  251] | loc. loss = 0.2234659046, classif. loss = 0.4417848587
2025-10-03 11:15:18,495 | INFO | iter is 76600 / 100000 [skipped  251] | loc. loss = 0.3296816945, classif. loss = 0.6424965858
2025-10-03 11:15:50,888 | INFO | iter is 76650 / 100000 [skipped  251] | loc. loss = 0.2725993991, classif. loss = 1.0280659199
2025-10-03 11:16:23,253 | INFO | iter is 76700 / 100000 [skipped  251] | loc. loss = 0.2111754417, classif. loss = 0.3371587992
2025-10-03 11:16:55,567 | INFO | iter is 76750 / 100000 [skipped  251] | loc. loss = 0.1707939655, classif. loss = 0.7997956276
2025-10-03 11:17:27,913 | INFO | iter is 76800 / 100000 [skipped  251] | loc. loss = 0.1808771193, classif. loss = 0.0244394280
2025-10-03 11:18:00,153 | INFO | iter is 76850 / 100000 [skipped  251] | loc. loss = 0.2613540590, classif. loss = 0.4060437083
2025-10-03 11:18:32,513 | INFO | iter is 76900 / 100000 [skipped  251] | loc. loss = 0.1242175698, classif. loss = 0.6939244270
2025-10-03 11:19:04,952 | INFO | iter is 76950 / 100000 [skipped  251] | loc. loss = 0.0873469710, classif. loss = 0.6399430037
2025-10-03 11:19:37,297 | INFO | iter is 77000 / 100000 [skipped  251] | loc. loss = 0.2320199460, classif. loss = 0.0186372735
2025-10-03 11:20:09,712 | INFO | iter is 77050 / 100000 [skipped  251] | loc. loss = 0.3012218177, classif. loss = 1.5129444599
2025-10-03 11:20:41,404 | INFO | iter is 77100 / 100000 [skipped  252] | loc. loss = 0.2474915087, classif. loss = 0.0980519503
2025-10-03 11:21:13,756 | INFO | iter is 77150 / 100000 [skipped  252] | loc. loss = 0.1805733442, classif. loss = 0.1430724263
2025-10-03 11:21:46,098 | INFO | iter is 77200 / 100000 [skipped  252] | loc. loss = 0.1169827059, classif. loss = 0.0201608352
2025-10-03 11:22:18,500 | INFO | iter is 77250 / 100000 [skipped  252] | loc. loss = 0.2414192557, classif. loss = 0.6615146995
2025-10-03 11:22:50,800 | INFO | iter is 77300 / 100000 [skipped  252] | loc. loss = 0.2473611534, classif. loss = 0.0353451036
2025-10-03 11:23:23,180 | INFO | iter is 77350 / 100000 [skipped  252] | loc. loss = 0.1734754741, classif. loss = 0.1196744367
2025-10-03 11:23:55,521 | INFO | iter is 77400 / 100000 [skipped  252] | loc. loss = 0.2987238765, classif. loss = 0.6511369944
2025-10-03 11:24:27,888 | INFO | iter is 77450 / 100000 [skipped  252] | loc. loss = 0.1101910099, classif. loss = 2.0325751305
2025-10-03 11:24:59,622 | INFO | iter is 77500 / 100000 [skipped  253] | loc. loss = 0.2146960348, classif. loss = 0.0827280283
2025-10-03 11:25:32,038 | INFO | iter is 77550 / 100000 [skipped  253] | loc. loss = 0.1241603047, classif. loss = 1.0624049902
2025-10-03 11:26:04,474 | INFO | iter is 77600 / 100000 [skipped  253] | loc. loss = 0.1936371326, classif. loss = 0.4659029841
2025-10-03 11:26:36,834 | INFO | iter is 77650 / 100000 [skipped  253] | loc. loss = 0.2095146030, classif. loss = 0.8660432100
2025-10-03 11:27:09,279 | INFO | iter is 77700 / 100000 [skipped  253] | loc. loss = 0.0936270878, classif. loss = 0.0107669318
2025-10-03 11:27:41,673 | INFO | iter is 77750 / 100000 [skipped  253] | loc. loss = 0.1461247355, classif. loss = 0.7689728737
2025-10-03 11:28:13,972 | INFO | iter is 77800 / 100000 [skipped  253] | loc. loss = 0.1780140102, classif. loss = 0.4234538674
2025-10-03 11:28:46,268 | INFO | iter is 77850 / 100000 [skipped  253] | loc. loss = 0.0938595831, classif. loss = 0.1655358374
2025-10-03 11:29:18,696 | INFO | iter is 77900 / 100000 [skipped  253] | loc. loss = 0.3303112984, classif. loss = 0.8934372067
2025-10-03 11:29:51,118 | INFO | iter is 77950 / 100000 [skipped  253] | loc. loss = 0.1319705844, classif. loss = 0.5600750446
2025-10-03 11:30:23,524 | INFO | iter is 78000 / 100000 [skipped  253] | loc. loss = 0.1983761787, classif. loss = 0.4963390827
2025-10-03 11:30:55,931 | INFO | iter is 78050 / 100000 [skipped  253] | loc. loss = 0.1823104322, classif. loss = 0.1834325790
2025-10-03 11:31:28,250 | INFO | iter is 78100 / 100000 [skipped  253] | loc. loss = 0.0646144301, classif. loss = 0.4155768454
2025-10-03 11:31:44,531 | INFO | ---------starting evaluation-----------
2025-10-03 11:31:44,984 | INFO | validation:    0/2126 (2025-10-03_11-31-44)
2025-10-03 11:32:13,232 | INFO | validation:  100/2126 (2025-10-03_11-32-13)
2025-10-03 11:32:42,113 | INFO | validation:  200/2126 (2025-10-03_11-32-42)
2025-10-03 11:33:08,607 | INFO | validation:  300/2126 (2025-10-03_11-33-08)
2025-10-03 11:33:37,830 | INFO | validation:  400/2126 (2025-10-03_11-33-37)
2025-10-03 11:34:08,092 | INFO | validation:  500/2126 (2025-10-03_11-34-08)
2025-10-03 11:34:38,689 | INFO | validation:  600/2126 (2025-10-03_11-34-38)
2025-10-03 11:35:05,188 | INFO | validation:  700/2126 (2025-10-03_11-35-05)
2025-10-03 11:35:34,419 | INFO | validation:  800/2126 (2025-10-03_11-35-34)
2025-10-03 11:36:01,933 | INFO | validation:  900/2126 (2025-10-03_11-36-01)
2025-10-03 11:36:34,601 | INFO | validation: 1000/2126 (2025-10-03_11-36-34)
2025-10-03 11:37:04,511 | INFO | validation: 1100/2126 (2025-10-03_11-37-04)
2025-10-03 11:37:33,735 | INFO | validation: 1200/2126 (2025-10-03_11-37-33)
2025-10-03 11:38:04,332 | INFO | validation: 1300/2126 (2025-10-03_11-38-04)
2025-10-03 11:38:32,549 | INFO | validation: 1400/2126 (2025-10-03_11-38-32)
2025-10-03 11:39:01,450 | INFO | validation: 1500/2126 (2025-10-03_11-39-01)
2025-10-03 11:39:30,674 | INFO | validation: 1600/2126 (2025-10-03_11-39-30)
2025-10-03 11:39:58,893 | INFO | validation: 1700/2126 (2025-10-03_11-39-58)
2025-10-03 11:40:28,470 | INFO | validation: 1800/2126 (2025-10-03_11-40-28)
2025-10-03 11:40:58,878 | INFO | validation: 1900/2126 (2025-10-03_11-40-58)
2025-10-03 11:41:26,460 | INFO | validation: 2000/2126 (2025-10-03_11-41-26)
2025-10-03 11:41:54,711 | INFO | validation: 2100/2126 (2025-10-03_11-41-54)
2025-10-03 11:42:03,198 | INFO | Confusion Matrix of Localization:
[[1294022395    5448038]
 [   7062807   45081224]]
2025-10-03 11:42:03,199 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99580749 0.00419251]
 [0.13544804 0.86455196]]
2025-10-03 11:42:03,199 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41322403  1752483   207476   167872]
 [       0   759964  1907602   390522    38115]
 [       0   124339   673885  1929570   175137]
 [       0    48836    62015    85222  1786202]]
2025-10-03 11:42:03,199 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95102832 0.04033311 0.00477503 0.00386355]
 [0.         0.24545031 0.61611012 0.12612933 0.01231024]
 [0.         0.04283223 0.23213952 0.66469716 0.06033109]
 [0.         0.02463634 0.03128476 0.04299202 0.90108688]]
2025-10-03 11:42:03,199 | INFO | lofF1 is 87.8149, clfF1 is 71.5353, oaF1 is 76.4192, sub class F1 score is [96.4285 50.9224 69.9662 86.0903]
2025-10-03 11:42:03,458 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step78125.pth
2025-10-03 11:42:03,459 | INFO | ---------starting train set evaluation-----------
2025-10-03 11:42:03,950 | INFO | [TrainBuf] locF1 is 88.1105, clfF1 is 77.1291, oaF1 is 80.4235, sub class F1 score is [95.8664 63.4495 75.6199 80.3513]
2025-10-03 11:42:20,165 | INFO | iter is 78150 / 100000 [skipped  253] | loc. loss = 0.1573185176, classif. loss = 0.2450822294
2025-10-03 11:42:52,586 | INFO | iter is 78200 / 100000 [skipped  253] | loc. loss = 0.1665468216, classif. loss = 0.0801514834
2025-10-03 11:43:25,013 | INFO | iter is 78250 / 100000 [skipped  253] | loc. loss = 0.0886100084, classif. loss = 0.6164391041
2025-10-03 11:43:57,350 | INFO | iter is 78300 / 100000 [skipped  253] | loc. loss = 0.1488711536, classif. loss = 0.1564826667
2025-10-03 11:44:29,691 | INFO | iter is 78350 / 100000 [skipped  253] | loc. loss = 0.1687240303, classif. loss = 0.9009813070
2025-10-03 11:45:02,054 | INFO | iter is 78400 / 100000 [skipped  253] | loc. loss = 0.1853250563, classif. loss = 0.1107628793
2025-10-03 11:45:34,361 | INFO | iter is 78450 / 100000 [skipped  253] | loc. loss = 0.1865114272, classif. loss = 0.6632236838
2025-10-03 11:46:06,668 | INFO | iter is 78500 / 100000 [skipped  253] | loc. loss = 0.1912300736, classif. loss = 0.5657964945
2025-10-03 11:46:38,969 | INFO | iter is 78550 / 100000 [skipped  253] | loc. loss = 0.1446741372, classif. loss = 0.4939817190
2025-10-03 11:47:11,354 | INFO | iter is 78600 / 100000 [skipped  253] | loc. loss = 0.1539685875, classif. loss = 2.7881212234
2025-10-03 11:47:43,714 | INFO | iter is 78650 / 100000 [skipped  253] | loc. loss = 0.1602795422, classif. loss = 0.6338105798
2025-10-03 11:48:16,085 | INFO | iter is 78700 / 100000 [skipped  253] | loc. loss = 0.1276097894, classif. loss = 1.1630065441
2025-10-03 11:48:48,405 | INFO | iter is 78750 / 100000 [skipped  253] | loc. loss = 0.1185762584, classif. loss = 0.0147037953
2025-10-03 11:49:20,824 | INFO | iter is 78800 / 100000 [skipped  253] | loc. loss = 0.2463915050, classif. loss = 1.5051101446
2025-10-03 11:49:52,561 | INFO | iter is 78850 / 100000 [skipped  254] | loc. loss = 0.1607415080, classif. loss = 0.3636408746
2025-10-03 11:50:24,933 | INFO | iter is 78900 / 100000 [skipped  254] | loc. loss = 0.1013493985, classif. loss = 0.7102842331
2025-10-03 11:50:57,278 | INFO | iter is 78950 / 100000 [skipped  254] | loc. loss = 0.1675230861, classif. loss = 0.4428427517
2025-10-03 11:51:29,616 | INFO | iter is 79000 / 100000 [skipped  254] | loc. loss = 0.1326321959, classif. loss = 0.1073887795
2025-10-03 11:52:01,918 | INFO | iter is 79050 / 100000 [skipped  254] | loc. loss = 0.2286837101, classif. loss = 0.8387995958
2025-10-03 11:52:34,275 | INFO | iter is 79100 / 100000 [skipped  254] | loc. loss = 0.1799046397, classif. loss = 0.3990299702
2025-10-03 11:53:06,600 | INFO | iter is 79150 / 100000 [skipped  254] | loc. loss = 0.2112819254, classif. loss = 1.8757761717
2025-10-03 11:53:39,043 | INFO | iter is 79200 / 100000 [skipped  254] | loc. loss = 0.1151626781, classif. loss = 0.5007773042
2025-10-03 11:54:11,427 | INFO | iter is 79250 / 100000 [skipped  254] | loc. loss = 0.1229222491, classif. loss = 1.2749971151
2025-10-03 11:54:43,738 | INFO | iter is 79300 / 100000 [skipped  254] | loc. loss = 0.1731104255, classif. loss = 0.1059053540
2025-10-03 11:55:16,074 | INFO | iter is 79350 / 100000 [skipped  254] | loc. loss = 0.1293409467, classif. loss = 0.2665635943
2025-10-03 11:55:48,497 | INFO | iter is 79400 / 100000 [skipped  254] | loc. loss = 0.2629157901, classif. loss = 0.8071309328
2025-10-03 11:56:20,747 | INFO | iter is 79450 / 100000 [skipped  254] | loc. loss = 0.1490619928, classif. loss = 0.3197484612
2025-10-03 11:56:53,113 | INFO | iter is 79500 / 100000 [skipped  254] | loc. loss = 0.1507272720, classif. loss = 0.0147797801
2025-10-03 11:57:25,495 | INFO | iter is 79550 / 100000 [skipped  254] | loc. loss = 0.2589249611, classif. loss = 0.9507248402
2025-10-03 11:57:57,954 | INFO | iter is 79600 / 100000 [skipped  254] | loc. loss = 0.2774015367, classif. loss = 1.3217461109
2025-10-03 11:58:30,323 | INFO | iter is 79650 / 100000 [skipped  254] | loc. loss = 0.0751042888, classif. loss = 0.0339250341
2025-10-03 11:59:02,691 | INFO | iter is 79700 / 100000 [skipped  254] | loc. loss = 0.1352369189, classif. loss = 0.6593204141
2025-10-03 11:59:35,092 | INFO | iter is 79750 / 100000 [skipped  254] | loc. loss = 0.1985927820, classif. loss = 0.4656351805
2025-10-03 12:00:07,404 | INFO | iter is 79800 / 100000 [skipped  254] | loc. loss = 0.1852192581, classif. loss = 0.3317796588
2025-10-03 12:00:39,154 | INFO | iter is 79850 / 100000 [skipped  255] | loc. loss = 0.2913593650, classif. loss = 1.4726428986
2025-10-03 12:01:11,536 | INFO | iter is 79900 / 100000 [skipped  255] | loc. loss = 0.2569786608, classif. loss = 0.1190728247
2025-10-03 12:01:43,356 | INFO | iter is 79950 / 100000 [skipped  256] | loc. loss = 0.1678234488, classif. loss = 0.3901213408
2025-10-03 12:02:15,687 | INFO | iter is 80000 / 100000 [skipped  256] | loc. loss = 0.1127730906, classif. loss = 0.5842713118
2025-10-03 12:02:48,028 | INFO | iter is 80050 / 100000 [skipped  256] | loc. loss = 0.1150392890, classif. loss = 0.5266855955
2025-10-03 12:03:19,890 | INFO | iter is 80100 / 100000 [skipped  257] | loc. loss = 0.0647127330, classif. loss = 0.0910267383
2025-10-03 12:03:52,201 | INFO | iter is 80150 / 100000 [skipped  257] | loc. loss = 0.1241484657, classif. loss = 0.4475793242
2025-10-03 12:04:24,471 | INFO | iter is 80200 / 100000 [skipped  257] | loc. loss = 0.1550824940, classif. loss = 0.6120898724
2025-10-03 12:04:56,913 | INFO | iter is 80250 / 100000 [skipped  257] | loc. loss = 0.2677844465, classif. loss = 1.7892398834
2025-10-03 12:05:29,250 | INFO | iter is 80300 / 100000 [skipped  257] | loc. loss = 0.1509838551, classif. loss = 0.7941374183
2025-10-03 12:06:01,583 | INFO | iter is 80350 / 100000 [skipped  257] | loc. loss = 0.2620418668, classif. loss = 0.5287107825
2025-10-03 12:06:33,937 | INFO | iter is 80400 / 100000 [skipped  257] | loc. loss = 0.1905914545, classif. loss = 0.0123271197
2025-10-03 12:07:06,341 | INFO | iter is 80450 / 100000 [skipped  257] | loc. loss = 0.1993316859, classif. loss = 0.0383344442
2025-10-03 12:07:38,759 | INFO | iter is 80500 / 100000 [skipped  257] | loc. loss = 0.1166033745, classif. loss = 0.0379749164
2025-10-03 12:08:10,519 | INFO | iter is 80550 / 100000 [skipped  258] | loc. loss = 0.1249254048, classif. loss = 0.5433444977
2025-10-03 12:08:42,916 | INFO | iter is 80600 / 100000 [skipped  258] | loc. loss = 0.1490509659, classif. loss = 0.0139227137
2025-10-03 12:09:15,233 | INFO | iter is 80650 / 100000 [skipped  258] | loc. loss = 0.1549567282, classif. loss = 0.3983488679
2025-10-03 12:09:47,619 | INFO | iter is 80700 / 100000 [skipped  258] | loc. loss = 0.1695415229, classif. loss = 0.4307630658
2025-10-03 12:10:19,975 | INFO | iter is 80750 / 100000 [skipped  258] | loc. loss = 0.1210790724, classif. loss = 0.5129550695
2025-10-03 12:10:52,233 | INFO | iter is 80800 / 100000 [skipped  258] | loc. loss = 0.1154458746, classif. loss = 0.3046036363
2025-10-03 12:11:24,585 | INFO | iter is 80850 / 100000 [skipped  258] | loc. loss = 0.2362952530, classif. loss = 0.3333899081
2025-10-03 12:11:56,270 | INFO | iter is 80900 / 100000 [skipped  259] | loc. loss = 0.1770735383, classif. loss = 0.5735608339
2025-10-03 12:12:28,590 | INFO | iter is 80950 / 100000 [skipped  259] | loc. loss = 0.2470919341, classif. loss = 0.6404430866
2025-10-03 12:13:00,986 | INFO | iter is 81000 / 100000 [skipped  259] | loc. loss = 0.1303850412, classif. loss = 0.4256155789
2025-10-03 12:13:33,422 | INFO | iter is 81050 / 100000 [skipped  259] | loc. loss = 0.1933914274, classif. loss = 0.0139288409
2025-10-03 12:14:05,873 | INFO | iter is 81100 / 100000 [skipped  259] | loc. loss = 0.1134819984, classif. loss = 0.5328879356
2025-10-03 12:14:38,245 | INFO | iter is 81150 / 100000 [skipped  259] | loc. loss = 0.1965868175, classif. loss = 0.0897420794
2025-10-03 12:15:10,640 | INFO | iter is 81200 / 100000 [skipped  259] | loc. loss = 0.1960486174, classif. loss = 0.4649761915
2025-10-03 12:15:43,056 | INFO | iter is 81250 / 100000 [skipped  259] | loc. loss = 0.1550820172, classif. loss = 1.5456069708
2025-10-03 12:15:43,058 | INFO | ---------starting evaluation-----------
2025-10-03 12:15:43,516 | INFO | validation:    0/2126 (2025-10-03_12-15-43)
2025-10-03 12:16:11,529 | INFO | validation:  100/2126 (2025-10-03_12-16-11)
2025-10-03 12:16:40,185 | INFO | validation:  200/2126 (2025-10-03_12-16-40)
2025-10-03 12:17:06,494 | INFO | validation:  300/2126 (2025-10-03_12-17-06)
2025-10-03 12:17:35,482 | INFO | validation:  400/2126 (2025-10-03_12-17-35)
2025-10-03 12:18:05,492 | INFO | validation:  500/2126 (2025-10-03_12-18-05)
2025-10-03 12:18:35,841 | INFO | validation:  600/2126 (2025-10-03_12-18-35)
2025-10-03 12:19:02,141 | INFO | validation:  700/2126 (2025-10-03_12-19-02)
2025-10-03 12:19:31,143 | INFO | validation:  800/2126 (2025-10-03_12-19-31)
2025-10-03 12:19:58,440 | INFO | validation:  900/2126 (2025-10-03_12-19-58)
2025-10-03 12:20:30,812 | INFO | validation: 1000/2126 (2025-10-03_12-20-30)
2025-10-03 12:21:00,484 | INFO | validation: 1100/2126 (2025-10-03_12-21-00)
2025-10-03 12:21:29,482 | INFO | validation: 1200/2126 (2025-10-03_12-21-29)
2025-10-03 12:21:59,822 | INFO | validation: 1300/2126 (2025-10-03_12-21-59)
2025-10-03 12:22:27,805 | INFO | validation: 1400/2126 (2025-10-03_12-22-27)
2025-10-03 12:22:56,476 | INFO | validation: 1500/2126 (2025-10-03_12-22-56)
2025-10-03 12:23:25,477 | INFO | validation: 1600/2126 (2025-10-03_12-23-25)
2025-10-03 12:23:53,468 | INFO | validation: 1700/2126 (2025-10-03_12-23-53)
2025-10-03 12:24:22,819 | INFO | validation: 1800/2126 (2025-10-03_12-24-22)
2025-10-03 12:24:52,832 | INFO | validation: 1900/2126 (2025-10-03_12-24-52)
2025-10-03 12:25:20,166 | INFO | validation: 2000/2126 (2025-10-03_12-25-20)
2025-10-03 12:25:48,191 | INFO | validation: 2100/2126 (2025-10-03_12-25-48)
2025-10-03 12:25:56,599 | INFO | Confusion Matrix of Localization:
[[1293729250    5741183]
 [   6746960   45397071]]
2025-10-03 12:25:56,600 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99558191 0.00441809]
 [0.12939084 0.87060916]]
2025-10-03 12:25:56,600 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41742472  1403419   159863   144480]
 [       0   895137  1676429   492659    31978]
 [       0   192014   510931  2038894   161092]
 [       0    70214    44451   100732  1766878]]
2025-10-03 12:25:56,600 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96069614 0.03229946 0.00367922 0.00332518]
 [0.         0.28910798 0.54144673 0.15911715 0.01032813]
 [0.         0.06614487 0.17600522 0.70235703 0.05549288]
 [0.         0.03542092 0.02242423 0.05081636 0.89133849]]
2025-10-03 12:25:56,600 | INFO | lofF1 is 87.9087, clfF1 is 71.4914, oaF1 is 76.4166, sub class F1 score is [96.682  49.809  71.602  86.4696]
2025-10-03 12:25:56,600 | INFO | ---------starting train set evaluation-----------
2025-10-03 12:25:57,092 | INFO | [TrainBuf] locF1 is 89.2293, clfF1 is 71.4241, oaF1 is 76.7656, sub class F1 score is [95.1853 51.738  70.9708 82.7865]
2025-10-03 12:26:29,460 | INFO | iter is 81300 / 100000 [skipped  259] | loc. loss = 0.1677859277, classif. loss = 0.0330990888
2025-10-03 12:27:01,978 | INFO | iter is 81350 / 100000 [skipped  259] | loc. loss = 0.1202256083, classif. loss = 0.6768336296
2025-10-03 12:27:33,742 | INFO | iter is 81400 / 100000 [skipped  260] | loc. loss = 0.1205352694, classif. loss = 0.3679009676
2025-10-03 12:28:06,138 | INFO | iter is 81450 / 100000 [skipped  260] | loc. loss = 0.0718879551, classif. loss = 0.0320711434
2025-10-03 12:28:38,561 | INFO | iter is 81500 / 100000 [skipped  260] | loc. loss = 0.1123858616, classif. loss = 0.0426159725
2025-10-03 12:29:10,900 | INFO | iter is 81550 / 100000 [skipped  260] | loc. loss = 0.2299418300, classif. loss = 0.0737427473
2025-10-03 12:29:43,410 | INFO | iter is 81600 / 100000 [skipped  260] | loc. loss = 0.1345891207, classif. loss = 0.8648023605
2025-10-03 12:30:15,850 | INFO | iter is 81650 / 100000 [skipped  260] | loc. loss = 0.1334011555, classif. loss = 0.2859193683
2025-10-03 12:30:48,346 | INFO | iter is 81700 / 100000 [skipped  260] | loc. loss = 0.1651022583, classif. loss = 0.5906885862
2025-10-03 12:31:20,725 | INFO | iter is 81750 / 100000 [skipped  260] | loc. loss = 0.1045551598, classif. loss = 0.7648218870
2025-10-03 12:31:53,093 | INFO | iter is 81800 / 100000 [skipped  260] | loc. loss = 0.1187789291, classif. loss = 0.0276475027
2025-10-03 12:32:25,455 | INFO | iter is 81850 / 100000 [skipped  260] | loc. loss = 0.2108928561, classif. loss = 1.6245429516
2025-10-03 12:32:57,884 | INFO | iter is 81900 / 100000 [skipped  260] | loc. loss = 0.1772879958, classif. loss = 0.6478154659
2025-10-03 12:33:30,283 | INFO | iter is 81950 / 100000 [skipped  260] | loc. loss = 0.0969436839, classif. loss = 0.7712818384
2025-10-03 12:34:02,128 | INFO | iter is 82000 / 100000 [skipped  261] | loc. loss = 0.1656945646, classif. loss = 0.8489564657
2025-10-03 12:34:34,496 | INFO | iter is 82050 / 100000 [skipped  261] | loc. loss = 0.1822170466, classif. loss = 0.4387606382
2025-10-03 12:35:06,879 | INFO | iter is 82100 / 100000 [skipped  261] | loc. loss = 0.2165399641, classif. loss = 0.1188765764
2025-10-03 12:35:39,228 | INFO | iter is 82150 / 100000 [skipped  261] | loc. loss = 0.1505681425, classif. loss = 0.6597564220
2025-10-03 12:36:43,437 | INFO | iter is 82250 / 100000 [skipped  262] | loc. loss = 0.0908516422, classif. loss = 0.4052787721
2025-10-03 12:37:15,783 | INFO | iter is 82300 / 100000 [skipped  262] | loc. loss = 0.1306680590, classif. loss = 0.7279348373
2025-10-03 12:37:48,130 | INFO | iter is 82350 / 100000 [skipped  262] | loc. loss = 0.1207544431, classif. loss = 0.3250173628
2025-10-03 12:38:20,508 | INFO | iter is 82400 / 100000 [skipped  262] | loc. loss = 0.1538713425, classif. loss = 0.7231335044
2025-10-03 12:38:52,889 | INFO | iter is 82450 / 100000 [skipped  262] | loc. loss = 0.1883810759, classif. loss = 0.9784221649
2025-10-03 12:39:25,277 | INFO | iter is 82500 / 100000 [skipped  262] | loc. loss = 0.1402309090, classif. loss = 0.3804507852
2025-10-03 12:39:57,018 | INFO | iter is 82550 / 100000 [skipped  263] | loc. loss = 0.1527046561, classif. loss = 0.6215191483
2025-10-03 12:40:29,361 | INFO | iter is 82600 / 100000 [skipped  263] | loc. loss = 0.1632564664, classif. loss = 0.5167447329
2025-10-03 12:41:01,726 | INFO | iter is 82650 / 100000 [skipped  263] | loc. loss = 0.1730283052, classif. loss = 0.7882421017
2025-10-03 12:41:34,068 | INFO | iter is 82700 / 100000 [skipped  263] | loc. loss = 0.2179566324, classif. loss = 0.5078842640
2025-10-03 12:42:05,778 | INFO | iter is 82750 / 100000 [skipped  264] | loc. loss = 0.2049352229, classif. loss = 0.7826544046
2025-10-03 12:42:38,209 | INFO | iter is 82800 / 100000 [skipped  264] | loc. loss = 0.2350475490, classif. loss = 0.5078994632
2025-10-03 12:43:09,972 | INFO | iter is 82850 / 100000 [skipped  265] | loc. loss = 0.1198887601, classif. loss = 0.3873627484
2025-10-03 12:43:42,283 | INFO | iter is 82900 / 100000 [skipped  265] | loc. loss = 0.1023828536, classif. loss = 0.2326652408
2025-10-03 12:44:14,657 | INFO | iter is 82950 / 100000 [skipped  265] | loc. loss = 0.2239312679, classif. loss = 0.8198443651
2025-10-03 12:44:47,048 | INFO | iter is 83000 / 100000 [skipped  265] | loc. loss = 0.1038778648, classif. loss = 0.7345358133
2025-10-03 12:45:19,394 | INFO | iter is 83050 / 100000 [skipped  265] | loc. loss = 0.1762198806, classif. loss = 0.3978181779
2025-10-03 12:45:51,760 | INFO | iter is 83100 / 100000 [skipped  265] | loc. loss = 0.2720408440, classif. loss = 0.8845094442
2025-10-03 12:46:24,136 | INFO | iter is 83150 / 100000 [skipped  265] | loc. loss = 0.1234600320, classif. loss = 0.0571104698
2025-10-03 12:46:56,648 | INFO | iter is 83200 / 100000 [skipped  265] | loc. loss = 0.1183083057, classif. loss = 1.2794165611
2025-10-03 12:47:29,039 | INFO | iter is 83250 / 100000 [skipped  265] | loc. loss = 0.1120646670, classif. loss = 0.6219982505
2025-10-03 12:48:01,501 | INFO | iter is 83300 / 100000 [skipped  265] | loc. loss = 0.1191282421, classif. loss = 0.0317830071
2025-10-03 12:48:33,902 | INFO | iter is 83350 / 100000 [skipped  265] | loc. loss = 0.1236349344, classif. loss = 0.0831056237
2025-10-03 12:49:06,318 | INFO | iter is 83400 / 100000 [skipped  265] | loc. loss = 0.2307460904, classif. loss = 0.4372496605
2025-10-03 12:49:38,676 | INFO | iter is 83450 / 100000 [skipped  265] | loc. loss = 0.1578420997, classif. loss = 1.0759239197
2025-10-03 12:50:11,098 | INFO | iter is 83500 / 100000 [skipped  265] | loc. loss = 0.0840695873, classif. loss = 0.0844306648
2025-10-03 12:50:43,398 | INFO | iter is 83550 / 100000 [skipped  265] | loc. loss = 0.1528799832, classif. loss = 0.7081642747
2025-10-03 12:51:15,766 | INFO | iter is 83600 / 100000 [skipped  265] | loc. loss = 0.1465750635, classif. loss = 0.0241477676
2025-10-03 12:51:48,170 | INFO | iter is 83650 / 100000 [skipped  265] | loc. loss = 0.1995808929, classif. loss = 0.8540071845
2025-10-03 12:52:20,444 | INFO | iter is 83700 / 100000 [skipped  265] | loc. loss = 0.1470103264, classif. loss = 1.0921447277
2025-10-03 12:52:52,812 | INFO | iter is 83750 / 100000 [skipped  265] | loc. loss = 0.2479103357, classif. loss = 0.0909996927
2025-10-03 12:53:25,145 | INFO | iter is 83800 / 100000 [skipped  265] | loc. loss = 0.1024418622, classif. loss = 1.0696914196
2025-10-03 12:53:57,516 | INFO | iter is 83850 / 100000 [skipped  265] | loc. loss = 0.1206815988, classif. loss = 0.2111533731
2025-10-03 12:54:29,849 | INFO | iter is 83900 / 100000 [skipped  265] | loc. loss = 0.0863429829, classif. loss = 0.6846596003
2025-10-03 12:55:02,295 | INFO | iter is 83950 / 100000 [skipped  265] | loc. loss = 0.2078252137, classif. loss = 0.9545843601
2025-10-03 12:55:34,531 | INFO | iter is 84000 / 100000 [skipped  265] | loc. loss = 0.0921674371, classif. loss = 1.2362473011
2025-10-03 12:56:06,936 | INFO | iter is 84050 / 100000 [skipped  265] | loc. loss = 0.1286969483, classif. loss = 0.0485545918
2025-10-03 12:56:39,267 | INFO | iter is 84100 / 100000 [skipped  265] | loc. loss = 0.1823285520, classif. loss = 0.5527380109
2025-10-03 12:57:11,639 | INFO | iter is 84150 / 100000 [skipped  265] | loc. loss = 0.1446355283, classif. loss = 0.6773602366
2025-10-03 12:57:43,939 | INFO | iter is 84200 / 100000 [skipped  265] | loc. loss = 0.1448033750, classif. loss = 0.5589871407
2025-10-03 12:58:16,379 | INFO | iter is 84250 / 100000 [skipped  265] | loc. loss = 0.1588085592, classif. loss = 0.3324318826
2025-10-03 12:58:48,773 | INFO | iter is 84300 / 100000 [skipped  265] | loc. loss = 0.1040219218, classif. loss = 0.6094818115
2025-10-03 12:59:21,233 | INFO | iter is 84350 / 100000 [skipped  265] | loc. loss = 0.2169944197, classif. loss = 0.0942423046
2025-10-03 12:59:37,408 | INFO | ---------starting evaluation-----------
2025-10-03 12:59:37,872 | INFO | validation:    0/2126 (2025-10-03_12-59-37)
2025-10-03 13:00:05,828 | INFO | validation:  100/2126 (2025-10-03_13-00-05)
2025-10-03 13:00:34,406 | INFO | validation:  200/2126 (2025-10-03_13-00-34)
2025-10-03 13:01:00,654 | INFO | validation:  300/2126 (2025-10-03_13-01-00)
2025-10-03 13:01:29,555 | INFO | validation:  400/2126 (2025-10-03_13-01-29)
2025-10-03 13:01:59,485 | INFO | validation:  500/2126 (2025-10-03_13-01-59)
2025-10-03 13:02:29,730 | INFO | validation:  600/2126 (2025-10-03_13-02-29)
2025-10-03 13:02:55,960 | INFO | validation:  700/2126 (2025-10-03_13-02-55)
2025-10-03 13:03:24,871 | INFO | validation:  800/2126 (2025-10-03_13-03-24)
2025-10-03 13:03:52,103 | INFO | validation:  900/2126 (2025-10-03_13-03-52)
2025-10-03 13:04:24,391 | INFO | validation: 1000/2126 (2025-10-03_13-04-24)
2025-10-03 13:04:53,977 | INFO | validation: 1100/2126 (2025-10-03_13-04-53)
2025-10-03 13:05:22,881 | INFO | validation: 1200/2126 (2025-10-03_13-05-22)
2025-10-03 13:05:53,134 | INFO | validation: 1300/2126 (2025-10-03_13-05-53)
2025-10-03 13:06:21,034 | INFO | validation: 1400/2126 (2025-10-03_13-06-21)
2025-10-03 13:06:49,622 | INFO | validation: 1500/2126 (2025-10-03_13-06-49)
2025-10-03 13:07:18,540 | INFO | validation: 1600/2126 (2025-10-03_13-07-18)
2025-10-03 13:07:46,453 | INFO | validation: 1700/2126 (2025-10-03_13-07-46)
2025-10-03 13:08:15,706 | INFO | validation: 1800/2126 (2025-10-03_13-08-15)
2025-10-03 13:08:45,628 | INFO | validation: 1900/2126 (2025-10-03_13-08-45)
2025-10-03 13:09:12,874 | INFO | validation: 2000/2126 (2025-10-03_13-09-12)
2025-10-03 13:09:40,811 | INFO | validation: 2100/2126 (2025-10-03_13-09-40)
2025-10-03 13:09:49,204 | INFO | Confusion Matrix of Localization:
[[1292540426    6930007]
 [   5858805   46285226]]
2025-10-03 13:09:49,204 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99466705 0.00533295]
 [0.11235811 0.88764189]]
2025-10-03 13:09:49,204 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41390360  1890143    74098    95633]
 [       0   788473  1992104   287337    28289]
 [       0   156492   751909  1873208   121322]
 [       0    76420    63985   101526  1740344]]
2025-10-03 13:09:49,204 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95259234 0.04350133 0.00170535 0.00220098]
 [0.         0.25465804 0.64340226 0.09280302 0.00913667]
 [0.         0.05390827 0.25901718 0.64528161 0.04179293]
 [0.         0.03855166 0.03227857 0.05121691 0.87795286]]
2025-10-03 13:09:49,204 | INFO | lofF1 is 87.8617, clfF1 is 72.3075, oaF1 is 76.9738, sub class F1 score is [96.4114 51.1167 71.5088 87.722 ]
2025-10-03 13:09:49,477 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step84375.pth
2025-10-03 13:09:49,477 | INFO | ---------starting train set evaluation-----------
2025-10-03 13:09:49,966 | INFO | [TrainBuf] locF1 is 88.8071, clfF1 is 76.4786, oaF1 is 80.1772, sub class F1 score is [97.0509 64.3662 68.2436 84.6822]
2025-10-03 13:10:06,161 | INFO | iter is 84400 / 100000 [skipped  265] | loc. loss = 0.1134296805, classif. loss = 1.0702253580
2025-10-03 13:10:38,552 | INFO | iter is 84450 / 100000 [skipped  265] | loc. loss = 0.0857574344, classif. loss = 0.7990085483
2025-10-03 13:11:11,040 | INFO | iter is 84500 / 100000 [skipped  265] | loc. loss = 0.2368833721, classif. loss = 0.3833590746
2025-10-03 13:12:15,213 | INFO | iter is 84600 / 100000 [skipped  266] | loc. loss = 0.1971015185, classif. loss = 0.1900908947
2025-10-03 13:12:47,563 | INFO | iter is 84650 / 100000 [skipped  266] | loc. loss = 0.2231349945, classif. loss = 1.6469068527
2025-10-03 13:13:19,976 | INFO | iter is 84700 / 100000 [skipped  266] | loc. loss = 0.2857025266, classif. loss = 0.8617793322
2025-10-03 13:13:52,287 | INFO | iter is 84750 / 100000 [skipped  266] | loc. loss = 0.1314893216, classif. loss = 0.5223847032
2025-10-03 13:14:24,699 | INFO | iter is 84800 / 100000 [skipped  266] | loc. loss = 0.1093111858, classif. loss = 0.4807388484
2025-10-03 13:14:57,138 | INFO | iter is 84850 / 100000 [skipped  266] | loc. loss = 0.2172427177, classif. loss = 0.1755443215
2025-10-03 13:15:29,562 | INFO | iter is 84900 / 100000 [skipped  266] | loc. loss = 0.1972073168, classif. loss = 0.3890181184
2025-10-03 13:16:01,868 | INFO | iter is 84950 / 100000 [skipped  266] | loc. loss = 0.1079585627, classif. loss = 0.0893020779
2025-10-03 13:16:33,705 | INFO | iter is 85000 / 100000 [skipped  267] | loc. loss = 0.1474758983, classif. loss = 0.4458748996
2025-10-03 13:17:05,440 | INFO | iter is 85050 / 100000 [skipped  268] | loc. loss = 0.0971805304, classif. loss = 0.7391421795
2025-10-03 13:17:37,851 | INFO | iter is 85100 / 100000 [skipped  268] | loc. loss = 0.1958407760, classif. loss = 0.5114870667
2025-10-03 13:18:10,153 | INFO | iter is 85150 / 100000 [skipped  268] | loc. loss = 0.0673324317, classif. loss = 0.6926062703
2025-10-03 13:18:42,490 | INFO | iter is 85200 / 100000 [skipped  268] | loc. loss = 0.1325877309, classif. loss = 0.4500461221
2025-10-03 13:19:14,872 | INFO | iter is 85250 / 100000 [skipped  268] | loc. loss = 0.0900129676, classif. loss = 0.0053746323
2025-10-03 13:19:47,156 | INFO | iter is 85300 / 100000 [skipped  268] | loc. loss = 0.0775973648, classif. loss = 0.2636265159
2025-10-03 13:20:19,481 | INFO | iter is 85350 / 100000 [skipped  268] | loc. loss = 0.1657233685, classif. loss = 0.2508974075
2025-10-03 13:20:51,844 | INFO | iter is 85400 / 100000 [skipped  268] | loc. loss = 0.1488183886, classif. loss = 0.1518893987
2025-10-03 13:21:24,248 | INFO | iter is 85450 / 100000 [skipped  268] | loc. loss = 0.1213115007, classif. loss = 0.0617925301
2025-10-03 13:21:56,632 | INFO | iter is 85500 / 100000 [skipped  268] | loc. loss = 0.1881974936, classif. loss = 1.1185059547
2025-10-03 13:22:28,435 | INFO | iter is 85550 / 100000 [skipped  269] | loc. loss = 0.1951327622, classif. loss = 0.5646360517
2025-10-03 13:23:00,811 | INFO | iter is 85600 / 100000 [skipped  269] | loc. loss = 0.1291818619, classif. loss = 0.0823044330
2025-10-03 13:23:33,188 | INFO | iter is 85650 / 100000 [skipped  269] | loc. loss = 0.1992065310, classif. loss = 0.5345809460
2025-10-03 13:24:05,470 | INFO | iter is 85700 / 100000 [skipped  269] | loc. loss = 0.1220309287, classif. loss = 1.0679579973
2025-10-03 13:24:37,867 | INFO | iter is 85750 / 100000 [skipped  269] | loc. loss = 0.1513460279, classif. loss = 0.0418292992
2025-10-03 13:25:10,345 | INFO | iter is 85800 / 100000 [skipped  269] | loc. loss = 0.3436074853, classif. loss = 0.3025899231
2025-10-03 13:25:42,666 | INFO | iter is 85850 / 100000 [skipped  269] | loc. loss = 0.1179450005, classif. loss = 0.2100343704
2025-10-03 13:26:14,980 | INFO | iter is 85900 / 100000 [skipped  269] | loc. loss = 0.1353015751, classif. loss = 0.6225508451
2025-10-03 13:26:47,319 | INFO | iter is 85950 / 100000 [skipped  269] | loc. loss = 0.1384209096, classif. loss = 0.0173789710
2025-10-03 13:27:19,779 | INFO | iter is 86000 / 100000 [skipped  269] | loc. loss = 0.1790197343, classif. loss = 0.0512668155
2025-10-03 13:27:51,487 | INFO | iter is 86050 / 100000 [skipped  270] | loc. loss = 0.1701216251, classif. loss = 0.7111128569
2025-10-03 13:28:23,309 | INFO | iter is 86100 / 100000 [skipped  271] | loc. loss = 0.1321206838, classif. loss = 0.2605904341
2025-10-03 13:28:55,639 | INFO | iter is 86150 / 100000 [skipped  271] | loc. loss = 0.1451231390, classif. loss = 0.0356811583
2025-10-03 13:29:28,049 | INFO | iter is 86200 / 100000 [skipped  271] | loc. loss = 0.2572863698, classif. loss = 0.8501846790
2025-10-03 13:30:00,426 | INFO | iter is 86250 / 100000 [skipped  271] | loc. loss = 0.1592401713, classif. loss = 0.4354633093
2025-10-03 13:30:32,819 | INFO | iter is 86300 / 100000 [skipped  271] | loc. loss = 0.2165917754, classif. loss = 0.0696857795
2025-10-03 13:31:05,181 | INFO | iter is 86350 / 100000 [skipped  271] | loc. loss = 0.1070013493, classif. loss = 0.4891105294
2025-10-03 13:31:37,596 | INFO | iter is 86400 / 100000 [skipped  271] | loc. loss = 0.1199525595, classif. loss = 0.3924393356
2025-10-03 13:32:09,965 | INFO | iter is 86450 / 100000 [skipped  271] | loc. loss = 0.2186586708, classif. loss = 0.7890336514
2025-10-03 13:32:42,308 | INFO | iter is 86500 / 100000 [skipped  271] | loc. loss = 0.1433830857, classif. loss = 0.4316830933
2025-10-03 13:33:14,705 | INFO | iter is 86550 / 100000 [skipped  271] | loc. loss = 0.1206206679, classif. loss = 0.3330521584
2025-10-03 13:33:47,008 | INFO | iter is 86600 / 100000 [skipped  271] | loc. loss = 0.1342835128, classif. loss = 0.0209476128
2025-10-03 13:34:19,373 | INFO | iter is 86650 / 100000 [skipped  271] | loc. loss = 0.2413542867, classif. loss = 0.5610871315
2025-10-03 13:34:51,734 | INFO | iter is 86700 / 100000 [skipped  271] | loc. loss = 0.1423492730, classif. loss = 0.5891057253
2025-10-03 13:35:24,188 | INFO | iter is 86750 / 100000 [skipped  271] | loc. loss = 0.1670909375, classif. loss = 0.3123371303
2025-10-03 13:35:56,523 | INFO | iter is 86800 / 100000 [skipped  271] | loc. loss = 0.1521284729, classif. loss = 0.0238839518
2025-10-03 13:36:28,813 | INFO | iter is 86850 / 100000 [skipped  271] | loc. loss = 0.2304288298, classif. loss = 1.2706775665
2025-10-03 13:37:01,137 | INFO | iter is 86900 / 100000 [skipped  271] | loc. loss = 0.1190798879, classif. loss = 0.5301764011
2025-10-03 13:37:33,610 | INFO | iter is 86950 / 100000 [skipped  271] | loc. loss = 0.2485723943, classif. loss = 0.6654165387
2025-10-03 13:38:06,015 | INFO | iter is 87000 / 100000 [skipped  271] | loc. loss = 0.2618439794, classif. loss = 0.6738816500
2025-10-03 13:38:38,377 | INFO | iter is 87050 / 100000 [skipped  271] | loc. loss = 0.1742435247, classif. loss = 0.6411616206
2025-10-03 13:39:10,801 | INFO | iter is 87100 / 100000 [skipped  271] | loc. loss = 0.2405018061, classif. loss = 0.6381680369
2025-10-03 13:39:43,242 | INFO | iter is 87150 / 100000 [skipped  271] | loc. loss = 0.1462614536, classif. loss = 0.5439507961
2025-10-03 13:40:15,671 | INFO | iter is 87200 / 100000 [skipped  271] | loc. loss = 0.2743273079, classif. loss = 0.5943271518
2025-10-03 13:40:48,025 | INFO | iter is 87250 / 100000 [skipped  271] | loc. loss = 0.2663316727, classif. loss = 0.6420059800
2025-10-03 13:41:20,329 | INFO | iter is 87300 / 100000 [skipped  271] | loc. loss = 0.2598690987, classif. loss = 0.2359412313
2025-10-03 13:41:52,701 | INFO | iter is 87350 / 100000 [skipped  271] | loc. loss = 0.1497700512, classif. loss = 0.0678633526
2025-10-03 13:42:25,097 | INFO | iter is 87400 / 100000 [skipped  271] | loc. loss = 0.1379815042, classif. loss = 0.0597622655
2025-10-03 13:42:57,496 | INFO | iter is 87450 / 100000 [skipped  271] | loc. loss = 0.1372829676, classif. loss = 0.3615819514
2025-10-03 13:43:29,839 | INFO | iter is 87500 / 100000 [skipped  271] | loc. loss = 0.2179984748, classif. loss = 0.7316112518
2025-10-03 13:43:29,840 | INFO | ---------starting evaluation-----------
2025-10-03 13:43:30,296 | INFO | validation:    0/2126 (2025-10-03_13-43-30)
2025-10-03 13:43:58,530 | INFO | validation:  100/2126 (2025-10-03_13-43-58)
2025-10-03 13:44:27,435 | INFO | validation:  200/2126 (2025-10-03_13-44-27)
2025-10-03 13:44:53,962 | INFO | validation:  300/2126 (2025-10-03_13-44-53)
2025-10-03 13:45:23,233 | INFO | validation:  400/2126 (2025-10-03_13-45-23)
2025-10-03 13:45:53,541 | INFO | validation:  500/2126 (2025-10-03_13-45-53)
2025-10-03 13:46:24,173 | INFO | validation:  600/2126 (2025-10-03_13-46-24)
2025-10-03 13:46:50,695 | INFO | validation:  700/2126 (2025-10-03_13-46-50)
2025-10-03 13:47:19,953 | INFO | validation:  800/2126 (2025-10-03_13-47-19)
2025-10-03 13:47:47,488 | INFO | validation:  900/2126 (2025-10-03_13-47-47)
2025-10-03 13:48:20,183 | INFO | validation: 1000/2126 (2025-10-03_13-48-20)
2025-10-03 13:48:50,117 | INFO | validation: 1100/2126 (2025-10-03_13-48-50)
2025-10-03 13:49:19,381 | INFO | validation: 1200/2126 (2025-10-03_13-49-19)
2025-10-03 13:49:50,002 | INFO | validation: 1300/2126 (2025-10-03_13-49-50)
2025-10-03 13:50:18,239 | INFO | validation: 1400/2126 (2025-10-03_13-50-18)
2025-10-03 13:50:47,161 | INFO | validation: 1500/2126 (2025-10-03_13-50-47)
2025-10-03 13:51:16,425 | INFO | validation: 1600/2126 (2025-10-03_13-51-16)
2025-10-03 13:51:44,652 | INFO | validation: 1700/2126 (2025-10-03_13-51-44)
2025-10-03 13:52:14,275 | INFO | validation: 1800/2126 (2025-10-03_13-52-14)
2025-10-03 13:52:44,578 | INFO | validation: 1900/2126 (2025-10-03_13-52-44)
2025-10-03 13:53:12,158 | INFO | validation: 2000/2126 (2025-10-03_13-53-12)
2025-10-03 13:53:40,407 | INFO | validation: 2100/2126 (2025-10-03_13-53-40)
2025-10-03 13:53:48,901 | INFO | Confusion Matrix of Localization:
[[1294082723    5387710]
 [   7196210   44947821]]
2025-10-03 13:53:48,901 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99585392 0.00414608]
 [0.1380064  0.8619936 ]]
2025-10-03 13:53:48,901 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42055775  1093832   210179    90448]
 [       0  1051386  1568028   449005    27784]
 [       0   222860   427642  2137684   114745]
 [       0    92389    41475   120705  1727706]]
2025-10-03 13:53:48,901 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96790676 0.02517436 0.00483724 0.00208165]
 [0.         0.3395727  0.50643579 0.14501795 0.00897357]
 [0.         0.07677068 0.14731387 0.73638815 0.03952729]
 [0.         0.04660756 0.02092293 0.06089216 0.87157735]]
2025-10-03 13:53:48,901 | INFO | lofF1 is 87.7206, clfF1 is 72.4506, oaF1 is 77.0316, sub class F1 score is [96.8217 50.3608 73.4536 87.635 ]
2025-10-03 13:53:49,159 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step87500.pth
2025-10-03 13:53:49,160 | INFO | ---------starting train set evaluation-----------
2025-10-03 13:53:49,654 | INFO | [TrainBuf] locF1 is 89.1057, clfF1 is 82.8211, oaF1 is 84.7065, sub class F1 score is [97.0242 71.1965 80.2396 87.0938]
2025-10-03 13:54:21,506 | INFO | iter is 87550 / 100000 [skipped  272] | loc. loss = 0.1308913678, classif. loss = 0.1240648180
2025-10-03 13:54:53,319 | INFO | iter is 87600 / 100000 [skipped  273] | loc. loss = 0.1804275215, classif. loss = 0.5164073110
2025-10-03 13:55:25,712 | INFO | iter is 87650 / 100000 [skipped  273] | loc. loss = 0.1322041899, classif. loss = 0.7791205645
2025-10-03 13:55:58,102 | INFO | iter is 87700 / 100000 [skipped  273] | loc. loss = 0.1502545476, classif. loss = 0.0286764503
2025-10-03 13:56:30,454 | INFO | iter is 87750 / 100000 [skipped  273] | loc. loss = 0.0896076784, classif. loss = 0.8462067246
2025-10-03 13:57:02,716 | INFO | iter is 87800 / 100000 [skipped  273] | loc. loss = 0.1837938577, classif. loss = 0.4067652524
2025-10-03 13:57:34,993 | INFO | iter is 87850 / 100000 [skipped  273] | loc. loss = 0.1400667876, classif. loss = 1.0961608887
2025-10-03 13:58:07,397 | INFO | iter is 87900 / 100000 [skipped  273] | loc. loss = 0.1605307013, classif. loss = 0.1152144670
2025-10-03 13:58:39,806 | INFO | iter is 87950 / 100000 [skipped  273] | loc. loss = 0.0735581294, classif. loss = 0.3855090141
2025-10-03 13:59:12,172 | INFO | iter is 88000 / 100000 [skipped  273] | loc. loss = 0.1181410551, classif. loss = 0.3086829484
2025-10-03 13:59:43,860 | INFO | iter is 88050 / 100000 [skipped  274] | loc. loss = 0.1623159647, classif. loss = 0.6650875807
2025-10-03 14:00:16,294 | INFO | iter is 88100 / 100000 [skipped  274] | loc. loss = 0.1057336181, classif. loss = 0.1496958733
2025-10-03 14:00:48,866 | INFO | iter is 88150 / 100000 [skipped  274] | loc. loss = 0.0999433696, classif. loss = 0.3346613348
2025-10-03 14:01:21,321 | INFO | iter is 88200 / 100000 [skipped  274] | loc. loss = 0.2363389581, classif. loss = 0.9288912416
2025-10-03 14:01:53,754 | INFO | iter is 88250 / 100000 [skipped  274] | loc. loss = 0.2054660469, classif. loss = 0.4783676267
2025-10-03 14:02:26,126 | INFO | iter is 88300 / 100000 [skipped  274] | loc. loss = 0.1102419496, classif. loss = 0.8886213303
2025-10-03 14:02:58,455 | INFO | iter is 88350 / 100000 [skipped  274] | loc. loss = 0.1613576114, classif. loss = 0.0926190168
2025-10-03 14:03:30,205 | INFO | iter is 88400 / 100000 [skipped  275] | loc. loss = 0.1620204449, classif. loss = 1.2380197048
2025-10-03 14:04:02,014 | INFO | iter is 88450 / 100000 [skipped  276] | loc. loss = 0.2024241388, classif. loss = 0.2424778193
2025-10-03 14:04:33,705 | INFO | iter is 88500 / 100000 [skipped  277] | loc. loss = 0.1798205227, classif. loss = 0.7325781584
2025-10-03 14:05:06,061 | INFO | iter is 88550 / 100000 [skipped  277] | loc. loss = 0.2115123123, classif. loss = 1.0619063377
2025-10-03 14:05:38,485 | INFO | iter is 88600 / 100000 [skipped  277] | loc. loss = 0.0979631171, classif. loss = 1.6450288296
2025-10-03 14:06:10,823 | INFO | iter is 88650 / 100000 [skipped  277] | loc. loss = 0.1560671180, classif. loss = 0.7498104572
2025-10-03 14:06:43,261 | INFO | iter is 88700 / 100000 [skipped  277] | loc. loss = 0.1724562943, classif. loss = 0.3610464931
2025-10-03 14:07:15,625 | INFO | iter is 88750 / 100000 [skipped  277] | loc. loss = 0.1723861694, classif. loss = 0.6986639500
2025-10-03 14:07:48,055 | INFO | iter is 88800 / 100000 [skipped  277] | loc. loss = 0.2368606478, classif. loss = 0.2728089690
2025-10-03 14:08:20,459 | INFO | iter is 88850 / 100000 [skipped  277] | loc. loss = 0.2193641663, classif. loss = 0.0232252441
2025-10-03 14:08:52,832 | INFO | iter is 88900 / 100000 [skipped  277] | loc. loss = 0.2501617372, classif. loss = 0.4032317102
2025-10-03 14:09:25,301 | INFO | iter is 88950 / 100000 [skipped  277] | loc. loss = 0.0988467485, classif. loss = 0.5050732493
2025-10-03 14:09:57,668 | INFO | iter is 89000 / 100000 [skipped  277] | loc. loss = 0.2437292933, classif. loss = 0.2785031497
2025-10-03 14:10:30,071 | INFO | iter is 89050 / 100000 [skipped  277] | loc. loss = 0.1882185042, classif. loss = 0.5053342581
2025-10-03 14:11:02,436 | INFO | iter is 89100 / 100000 [skipped  277] | loc. loss = 0.2840046287, classif. loss = 0.6401367188
2025-10-03 14:11:34,926 | INFO | iter is 89150 / 100000 [skipped  277] | loc. loss = 0.2252576947, classif. loss = 0.9482343197
2025-10-03 14:12:07,260 | INFO | iter is 89200 / 100000 [skipped  277] | loc. loss = 0.2000679225, classif. loss = 0.3402547836
2025-10-03 14:12:39,053 | INFO | iter is 89250 / 100000 [skipped  278] | loc. loss = 0.0821636245, classif. loss = 0.6768893003
2025-10-03 14:13:11,452 | INFO | iter is 89300 / 100000 [skipped  278] | loc. loss = 0.1108238474, classif. loss = 0.0115529504
2025-10-03 14:13:43,850 | INFO | iter is 89350 / 100000 [skipped  278] | loc. loss = 0.1099598333, classif. loss = 1.0439994335
2025-10-03 14:14:16,286 | INFO | iter is 89400 / 100000 [skipped  278] | loc. loss = 0.2327617109, classif. loss = 0.2239791304
2025-10-03 14:14:48,634 | INFO | iter is 89450 / 100000 [skipped  278] | loc. loss = 0.1585370898, classif. loss = 0.0155984629
2025-10-03 14:15:20,991 | INFO | iter is 89500 / 100000 [skipped  278] | loc. loss = 0.1025842130, classif. loss = 1.0149586201
2025-10-03 14:15:53,488 | INFO | iter is 89550 / 100000 [skipped  278] | loc. loss = 0.1275814921, classif. loss = 0.5202320814
2025-10-03 14:16:25,900 | INFO | iter is 89600 / 100000 [skipped  278] | loc. loss = 0.1738005728, classif. loss = 1.3949067593
2025-10-03 14:16:58,204 | INFO | iter is 89650 / 100000 [skipped  278] | loc. loss = 0.1734829694, classif. loss = 0.4861224294
2025-10-03 14:17:30,635 | INFO | iter is 89700 / 100000 [skipped  278] | loc. loss = 0.1420233548, classif. loss = 0.6551024914
2025-10-03 14:18:02,993 | INFO | iter is 89750 / 100000 [skipped  278] | loc. loss = 0.1276316047, classif. loss = 0.5242358446
2025-10-03 14:18:35,460 | INFO | iter is 89800 / 100000 [skipped  278] | loc. loss = 0.1629299372, classif. loss = 0.4444537461
2025-10-03 14:19:07,906 | INFO | iter is 89850 / 100000 [skipped  278] | loc. loss = 0.1612547487, classif. loss = 0.4416633248
2025-10-03 14:19:40,398 | INFO | iter is 89900 / 100000 [skipped  278] | loc. loss = 0.1873643398, classif. loss = 0.0257723443
2025-10-03 14:20:12,151 | INFO | iter is 89950 / 100000 [skipped  279] | loc. loss = 0.1573643237, classif. loss = 0.1619697213
2025-10-03 14:20:43,893 | INFO | iter is 90000 / 100000 [skipped  280] | loc. loss = 0.0543659776, classif. loss = 0.3748950362
2025-10-03 14:21:16,368 | INFO | iter is 90050 / 100000 [skipped  280] | loc. loss = 0.2393495142, classif. loss = 0.6448844075
2025-10-03 14:21:48,841 | INFO | iter is 90100 / 100000 [skipped  280] | loc. loss = 0.2175520957, classif. loss = 0.6364204884
2025-10-03 14:22:21,261 | INFO | iter is 90150 / 100000 [skipped  280] | loc. loss = 0.1283942759, classif. loss = 0.6846307516
2025-10-03 14:22:53,102 | INFO | iter is 90200 / 100000 [skipped  281] | loc. loss = 0.1491043270, classif. loss = 0.0056966236
2025-10-03 14:23:25,488 | INFO | iter is 90250 / 100000 [skipped  281] | loc. loss = 0.1098756194, classif. loss = 0.0699896216
2025-10-03 14:23:57,292 | INFO | iter is 90300 / 100000 [skipped  282] | loc. loss = 0.2421306074, classif. loss = 0.4427415133
2025-10-03 14:24:29,625 | INFO | iter is 90350 / 100000 [skipped  282] | loc. loss = 0.1917362362, classif. loss = 0.2920560539
2025-10-03 14:25:01,371 | INFO | iter is 90400 / 100000 [skipped  283] | loc. loss = 0.1148795187, classif. loss = 0.4945039153
2025-10-03 14:25:33,778 | INFO | iter is 90450 / 100000 [skipped  283] | loc. loss = 0.1315808296, classif. loss = 0.5475474596
2025-10-03 14:26:06,113 | INFO | iter is 90500 / 100000 [skipped  283] | loc. loss = 0.1004427448, classif. loss = 0.1148425639
2025-10-03 14:26:38,516 | INFO | iter is 90550 / 100000 [skipped  283] | loc. loss = 0.0918450058, classif. loss = 0.0117026176
2025-10-03 14:27:10,251 | INFO | iter is 90600 / 100000 [skipped  284] | loc. loss = 0.2188628912, classif. loss = 0.1581559330
2025-10-03 14:27:26,491 | INFO | ---------starting evaluation-----------
2025-10-03 14:27:26,948 | INFO | validation:    0/2126 (2025-10-03_14-27-26)
2025-10-03 14:27:54,906 | INFO | validation:  100/2126 (2025-10-03_14-27-54)
2025-10-03 14:28:23,505 | INFO | validation:  200/2126 (2025-10-03_14-28-23)
2025-10-03 14:28:49,755 | INFO | validation:  300/2126 (2025-10-03_14-28-49)
2025-10-03 14:29:18,681 | INFO | validation:  400/2126 (2025-10-03_14-29-18)
2025-10-03 14:29:48,623 | INFO | validation:  500/2126 (2025-10-03_14-29-48)
2025-10-03 14:30:18,890 | INFO | validation:  600/2126 (2025-10-03_14-30-18)
2025-10-03 14:30:45,125 | INFO | validation:  700/2126 (2025-10-03_14-30-45)
2025-10-03 14:31:14,044 | INFO | validation:  800/2126 (2025-10-03_14-31-14)
2025-10-03 14:31:41,262 | INFO | validation:  900/2126 (2025-10-03_14-31-41)
2025-10-03 14:32:13,554 | INFO | validation: 1000/2126 (2025-10-03_14-32-13)
2025-10-03 14:32:43,148 | INFO | validation: 1100/2126 (2025-10-03_14-32-43)
2025-10-03 14:33:12,067 | INFO | validation: 1200/2126 (2025-10-03_14-33-12)
2025-10-03 14:33:42,350 | INFO | validation: 1300/2126 (2025-10-03_14-33-42)
2025-10-03 14:34:10,266 | INFO | validation: 1400/2126 (2025-10-03_14-34-10)
2025-10-03 14:34:38,851 | INFO | validation: 1500/2126 (2025-10-03_14-34-38)
2025-10-03 14:35:07,770 | INFO | validation: 1600/2126 (2025-10-03_14-35-07)
2025-10-03 14:35:35,678 | INFO | validation: 1700/2126 (2025-10-03_14-35-35)
2025-10-03 14:36:04,958 | INFO | validation: 1800/2126 (2025-10-03_14-36-04)
2025-10-03 14:36:34,904 | INFO | validation: 1900/2126 (2025-10-03_14-36-34)
2025-10-03 14:37:02,190 | INFO | validation: 2000/2126 (2025-10-03_14-37-02)
2025-10-03 14:37:30,122 | INFO | validation: 2100/2126 (2025-10-03_14-37-30)
2025-10-03 14:37:38,504 | INFO | Confusion Matrix of Localization:
[[1293670756    5799677]
 [   6678123   45465908]]
2025-10-03 14:37:38,504 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99553689 0.00446311]
 [0.12807071 0.87192929]]
2025-10-03 14:37:38,504 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42377788   924456    85051    62939]
 [       0  1121299  1618959   334143    21802]
 [       0   244725   622054  1906327   129825]
 [       0   114833    55302   121743  1690397]]
2025-10-03 14:37:38,505 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.97531783 0.0212762  0.00195743 0.00144853]
 [0.         0.36215293 0.52288529 0.10792025 0.00704153]
 [0.         0.08430273 0.2142848  0.65669043 0.04472204]
 [0.         0.0579299  0.02789825 0.0614158  0.85275605]]
2025-10-03 14:37:38,505 | INFO | lofF1 is 87.9336, clfF1 is 72.2787, oaF1 is 76.9752, sub class F1 score is [97.0755 51.2574 71.262  86.9716]
2025-10-03 14:37:38,505 | INFO | ---------starting train set evaluation-----------
2025-10-03 14:37:39,013 | INFO | [TrainBuf] locF1 is 88.7999, clfF1 is 83.4169, oaF1 is 85.0318, sub class F1 score is [97.5281 77.92   77.3079 83.8257]
2025-10-03 14:37:55,212 | INFO | iter is 90650 / 100000 [skipped  284] | loc. loss = 0.2069617212, classif. loss = 0.2920894623
2025-10-03 14:38:27,671 | INFO | iter is 90700 / 100000 [skipped  284] | loc. loss = 0.1276800185, classif. loss = 0.0725639537
2025-10-03 14:39:00,215 | INFO | iter is 90750 / 100000 [skipped  284] | loc. loss = 0.1735917479, classif. loss = 1.1191713810
2025-10-03 14:39:32,654 | INFO | iter is 90800 / 100000 [skipped  284] | loc. loss = 0.2211001664, classif. loss = 0.2181438506
2025-10-03 14:40:05,138 | INFO | iter is 90850 / 100000 [skipped  284] | loc. loss = 0.1810386032, classif. loss = 0.0883116573
2025-10-03 14:40:37,514 | INFO | iter is 90900 / 100000 [skipped  284] | loc. loss = 0.1392275691, classif. loss = 0.0161252618
2025-10-03 14:41:10,037 | INFO | iter is 90950 / 100000 [skipped  284] | loc. loss = 0.0917738378, classif. loss = 0.4227627218
2025-10-03 14:41:42,419 | INFO | iter is 91000 / 100000 [skipped  284] | loc. loss = 0.1161522865, classif. loss = 0.4822825491
2025-10-03 14:42:14,842 | INFO | iter is 91050 / 100000 [skipped  284] | loc. loss = 0.1381337941, classif. loss = 0.5417535305
2025-10-03 14:42:47,209 | INFO | iter is 91100 / 100000 [skipped  284] | loc. loss = 0.3005633354, classif. loss = 0.2554870248
2025-10-03 14:43:19,616 | INFO | iter is 91150 / 100000 [skipped  284] | loc. loss = 0.1465830505, classif. loss = 0.7189285159
2025-10-03 14:43:51,976 | INFO | iter is 91200 / 100000 [skipped  284] | loc. loss = 0.2151141912, classif. loss = 0.3235726357
2025-10-03 14:44:24,356 | INFO | iter is 91250 / 100000 [skipped  284] | loc. loss = 0.1859530956, classif. loss = 0.1734432876
2025-10-03 14:44:56,012 | INFO | iter is 91300 / 100000 [skipped  285] | loc. loss = 0.1121047288, classif. loss = 0.3325127959
2025-10-03 14:45:28,375 | INFO | iter is 91350 / 100000 [skipped  285] | loc. loss = 0.1478521526, classif. loss = 0.7109538317
2025-10-03 14:46:00,774 | INFO | iter is 91400 / 100000 [skipped  285] | loc. loss = 0.2049066126, classif. loss = 0.0224528592
2025-10-03 14:46:33,173 | INFO | iter is 91450 / 100000 [skipped  285] | loc. loss = 0.1879862249, classif. loss = 0.3216557503
2025-10-03 14:47:05,547 | INFO | iter is 91500 / 100000 [skipped  285] | loc. loss = 0.2302233279, classif. loss = 0.3528394997
2025-10-03 14:47:37,957 | INFO | iter is 91550 / 100000 [skipped  285] | loc. loss = 0.2402648777, classif. loss = 0.1866251528
2025-10-03 14:48:09,724 | INFO | iter is 91600 / 100000 [skipped  286] | loc. loss = 0.1200913638, classif. loss = 0.1176900119
2025-10-03 14:48:42,130 | INFO | iter is 91650 / 100000 [skipped  286] | loc. loss = 0.1802394986, classif. loss = 0.5030174851
2025-10-03 14:49:14,503 | INFO | iter is 91700 / 100000 [skipped  286] | loc. loss = 0.1057368591, classif. loss = 0.0853714719
2025-10-03 14:49:46,379 | INFO | iter is 91750 / 100000 [skipped  287] | loc. loss = 0.1708710194, classif. loss = 0.8939517140
2025-10-03 14:50:17,534 | INFO | iter is 91800 / 100000 [skipped  289] | loc. loss = 0.2615201771, classif. loss = 0.7657915354
2025-10-03 14:50:49,882 | INFO | iter is 91850 / 100000 [skipped  289] | loc. loss = 0.2226772904, classif. loss = 0.1923889816
2025-10-03 14:51:22,347 | INFO | iter is 91900 / 100000 [skipped  289] | loc. loss = 0.1902537942, classif. loss = 1.3357973099
2025-10-03 14:51:54,155 | INFO | iter is 91950 / 100000 [skipped  290] | loc. loss = 0.2015520632, classif. loss = 0.8864842653
2025-10-03 14:52:26,533 | INFO | iter is 92000 / 100000 [skipped  290] | loc. loss = 0.1322734505, classif. loss = 0.0318364017
2025-10-03 14:52:58,995 | INFO | iter is 92050 / 100000 [skipped  290] | loc. loss = 0.0926929489, classif. loss = 0.0205909610
2025-10-03 14:53:31,478 | INFO | iter is 92100 / 100000 [skipped  290] | loc. loss = 0.1838477254, classif. loss = 0.0199759137
2025-10-03 14:54:03,921 | INFO | iter is 92150 / 100000 [skipped  290] | loc. loss = 0.0871718600, classif. loss = 0.5588312149
2025-10-03 14:54:36,387 | INFO | iter is 92200 / 100000 [skipped  290] | loc. loss = 0.0435806401, classif. loss = 0.2264297009
2025-10-03 14:55:08,824 | INFO | iter is 92250 / 100000 [skipped  290] | loc. loss = 0.1634959430, classif. loss = 0.1067569107
2025-10-03 14:55:41,231 | INFO | iter is 92300 / 100000 [skipped  290] | loc. loss = 0.1366472691, classif. loss = 1.5543774366
2025-10-03 14:56:13,658 | INFO | iter is 92350 / 100000 [skipped  290] | loc. loss = 0.2499680668, classif. loss = 0.0356693640
2025-10-03 14:56:46,050 | INFO | iter is 92400 / 100000 [skipped  290] | loc. loss = 0.1535490751, classif. loss = 0.0084039960
2025-10-03 14:57:18,463 | INFO | iter is 92450 / 100000 [skipped  290] | loc. loss = 0.1652937829, classif. loss = 0.8997915983
2025-10-03 14:57:50,897 | INFO | iter is 92500 / 100000 [skipped  290] | loc. loss = 0.2672536969, classif. loss = 0.0733247474
2025-10-03 14:58:22,785 | INFO | iter is 92550 / 100000 [skipped  291] | loc. loss = 0.1391029805, classif. loss = 0.3789449632
2025-10-03 14:58:55,215 | INFO | iter is 92600 / 100000 [skipped  291] | loc. loss = 0.1649132073, classif. loss = 0.0061629321
2025-10-03 14:59:27,680 | INFO | iter is 92650 / 100000 [skipped  291] | loc. loss = 0.1566001475, classif. loss = 0.6749135256
2025-10-03 15:00:00,003 | INFO | iter is 92700 / 100000 [skipped  291] | loc. loss = 0.2010792792, classif. loss = 0.9117975235
2025-10-03 15:00:32,474 | INFO | iter is 92750 / 100000 [skipped  291] | loc. loss = 0.2243191600, classif. loss = 0.5449770689
2025-10-03 15:01:04,860 | INFO | iter is 92800 / 100000 [skipped  291] | loc. loss = 0.2161447257, classif. loss = 0.6151540875
2025-10-03 15:01:37,147 | INFO | iter is 92850 / 100000 [skipped  291] | loc. loss = 0.1826114804, classif. loss = 0.4313043952
2025-10-03 15:02:09,533 | INFO | iter is 92900 / 100000 [skipped  291] | loc. loss = 0.1817632467, classif. loss = 0.0618958957
2025-10-03 15:02:41,319 | INFO | iter is 92950 / 100000 [skipped  292] | loc. loss = 0.2292921543, classif. loss = 0.4836387038
2025-10-03 15:03:12,994 | INFO | iter is 93000 / 100000 [skipped  293] | loc. loss = 0.1834749877, classif. loss = 0.6928026676
2025-10-03 15:03:45,303 | INFO | iter is 93050 / 100000 [skipped  293] | loc. loss = 0.1438918859, classif. loss = 0.0838889480
2025-10-03 15:04:17,725 | INFO | iter is 93100 / 100000 [skipped  293] | loc. loss = 0.1565293223, classif. loss = 1.1824691296
2025-10-03 15:04:50,159 | INFO | iter is 93150 / 100000 [skipped  293] | loc. loss = 0.1278271675, classif. loss = 0.5312454700
2025-10-03 15:05:21,945 | INFO | iter is 93200 / 100000 [skipped  294] | loc. loss = 0.2575013041, classif. loss = 1.4213595390
2025-10-03 15:05:54,361 | INFO | iter is 93250 / 100000 [skipped  294] | loc. loss = 0.1421875060, classif. loss = 0.3104467392
2025-10-03 15:06:26,763 | INFO | iter is 93300 / 100000 [skipped  294] | loc. loss = 0.1835891455, classif. loss = 0.9962525964
2025-10-03 15:06:58,532 | INFO | iter is 93350 / 100000 [skipped  295] | loc. loss = 0.2090126276, classif. loss = 0.9637163877
2025-10-03 15:07:30,867 | INFO | iter is 93400 / 100000 [skipped  295] | loc. loss = 0.1830199659, classif. loss = 0.0292705521
2025-10-03 15:08:03,266 | INFO | iter is 93450 / 100000 [skipped  295] | loc. loss = 0.1140034050, classif. loss = 0.4252251983
2025-10-03 15:08:35,711 | INFO | iter is 93500 / 100000 [skipped  295] | loc. loss = 0.0902506709, classif. loss = 0.0062285746
2025-10-03 15:09:08,086 | INFO | iter is 93550 / 100000 [skipped  295] | loc. loss = 0.2037668228, classif. loss = 0.2267623246
2025-10-03 15:09:40,544 | INFO | iter is 93600 / 100000 [skipped  295] | loc. loss = 0.1363337040, classif. loss = 0.1148640886
2025-10-03 15:10:13,936 | INFO | iter is 93650 / 100000 [skipped  295] | loc. loss = 0.1733572632, classif. loss = 0.1334639937
2025-10-03 15:10:46,352 | INFO | iter is 93700 / 100000 [skipped  295] | loc. loss = 0.1904526055, classif. loss = 0.8131343722
2025-10-03 15:11:18,894 | INFO | iter is 93750 / 100000 [skipped  295] | loc. loss = 0.1592594534, classif. loss = 0.3436493278
2025-10-03 15:11:18,895 | INFO | ---------starting evaluation-----------
2025-10-03 15:11:19,359 | INFO | validation:    0/2126 (2025-10-03_15-11-19)
2025-10-03 15:11:47,355 | INFO | validation:  100/2126 (2025-10-03_15-11-47)
2025-10-03 15:12:15,953 | INFO | validation:  200/2126 (2025-10-03_15-12-15)
2025-10-03 15:12:42,221 | INFO | validation:  300/2126 (2025-10-03_15-12-42)
2025-10-03 15:13:11,170 | INFO | validation:  400/2126 (2025-10-03_15-13-11)
2025-10-03 15:13:41,152 | INFO | validation:  500/2126 (2025-10-03_15-13-41)
2025-10-03 15:14:11,479 | INFO | validation:  600/2126 (2025-10-03_15-14-11)
2025-10-03 15:14:37,758 | INFO | validation:  700/2126 (2025-10-03_15-14-37)
2025-10-03 15:15:06,732 | INFO | validation:  800/2126 (2025-10-03_15-15-06)
2025-10-03 15:15:34,021 | INFO | validation:  900/2126 (2025-10-03_15-15-34)
2025-10-03 15:16:06,372 | INFO | validation: 1000/2126 (2025-10-03_15-16-06)
2025-10-03 15:16:36,006 | INFO | validation: 1100/2126 (2025-10-03_15-16-36)
2025-10-03 15:17:04,979 | INFO | validation: 1200/2126 (2025-10-03_15-17-04)
2025-10-03 15:17:35,315 | INFO | validation: 1300/2126 (2025-10-03_15-17-35)
2025-10-03 15:18:03,284 | INFO | validation: 1400/2126 (2025-10-03_15-18-03)
2025-10-03 15:18:31,895 | INFO | validation: 1500/2126 (2025-10-03_15-18-31)
2025-10-03 15:19:00,873 | INFO | validation: 1600/2126 (2025-10-03_15-19-00)
2025-10-03 15:19:28,824 | INFO | validation: 1700/2126 (2025-10-03_15-19-28)
2025-10-03 15:19:58,097 | INFO | validation: 1800/2126 (2025-10-03_15-19-58)
2025-10-03 15:20:28,057 | INFO | validation: 1900/2126 (2025-10-03_15-20-28)
2025-10-03 15:20:55,372 | INFO | validation: 2000/2126 (2025-10-03_15-20-55)
2025-10-03 15:21:23,323 | INFO | validation: 2100/2126 (2025-10-03_15-21-23)
2025-10-03 15:21:31,724 | INFO | Confusion Matrix of Localization:
[[1293893111    5577322]
 [   6735314   45408717]]
2025-10-03 15:21:31,724 | INFO | Confusion Matrix of Localization - Normalized:
[[0.995708  0.004292 ]
 [0.1291675 0.8708325]]
2025-10-03 15:21:31,724 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41713556  1473284   128945   134449]
 [       0   868145  1894750   292020    41288]
 [       0   128543   870249  1722576   181563]
 [       0    77339    46163    81631  1777142]]
2025-10-03 15:21:31,725 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96003064 0.03390739 0.00296765 0.00309432]
 [0.         0.28039021 0.61195923 0.09431552 0.01333504]
 [0.         0.04428042 0.29978287 0.59339199 0.06254472]
 [0.         0.03901527 0.02328789 0.04118046 0.89651638]]
2025-10-03 15:21:31,725 | INFO | lofF1 is 88.0611, clfF1 is 71.0721, oaF1 is 76.1688, sub class F1 score is [96.7407 51.3437 67.1818 86.3378]
2025-10-03 15:21:31,725 | INFO | ---------starting train set evaluation-----------
2025-10-03 15:21:32,229 | INFO | [TrainBuf] locF1 is 87.7823, clfF1 is 75.7000, oaF1 is 79.3247, sub class F1 score is [95.685  55.9089 74.2021 90.6924]
2025-10-03 15:22:04,645 | INFO | iter is 93800 / 100000 [skipped  295] | loc. loss = 0.1781467050, classif. loss = 0.1199373305
2025-10-03 15:22:36,558 | INFO | iter is 93850 / 100000 [skipped  296] | loc. loss = 0.2471536994, classif. loss = 0.8275692463
2025-10-03 15:23:08,985 | INFO | iter is 93900 / 100000 [skipped  296] | loc. loss = 0.1544887125, classif. loss = 0.4489865303
2025-10-03 15:23:41,445 | INFO | iter is 93950 / 100000 [skipped  296] | loc. loss = 0.0613203607, classif. loss = 0.2617819309
2025-10-03 15:24:13,225 | INFO | iter is 94000 / 100000 [skipped  297] | loc. loss = 0.0901526660, classif. loss = 0.9257966280
2025-10-03 15:24:45,669 | INFO | iter is 94050 / 100000 [skipped  297] | loc. loss = 0.1015302837, classif. loss = 0.3550980389
2025-10-03 15:25:18,028 | INFO | iter is 94100 / 100000 [skipped  297] | loc. loss = 0.1325336397, classif. loss = 0.3460669816
2025-10-03 15:25:50,445 | INFO | iter is 94150 / 100000 [skipped  297] | loc. loss = 0.1415180117, classif. loss = 0.2818090618
2025-10-03 15:26:22,894 | INFO | iter is 94200 / 100000 [skipped  297] | loc. loss = 0.0553003959, classif. loss = 0.0086963940
2025-10-03 15:26:55,394 | INFO | iter is 94250 / 100000 [skipped  297] | loc. loss = 0.1528579593, classif. loss = 0.9432107210
2025-10-03 15:27:27,870 | INFO | iter is 94300 / 100000 [skipped  297] | loc. loss = 0.2161057293, classif. loss = 0.7433797121
2025-10-03 15:28:00,315 | INFO | iter is 94350 / 100000 [skipped  297] | loc. loss = 0.2528312504, classif. loss = 0.0952483043
2025-10-03 15:28:32,791 | INFO | iter is 94400 / 100000 [skipped  297] | loc. loss = 0.1475262642, classif. loss = 0.0718547329
2025-10-03 15:29:05,202 | INFO | iter is 94450 / 100000 [skipped  297] | loc. loss = 0.1708385050, classif. loss = 1.4726932049
2025-10-03 15:29:36,928 | INFO | iter is 94500 / 100000 [skipped  298] | loc. loss = 0.1907644570, classif. loss = 0.8720787168
2025-10-03 15:30:08,751 | INFO | iter is 94550 / 100000 [skipped  299] | loc. loss = 0.0857473761, classif. loss = 0.4074949026
2025-10-03 15:30:41,094 | INFO | iter is 94600 / 100000 [skipped  299] | loc. loss = 0.1511586308, classif. loss = 0.5973755121
2025-10-03 15:31:13,564 | INFO | iter is 94650 / 100000 [skipped  299] | loc. loss = 0.1404393613, classif. loss = 0.2387688458
2025-10-03 15:31:45,947 | INFO | iter is 94700 / 100000 [skipped  299] | loc. loss = 0.0853182077, classif. loss = 0.0155344550
2025-10-03 15:32:18,406 | INFO | iter is 94750 / 100000 [skipped  299] | loc. loss = 0.1550765932, classif. loss = 0.2781895995
2025-10-03 15:32:50,777 | INFO | iter is 94800 / 100000 [skipped  299] | loc. loss = 0.1942745894, classif. loss = 1.3826750517
2025-10-03 15:33:23,228 | INFO | iter is 94850 / 100000 [skipped  299] | loc. loss = 0.0508611314, classif. loss = 1.1676034927
2025-10-03 15:33:55,648 | INFO | iter is 94900 / 100000 [skipped  299] | loc. loss = 0.1715036482, classif. loss = 0.4464174509
2025-10-03 15:34:28,070 | INFO | iter is 94950 / 100000 [skipped  299] | loc. loss = 0.1415579766, classif. loss = 0.1542113125
2025-10-03 15:35:00,491 | INFO | iter is 95000 / 100000 [skipped  299] | loc. loss = 0.1616184413, classif. loss = 0.1832286716
2025-10-03 15:35:32,941 | INFO | iter is 95050 / 100000 [skipped  299] | loc. loss = 0.1096502990, classif. loss = 0.4902184010
2025-10-03 15:36:05,382 | INFO | iter is 95100 / 100000 [skipped  299] | loc. loss = 0.1759403348, classif. loss = 0.4950031042
2025-10-03 15:36:37,826 | INFO | iter is 95150 / 100000 [skipped  299] | loc. loss = 0.2058952004, classif. loss = 0.0359976701
2025-10-03 15:37:10,261 | INFO | iter is 95200 / 100000 [skipped  299] | loc. loss = 0.1365564466, classif. loss = 0.7131789923
2025-10-03 15:37:42,634 | INFO | iter is 95250 / 100000 [skipped  299] | loc. loss = 0.1458224356, classif. loss = 0.5541305542
2025-10-03 15:38:15,064 | INFO | iter is 95300 / 100000 [skipped  299] | loc. loss = 0.1414388269, classif. loss = 0.4791375995
2025-10-03 15:38:47,476 | INFO | iter is 95350 / 100000 [skipped  299] | loc. loss = 0.0454905517, classif. loss = 0.0012466703
2025-10-03 15:39:19,924 | INFO | iter is 95400 / 100000 [skipped  299] | loc. loss = 0.1285431087, classif. loss = 0.5422055721
2025-10-03 15:39:52,398 | INFO | iter is 95450 / 100000 [skipped  299] | loc. loss = 0.2105772942, classif. loss = 0.5576773882
2025-10-03 15:40:24,924 | INFO | iter is 95500 / 100000 [skipped  299] | loc. loss = 0.1733134687, classif. loss = 0.5100520253
2025-10-03 15:40:57,395 | INFO | iter is 95550 / 100000 [skipped  299] | loc. loss = 0.1910930127, classif. loss = 0.4523099661
2025-10-03 15:41:29,869 | INFO | iter is 95600 / 100000 [skipped  299] | loc. loss = 0.1540125757, classif. loss = 0.7429394722
2025-10-03 15:42:02,316 | INFO | iter is 95650 / 100000 [skipped  299] | loc. loss = 0.1568272859, classif. loss = 0.9249926209
2025-10-03 15:42:34,756 | INFO | iter is 95700 / 100000 [skipped  299] | loc. loss = 0.0674474612, classif. loss = 0.1825380921
2025-10-03 15:43:07,240 | INFO | iter is 95750 / 100000 [skipped  299] | loc. loss = 0.1406220198, classif. loss = 0.3417049646
2025-10-03 15:43:39,654 | INFO | iter is 95800 / 100000 [skipped  299] | loc. loss = 0.1706642359, classif. loss = 0.7791496515
2025-10-03 15:44:11,451 | INFO | iter is 95850 / 100000 [skipped  300] | loc. loss = 0.1494020969, classif. loss = 0.6754453778
2025-10-03 15:44:43,981 | INFO | iter is 95900 / 100000 [skipped  300] | loc. loss = 0.1218336523, classif. loss = 0.1095788702
2025-10-03 15:45:16,322 | INFO | iter is 95950 / 100000 [skipped  300] | loc. loss = 0.2507746816, classif. loss = 0.0130390748
2025-10-03 15:45:48,781 | INFO | iter is 96000 / 100000 [skipped  300] | loc. loss = 0.0962416530, classif. loss = 0.2624391317
2025-10-03 15:46:21,268 | INFO | iter is 96050 / 100000 [skipped  300] | loc. loss = 0.1521442831, classif. loss = 0.8831640482
2025-10-03 15:46:53,750 | INFO | iter is 96100 / 100000 [skipped  300] | loc. loss = 0.1491548419, classif. loss = 0.0842079893
2025-10-03 15:47:26,216 | INFO | iter is 96150 / 100000 [skipped  300] | loc. loss = 0.0693755075, classif. loss = 0.3098702133
2025-10-03 15:47:58,763 | INFO | iter is 96200 / 100000 [skipped  300] | loc. loss = 0.2513576150, classif. loss = 0.8458597660
2025-10-03 15:48:31,310 | INFO | iter is 96250 / 100000 [skipped  300] | loc. loss = 0.1787652969, classif. loss = 0.4074120522
2025-10-03 15:49:03,735 | INFO | iter is 96300 / 100000 [skipped  300] | loc. loss = 0.1549025476, classif. loss = 0.1643225104
2025-10-03 15:49:36,194 | INFO | iter is 96350 / 100000 [skipped  300] | loc. loss = 0.1653497666, classif. loss = 0.0971061215
2025-10-03 15:50:08,734 | INFO | iter is 96400 / 100000 [skipped  300] | loc. loss = 0.1689371467, classif. loss = 0.4939610660
2025-10-03 15:50:41,178 | INFO | iter is 96450 / 100000 [skipped  300] | loc. loss = 0.2340450287, classif. loss = 0.2089687735
2025-10-03 15:51:12,941 | INFO | iter is 96500 / 100000 [skipped  301] | loc. loss = 0.1398725659, classif. loss = 0.6586270928
2025-10-03 15:51:45,302 | INFO | iter is 96550 / 100000 [skipped  301] | loc. loss = 0.1140210405, classif. loss = 0.5883099437
2025-10-03 15:52:17,631 | INFO | iter is 96600 / 100000 [skipped  301] | loc. loss = 0.1961203814, classif. loss = 1.0018043518
2025-10-03 15:52:50,007 | INFO | iter is 96650 / 100000 [skipped  301] | loc. loss = 0.2175067365, classif. loss = 0.7480372190
2025-10-03 15:53:21,793 | INFO | iter is 96700 / 100000 [skipped  302] | loc. loss = 0.1306193471, classif. loss = 0.3270515203
2025-10-03 15:53:53,480 | INFO | iter is 96750 / 100000 [skipped  303] | loc. loss = 0.1311488450, classif. loss = 0.1864736527
2025-10-03 15:54:25,271 | INFO | iter is 96800 / 100000 [skipped  304] | loc. loss = 0.1630354077, classif. loss = 1.0874140263
2025-10-03 15:54:57,676 | INFO | iter is 96850 / 100000 [skipped  304] | loc. loss = 0.1896876842, classif. loss = 0.2433391809
2025-10-03 15:55:13,865 | INFO | ---------starting evaluation-----------
2025-10-03 15:55:14,321 | INFO | validation:    0/2126 (2025-10-03_15-55-14)
2025-10-03 15:55:42,303 | INFO | validation:  100/2126 (2025-10-03_15-55-42)
2025-10-03 15:56:10,922 | INFO | validation:  200/2126 (2025-10-03_15-56-10)
2025-10-03 15:56:37,191 | INFO | validation:  300/2126 (2025-10-03_15-56-37)
2025-10-03 15:57:06,139 | INFO | validation:  400/2126 (2025-10-03_15-57-06)
2025-10-03 15:57:36,089 | INFO | validation:  500/2126 (2025-10-03_15-57-36)
2025-10-03 15:58:06,368 | INFO | validation:  600/2126 (2025-10-03_15-58-06)
2025-10-03 15:58:32,630 | INFO | validation:  700/2126 (2025-10-03_15-58-32)
2025-10-03 15:59:01,583 | INFO | validation:  800/2126 (2025-10-03_15-59-01)
2025-10-03 15:59:28,830 | INFO | validation:  900/2126 (2025-10-03_15-59-28)
2025-10-03 16:00:01,128 | INFO | validation: 1000/2126 (2025-10-03_16-00-01)
2025-10-03 16:00:30,743 | INFO | validation: 1100/2126 (2025-10-03_16-00-30)
2025-10-03 16:00:59,685 | INFO | validation: 1200/2126 (2025-10-03_16-00-59)
2025-10-03 16:01:29,987 | INFO | validation: 1300/2126 (2025-10-03_16-01-29)
2025-10-03 16:01:57,949 | INFO | validation: 1400/2126 (2025-10-03_16-01-57)
2025-10-03 16:02:26,585 | INFO | validation: 1500/2126 (2025-10-03_16-02-26)
2025-10-03 16:02:55,549 | INFO | validation: 1600/2126 (2025-10-03_16-02-55)
2025-10-03 16:03:23,499 | INFO | validation: 1700/2126 (2025-10-03_16-03-23)
2025-10-03 16:03:52,770 | INFO | validation: 1800/2126 (2025-10-03_16-03-52)
2025-10-03 16:04:22,717 | INFO | validation: 1900/2126 (2025-10-03_16-04-22)
2025-10-03 16:04:49,986 | INFO | validation: 2000/2126 (2025-10-03_16-04-49)
2025-10-03 16:05:17,947 | INFO | validation: 2100/2126 (2025-10-03_16-05-17)
2025-10-03 16:05:26,339 | INFO | Confusion Matrix of Localization:
[[1294268326    5202107]
 [   7022051   45121980]]
2025-10-03 16:05:26,339 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99599675 0.00400325]
 [0.13466644 0.86533356]]
2025-10-03 16:05:26,339 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41871470  1255072   233808    89884]
 [       0   866471  1602085   595547    32100]
 [       0   140846   348098  2290906   123081]
 [       0    94407    47867   138017  1701984]]
2025-10-03 16:05:26,339 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96366501 0.02888528 0.00538105 0.00206867]
 [0.         0.27984954 0.51743539 0.19234753 0.01036754]
 [0.         0.04851855 0.1199126  0.78916998 0.04239887]
 [0.         0.04762558 0.02414751 0.06962556 0.85860135]]
2025-10-03 16:05:26,339 | INFO | lofF1 is 88.0703, clfF1 is 72.5606, oaF1 is 77.2135, sub class F1 score is [96.8984 50.4647 74.3655 86.6299]
2025-10-03 16:05:26,602 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step96875.pth
2025-10-03 16:05:26,602 | INFO | ---------starting train set evaluation-----------
2025-10-03 16:05:27,101 | INFO | [TrainBuf] locF1 is 89.5857, clfF1 is 81.9635, oaF1 is 84.2502, sub class F1 score is [97.3017 70.4223 79.4003 85.2484]
2025-10-03 16:05:43,412 | INFO | iter is 96900 / 100000 [skipped  304] | loc. loss = 0.1766220182, classif. loss = 0.0190335400
2025-10-03 16:06:15,860 | INFO | iter is 96950 / 100000 [skipped  304] | loc. loss = 0.1038652584, classif. loss = 0.0028285799
2025-10-03 16:06:48,189 | INFO | iter is 97000 / 100000 [skipped  304] | loc. loss = 0.1394332349, classif. loss = 0.7318353653
2025-10-03 16:07:20,642 | INFO | iter is 97050 / 100000 [skipped  304] | loc. loss = 0.3138256967, classif. loss = 0.7148337364
2025-10-03 16:07:53,094 | INFO | iter is 97100 / 100000 [skipped  304] | loc. loss = 0.1061776727, classif. loss = 0.2860923409
2025-10-03 16:08:25,619 | INFO | iter is 97150 / 100000 [skipped  304] | loc. loss = 0.1396916211, classif. loss = 0.1337222159
2025-10-03 16:08:58,050 | INFO | iter is 97200 / 100000 [skipped  304] | loc. loss = 0.1227402389, classif. loss = 0.8065871000
2025-10-03 16:09:30,531 | INFO | iter is 97250 / 100000 [skipped  304] | loc. loss = 0.1912562400, classif. loss = 0.0218077973
2025-10-03 16:10:02,960 | INFO | iter is 97300 / 100000 [skipped  304] | loc. loss = 0.1026251167, classif. loss = 0.4207952321
2025-10-03 16:10:35,411 | INFO | iter is 97350 / 100000 [skipped  304] | loc. loss = 0.1511424333, classif. loss = 0.2335762084
2025-10-03 16:11:07,795 | INFO | iter is 97400 / 100000 [skipped  304] | loc. loss = 0.1283172965, classif. loss = 0.0225858893
2025-10-03 16:11:40,249 | INFO | iter is 97450 / 100000 [skipped  304] | loc. loss = 0.1962866634, classif. loss = 0.1460272968
2025-10-03 16:12:12,045 | INFO | iter is 97500 / 100000 [skipped  305] | loc. loss = 0.2014641464, classif. loss = 0.2859210372
2025-10-03 16:12:43,894 | INFO | iter is 97550 / 100000 [skipped  306] | loc. loss = 0.0955090225, classif. loss = 0.8118479252
2025-10-03 16:13:16,312 | INFO | iter is 97600 / 100000 [skipped  306] | loc. loss = 0.2130640745, classif. loss = 0.0969305933
2025-10-03 16:13:48,659 | INFO | iter is 97650 / 100000 [skipped  306] | loc. loss = 0.2334203124, classif. loss = 0.5567944646
2025-10-03 16:14:21,149 | INFO | iter is 97700 / 100000 [skipped  306] | loc. loss = 0.1077753380, classif. loss = 0.5564105511
2025-10-03 16:14:53,597 | INFO | iter is 97750 / 100000 [skipped  306] | loc. loss = 0.1323662996, classif. loss = 0.2645222545
2025-10-03 16:15:26,142 | INFO | iter is 97800 / 100000 [skipped  306] | loc. loss = 0.0724399388, classif. loss = 0.2164458632
2025-10-03 16:15:58,553 | INFO | iter is 97850 / 100000 [skipped  306] | loc. loss = 0.1892817914, classif. loss = 0.2968552709
2025-10-03 16:16:30,927 | INFO | iter is 97900 / 100000 [skipped  306] | loc. loss = 0.1366661936, classif. loss = 0.0108068883
2025-10-03 16:17:02,708 | INFO | iter is 97950 / 100000 [skipped  307] | loc. loss = 0.0677215382, classif. loss = 0.5169367790
2025-10-03 16:17:35,102 | INFO | iter is 98000 / 100000 [skipped  307] | loc. loss = 0.2028227150, classif. loss = 0.2859475911
2025-10-03 16:18:07,485 | INFO | iter is 98050 / 100000 [skipped  307] | loc. loss = 0.1946440935, classif. loss = 0.7272055745
2025-10-03 16:18:39,924 | INFO | iter is 98100 / 100000 [skipped  307] | loc. loss = 0.1139452457, classif. loss = 0.4557960629
2025-10-03 16:19:12,245 | INFO | iter is 98150 / 100000 [skipped  307] | loc. loss = 0.2076893002, classif. loss = 0.7608292699
2025-10-03 16:19:44,533 | INFO | iter is 98200 / 100000 [skipped  307] | loc. loss = 0.3129057884, classif. loss = 0.7869564295
2025-10-03 16:20:16,846 | INFO | iter is 98250 / 100000 [skipped  307] | loc. loss = 0.1368873566, classif. loss = 0.1861887872
2025-10-03 16:20:49,236 | INFO | iter is 98300 / 100000 [skipped  307] | loc. loss = 0.1548400223, classif. loss = 1.4722257853
2025-10-03 16:21:21,704 | INFO | iter is 98350 / 100000 [skipped  307] | loc. loss = 0.0925775617, classif. loss = 0.1374039948
2025-10-03 16:21:52,924 | INFO | iter is 98400 / 100000 [skipped  309] | loc. loss = 0.2478905916, classif. loss = 0.9351518750
2025-10-03 16:22:25,323 | INFO | iter is 98450 / 100000 [skipped  309] | loc. loss = 0.2011501044, classif. loss = 0.9474527836
2025-10-03 16:22:57,741 | INFO | iter is 98500 / 100000 [skipped  309] | loc. loss = 0.1467350274, classif. loss = 0.3604498506
2025-10-03 16:23:30,096 | INFO | iter is 98550 / 100000 [skipped  309] | loc. loss = 0.2746564448, classif. loss = 0.6193754673
2025-10-03 16:24:02,497 | INFO | iter is 98600 / 100000 [skipped  309] | loc. loss = 0.2113830894, classif. loss = 2.1922297478
2025-10-03 16:24:34,939 | INFO | iter is 98650 / 100000 [skipped  309] | loc. loss = 0.2034934908, classif. loss = 0.7212799788
2025-10-03 16:25:07,421 | INFO | iter is 98700 / 100000 [skipped  309] | loc. loss = 0.1907026321, classif. loss = 0.0749133080
2025-10-03 16:25:39,732 | INFO | iter is 98750 / 100000 [skipped  309] | loc. loss = 0.1782572567, classif. loss = 0.1236672997
2025-10-03 16:26:12,154 | INFO | iter is 98800 / 100000 [skipped  309] | loc. loss = 0.0816936493, classif. loss = 0.2276050150
2025-10-03 16:26:43,948 | INFO | iter is 98850 / 100000 [skipped  310] | loc. loss = 0.1007425860, classif. loss = 0.0995389745
2025-10-03 16:27:16,409 | INFO | iter is 98900 / 100000 [skipped  310] | loc. loss = 0.2431619167, classif. loss = 1.0660262108
2025-10-03 16:27:48,812 | INFO | iter is 98950 / 100000 [skipped  310] | loc. loss = 0.2779877782, classif. loss = 0.4911988676
2025-10-03 16:28:21,177 | INFO | iter is 99000 / 100000 [skipped  310] | loc. loss = 0.2272902727, classif. loss = 0.3276977241
2025-10-03 16:28:53,577 | INFO | iter is 99050 / 100000 [skipped  310] | loc. loss = 0.1115229949, classif. loss = 0.0832357928
2025-10-03 16:29:26,012 | INFO | iter is 99100 / 100000 [skipped  310] | loc. loss = 0.2266883850, classif. loss = 0.4452861249
2025-10-03 16:29:58,376 | INFO | iter is 99150 / 100000 [skipped  310] | loc. loss = 0.1454412937, classif. loss = 0.1008655280
2025-10-03 16:30:30,161 | INFO | iter is 99200 / 100000 [skipped  311] | loc. loss = 0.2071435004, classif. loss = 0.0244902633
2025-10-03 16:31:01,865 | INFO | iter is 99250 / 100000 [skipped  312] | loc. loss = 0.1497870684, classif. loss = 0.3640246987
2025-10-03 16:31:34,266 | INFO | iter is 99300 / 100000 [skipped  312] | loc. loss = 0.1628796756, classif. loss = 0.7525783777
2025-10-03 16:32:06,684 | INFO | iter is 99350 / 100000 [skipped  312] | loc. loss = 0.1105303839, classif. loss = 0.3869071305
2025-10-03 16:32:39,159 | INFO | iter is 99400 / 100000 [skipped  312] | loc. loss = 0.1775760204, classif. loss = 0.1602802277
2025-10-03 16:33:11,552 | INFO | iter is 99450 / 100000 [skipped  312] | loc. loss = 0.0875308365, classif. loss = 0.2597460449
2025-10-03 16:33:43,887 | INFO | iter is 99500 / 100000 [skipped  312] | loc. loss = 0.2331423610, classif. loss = 0.7041302919
2025-10-03 16:34:16,342 | INFO | iter is 99550 / 100000 [skipped  312] | loc. loss = 0.1833141446, classif. loss = 0.0824211985
2025-10-03 16:34:48,756 | INFO | iter is 99600 / 100000 [skipped  312] | loc. loss = 0.2207540870, classif. loss = 0.6489998102
2025-10-03 16:35:21,167 | INFO | iter is 99650 / 100000 [skipped  312] | loc. loss = 0.1228504777, classif. loss = 0.5866208076
2025-10-03 16:35:53,544 | INFO | iter is 99700 / 100000 [skipped  312] | loc. loss = 0.1554421335, classif. loss = 0.9403480291
2025-10-03 16:36:25,890 | INFO | iter is 99750 / 100000 [skipped  312] | loc. loss = 0.2259464413, classif. loss = 0.7108345032
2025-10-03 16:36:58,258 | INFO | iter is 99800 / 100000 [skipped  312] | loc. loss = 0.0879895240, classif. loss = 0.3939264417
2025-10-03 16:37:30,001 | INFO | iter is 99850 / 100000 [skipped  313] | loc. loss = 0.1666675955, classif. loss = 0.1907500327
2025-10-03 16:38:01,735 | INFO | iter is 99900 / 100000 [skipped  314] | loc. loss = 0.1825623512, classif. loss = 0.7099887133
2025-10-03 16:38:34,174 | INFO | iter is 99950 / 100000 [skipped  314] | loc. loss = 0.1401512325, classif. loss = 0.0131125664
2025-10-03 16:39:06,312 | INFO | iter is 100000 / 100000 [skipped  314] | loc. loss = 0.1233819649, classif. loss = 0.5624952316
2025-10-03 16:39:06,312 | INFO | -----------Training is completed-----------
2025-10-03 16:39:06,570 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-02_17-24-28_MambaBDA_Base_merged1_FOCAL_ALIGN_AGBD/model_step100000_last.pth
2025-10-03 16:39:06,570 | INFO | !! Total Skipped: 314 (0.31%)
2025-10-03 16:39:06,572 | INFO | ---------starting evaluation-----------
2025-10-03 16:39:07,028 | INFO | validation:    0/2126 (2025-10-03_16-39-07)
2025-10-03 16:39:35,042 | INFO | validation:  100/2126 (2025-10-03_16-39-35)
2025-10-03 16:40:03,691 | INFO | validation:  200/2126 (2025-10-03_16-40-03)
2025-10-03 16:40:29,988 | INFO | validation:  300/2126 (2025-10-03_16-40-29)
2025-10-03 16:40:58,952 | INFO | validation:  400/2126 (2025-10-03_16-40-58)
2025-10-03 16:41:28,941 | INFO | validation:  500/2126 (2025-10-03_16-41-28)
2025-10-03 16:41:59,270 | INFO | validation:  600/2126 (2025-10-03_16-41-59)
2025-10-03 16:42:25,564 | INFO | validation:  700/2126 (2025-10-03_16-42-25)
2025-10-03 16:42:54,538 | INFO | validation:  800/2126 (2025-10-03_16-42-54)
2025-10-03 16:43:21,833 | INFO | validation:  900/2126 (2025-10-03_16-43-21)
2025-10-03 16:43:54,202 | INFO | validation: 1000/2126 (2025-10-03_16-43-54)
2025-10-03 16:44:23,890 | INFO | validation: 1100/2126 (2025-10-03_16-44-23)
2025-10-03 16:44:52,897 | INFO | validation: 1200/2126 (2025-10-03_16-44-52)
2025-10-03 16:45:23,251 | INFO | validation: 1300/2126 (2025-10-03_16-45-23)
2025-10-03 16:45:51,215 | INFO | validation: 1400/2126 (2025-10-03_16-45-51)
2025-10-03 16:46:19,872 | INFO | validation: 1500/2126 (2025-10-03_16-46-19)
2025-10-03 16:46:48,869 | INFO | validation: 1600/2126 (2025-10-03_16-46-48)
2025-10-03 16:47:16,870 | INFO | validation: 1700/2126 (2025-10-03_16-47-16)
2025-10-03 16:47:46,224 | INFO | validation: 1800/2126 (2025-10-03_16-47-46)
2025-10-03 16:48:16,244 | INFO | validation: 1900/2126 (2025-10-03_16-48-16)
2025-10-03 16:48:43,576 | INFO | validation: 2000/2126 (2025-10-03_16-48-43)
2025-10-03 16:49:11,573 | INFO | validation: 2100/2126 (2025-10-03_16-49-11)
2025-10-03 16:49:19,979 | INFO | Confusion Matrix of Localization:
[[1292406501    7063932]
 [   5689155   46454876]]
2025-10-03 16:49:19,979 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99456399 0.00543601]
 [0.10910463 0.89089537]]
2025-10-03 16:49:19,979 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42047908  1078981   176452   146893]
 [       0  1022353  1484179   522255    67416]
 [       0   196482   320231  2198904   187314]
 [       0    63892    33190    90352  1794841]]
2025-10-03 16:49:19,979 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.9677257  0.02483257 0.00406101 0.00338072]
 [0.         0.33019573 0.47935455 0.16867596 0.02177377]
 [0.         0.06768401 0.11031299 0.75747718 0.06452582]
 [0.         0.03223165 0.01674339 0.04557995 0.90544501]]
2025-10-03 16:49:19,979 | INFO | lofF1 is 87.9304, clfF1 is 71.9274, oaF1 is 76.7283, sub class F1 score is [96.9059 49.3674 74.6543 85.9035]
2025-10-03 16:49:19,980 | INFO | loc_f1_score=np.float64(87.9304), harmonic_mean_f1=np.float64(71.9274), oaf1=np.float64(76.7283), damage_f1_score=array([96.9059, 49.3674, 74.6543, 85.9035])
2025-10-03 16:49:19,980 | INFO | ---------starting train set evaluation-----------
2025-10-03 16:49:20,477 | INFO | [TrainBuf] locF1 is 89.1411, clfF1 is 72.6881, oaF1 is 77.6240, sub class F1 score is [96.7159 54.512  70.0504 82.8497]
2025-10-03 16:49:20,478 | INFO | Validation Results:
2025-10-03 16:49:20,478 | INFO | [TEST ] Step  3125: (np.float64(81.9955), np.float64(58.3566), np.float64(65.4483), array([95.033 , 33.5989, 62.3124, 81.8976]))
2025-10-03 16:49:20,478 | INFO | [TRAIN] Step  3125: (np.float64(82.1143), np.float64(51.9061), np.float64(60.9685), array([93.5853, 34.2737, 48.4363, 60.4073]))

2025-10-03 16:49:20,478 | INFO | [TEST ] Step  6250: (np.float64(84.0541), np.float64(59.6718), np.float64(66.9865), array([93.1475, 36.1171, 60.2694, 83.21  ]))
2025-10-03 16:49:20,479 | INFO | [TRAIN] Step  6250: (np.float64(83.9217), np.float64(55.3525), np.float64(63.9233), array([92.9587, 37.1906, 53.0845, 63.3706]))

2025-10-03 16:49:20,479 | INFO | [TEST ] Step  9375: (np.float64(85.1657), np.float64(67.192), np.float64(72.5841), array([96.026 , 44.2524, 68.6965, 83.5939]))
2025-10-03 16:49:20,479 | INFO | [TRAIN] Step  9375: (np.float64(85.873), np.float64(61.7828), np.float64(69.0099), array([94.3081, 42.3442, 59.0878, 73.5324]))

2025-10-03 16:49:20,479 | INFO | [TEST ] Step 12500: (np.float64(85.683), np.float64(68.7828), np.float64(73.8529), array([95.8881, 45.5904, 71.1026, 85.2764]))
2025-10-03 16:49:20,479 | INFO | [TRAIN] Step 12500: (np.float64(86.0328), np.float64(62.279), np.float64(69.4052), array([93.9024, 37.0268, 66.3504, 86.9657]))

2025-10-03 16:49:20,479 | INFO | [TEST ] Step 15625: (np.float64(86.3971), np.float64(65.006), np.float64(71.4233), array([94.3177, 40.4034, 70.3114, 83.6296]))
2025-10-03 16:49:20,479 | INFO | [TRAIN] Step 15625: (np.float64(86.2867), np.float64(68.3672), np.float64(73.7431), array([94.9525, 58.3624, 53.2956, 82.7923]))

2025-10-03 16:49:20,479 | INFO | [TEST ] Step 18750: (np.float64(85.9003), np.float64(67.724), np.float64(73.1769), array([96.4249, 44.8936, 68.5001, 84.6088]))
2025-10-03 16:49:20,479 | INFO | [TRAIN] Step 18750: (np.float64(86.5694), np.float64(69.3706), np.float64(74.5302), array([94.9507, 50.2833, 66.4738, 81.9759]))

2025-10-03 16:49:20,479 | INFO | [TEST ] Step 21875: (np.float64(86.29), np.float64(66.0707), np.float64(72.1365), array([95.911 , 41.5974, 69.6937, 85.278 ]))
2025-10-03 16:49:20,479 | INFO | [TRAIN] Step 21875: (np.float64(87.5923), np.float64(75.8433), np.float64(79.368), array([96.0573, 62.5701, 76.2128, 75.6048]))

2025-10-03 16:49:20,479 | INFO | [TEST ] Step 25000: (np.float64(86.5201), np.float64(65.3715), np.float64(71.7161), array([95.3786, 42.5592, 66.6742, 81.9052]))
2025-10-03 16:49:20,479 | INFO | [TRAIN] Step 25000: (np.float64(86.7981), np.float64(75.2463), np.float64(78.7119), array([95.506 , 62.4154, 75.6629, 74.3494]))

2025-10-03 16:49:20,479 | INFO | [TEST ] Step 28125: (np.float64(87.2934), np.float64(71.1381), np.float64(75.9847), array([96.4034, 48.8163, 72.1034, 86.944 ]))
2025-10-03 16:49:20,479 | INFO | [TRAIN] Step 28125: (np.float64(88.7119), np.float64(68.3596), np.float64(74.4653), array([95.1857, 48.7057, 70.7832, 74.911 ]))

2025-10-03 16:49:20,479 | INFO | [TEST ] Step 31250: (np.float64(86.3782), np.float64(67.6252), np.float64(73.2511), array([95.3802, 43.7497, 70.9113, 85.4281]))
2025-10-03 16:49:20,479 | INFO | [TRAIN] Step 31250: (np.float64(88.1291), np.float64(69.593), np.float64(75.1539), array([95.6356, 53.2732, 60.5274, 85.2655]))

2025-10-03 16:49:20,479 | INFO | [TEST ] Step 34375: (np.float64(86.9808), np.float64(68.668), np.float64(74.1619), array([96.3497, 44.3484, 72.773 , 86.3385]))
2025-10-03 16:49:20,480 | INFO | [TRAIN] Step 34375: (np.float64(88.4606), np.float64(71.6559), np.float64(76.6973), array([95.6527, 52.4851, 70.6325, 82.2569]))

2025-10-03 16:49:20,480 | INFO | [TEST ] Step 37500: (np.float64(87.2646), np.float64(67.1525), np.float64(73.1861), array([96.2352, 43.9764, 68.4343, 84.5836]))
2025-10-03 16:49:20,480 | INFO | [TRAIN] Step 37500: (np.float64(87.3409), np.float64(72.6411), np.float64(77.0511), array([95.3975, 54.9526, 68.1573, 85.373 ]))

2025-10-03 16:49:20,480 | INFO | [TEST ] Step 40625: (np.float64(86.8177), np.float64(68.6329), np.float64(74.0884), array([96.264 , 46.7748, 68.2761, 84.2637]))
2025-10-03 16:49:20,480 | INFO | [TRAIN] Step 40625: (np.float64(87.82), np.float64(66.2511), np.float64(72.7217), array([94.546 , 56.0068, 54.2893, 73.9388]))

2025-10-03 16:49:20,480 | INFO | [TEST ] Step 43750: (np.float64(87.4434), np.float64(70.7895), np.float64(75.7856), array([96.5049, 47.9014, 72.8122, 86.7059]))
2025-10-03 16:49:20,480 | INFO | [TRAIN] Step 43750: (np.float64(89.0408), np.float64(79.6322), np.float64(82.4548), array([97.2156, 68.5366, 74.5874, 83.7053]))

2025-10-03 16:49:20,480 | INFO | [TEST ] Step 46875: (np.float64(87.4986), np.float64(68.521), np.float64(74.2143), array([95.6904, 46.3498, 68.4245, 85.2067]))
2025-10-03 16:49:20,480 | INFO | [TRAIN] Step 46875: (np.float64(88.3385), np.float64(70.4424), np.float64(75.8112), array([95.545 , 52.1827, 67.0621, 81.6811]))

2025-10-03 16:49:20,480 | INFO | [TEST ] Step 50000: (np.float64(87.0985), np.float64(67.8537), np.float64(73.6271), array([95.7821, 45.3548, 69.8007, 82.4051]))
2025-10-03 16:49:20,480 | INFO | [TRAIN] Step 50000: (np.float64(88.2386), np.float64(74.2614), np.float64(78.4546), array([96.3025, 52.5521, 75.9835, 88.5713]))

2025-10-03 16:49:20,480 | INFO | [TEST ] Step 53125: (np.float64(87.6181), np.float64(68.3754), np.float64(74.1482), array([96.6158, 44.6447, 70.7165, 86.1308]))
2025-10-03 16:49:20,480 | INFO | [TRAIN] Step 53125: (np.float64(87.9299), np.float64(69.8253), np.float64(75.2567), array([95.3638, 56.5056, 61.0612, 78.5836]))

2025-10-03 16:49:20,480 | INFO | [TEST ] Step 56250: (np.float64(87.6189), np.float64(69.8516), np.float64(75.1818), array([96.362 , 46.8102, 72.5307, 85.2036]))
2025-10-03 16:49:20,480 | INFO | [TRAIN] Step 56250: (np.float64(89.0297), np.float64(73.0427), np.float64(77.8388), array([96.7072, 63.4802, 63.8485, 76.8816]))

2025-10-03 16:49:20,480 | INFO | [TEST ] Step 59375: (np.float64(87.5395), np.float64(63.7767), np.float64(70.9055), array([96.8494, 46.3939, 52.2918, 85.3568]))
2025-10-03 16:49:20,480 | INFO | [TRAIN] Step 59375: (np.float64(88.8477), np.float64(75.2812), np.float64(79.3512), array([96.8421, 67.4958, 67.0081, 76.5186]))

2025-10-03 16:49:20,480 | INFO | [TEST ] Step 62500: (np.float64(87.2576), np.float64(69.5003), np.float64(74.8275), array([95.619 , 48.2667, 67.5903, 86.3387]))
2025-10-03 16:49:20,480 | INFO | [TRAIN] Step 62500: (np.float64(88.647), np.float64(82.0703), np.float64(84.0433), array([96.945 , 66.4836, 82.5529, 88.7406]))

2025-10-03 16:49:20,481 | INFO | [TEST ] Step 65625: (np.float64(87.7026), np.float64(70.0457), np.float64(75.3428), array([96.6971, 49.6624, 66.0182, 87.1028]))
2025-10-03 16:49:20,481 | INFO | [TRAIN] Step 65625: (np.float64(88.8227), np.float64(73.9846), np.float64(78.436), array([96.2468, 57.4155, 68.6343, 85.5544]))

2025-10-03 16:49:20,481 | INFO | [TEST ] Step 68750: (np.float64(87.9799), np.float64(71.0722), np.float64(76.1445), array([96.5499, 50.2108, 69.3493, 86.2987]))
2025-10-03 16:49:20,481 | INFO | [TRAIN] Step 68750: (np.float64(89.1188), np.float64(76.0375), np.float64(79.9619), array([97.5307, 65.6967, 64.3193, 86.3292]))

2025-10-03 16:49:20,481 | INFO | [TEST ] Step 71875: (np.float64(87.7532), np.float64(67.4675), np.float64(73.5532), array([96.0077, 45.9366, 64.4418, 86.3184]))
2025-10-03 16:49:20,481 | INFO | [TRAIN] Step 71875: (np.float64(88.5311), np.float64(80.5302), np.float64(82.9305), array([96.7433, 69.585 , 76.2575, 84.3896]))

2025-10-03 16:49:20,481 | INFO | [TEST ] Step 75000: (np.float64(87.7625), np.float64(71.1731), np.float64(76.1499), array([96.8302, 50.6283, 68.8691, 86.1951]))
2025-10-03 16:49:20,481 | INFO | [TRAIN] Step 75000: (np.float64(88.1051), np.float64(76.9878), np.float64(80.323), array([96.8997, 57.7868, 81.3614, 83.053 ]))

2025-10-03 16:49:20,481 | INFO | [TEST ] Step 78125: (np.float64(87.8149), np.float64(71.5353), np.float64(76.4192), array([96.4285, 50.9224, 69.9662, 86.0903]))
2025-10-03 16:49:20,481 | INFO | [TRAIN] Step 78125: (np.float64(88.1105), np.float64(77.1291), np.float64(80.4235), array([95.8664, 63.4495, 75.6199, 80.3513]))

2025-10-03 16:49:20,481 | INFO | [TEST ] Step 81250: (np.float64(87.9087), np.float64(71.4914), np.float64(76.4166), array([96.682 , 49.809 , 71.602 , 86.4696]))
2025-10-03 16:49:20,481 | INFO | [TRAIN] Step 81250: (np.float64(89.2293), np.float64(71.4241), np.float64(76.7656), array([95.1853, 51.738 , 70.9708, 82.7865]))

2025-10-03 16:49:20,481 | INFO | [TEST ] Step 84375: (np.float64(87.8617), np.float64(72.3075), np.float64(76.9738), array([96.4114, 51.1167, 71.5088, 87.722 ]))
2025-10-03 16:49:20,481 | INFO | [TRAIN] Step 84375: (np.float64(88.8071), np.float64(76.4786), np.float64(80.1772), array([97.0509, 64.3662, 68.2436, 84.6822]))

2025-10-03 16:49:20,481 | INFO | [TEST ] Step 87500: (np.float64(87.7206), np.float64(72.4506), np.float64(77.0316), array([96.8217, 50.3608, 73.4536, 87.635 ]))
2025-10-03 16:49:20,481 | INFO | [TRAIN] Step 87500: (np.float64(89.1057), np.float64(82.8211), np.float64(84.7065), array([97.0242, 71.1965, 80.2396, 87.0938]))

2025-10-03 16:49:20,481 | INFO | [TEST ] Step 90625: (np.float64(87.9336), np.float64(72.2787), np.float64(76.9752), array([97.0755, 51.2574, 71.262 , 86.9716]))
2025-10-03 16:49:20,481 | INFO | [TRAIN] Step 90625: (np.float64(88.7999), np.float64(83.4169), np.float64(85.0318), array([97.5281, 77.92  , 77.3079, 83.8257]))

2025-10-03 16:49:20,481 | INFO | [TEST ] Step 93750: (np.float64(88.0611), np.float64(71.0721), np.float64(76.1688), array([96.7407, 51.3437, 67.1818, 86.3378]))
2025-10-03 16:49:20,481 | INFO | [TRAIN] Step 93750: (np.float64(87.7823), np.float64(75.7), np.float64(79.3247), array([95.685 , 55.9089, 74.2021, 90.6924]))

2025-10-03 16:49:20,482 | INFO | [TEST ] Step 96875: (np.float64(88.0703), np.float64(72.5606), np.float64(77.2135), array([96.8984, 50.4647, 74.3655, 86.6299]))
2025-10-03 16:49:20,482 | INFO | [TRAIN] Step 96875: (np.float64(89.5857), np.float64(81.9635), np.float64(84.2502), array([97.3017, 70.4223, 79.4003, 85.2484]))

2025-10-03 16:49:20,482 | INFO | [TEST ] Step    -1: (np.float64(87.9304), np.float64(71.9274), np.float64(76.7283), array([96.9059, 49.3674, 74.6543, 85.9035]))
2025-10-03 16:49:20,482 | INFO | [TRAIN] Step    -1: (np.float64(89.1411), np.float64(72.6881), np.float64(77.624), array([96.7159, 54.512 , 70.0504, 82.8497]))

2025-10-03 16:49:20,482 | INFO | The accuracy of the best round is: [np.float64(88.0703), np.float64(72.5606), np.float64(77.2135), array([96.8984, 50.4647, 74.3655, 86.6299])]
2025-10-03 16:49:20,511 | INFO | MAIN - DONE.
2025-10-03 16:49:20,512 | INFO | MAIN - EXIT.
