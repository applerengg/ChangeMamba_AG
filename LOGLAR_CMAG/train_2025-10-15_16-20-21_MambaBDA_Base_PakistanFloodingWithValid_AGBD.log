2025-10-15 16:20:22,571 | INFO | MAIN - START
2025-10-15 16:20:22,571 | INFO |  > FOCAL LOSS set to False
2025-10-15 16:20:22,571 | INFO |  > ALINGNMENT set to False
2025-10-15 16:20:22,571 | INFO |  > ATTENTION GATE set to -> Building: True, Damage: True
2025-10-15 16:20:22,572 | INFO | Command Line Args:
{
    "cfg": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/configs/vssm1/vssm_base_224.yaml",
    "opts": null,
    "pretrained_weight_path": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/pretrained_weight/vssm_base_0229_ckpt_epoch_237.pth",
    "dataset": "PakistanFloodingWithValid",
    "type": "train",
    "train_dataset_path": "/mnt/storage1/alpgenc/change_detection/datasets/pakistan_flooding/pakistan-flooding",
    "train_data_list_path": "/mnt/storage1/alpgenc/change_detection/datasets/pakistan_flooding/pakistan-flooding/train_list_v2.txt",
    "test_dataset_path": "/mnt/storage1/alpgenc/change_detection/datasets/pakistan_flooding/pakistan-flooding",
    "test_data_list_path": "/mnt/storage1/alpgenc/change_detection/datasets/pakistan_flooding/pakistan-flooding/validation_list_v2.txt",
    "shuffle": true,
    "batch_size": 8,
    "crop_size": 256,
    "start_iter": 0,
    "cuda": true,
    "max_iters": 200000,
    "model_type": "MambaBDA_Base",
    "model_param_path": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD",
    "resume": null,
    "learning_rate": 0.0001,
    "momentum": 0.9,
    "weight_decay": 0.005,
    "logfile": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/LOGLAR_CMAG/train_2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD.log",
    "extension": "png",
    "focal_loss": false,
    "enable_alignment": false,
    "enable_attn_gate_building": true,
    "enable_attn_gate_damage": true,
    "deterministic": false,
    "validations": 16,
    "measure_train_scores": true
}
2025-10-15 16:20:22,572 | INFO | Starting in RANDOM mode / not deterministic.
2025-10-15 16:20:22,575 | INFO |  > TRAIN EVALUATION params: TRAIN_BUF_MAXLEN = 8000
2025-10-15 16:20:22,575 | INFO |  > ALIGNMENT params: alignment_args = AlignmentArgs(enabled=False, stages=None, mid_ch=None)
2025-10-15 16:20:22,575 | INFO |  > ATTENTION GATE params: attn_gate_args = AttentionGateArgs(enable_building_ag=True, enable_damage_ag=True)
2025-10-15 16:20:22,575 | INFO | ChangeMambaBDA class
2025-10-15 16:20:23,836 | INFO | Attention Gate params: 54, Base params: 794
2025-10-15 16:20:23,836 | INFO | ---------starting training-----------
2025-10-15 16:20:23,909 | INFO | VAL_STEP=1562, (number_of_validations = 16)
2025-10-15 16:20:56,407 | INFO | iter is 50 / 25000 [skipped    0] | loc. loss = 0.3317609727, classif. loss = 0.6997287273
2025-10-15 16:21:27,089 | INFO | iter is 100 / 25000 [skipped    1] | loc. loss = 0.4542931318, classif. loss = 0.1600352973
2025-10-15 16:21:58,574 | INFO | iter is 150 / 25000 [skipped    1] | loc. loss = 0.4465790391, classif. loss = 0.9801689386
2025-10-15 16:22:29,407 | INFO | iter is 200 / 25000 [skipped    2] | loc. loss = 0.3176037073, classif. loss = 0.5825795531
2025-10-15 16:23:00,925 | INFO | iter is 250 / 25000 [skipped    2] | loc. loss = 0.2737054229, classif. loss = 1.2167941332
2025-10-15 16:23:32,382 | INFO | iter is 300 / 25000 [skipped    2] | loc. loss = 0.3707695901, classif. loss = 0.1942936331
2025-10-15 16:24:03,846 | INFO | iter is 350 / 25000 [skipped    2] | loc. loss = 0.3080937862, classif. loss = 1.0824003220
2025-10-15 16:24:32,917 | INFO | iter is 400 / 25000 [skipped    6] | loc. loss = 0.2280075252, classif. loss = 1.2286691666
2025-10-15 16:25:03,784 | INFO | iter is 450 / 25000 [skipped    7] | loc. loss = 0.4234460592, classif. loss = 0.8410072923
2025-10-15 16:25:34,041 | INFO | iter is 500 / 25000 [skipped    9] | loc. loss = 0.2741270363, classif. loss = 1.7606810331
2025-10-15 16:26:05,590 | INFO | iter is 550 / 25000 [skipped    9] | loc. loss = 0.2553132176, classif. loss = 1.1104780436
2025-10-15 16:26:37,081 | INFO | iter is 600 / 25000 [skipped    9] | loc. loss = 0.2100975662, classif. loss = 0.1698127538
2025-10-15 16:27:07,427 | INFO | iter is 650 / 25000 [skipped   11] | loc. loss = 0.1299228966, classif. loss = 0.0998704582
2025-10-15 16:27:38,319 | INFO | iter is 700 / 25000 [skipped   12] | loc. loss = 0.2281950116, classif. loss = 0.0121901967
2025-10-15 16:28:08,002 | INFO | iter is 750 / 25000 [skipped   15] | loc. loss = 0.2487068772, classif. loss = 0.0503571481
2025-10-15 16:28:38,964 | INFO | iter is 800 / 25000 [skipped   16] | loc. loss = 0.2394482940, classif. loss = 3.4506049156
2025-10-15 16:29:10,488 | INFO | iter is 850 / 25000 [skipped   16] | loc. loss = 0.2207637727, classif. loss = 1.0601937771
2025-10-15 16:29:40,773 | INFO | iter is 900 / 25000 [skipped   18] | loc. loss = 0.1833681315, classif. loss = 0.7852960825
2025-10-15 16:30:11,735 | INFO | iter is 950 / 25000 [skipped   19] | loc. loss = 0.2574749291, classif. loss = 0.6082552671
2025-10-15 16:30:41,399 | INFO | iter is 1000 / 25000 [skipped   22] | loc. loss = 0.1541610360, classif. loss = 0.7089126110
2025-10-15 16:31:11,706 | INFO | iter is 1050 / 25000 [skipped   24] | loc. loss = 0.1331226975, classif. loss = 1.9606343508
2025-10-15 16:31:42,686 | INFO | iter is 1100 / 25000 [skipped   25] | loc. loss = 0.1192729473, classif. loss = 0.8076955080
2025-10-15 16:32:13,601 | INFO | iter is 1150 / 25000 [skipped   26] | loc. loss = 0.1946911365, classif. loss = 0.9158959985
2025-10-15 16:32:42,730 | INFO | iter is 1200 / 25000 [skipped   30] | loc. loss = 0.1665638238, classif. loss = 0.6957164407
2025-10-15 16:33:13,663 | INFO | iter is 1250 / 25000 [skipped   31] | loc. loss = 0.1549701393, classif. loss = 0.9819673300
2025-10-15 16:33:44,655 | INFO | iter is 1300 / 25000 [skipped   32] | loc. loss = 0.1662464589, classif. loss = 0.6419018507
2025-10-15 16:34:15,593 | INFO | iter is 1350 / 25000 [skipped   33] | loc. loss = 0.1868611127, classif. loss = 0.4198814332
2025-10-15 16:34:45,911 | INFO | iter is 1400 / 25000 [skipped   35] | loc. loss = 0.1472300887, classif. loss = 5.7808170319
2025-10-15 16:35:16,917 | INFO | iter is 1450 / 25000 [skipped   36] | loc. loss = 0.2441605479, classif. loss = 0.0601978786
2025-10-15 16:35:48,474 | INFO | iter is 1500 / 25000 [skipped   36] | loc. loss = 0.2248505801, classif. loss = 0.9009804726
2025-10-15 16:36:19,502 | INFO | iter is 1550 / 25000 [skipped   37] | loc. loss = 0.1198010594, classif. loss = 0.8252819777
2025-10-15 16:36:27,090 | INFO | ---------starting evaluation-----------
2025-10-15 16:36:28,304 | INFO | validation:    0/ 531 (2025-10-15_16-36-28)
2025-10-15 16:36:41,078 | INFO | validation:  100/ 531 (2025-10-15_16-36-41)
2025-10-15 16:36:53,793 | INFO | validation:  200/ 531 (2025-10-15_16-36-53)
2025-10-15 16:37:06,528 | INFO | validation:  300/ 531 (2025-10-15_16-37-06)
2025-10-15 16:37:19,256 | INFO | validation:  400/ 531 (2025-10-15_16-37-19)
2025-10-15 16:37:32,000 | INFO | validation:  500/ 531 (2025-10-15_16-37-32)
2025-10-15 16:37:36,279 | INFO | Confusion Matrix of Localization:
[[136595460    428692]
 [   296364   1877948]]
2025-10-15 16:37:36,279 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99687141 0.00312859]
 [0.13630243 0.86369757]]
2025-10-15 16:37:36,280 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1714239   17566     116   26471]
 [      0   60776  170858     201    8688]
 [      0    2636   34415   10669    5125]
 [      0   27182   17121    1708   76541]]
2025-10-15 16:37:36,280 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.74890127e-01 9.98980887e-03 6.59693629e-05
  1.50540949e-02]
 [0.00000000e+00 2.52682696e-01 7.10360340e-01 8.35678916e-04
  3.61212857e-02]
 [0.00000000e+00 4.98817296e-02 6.51244205e-01 2.01892327e-01
  9.69817390e-02]
 [0.00000000e+00 2.21799726e-01 1.39703962e-01 1.39369411e-02
  6.24559371e-01]]
2025-10-15 16:37:36,280 | INFO | lofF1 is 83.8192, clfF1 is 56.4926, oaF1 is 64.6905, sub class F1 score is [96.2184 71.1193 32.5577 63.9502]
2025-10-15 16:37:36,542 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD/model_step1562.pth
2025-10-15 16:37:36,542 | INFO | ---------starting train set evaluation-----------
2025-10-15 16:37:36,542 | INFO | Train buffer size: 1525.
2025-10-15 16:37:42,251 | INFO | [TrainBuf] locF1 is 74.7209, clfF1 is 54.2567, oaF1 is 60.3959, sub class F1 score is [94.9475 60.6501 32.6484 62.2117]
2025-10-15 16:37:42,274 | INFO | Damage Head - Attention Gate Statistics @ step 1562:
2025-10-15 16:37:42,274 | INFO |   ag3: {'mean': 0.40104472637176514, 'std': 0.17345348000526428, 'active_ratio': 0.232421875}
2025-10-15 16:37:42,274 | INFO |   ag2: {'mean': 0.7548714876174927, 'std': 0.13952912390232086, 'active_ratio': 0.96533203125}
2025-10-15 16:37:42,274 | INFO |   ag1: {'mean': 0.5018499493598938, 'std': 0.20536743104457855, 'active_ratio': 0.4267578125}
2025-10-15 16:37:42,274 | INFO | Building Head - Attention Gate Statistics @ step 1562:
2025-10-15 16:37:42,274 | INFO |   ag3: {'mean': 0.8474706411361694, 'std': 0.04698287695646286, 'active_ratio': 1.0}
2025-10-15 16:37:42,274 | INFO |   ag2: {'mean': 0.7666122317314148, 'std': 0.13856177031993866, 'active_ratio': 0.94580078125}
2025-10-15 16:37:42,274 | INFO |   ag1: {'mean': 0.8115997314453125, 'std': 0.11095071583986282, 'active_ratio': 0.99151611328125}
2025-10-15 16:38:06,205 | INFO | iter is 1600 / 25000 [skipped   37] | loc. loss = 0.1646274775, classif. loss = 0.7279124856
2025-10-15 16:38:35,317 | INFO | iter is 1650 / 25000 [skipped   41] | loc. loss = 0.1724729389, classif. loss = 0.4802807868
2025-10-15 16:39:06,194 | INFO | iter is 1700 / 25000 [skipped   42] | loc. loss = 0.1767010987, classif. loss = 1.1606029272
2025-10-15 16:39:37,068 | INFO | iter is 1750 / 25000 [skipped   43] | loc. loss = 0.2367381752, classif. loss = 0.2622171342
2025-10-15 16:40:08,577 | INFO | iter is 1800 / 25000 [skipped   43] | loc. loss = 0.0949680284, classif. loss = 1.5992643833
2025-10-15 16:40:37,051 | INFO | iter is 1850 / 25000 [skipped   48] | loc. loss = 0.2179104239, classif. loss = 0.5408213735
2025-10-15 16:41:07,370 | INFO | iter is 1900 / 25000 [skipped   50] | loc. loss = 0.2259493321, classif. loss = 1.0017706156
2025-10-15 16:41:38,881 | INFO | iter is 1950 / 25000 [skipped   50] | loc. loss = 0.2848288715, classif. loss = 1.5900359154
2025-10-15 16:42:09,797 | INFO | iter is 2000 / 25000 [skipped   51] | loc. loss = 0.2894782126, classif. loss = 0.0671540052
2025-10-15 16:42:40,760 | INFO | iter is 2050 / 25000 [skipped   52] | loc. loss = 0.1944122314, classif. loss = 0.2663741410
2025-10-15 16:43:12,309 | INFO | iter is 2100 / 25000 [skipped   52] | loc. loss = 0.2668798268, classif. loss = 0.7372755408
2025-10-15 16:43:43,294 | INFO | iter is 2150 / 25000 [skipped   53] | loc. loss = 0.2768251896, classif. loss = 0.8177981377
2025-10-15 16:44:11,772 | INFO | iter is 2200 / 25000 [skipped   58] | loc. loss = 0.3245873153, classif. loss = 0.4199041724
2025-10-15 16:44:42,145 | INFO | iter is 2250 / 25000 [skipped   60] | loc. loss = 0.1662615538, classif. loss = 0.1841217428
2025-10-15 16:45:13,704 | INFO | iter is 2300 / 25000 [skipped   60] | loc. loss = 0.1542567164, classif. loss = 0.4599315524
2025-10-15 16:45:44,656 | INFO | iter is 2350 / 25000 [skipped   61] | loc. loss = 0.2255174518, classif. loss = 0.0091615282
2025-10-15 16:46:14,378 | INFO | iter is 2400 / 25000 [skipped   64] | loc. loss = 0.2067540437, classif. loss = 1.4516737461
2025-10-15 16:46:44,748 | INFO | iter is 2450 / 25000 [skipped   66] | loc. loss = 0.1031173542, classif. loss = 1.8287160397
2025-10-15 16:47:13,241 | INFO | iter is 2500 / 25000 [skipped   71] | loc. loss = 0.1995979249, classif. loss = 0.2508339286
2025-10-15 16:47:43,570 | INFO | iter is 2550 / 25000 [skipped   73] | loc. loss = 0.0770230740, classif. loss = 1.0487519503
2025-10-15 16:48:15,200 | INFO | iter is 2600 / 25000 [skipped   73] | loc. loss = 0.1658178568, classif. loss = 1.0918588638
2025-10-15 16:48:46,794 | INFO | iter is 2650 / 25000 [skipped   73] | loc. loss = 0.2522857189, classif. loss = 0.6629400253
2025-10-15 16:49:17,835 | INFO | iter is 2700 / 25000 [skipped   74] | loc. loss = 0.1092893407, classif. loss = 0.0285143945
2025-10-15 16:49:48,817 | INFO | iter is 2750 / 25000 [skipped   75] | loc. loss = 0.2022462934, classif. loss = 1.2734433413
2025-10-15 16:50:19,789 | INFO | iter is 2800 / 25000 [skipped   76] | loc. loss = 0.1717840880, classif. loss = 1.3592791557
2025-10-15 16:50:49,549 | INFO | iter is 2850 / 25000 [skipped   79] | loc. loss = 0.1880203485, classif. loss = 0.4027647972
2025-10-15 16:51:20,622 | INFO | iter is 2900 / 25000 [skipped   80] | loc. loss = 0.1825474501, classif. loss = 2.1020286083
2025-10-15 16:51:51,013 | INFO | iter is 2950 / 25000 [skipped   82] | loc. loss = 0.2296540141, classif. loss = 0.9923859835
2025-10-15 16:52:22,084 | INFO | iter is 3000 / 25000 [skipped   83] | loc. loss = 0.2025700659, classif. loss = 0.7232106924
2025-10-15 16:52:53,092 | INFO | iter is 3050 / 25000 [skipped   84] | loc. loss = 0.1435390264, classif. loss = 0.0605285838
2025-10-15 16:53:23,488 | INFO | iter is 3100 / 25000 [skipped   86] | loc. loss = 0.3445755541, classif. loss = 0.3445017040
2025-10-15 16:53:38,740 | INFO | ---------starting evaluation-----------
2025-10-15 16:53:40,045 | INFO | validation:    0/ 531 (2025-10-15_16-53-40)
2025-10-15 16:53:52,861 | INFO | validation:  100/ 531 (2025-10-15_16-53-52)
2025-10-15 16:54:05,659 | INFO | validation:  200/ 531 (2025-10-15_16-54-05)
2025-10-15 16:54:18,451 | INFO | validation:  300/ 531 (2025-10-15_16-54-18)
2025-10-15 16:54:31,246 | INFO | validation:  400/ 531 (2025-10-15_16-54-31)
2025-10-15 16:54:44,032 | INFO | validation:  500/ 531 (2025-10-15_16-54-44)
2025-10-15 16:54:48,360 | INFO | Confusion Matrix of Localization:
[[136829074    195078]
 [   410168   1764144]]
2025-10-15 16:54:48,360 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99857632 0.00142368]
 [0.18864266 0.81135734]]
2025-10-15 16:54:48,360 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1672634   63124     628   22006]
 [      0   26946  189332    8418   15827]
 [      0     667   22959   18135   11084]
 [      0   21349    6077    1392   93734]]
2025-10-15 16:54:48,360 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.51229305e-01 3.58987075e-02 3.57144482e-04
  1.25148431e-02]
 [0.00000000e+00 1.12030866e-01 7.87167963e-01 3.49987319e-02
  6.58024389e-02]
 [0.00000000e+00 1.26218185e-02 4.34459268e-01 3.43173432e-01
  2.09745482e-01]
 [0.00000000e+00 1.74203603e-01 4.95871140e-02 1.13584438e-02
  7.64850839e-01]]
2025-10-15 16:54:48,360 | INFO | lofF1 is 85.3577, clfF1 is 65.8081, oaF1 is 71.6730, sub class F1 score is [96.1287 72.5389 44.5479 70.6885]
2025-10-15 16:54:48,625 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD/model_step3124.pth
2025-10-15 16:54:48,625 | INFO | ---------starting train set evaluation-----------
2025-10-15 16:54:48,625 | INFO | Train buffer size: 1513.
2025-10-15 16:54:54,342 | INFO | [TrainBuf] locF1 is 83.3905, clfF1 is 65.4464, oaF1 is 70.8296, sub class F1 score is [96.26   70.1046 44.7305 70.8733]
2025-10-15 16:54:54,354 | INFO | Damage Head - Attention Gate Statistics @ step 3124:
2025-10-15 16:54:54,354 | INFO |   ag3: {'mean': 0.32143133878707886, 'std': 0.18055197596549988, 'active_ratio': 0.162109375}
2025-10-15 16:54:54,354 | INFO |   ag2: {'mean': 0.8646164536476135, 'std': 0.0961088016629219, 'active_ratio': 0.99609375}
2025-10-15 16:54:54,354 | INFO |   ag1: {'mean': 0.7052735090255737, 'std': 0.14412610232830048, 'active_ratio': 0.90716552734375}
2025-10-15 16:54:54,355 | INFO | Building Head - Attention Gate Statistics @ step 3124:
2025-10-15 16:54:54,355 | INFO |   ag3: {'mean': 0.769500732421875, 'std': 0.11425337195396423, 'active_ratio': 0.9794921875}
2025-10-15 16:54:54,355 | INFO |   ag2: {'mean': 0.7788251042366028, 'std': 0.1456289142370224, 'active_ratio': 0.944091796875}
2025-10-15 16:54:54,355 | INFO |   ag1: {'mean': 0.5917534828186035, 'std': 0.2051720768213272, 'active_ratio': 0.646484375}
2025-10-15 16:55:10,137 | INFO | iter is 3150 / 25000 [skipped   87] | loc. loss = 0.1238013878, classif. loss = 0.6756939888
2025-10-15 16:55:41,035 | INFO | iter is 3200 / 25000 [skipped   88] | loc. loss = 0.2192205936, classif. loss = 0.0947482213
2025-10-15 16:56:12,607 | INFO | iter is 3250 / 25000 [skipped   88] | loc. loss = 0.1629183143, classif. loss = 0.8108155727
2025-10-15 16:56:43,516 | INFO | iter is 3300 / 25000 [skipped   89] | loc. loss = 0.2393660992, classif. loss = 0.1894333810
2025-10-15 16:57:13,865 | INFO | iter is 3350 / 25000 [skipped   91] | loc. loss = 0.1044791788, classif. loss = 0.6878464222
2025-10-15 16:57:44,778 | INFO | iter is 3400 / 25000 [skipped   92] | loc. loss = 0.1792668998, classif. loss = 1.1373583078
2025-10-15 16:58:15,696 | INFO | iter is 3450 / 25000 [skipped   93] | loc. loss = 0.1569430083, classif. loss = 0.8336502314
2025-10-15 16:58:47,284 | INFO | iter is 3500 / 25000 [skipped   93] | loc. loss = 0.1620704830, classif. loss = 0.7580990791
2025-10-15 16:59:18,217 | INFO | iter is 3550 / 25000 [skipped   94] | loc. loss = 0.1927643716, classif. loss = 0.8391768336
2025-10-15 16:59:49,214 | INFO | iter is 3600 / 25000 [skipped   95] | loc. loss = 0.0830681920, classif. loss = 0.7444950342
2025-10-15 17:00:17,678 | INFO | iter is 3650 / 25000 [skipped  100] | loc. loss = 0.1717608273, classif. loss = 1.1937742233
2025-10-15 17:00:47,995 | INFO | iter is 3700 / 25000 [skipped  102] | loc. loss = 0.1192177087, classif. loss = 0.0578569882
2025-10-15 17:01:19,541 | INFO | iter is 3750 / 25000 [skipped  102] | loc. loss = 0.1354701221, classif. loss = 0.4426490068
2025-10-15 17:01:50,541 | INFO | iter is 3800 / 25000 [skipped  103] | loc. loss = 0.1494239271, classif. loss = 0.2654267251
2025-10-15 17:02:20,261 | INFO | iter is 3850 / 25000 [skipped  106] | loc. loss = 0.1286036968, classif. loss = 0.0976890475
2025-10-15 17:02:51,252 | INFO | iter is 3900 / 25000 [skipped  107] | loc. loss = 0.1749014407, classif. loss = 1.5633273125
2025-10-15 17:03:22,807 | INFO | iter is 3950 / 25000 [skipped  107] | loc. loss = 0.1401641816, classif. loss = 0.4198509157
2025-10-15 17:03:53,200 | INFO | iter is 4000 / 25000 [skipped  109] | loc. loss = 0.1405126601, classif. loss = 1.1054500341
2025-10-15 17:04:22,911 | INFO | iter is 4050 / 25000 [skipped  112] | loc. loss = 0.1934379935, classif. loss = 0.1899812669
2025-10-15 17:04:53,861 | INFO | iter is 4100 / 25000 [skipped  113] | loc. loss = 0.1252554208, classif. loss = 0.5779778957
2025-10-15 17:05:24,199 | INFO | iter is 4150 / 25000 [skipped  115] | loc. loss = 0.1420340240, classif. loss = 0.3946014643
2025-10-15 17:05:55,237 | INFO | iter is 4200 / 25000 [skipped  116] | loc. loss = 0.1154016554, classif. loss = 0.1919073462
2025-10-15 17:06:25,597 | INFO | iter is 4250 / 25000 [skipped  118] | loc. loss = 0.2768548131, classif. loss = 0.6632086635
2025-10-15 17:06:55,955 | INFO | iter is 4300 / 25000 [skipped  120] | loc. loss = 0.1779544502, classif. loss = 0.6276516318
2025-10-15 17:07:25,126 | INFO | iter is 4350 / 25000 [skipped  124] | loc. loss = 0.1301687062, classif. loss = 0.4600977302
2025-10-15 17:07:56,098 | INFO | iter is 4400 / 25000 [skipped  125] | loc. loss = 0.2310209423, classif. loss = 0.9087255597
2025-10-15 17:08:27,781 | INFO | iter is 4450 / 25000 [skipped  125] | loc. loss = 0.2511174679, classif. loss = 0.6696841717
2025-10-15 17:08:58,165 | INFO | iter is 4500 / 25000 [skipped  127] | loc. loss = 0.1549191475, classif. loss = 1.4985750914
2025-10-15 17:09:28,606 | INFO | iter is 4550 / 25000 [skipped  129] | loc. loss = 0.1175685674, classif. loss = 0.0725796223
2025-10-15 17:09:59,617 | INFO | iter is 4600 / 25000 [skipped  130] | loc. loss = 0.0513007045, classif. loss = 0.8636775017
2025-10-15 17:10:29,389 | INFO | iter is 4650 / 25000 [skipped  133] | loc. loss = 0.1149174199, classif. loss = 1.2005300522
2025-10-15 17:10:50,982 | INFO | ---------starting evaluation-----------
2025-10-15 17:10:52,315 | INFO | validation:    0/ 531 (2025-10-15_17-10-52)
2025-10-15 17:11:05,163 | INFO | validation:  100/ 531 (2025-10-15_17-11-05)
2025-10-15 17:11:17,982 | INFO | validation:  200/ 531 (2025-10-15_17-11-17)
2025-10-15 17:11:30,816 | INFO | validation:  300/ 531 (2025-10-15_17-11-30)
2025-10-15 17:11:43,633 | INFO | validation:  400/ 531 (2025-10-15_17-11-43)
2025-10-15 17:11:56,474 | INFO | validation:  500/ 531 (2025-10-15_17-11-56)
2025-10-15 17:12:00,825 | INFO | Confusion Matrix of Localization:
[[136668284    355868]
 [   252483   1921829]]
2025-10-15 17:12:00,825 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99740288 0.00259712]
 [0.11612087 0.88387913]]
2025-10-15 17:12:00,826 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1730622   19896       0    7874]
 [      0   47869  182984     578    9092]
 [      0    1684   31299   11523    8339]
 [      0   37660    7405    1318   76169]]
2025-10-15 17:12:00,826 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.98420716 0.01131488 0.         0.00447795]
 [0.         0.19902047 0.76077548 0.0024031  0.03780096]
 [0.         0.03186678 0.59227931 0.2180528  0.15780112]
 [0.         0.30729813 0.06042333 0.01075462 0.62152392]]
2025-10-15 17:12:00,826 | INFO | lofF1 is 86.3354, clfF1 is 59.7332, oaF1 is 67.7138, sub class F1 score is [96.7848 75.9101 34.7791 68.0001]
2025-10-15 17:12:00,827 | INFO | ---------starting train set evaluation-----------
2025-10-15 17:12:00,827 | INFO | Train buffer size: 1513.
2025-10-15 17:12:06,581 | INFO | [TrainBuf] locF1 is 85.3480, clfF1 is 73.3625, oaF1 is 76.9582, sub class F1 score is [96.4151 73.4657 59.5887 72.6827]
2025-10-15 17:12:06,593 | INFO | Damage Head - Attention Gate Statistics @ step 4686:
2025-10-15 17:12:06,594 | INFO |   ag3: {'mean': 0.4838235378265381, 'std': 0.15224987268447876, 'active_ratio': 0.48828125}
2025-10-15 17:12:06,594 | INFO |   ag2: {'mean': 0.808030903339386, 'std': 0.1327536702156067, 'active_ratio': 0.967041015625}
2025-10-15 17:12:06,594 | INFO |   ag1: {'mean': 0.7447090744972229, 'std': 0.14610479772090912, 'active_ratio': 0.92877197265625}
2025-10-15 17:12:06,594 | INFO | Building Head - Attention Gate Statistics @ step 4686:
2025-10-15 17:12:06,594 | INFO |   ag3: {'mean': 0.7912377119064331, 'std': 0.11290985345840454, 'active_ratio': 0.984375}
2025-10-15 17:12:06,594 | INFO |   ag2: {'mean': 0.8070719838142395, 'std': 0.16502918303012848, 'active_ratio': 0.9296875}
2025-10-15 17:12:06,594 | INFO |   ag1: {'mean': 0.36771655082702637, 'std': 0.20074261724948883, 'active_ratio': 0.23895263671875}
2025-10-15 17:12:15,445 | INFO | iter is 4700 / 25000 [skipped  135] | loc. loss = 0.1494099498, classif. loss = 0.6318651438
2025-10-15 17:12:46,345 | INFO | iter is 4750 / 25000 [skipped  136] | loc. loss = 0.1000608951, classif. loss = 0.2529255152
2025-10-15 17:13:15,418 | INFO | iter is 4800 / 25000 [skipped  140] | loc. loss = 0.1489685476, classif. loss = 0.3782793581
2025-10-15 17:13:47,025 | INFO | iter is 4850 / 25000 [skipped  140] | loc. loss = 0.3490197361, classif. loss = 0.4965861440
2025-10-15 17:14:17,941 | INFO | iter is 4900 / 25000 [skipped  141] | loc. loss = 0.1429529041, classif. loss = 0.7950917482
2025-10-15 17:14:48,914 | INFO | iter is 4950 / 25000 [skipped  142] | loc. loss = 0.1172603220, classif. loss = 0.3816575110
2025-10-15 17:15:20,465 | INFO | iter is 5000 / 25000 [skipped  142] | loc. loss = 0.1025166884, classif. loss = 0.5135748386
2025-10-15 17:15:51,389 | INFO | iter is 5050 / 25000 [skipped  143] | loc. loss = 0.2014107853, classif. loss = 2.4343209267
2025-10-15 17:16:21,141 | INFO | iter is 5100 / 25000 [skipped  146] | loc. loss = 0.2238843739, classif. loss = 1.0283164978
2025-10-15 17:16:52,076 | INFO | iter is 5150 / 25000 [skipped  147] | loc. loss = 0.1601824909, classif. loss = 0.5608065724
2025-10-15 17:17:23,035 | INFO | iter is 5200 / 25000 [skipped  148] | loc. loss = 0.1340900809, classif. loss = 0.1225548238
2025-10-15 17:17:53,411 | INFO | iter is 5250 / 25000 [skipped  150] | loc. loss = 0.0924838260, classif. loss = 0.6221354008
2025-10-15 17:18:23,120 | INFO | iter is 5300 / 25000 [skipped  153] | loc. loss = 0.1059518158, classif. loss = 0.5713396668
2025-10-15 17:18:53,451 | INFO | iter is 5350 / 25000 [skipped  155] | loc. loss = 0.0351126306, classif. loss = 0.0007172495
2025-10-15 17:19:23,226 | INFO | iter is 5400 / 25000 [skipped  158] | loc. loss = 0.1552500278, classif. loss = 0.8096429110
2025-10-15 17:19:52,951 | INFO | iter is 5450 / 25000 [skipped  161] | loc. loss = 0.1443773806, classif. loss = 0.3686404228
2025-10-15 17:20:24,530 | INFO | iter is 5500 / 25000 [skipped  161] | loc. loss = 0.2448083013, classif. loss = 1.5447068214
2025-10-15 17:20:55,553 | INFO | iter is 5550 / 25000 [skipped  162] | loc. loss = 0.1322662234, classif. loss = 0.4941689670
2025-10-15 17:21:25,903 | INFO | iter is 5600 / 25000 [skipped  164] | loc. loss = 0.2415803075, classif. loss = 0.0288024768
2025-10-15 17:21:57,544 | INFO | iter is 5650 / 25000 [skipped  164] | loc. loss = 0.1958813667, classif. loss = 0.3977519274
2025-10-15 17:22:28,525 | INFO | iter is 5700 / 25000 [skipped  165] | loc. loss = 0.2119005173, classif. loss = 0.3306496739
2025-10-15 17:22:59,569 | INFO | iter is 5750 / 25000 [skipped  166] | loc. loss = 0.2062303126, classif. loss = 0.3150818944
2025-10-15 17:23:29,935 | INFO | iter is 5800 / 25000 [skipped  168] | loc. loss = 0.2728047073, classif. loss = 0.0589408204
2025-10-15 17:24:00,980 | INFO | iter is 5850 / 25000 [skipped  169] | loc. loss = 0.1059671193, classif. loss = 1.0430505276
2025-10-15 17:24:30,722 | INFO | iter is 5900 / 25000 [skipped  172] | loc. loss = 0.1740367562, classif. loss = 0.0241208337
2025-10-15 17:25:01,703 | INFO | iter is 5950 / 25000 [skipped  173] | loc. loss = 0.1356542408, classif. loss = 0.5318994522
2025-10-15 17:25:32,159 | INFO | iter is 6000 / 25000 [skipped  175] | loc. loss = 0.1740655303, classif. loss = 0.0519608632
2025-10-15 17:26:02,554 | INFO | iter is 6050 / 25000 [skipped  177] | loc. loss = 0.2572276294, classif. loss = 0.8928465843
2025-10-15 17:27:04,029 | INFO | iter is 6150 / 25000 [skipped  180] | loc. loss = 0.1462084800, classif. loss = 0.8577845097
2025-10-15 17:27:35,051 | INFO | iter is 6200 / 25000 [skipped  181] | loc. loss = 0.0968957171, classif. loss = 0.1102608740
2025-10-15 17:28:05,421 | INFO | ---------starting evaluation-----------
2025-10-15 17:28:06,763 | INFO | validation:    0/ 531 (2025-10-15_17-28-06)
2025-10-15 17:28:19,600 | INFO | validation:  100/ 531 (2025-10-15_17-28-19)
2025-10-15 17:28:32,408 | INFO | validation:  200/ 531 (2025-10-15_17-28-32)
2025-10-15 17:28:45,223 | INFO | validation:  300/ 531 (2025-10-15_17-28-45)
2025-10-15 17:28:58,029 | INFO | validation:  400/ 531 (2025-10-15_17-28-58)
2025-10-15 17:29:10,834 | INFO | validation:  500/ 531 (2025-10-15_17-29-10)
2025-10-15 17:29:15,193 | INFO | Confusion Matrix of Localization:
[[136753371    270781]
 [   280183   1894129]]
2025-10-15 17:29:15,194 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99802384 0.00197616]
 [0.12886053 0.87113947]]
2025-10-15 17:29:15,194 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1703662   33928      83   20719]
 [      0   34018  196125    2112    8268]
 [      0    1307   28445   12316   10777]
 [      0   20757    6874     366   94555]]
2025-10-15 17:29:15,194 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.68874972e-01 1.92949013e-02 4.72022166e-05
  1.17829244e-02]
 [0.00000000e+00 1.41433460e-01 8.15410584e-01 8.78086503e-03
  3.43750909e-02]
 [0.00000000e+00 2.47327089e-02 5.38272306e-01 2.33058946e-01
  2.03936039e-01]
 [0.00000000e+00 1.69373001e-01 5.60904759e-02 2.98648737e-03
  7.71550036e-01]]
2025-10-15 17:29:15,194 | INFO | lofF1 is 87.3027, clfF1 is 62.2092, oaF1 is 69.7373, sub class F1 score is [96.8503 77.5358 36.3722 73.6206]
2025-10-15 17:29:15,194 | INFO | ---------starting train set evaluation-----------
2025-10-15 17:29:15,194 | INFO | Train buffer size: 1516.
2025-10-15 17:29:20,950 | INFO | [TrainBuf] locF1 is 85.5861, clfF1 is 74.7325, oaF1 is 77.9886, sub class F1 score is [96.5452 74.9058 59.3712 77.0826]
2025-10-15 17:29:20,961 | INFO | Damage Head - Attention Gate Statistics @ step 6248:
2025-10-15 17:29:20,962 | INFO |   ag3: {'mean': 0.43127644062042236, 'std': 0.21782149374485016, 'active_ratio': 0.4365234375}
2025-10-15 17:29:20,962 | INFO |   ag2: {'mean': 0.8332037329673767, 'std': 0.11501515656709671, 'active_ratio': 0.984619140625}
2025-10-15 17:29:20,962 | INFO |   ag1: {'mean': 0.7311502695083618, 'std': 0.1445338875055313, 'active_ratio': 0.92034912109375}
2025-10-15 17:29:20,962 | INFO | Building Head - Attention Gate Statistics @ step 6248:
2025-10-15 17:29:20,962 | INFO |   ag3: {'mean': 0.7317541837692261, 'std': 0.17667247354984283, 'active_ratio': 0.8818359375}
2025-10-15 17:29:20,962 | INFO |   ag2: {'mean': 0.7974609732627869, 'std': 0.18760374188423157, 'active_ratio': 0.906005859375}
2025-10-15 17:29:20,962 | INFO |   ag1: {'mean': 0.24545225501060486, 'std': 0.1490338146686554, 'active_ratio': 0.074951171875}
2025-10-15 17:29:22,253 | INFO | iter is 6250 / 25000 [skipped  181] | loc. loss = 0.1821429133, classif. loss = 0.0310957860
2025-10-15 17:29:53,203 | INFO | iter is 6300 / 25000 [skipped  182] | loc. loss = 0.0715641156, classif. loss = 0.7089927197
2025-10-15 17:30:22,888 | INFO | iter is 6350 / 25000 [skipped  185] | loc. loss = 0.1029768884, classif. loss = 0.1313899904
2025-10-15 17:30:53,860 | INFO | iter is 6400 / 25000 [skipped  186] | loc. loss = 0.1898593605, classif. loss = 0.3866805136
2025-10-15 17:31:24,780 | INFO | iter is 6450 / 25000 [skipped  187] | loc. loss = 0.1689965278, classif. loss = 0.4941404760
2025-10-15 17:31:54,519 | INFO | iter is 6500 / 25000 [skipped  190] | loc. loss = 0.1091299281, classif. loss = 0.0431026854
2025-10-15 17:32:24,221 | INFO | iter is 6550 / 25000 [skipped  193] | loc. loss = 0.1311317980, classif. loss = 2.6024961472
2025-10-15 17:32:55,820 | INFO | iter is 6600 / 25000 [skipped  193] | loc. loss = 0.2715863585, classif. loss = 1.2805739641
2025-10-15 17:33:27,369 | INFO | iter is 6650 / 25000 [skipped  193] | loc. loss = 0.1715863198, classif. loss = 0.8036955595
2025-10-15 17:33:58,378 | INFO | iter is 6700 / 25000 [skipped  194] | loc. loss = 0.1076464579, classif. loss = 0.0299662948
2025-10-15 17:34:29,299 | INFO | iter is 6750 / 25000 [skipped  195] | loc. loss = 0.1196089461, classif. loss = 0.4043202400
2025-10-15 17:34:59,608 | INFO | iter is 6800 / 25000 [skipped  197] | loc. loss = 0.1183311790, classif. loss = 0.0604727343
2025-10-15 17:35:31,185 | INFO | iter is 6850 / 25000 [skipped  197] | loc. loss = 0.1196355224, classif. loss = 0.0734176487
2025-10-15 17:36:02,519 | INFO | iter is 6900 / 25000 [skipped  198] | loc. loss = 0.2207253724, classif. loss = 1.5312581062
2025-10-15 17:36:32,872 | INFO | iter is 6950 / 25000 [skipped  200] | loc. loss = 0.1490095854, classif. loss = 0.5730471015
2025-10-15 17:37:04,531 | INFO | iter is 7000 / 25000 [skipped  200] | loc. loss = 0.1036336720, classif. loss = 1.0292866230
2025-10-15 17:37:34,282 | INFO | iter is 7050 / 25000 [skipped  203] | loc. loss = 0.1117803752, classif. loss = 0.0038662401
2025-10-15 17:38:05,956 | INFO | iter is 7100 / 25000 [skipped  203] | loc. loss = 0.1426388770, classif. loss = 0.5138577223
2025-10-15 17:38:36,954 | INFO | iter is 7150 / 25000 [skipped  204] | loc. loss = 0.1505297124, classif. loss = 0.0212232098
2025-10-15 17:39:08,571 | INFO | iter is 7200 / 25000 [skipped  204] | loc. loss = 0.1035032421, classif. loss = 0.1304183751
2025-10-15 17:39:40,182 | INFO | iter is 7250 / 25000 [skipped  204] | loc. loss = 0.1896837205, classif. loss = 0.3978683352
2025-10-15 17:40:10,003 | INFO | iter is 7300 / 25000 [skipped  207] | loc. loss = 0.1511859298, classif. loss = 0.6198253036
2025-10-15 17:40:39,785 | INFO | iter is 7350 / 25000 [skipped  210] | loc. loss = 0.1106159836, classif. loss = 0.3033980131
2025-10-15 17:41:09,631 | INFO | iter is 7400 / 25000 [skipped  213] | loc. loss = 0.0998471975, classif. loss = 0.5817418098
2025-10-15 17:41:40,019 | INFO | iter is 7450 / 25000 [skipped  215] | loc. loss = 0.1063638926, classif. loss = 0.2887907326
2025-10-15 17:42:11,707 | INFO | iter is 7500 / 25000 [skipped  215] | loc. loss = 0.1827098131, classif. loss = 0.2748366594
2025-10-15 17:42:42,086 | INFO | iter is 7550 / 25000 [skipped  217] | loc. loss = 0.2056155652, classif. loss = 0.0880590975
2025-10-15 17:43:12,497 | INFO | iter is 7600 / 25000 [skipped  219] | loc. loss = 0.0944000185, classif. loss = 0.0078331707
2025-10-15 17:43:42,961 | INFO | iter is 7650 / 25000 [skipped  221] | loc. loss = 0.2434089035, classif. loss = 1.9481128454
2025-10-15 17:44:14,616 | INFO | iter is 7700 / 25000 [skipped  221] | loc. loss = 0.1869999766, classif. loss = 0.8833780885
2025-10-15 17:44:45,680 | INFO | iter is 7750 / 25000 [skipped  222] | loc. loss = 0.0705896690, classif. loss = 2.6605491638
2025-10-15 17:45:22,429 | INFO | ---------starting evaluation-----------
2025-10-15 17:45:23,793 | INFO | validation:    0/ 531 (2025-10-15_17-45-23)
2025-10-15 17:45:36,677 | INFO | validation:  100/ 531 (2025-10-15_17-45-36)
2025-10-15 17:45:49,539 | INFO | validation:  200/ 531 (2025-10-15_17-45-49)
2025-10-15 17:46:02,386 | INFO | validation:  300/ 531 (2025-10-15_17-46-02)
2025-10-15 17:46:15,253 | INFO | validation:  400/ 531 (2025-10-15_17-46-15)
2025-10-15 17:46:28,102 | INFO | validation:  500/ 531 (2025-10-15_17-46-28)
2025-10-15 17:46:32,476 | INFO | Confusion Matrix of Localization:
[[136898633    125519]
 [   471464   1702848]]
2025-10-15 17:46:32,476 | INFO | Confusion Matrix of Localization - Normalized:
[[9.99083964e-01 9.16035591e-04]
 [2.16833647e-01 7.83166353e-01]]
2025-10-15 17:46:32,476 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1590233  143703     940   23516]
 [      0   18445  208480    9870    3728]
 [      0     765   24063   23506    4511]
 [      0   16030   14716    3692   88114]]
2025-10-15 17:46:32,476 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.04367741e-01 8.17240979e-02 5.34579320e-04
  1.33735822e-02]
 [0.00000000e+00 7.66870528e-02 8.66777813e-01 4.10355766e-02
  1.54995572e-02]
 [0.00000000e+00 1.44762986e-02 4.55350554e-01 4.44810294e-01
  8.53628536e-02]
 [0.00000000e+00 1.30801619e-01 1.20079640e-01 3.01259873e-02
  7.18992754e-01]]
2025-10-15 17:46:32,477 | INFO | lofF1 is 85.0854, clfF1 is 67.9508, oaF1 is 73.0912, sub class F1 score is [93.9891 66.0285 51.7451 72.695 ]
2025-10-15 17:46:32,733 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD/model_step7810.pth
2025-10-15 17:46:32,733 | INFO | ---------starting train set evaluation-----------
2025-10-15 17:46:32,733 | INFO | Train buffer size: 1519.
2025-10-15 17:46:38,498 | INFO | [TrainBuf] locF1 is 86.3868, clfF1 is 76.9053, oaF1 is 79.7498, sub class F1 score is [96.6655 75.8875 64.6898 76.7384]
2025-10-15 17:46:38,509 | INFO | Damage Head - Attention Gate Statistics @ step 7810:
2025-10-15 17:46:38,510 | INFO |   ag3: {'mean': 0.2608158588409424, 'std': 0.27351152896881104, 'active_ratio': 0.16015625}
2025-10-15 17:46:38,510 | INFO |   ag2: {'mean': 0.6527788639068604, 'std': 0.1340181529521942, 'active_ratio': 0.87158203125}
2025-10-15 17:46:38,510 | INFO |   ag1: {'mean': 0.7798224687576294, 'std': 0.14185847342014313, 'active_ratio': 0.959228515625}
2025-10-15 17:46:38,510 | INFO | Building Head - Attention Gate Statistics @ step 7810:
2025-10-15 17:46:38,510 | INFO |   ag3: {'mean': 0.7019970417022705, 'std': 0.21465961635112762, 'active_ratio': 0.794921875}
2025-10-15 17:46:38,510 | INFO |   ag2: {'mean': 0.8612062931060791, 'std': 0.1479017734527588, 'active_ratio': 0.963134765625}
2025-10-15 17:46:38,510 | INFO |   ag1: {'mean': 0.1923694610595703, 'std': 0.12599089741706848, 'active_ratio': 0.03521728515625}
2025-10-15 17:47:03,138 | INFO | iter is 7850 / 25000 [skipped  225] | loc. loss = 0.5059651732, classif. loss = 1.8990553617
2025-10-15 17:47:34,107 | INFO | iter is 7900 / 25000 [skipped  226] | loc. loss = 0.2030233294, classif. loss = 0.6226311922
2025-10-15 17:48:04,421 | INFO | iter is 7950 / 25000 [skipped  228] | loc. loss = 0.1068790704, classif. loss = 1.3514175415
2025-10-15 17:48:36,028 | INFO | iter is 8000 / 25000 [skipped  228] | loc. loss = 0.1183963642, classif. loss = 0.4800939560
2025-10-15 17:49:05,727 | INFO | iter is 8050 / 25000 [skipped  231] | loc. loss = 0.2669937015, classif. loss = 0.0514904186
2025-10-15 17:49:36,041 | INFO | iter is 8100 / 25000 [skipped  233] | loc. loss = 0.1006039381, classif. loss = 0.8159083128
2025-10-15 17:50:05,800 | INFO | iter is 8150 / 25000 [skipped  236] | loc. loss = 0.1140732318, classif. loss = 0.9307605028
2025-10-15 17:50:36,751 | INFO | iter is 8200 / 25000 [skipped  237] | loc. loss = 0.1771437079, classif. loss = 0.7391086817
2025-10-15 17:51:07,740 | INFO | iter is 8250 / 25000 [skipped  238] | loc. loss = 0.1217284575, classif. loss = 0.0111052431
2025-10-15 17:51:38,083 | INFO | iter is 8300 / 25000 [skipped  240] | loc. loss = 0.1390350312, classif. loss = 0.4129821956
2025-10-15 17:52:07,810 | INFO | iter is 8350 / 25000 [skipped  243] | loc. loss = 0.1102619469, classif. loss = 1.2283785343
2025-10-15 17:52:39,449 | INFO | iter is 8400 / 25000 [skipped  243] | loc. loss = 0.1669312268, classif. loss = 0.0702908486
2025-10-15 17:53:10,422 | INFO | iter is 8450 / 25000 [skipped  244] | loc. loss = 0.1200041771, classif. loss = 0.4911864400
2025-10-15 17:53:42,023 | INFO | iter is 8500 / 25000 [skipped  244] | loc. loss = 0.1780580729, classif. loss = 0.0845566094
2025-10-15 17:54:12,999 | INFO | iter is 8550 / 25000 [skipped  245] | loc. loss = 0.3080760837, classif. loss = 3.3600461483
2025-10-15 17:54:44,646 | INFO | iter is 8600 / 25000 [skipped  245] | loc. loss = 0.1860436499, classif. loss = 0.5206820965
2025-10-15 17:55:16,248 | INFO | iter is 8650 / 25000 [skipped  245] | loc. loss = 0.1366657764, classif. loss = 0.0130231110
2025-10-15 17:55:46,686 | INFO | iter is 8700 / 25000 [skipped  247] | loc. loss = 0.2683049142, classif. loss = 0.1996804178
2025-10-15 17:56:16,458 | INFO | iter is 8750 / 25000 [skipped  250] | loc. loss = 0.1414668411, classif. loss = 0.2441515326
2025-10-15 17:56:48,088 | INFO | iter is 8800 / 25000 [skipped  250] | loc. loss = 0.0762050822, classif. loss = 0.9243901968
2025-10-15 17:57:19,771 | INFO | iter is 8850 / 25000 [skipped  250] | loc. loss = 0.1265304685, classif. loss = 0.6296142936
2025-10-15 17:57:50,168 | INFO | iter is 8900 / 25000 [skipped  252] | loc. loss = 0.1004340425, classif. loss = 0.0696165040
2025-10-15 17:58:20,631 | INFO | iter is 8950 / 25000 [skipped  254] | loc. loss = 0.2711059451, classif. loss = 0.2173717618
2025-10-15 17:58:51,636 | INFO | iter is 9000 / 25000 [skipped  255] | loc. loss = 0.1096541882, classif. loss = 0.5216219425
2025-10-15 17:59:22,723 | INFO | iter is 9050 / 25000 [skipped  256] | loc. loss = 0.0849785060, classif. loss = 0.1035663858
2025-10-15 17:59:53,124 | INFO | iter is 9100 / 25000 [skipped  258] | loc. loss = 0.1461511850, classif. loss = 0.1562122107
2025-10-15 18:00:22,315 | INFO | iter is 9150 / 25000 [skipped  262] | loc. loss = 0.1852217466, classif. loss = 0.0296753757
2025-10-15 18:00:54,014 | INFO | iter is 9200 / 25000 [skipped  262] | loc. loss = 0.2102497220, classif. loss = 0.7146970034
2025-10-15 18:01:25,051 | INFO | iter is 9250 / 25000 [skipped  263] | loc. loss = 0.1452041268, classif. loss = 0.5338484049
2025-10-15 18:01:56,767 | INFO | iter is 9300 / 25000 [skipped  263] | loc. loss = 0.0954576433, classif. loss = 0.3831195235
2025-10-15 18:02:28,424 | INFO | iter is 9350 / 25000 [skipped  263] | loc. loss = 0.1332585514, classif. loss = 0.2530625463
2025-10-15 18:02:42,357 | INFO | ---------starting evaluation-----------
2025-10-15 18:02:43,739 | INFO | validation:    0/ 531 (2025-10-15_18-02-43)
2025-10-15 18:02:56,587 | INFO | validation:  100/ 531 (2025-10-15_18-02-56)
2025-10-15 18:03:09,418 | INFO | validation:  200/ 531 (2025-10-15_18-03-09)
2025-10-15 18:03:22,245 | INFO | validation:  300/ 531 (2025-10-15_18-03-22)
2025-10-15 18:03:35,069 | INFO | validation:  400/ 531 (2025-10-15_18-03-35)
2025-10-15 18:03:47,892 | INFO | validation:  500/ 531 (2025-10-15_18-03-47)
2025-10-15 18:03:52,268 | INFO | Confusion Matrix of Localization:
[[136783446    240706]
 [   291344   1882968]]
2025-10-15 18:03:52,269 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99824333 0.00175667]
 [0.13399365 0.86600635]]
2025-10-15 18:03:52,269 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1676517   39759    1732   40384]
 [      0   26869  190678    9816   13160]
 [      0     662   16231   25355   10597]
 [      0   14071    3570    2813  102098]]
2025-10-15 18:03:52,269 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95343757 0.022611   0.00098499 0.02296644]
 [0.         0.11171073 0.7927641  0.04081107 0.0547141 ]
 [0.         0.0125272  0.30714353 0.47979941 0.20052985]
 [0.         0.11481657 0.02913049 0.02295352 0.83309942]]
2025-10-15 18:03:52,269 | INFO | lofF1 is 87.6209, clfF1 is 71.8998, oaF1 is 76.6162, sub class F1 score is [96.4482 77.7071 54.7855 70.7072]
2025-10-15 18:03:52,531 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD/model_step9372.pth
2025-10-15 18:03:52,531 | INFO | ---------starting train set evaluation-----------
2025-10-15 18:03:52,531 | INFO | Train buffer size: 1523.
2025-10-15 18:03:58,280 | INFO | [TrainBuf] locF1 is 86.8151, clfF1 is 80.4926, oaF1 is 82.3894, sub class F1 score is [97.07   78.5748 72.267  77.9554]
2025-10-15 18:03:58,292 | INFO | Damage Head - Attention Gate Statistics @ step 9372:
2025-10-15 18:03:58,293 | INFO |   ag3: {'mean': 0.10020537674427032, 'std': 0.10565681010484695, 'active_ratio': 0.01171875}
2025-10-15 18:03:58,293 | INFO |   ag2: {'mean': 0.707155704498291, 'std': 0.1891167163848877, 'active_ratio': 0.834716796875}
2025-10-15 18:03:58,293 | INFO |   ag1: {'mean': 0.39233964681625366, 'std': 0.21584399044513702, 'active_ratio': 0.3089599609375}
2025-10-15 18:03:58,293 | INFO | Building Head - Attention Gate Statistics @ step 9372:
2025-10-15 18:03:58,293 | INFO |   ag3: {'mean': 0.7992711067199707, 'std': 0.18816803395748138, 'active_ratio': 0.892578125}
2025-10-15 18:03:58,293 | INFO |   ag2: {'mean': 0.7930296063423157, 'std': 0.20734389126300812, 'active_ratio': 0.88037109375}
2025-10-15 18:03:58,293 | INFO |   ag1: {'mean': 0.1399417221546173, 'std': 0.129073366522789, 'active_ratio': 0.03021240234375}
2025-10-15 18:04:15,377 | INFO | iter is 9400 / 25000 [skipped  264] | loc. loss = 0.1456758380, classif. loss = 1.3356349468
2025-10-15 18:04:44,522 | INFO | iter is 9450 / 25000 [skipped  268] | loc. loss = 0.1331407130, classif. loss = 0.5321503282
2025-10-15 18:05:14,846 | INFO | iter is 9500 / 25000 [skipped  270] | loc. loss = 0.1427990198, classif. loss = 0.8024502993
2025-10-15 18:05:45,845 | INFO | iter is 9550 / 25000 [skipped  271] | loc. loss = 0.1496025324, classif. loss = 1.2092983723
2025-10-15 18:06:17,413 | INFO | iter is 9600 / 25000 [skipped  271] | loc. loss = 0.1500152797, classif. loss = 3.0215020180
2025-10-15 18:06:48,430 | INFO | iter is 9650 / 25000 [skipped  272] | loc. loss = 0.1923540086, classif. loss = 0.2660833001
2025-10-15 18:07:19,387 | INFO | iter is 9700 / 25000 [skipped  273] | loc. loss = 0.1996960491, classif. loss = 1.1410362720
2025-10-15 18:07:50,411 | INFO | iter is 9750 / 25000 [skipped  274] | loc. loss = 0.1729085147, classif. loss = 0.6604279280
2025-10-15 18:08:21,380 | INFO | iter is 9800 / 25000 [skipped  275] | loc. loss = 0.1797074676, classif. loss = 0.5266773105
2025-10-15 18:08:51,726 | INFO | iter is 9850 / 25000 [skipped  277] | loc. loss = 0.1398626268, classif. loss = 0.0067779245
2025-10-15 18:09:22,767 | INFO | iter is 9900 / 25000 [skipped  278] | loc. loss = 0.1642548144, classif. loss = 0.5564857125
2025-10-15 18:09:53,745 | INFO | iter is 9950 / 25000 [skipped  279] | loc. loss = 0.1306967884, classif. loss = 0.0711252987
2025-10-15 18:10:24,172 | INFO | iter is 10000 / 25000 [skipped  281] | loc. loss = 0.2110243440, classif. loss = 0.6641482115
2025-10-15 18:10:54,543 | INFO | iter is 10050 / 25000 [skipped  283] | loc. loss = 0.1236962900, classif. loss = 0.3701166511
2025-10-15 18:11:24,296 | INFO | iter is 10100 / 25000 [skipped  286] | loc. loss = 0.1294683814, classif. loss = 0.0607912615
2025-10-15 18:11:55,990 | INFO | iter is 10150 / 25000 [skipped  286] | loc. loss = 0.1194956228, classif. loss = 0.6893385053
2025-10-15 18:12:27,614 | INFO | iter is 10200 / 25000 [skipped  286] | loc. loss = 0.1277543008, classif. loss = 0.2335128635
2025-10-15 18:12:57,998 | INFO | iter is 10250 / 25000 [skipped  288] | loc. loss = 0.1614957750, classif. loss = 0.7025636435
2025-10-15 18:13:59,451 | INFO | iter is 10350 / 25000 [skipped  291] | loc. loss = 0.1712467819, classif. loss = 0.4944732487
2025-10-15 18:14:30,469 | INFO | iter is 10400 / 25000 [skipped  292] | loc. loss = 0.1704919636, classif. loss = 0.2829247117
2025-10-15 18:15:00,941 | INFO | iter is 10450 / 25000 [skipped  294] | loc. loss = 0.1575836390, classif. loss = 0.7093054056
2025-10-15 18:15:30,783 | INFO | iter is 10500 / 25000 [skipped  297] | loc. loss = 0.1666436791, classif. loss = 0.0486495011
2025-10-15 18:16:01,195 | INFO | iter is 10550 / 25000 [skipped  299] | loc. loss = 0.2136670649, classif. loss = 0.4974147081
2025-10-15 18:16:31,623 | INFO | iter is 10600 / 25000 [skipped  301] | loc. loss = 0.0962230116, classif. loss = 0.5685874224
2025-10-15 18:17:01,485 | INFO | iter is 10650 / 25000 [skipped  304] | loc. loss = 0.0877917781, classif. loss = 0.4729369283
2025-10-15 18:17:31,908 | INFO | iter is 10700 / 25000 [skipped  306] | loc. loss = 0.1040981784, classif. loss = 0.1599412113
2025-10-15 18:18:03,548 | INFO | iter is 10750 / 25000 [skipped  306] | loc. loss = 0.1562449932, classif. loss = 0.7699073553
2025-10-15 18:18:34,029 | INFO | iter is 10800 / 25000 [skipped  308] | loc. loss = 0.1587858796, classif. loss = 0.5818567276
2025-10-15 18:19:05,690 | INFO | iter is 10850 / 25000 [skipped  308] | loc. loss = 0.1354405135, classif. loss = 1.5169560909
2025-10-15 18:19:36,174 | INFO | iter is 10900 / 25000 [skipped  310] | loc. loss = 0.2294321358, classif. loss = 0.0064881914
2025-10-15 18:19:57,069 | INFO | ---------starting evaluation-----------
2025-10-15 18:19:58,453 | INFO | validation:    0/ 531 (2025-10-15_18-19-58)
2025-10-15 18:20:11,248 | INFO | validation:  100/ 531 (2025-10-15_18-20-11)
2025-10-15 18:20:24,025 | INFO | validation:  200/ 531 (2025-10-15_18-20-24)
2025-10-15 18:20:36,804 | INFO | validation:  300/ 531 (2025-10-15_18-20-36)
2025-10-15 18:20:49,581 | INFO | validation:  400/ 531 (2025-10-15_18-20-49)
2025-10-15 18:21:02,388 | INFO | validation:  500/ 531 (2025-10-15_18-21-02)
2025-10-15 18:21:06,759 | INFO | Confusion Matrix of Localization:
[[136715932    308220]
 [   252544   1921768]]
2025-10-15 18:21:06,759 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99775062 0.00224938]
 [0.11614892 0.88385108]]
2025-10-15 18:21:06,759 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1699191   36503    2006   20692]
 [      0   33105  127398   65733   14287]
 [      0     701    5043   38800    8301]
 [      0   24791    1463    5193   91105]]
2025-10-15 18:21:06,759 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96633231 0.02075931 0.00114082 0.01176757]
 [0.         0.13763756 0.52967076 0.27329195 0.05939972]
 [0.         0.01326521 0.09543003 0.73422273 0.15708203]
 [0.         0.20228964 0.01193779 0.04237385 0.74339872]]
2025-10-15 18:21:06,759 | INFO | lofF1 is 87.2678, clfF1 is 64.7417, oaF1 is 71.4995, sub class F1 score is [96.6498 62.0047 47.1512 70.9162]
2025-10-15 18:21:06,760 | INFO | ---------starting train set evaluation-----------
2025-10-15 18:21:06,760 | INFO | Train buffer size: 1514.
2025-10-15 18:21:12,411 | INFO | [TrainBuf] locF1 is 86.8898, clfF1 is 80.0743, oaF1 is 82.1189, sub class F1 score is [97.0846 78.4862 70.8299 78.1621]
2025-10-15 18:21:12,423 | INFO | Damage Head - Attention Gate Statistics @ step 10934:
2025-10-15 18:21:12,424 | INFO |   ag3: {'mean': 0.3375796377658844, 'std': 0.2671467661857605, 'active_ratio': 0.271484375}
2025-10-15 18:21:12,424 | INFO |   ag2: {'mean': 0.6538341045379639, 'std': 0.19824105501174927, 'active_ratio': 0.7451171875}
2025-10-15 18:21:12,424 | INFO |   ag1: {'mean': 0.45470863580703735, 'std': 0.1302352249622345, 'active_ratio': 0.37860107421875}
2025-10-15 18:21:12,424 | INFO | Building Head - Attention Gate Statistics @ step 10934:
2025-10-15 18:21:12,424 | INFO |   ag3: {'mean': 0.790763795375824, 'std': 0.17755305767059326, 'active_ratio': 0.912109375}
2025-10-15 18:21:12,424 | INFO |   ag2: {'mean': 0.8225435614585876, 'std': 0.1819532960653305, 'active_ratio': 0.920654296875}
2025-10-15 18:21:12,424 | INFO |   ag1: {'mean': 0.15883859992027283, 'std': 0.14620158076286316, 'active_ratio': 0.04522705078125}
2025-10-15 18:21:22,545 | INFO | iter is 10950 / 25000 [skipped  311] | loc. loss = 0.1659086198, classif. loss = 0.0049993531
2025-10-15 18:21:53,502 | INFO | iter is 11000 / 25000 [skipped  312] | loc. loss = 0.1946772933, classif. loss = 0.2205428183
2025-10-15 18:22:25,039 | INFO | iter is 11050 / 25000 [skipped  312] | loc. loss = 0.1537077725, classif. loss = 0.5955839157
2025-10-15 18:22:56,578 | INFO | iter is 11100 / 25000 [skipped  312] | loc. loss = 0.0582808331, classif. loss = 0.6674734354
2025-10-15 18:23:26,965 | INFO | iter is 11150 / 25000 [skipped  314] | loc. loss = 0.0886071175, classif. loss = 0.0197574571
2025-10-15 18:23:57,892 | INFO | iter is 11200 / 25000 [skipped  315] | loc. loss = 0.1458080113, classif. loss = 0.0062147025
2025-10-15 18:24:27,658 | INFO | iter is 11250 / 25000 [skipped  318] | loc. loss = 0.1120242402, classif. loss = 0.1021752506
2025-10-15 18:24:59,200 | INFO | iter is 11300 / 25000 [skipped  318] | loc. loss = 0.1301303059, classif. loss = 2.7771563530
2025-10-15 18:25:29,527 | INFO | iter is 11350 / 25000 [skipped  320] | loc. loss = 0.0511264503, classif. loss = 0.0208887439
2025-10-15 18:26:00,545 | INFO | iter is 11400 / 25000 [skipped  321] | loc. loss = 0.1510837823, classif. loss = 0.3255636096
2025-10-15 18:26:31,513 | INFO | iter is 11450 / 25000 [skipped  322] | loc. loss = 0.1711148471, classif. loss = 0.4380543828
2025-10-15 18:27:02,463 | INFO | iter is 11500 / 25000 [skipped  323] | loc. loss = 0.1227305532, classif. loss = 0.4306868315
2025-10-15 18:27:33,422 | INFO | iter is 11550 / 25000 [skipped  324] | loc. loss = 0.0569781102, classif. loss = 0.1860448718
2025-10-15 18:28:03,819 | INFO | iter is 11600 / 25000 [skipped  326] | loc. loss = 0.1591425538, classif. loss = 1.0257081985
2025-10-15 18:28:35,406 | INFO | iter is 11650 / 25000 [skipped  326] | loc. loss = 0.1722359657, classif. loss = 0.0057578767
2025-10-15 18:29:36,815 | INFO | iter is 11750 / 25000 [skipped  329] | loc. loss = 0.1851470023, classif. loss = 0.5321326256
2025-10-15 18:30:07,249 | INFO | iter is 11800 / 25000 [skipped  331] | loc. loss = 0.2044707835, classif. loss = 0.3529695272
2025-10-15 18:30:38,857 | INFO | iter is 11850 / 25000 [skipped  331] | loc. loss = 0.1363602132, classif. loss = 0.2324159145
2025-10-15 18:31:09,293 | INFO | iter is 11900 / 25000 [skipped  333] | loc. loss = 0.1401186436, classif. loss = 0.5030918121
2025-10-15 18:31:40,922 | INFO | iter is 11950 / 25000 [skipped  333] | loc. loss = 0.2121276706, classif. loss = 1.2724184990
2025-10-15 18:32:11,978 | INFO | iter is 12000 / 25000 [skipped  334] | loc. loss = 0.1580689400, classif. loss = 0.0020341836
2025-10-15 18:32:42,353 | INFO | iter is 12050 / 25000 [skipped  336] | loc. loss = 0.1615443081, classif. loss = 0.5375156999
2025-10-15 18:33:12,758 | INFO | iter is 12100 / 25000 [skipped  338] | loc. loss = 0.1645931304, classif. loss = 1.8626766205
2025-10-15 18:33:44,438 | INFO | iter is 12150 / 25000 [skipped  338] | loc. loss = 0.0578544475, classif. loss = 0.0303565264
2025-10-15 18:34:16,061 | INFO | iter is 12200 / 25000 [skipped  338] | loc. loss = 0.2030286789, classif. loss = 0.3474934995
2025-10-15 18:34:44,661 | INFO | iter is 12250 / 25000 [skipped  343] | loc. loss = 0.1630894542, classif. loss = 0.4711557031
2025-10-15 18:35:16,288 | INFO | iter is 12300 / 25000 [skipped  343] | loc. loss = 0.0919308364, classif. loss = 3.1398353577
2025-10-15 18:35:46,741 | INFO | iter is 12350 / 25000 [skipped  345] | loc. loss = 0.2457747906, classif. loss = 0.8894078135
2025-10-15 18:36:17,152 | INFO | iter is 12400 / 25000 [skipped  347] | loc. loss = 0.1746269763, classif. loss = 1.1533846855
2025-10-15 18:36:48,239 | INFO | iter is 12450 / 25000 [skipped  348] | loc. loss = 0.1832021326, classif. loss = 1.0789713860
2025-10-15 18:37:17,352 | INFO | ---------starting evaluation-----------
2025-10-15 18:37:18,745 | INFO | validation:    0/ 531 (2025-10-15_18-37-18)
2025-10-15 18:37:31,559 | INFO | validation:  100/ 531 (2025-10-15_18-37-31)
2025-10-15 18:37:44,357 | INFO | validation:  200/ 531 (2025-10-15_18-37-44)
2025-10-15 18:37:57,169 | INFO | validation:  300/ 531 (2025-10-15_18-37-57)
2025-10-15 18:38:09,991 | INFO | validation:  400/ 531 (2025-10-15_18-38-09)
2025-10-15 18:38:22,799 | INFO | validation:  500/ 531 (2025-10-15_18-38-22)
2025-10-15 18:38:27,177 | INFO | Confusion Matrix of Localization:
[[136768817    255335]
 [   271486   1902826]]
2025-10-15 18:38:27,178 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99813657 0.00186343]
 [0.12486065 0.87513935]]
2025-10-15 18:38:27,178 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1704697   26994    2016   24685]
 [      0   34184  180237   17412    8690]
 [      0     662    9060   33873    9250]
 [      0   18519    4551    3436   96046]]
2025-10-15 18:38:27,178 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96946358 0.01535153 0.0011465  0.01403839]
 [0.         0.14212362 0.74935453 0.07239225 0.0361296 ]
 [0.         0.0125272  0.17144479 0.64098779 0.17504021]
 [0.         0.15111136 0.03713526 0.02803708 0.7837163 ]]
2025-10-15 18:38:27,178 | INFO | lofF1 is 87.8402, clfF1 is 75.6328, oaF1 is 79.2950, sub class F1 score is [96.9555 78.1321 61.8222 73.5356]
2025-10-15 18:38:27,442 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD/model_step12496.pth
2025-10-15 18:38:27,443 | INFO | ---------starting train set evaluation-----------
2025-10-15 18:38:27,443 | INFO | Train buffer size: 1525.
2025-10-15 18:38:33,177 | INFO | [TrainBuf] locF1 is 86.9791, clfF1 is 81.3034, oaF1 is 83.0061, sub class F1 score is [97.2535 80.3137 72.9797 78.355 ]
2025-10-15 18:38:33,189 | INFO | Damage Head - Attention Gate Statistics @ step 12496:
2025-10-15 18:38:33,189 | INFO |   ag3: {'mean': 0.2078426480293274, 'std': 0.23992469906806946, 'active_ratio': 0.099609375}
2025-10-15 18:38:33,189 | INFO |   ag2: {'mean': 0.6419889330863953, 'std': 0.22116030752658844, 'active_ratio': 0.720703125}
2025-10-15 18:38:33,189 | INFO |   ag1: {'mean': 0.710898756980896, 'std': 0.1831921637058258, 'active_ratio': 0.86175537109375}
2025-10-15 18:38:33,189 | INFO | Building Head - Attention Gate Statistics @ step 12496:
2025-10-15 18:38:33,190 | INFO |   ag3: {'mean': 0.8038740158081055, 'std': 0.19844511151313782, 'active_ratio': 0.9013671875}
2025-10-15 18:38:33,190 | INFO |   ag2: {'mean': 0.8764127492904663, 'std': 0.13923168182373047, 'active_ratio': 0.97216796875}
2025-10-15 18:38:33,190 | INFO |   ag1: {'mean': 0.13222220540046692, 'std': 0.11572479456663132, 'active_ratio': 0.01971435546875}
2025-10-15 18:38:35,738 | INFO | iter is 12500 / 25000 [skipped  348] | loc. loss = 0.0904468745, classif. loss = 0.1807752550
2025-10-15 18:39:07,287 | INFO | iter is 12550 / 25000 [skipped  348] | loc. loss = 0.0325262025, classif. loss = 0.1113262624
2025-10-15 18:39:38,805 | INFO | iter is 12600 / 25000 [skipped  348] | loc. loss = 0.1628655344, classif. loss = 0.2517744601
2025-10-15 18:40:09,786 | INFO | iter is 12650 / 25000 [skipped  349] | loc. loss = 0.2593154907, classif. loss = 1.6213102341
2025-10-15 18:40:39,474 | INFO | iter is 12700 / 25000 [skipped  352] | loc. loss = 0.1842218190, classif. loss = 0.4664923847
2025-10-15 18:41:09,764 | INFO | iter is 12750 / 25000 [skipped  354] | loc. loss = 0.0898504108, classif. loss = 1.1985179186
2025-10-15 18:41:40,755 | INFO | iter is 12800 / 25000 [skipped  355] | loc. loss = 0.1676695794, classif. loss = 0.0550646372
2025-10-15 18:42:11,061 | INFO | iter is 12850 / 25000 [skipped  357] | loc. loss = 0.1223708019, classif. loss = 0.0249744207
2025-10-15 18:42:42,052 | INFO | iter is 12900 / 25000 [skipped  358] | loc. loss = 0.1134814247, classif. loss = 0.2447833568
2025-10-15 18:43:12,384 | INFO | iter is 12950 / 25000 [skipped  360] | loc. loss = 0.2059365362, classif. loss = 0.3173475862
2025-10-15 18:43:42,718 | INFO | iter is 13000 / 25000 [skipped  362] | loc. loss = 0.1544355303, classif. loss = 0.0139448205
2025-10-15 18:44:13,742 | INFO | iter is 13050 / 25000 [skipped  363] | loc. loss = 0.0916918591, classif. loss = 0.2127167583
2025-10-15 18:44:45,371 | INFO | iter is 13100 / 25000 [skipped  363] | loc. loss = 0.0594711639, classif. loss = 0.4874557257
2025-10-15 18:45:16,355 | INFO | iter is 13150 / 25000 [skipped  364] | loc. loss = 0.1473899335, classif. loss = 0.1034618020
2025-10-15 18:45:47,316 | INFO | iter is 13200 / 25000 [skipped  365] | loc. loss = 0.0990582407, classif. loss = 1.0520031452
2025-10-15 18:46:18,962 | INFO | iter is 13250 / 25000 [skipped  365] | loc. loss = 0.3057932854, classif. loss = 0.2960027456
2025-10-15 18:46:49,992 | INFO | iter is 13300 / 25000 [skipped  366] | loc. loss = 0.2743120193, classif. loss = 0.3055464625
2025-10-15 18:47:21,573 | INFO | iter is 13350 / 25000 [skipped  366] | loc. loss = 0.1668700725, classif. loss = 0.1653190851
2025-10-15 18:47:52,559 | INFO | iter is 13400 / 25000 [skipped  367] | loc. loss = 0.1095019430, classif. loss = 0.8004571199
2025-10-15 18:48:24,166 | INFO | iter is 13450 / 25000 [skipped  367] | loc. loss = 0.2877097130, classif. loss = 0.4360643625
2025-10-15 18:48:55,825 | INFO | iter is 13500 / 25000 [skipped  367] | loc. loss = 0.1133387312, classif. loss = 0.0503335521
2025-10-15 18:49:24,969 | INFO | iter is 13550 / 25000 [skipped  371] | loc. loss = 0.2373709530, classif. loss = 1.5894041061
2025-10-15 18:49:54,741 | INFO | iter is 13600 / 25000 [skipped  374] | loc. loss = 0.1558770090, classif. loss = 0.2207663059
2025-10-15 18:50:55,570 | INFO | iter is 13700 / 25000 [skipped  378] | loc. loss = 0.1860723048, classif. loss = 0.1534531713
2025-10-15 18:51:26,644 | INFO | iter is 13750 / 25000 [skipped  379] | loc. loss = 0.0830965415, classif. loss = 0.5028968453
2025-10-15 18:51:57,652 | INFO | iter is 13800 / 25000 [skipped  380] | loc. loss = 0.1121836454, classif. loss = 0.0280612037
2025-10-15 18:52:29,287 | INFO | iter is 13850 / 25000 [skipped  380] | loc. loss = 0.0741051659, classif. loss = 0.0110578304
2025-10-15 18:52:58,467 | INFO | iter is 13900 / 25000 [skipped  384] | loc. loss = 0.3350567818, classif. loss = 0.3801000714
2025-10-15 18:53:28,942 | INFO | iter is 13950 / 25000 [skipped  386] | loc. loss = 0.1783353984, classif. loss = 1.1111103296
2025-10-15 18:54:00,593 | INFO | iter is 14000 / 25000 [skipped  386] | loc. loss = 0.1512114108, classif. loss = 0.7097652555
2025-10-15 18:54:31,053 | INFO | iter is 14050 / 25000 [skipped  388] | loc. loss = 0.1501145959, classif. loss = 0.2081427574
2025-10-15 18:54:35,500 | INFO | ---------starting evaluation-----------
2025-10-15 18:54:36,904 | INFO | validation:    0/ 531 (2025-10-15_18-54-36)
2025-10-15 18:54:49,773 | INFO | validation:  100/ 531 (2025-10-15_18-54-49)
2025-10-15 18:55:02,610 | INFO | validation:  200/ 531 (2025-10-15_18-55-02)
2025-10-15 18:55:15,448 | INFO | validation:  300/ 531 (2025-10-15_18-55-15)
2025-10-15 18:55:28,285 | INFO | validation:  400/ 531 (2025-10-15_18-55-28)
2025-10-15 18:55:41,118 | INFO | validation:  500/ 531 (2025-10-15_18-55-41)
2025-10-15 18:55:45,503 | INFO | Confusion Matrix of Localization:
[[136838939    185213]
 [   312807   1861505]]
2025-10-15 18:55:45,503 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99864832 0.00135168]
 [0.14386482 0.85613518]]
2025-10-15 18:55:45,503 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1684942   47836    2008   23606]
 [      0   29157  194383    8742    8241]
 [      0     662   19074   25525    7584]
 [      0   15221    5397    3495   98439]]
2025-10-15 18:55:45,504 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95822888 0.0272044  0.00114195 0.01342477]
 [0.         0.12122333 0.80816803 0.0363458  0.03426284]
 [0.         0.0125272  0.36094238 0.48301637 0.14351405]
 [0.         0.12420034 0.04403845 0.02851851 0.80324271]]
2025-10-15 18:55:45,504 | INFO | lofF1 is 88.2015, clfF1 is 73.0354, oaF1 is 77.5852, sub class F1 score is [96.6033 76.6475 55.1207 75.5996]
2025-10-15 18:55:45,504 | INFO | ---------starting train set evaluation-----------
2025-10-15 18:55:45,504 | INFO | Train buffer size: 1521.
2025-10-15 18:55:51,261 | INFO | [TrainBuf] locF1 is 87.8770, clfF1 is 81.9969, oaF1 is 83.7610, sub class F1 score is [97.4754 83.4924 70.4343 80.9812]
2025-10-15 18:55:51,273 | INFO | Damage Head - Attention Gate Statistics @ step 14058:
2025-10-15 18:55:51,273 | INFO |   ag3: {'mean': 0.1537991762161255, 'std': 0.20600561797618866, 'active_ratio': 0.0751953125}
2025-10-15 18:55:51,273 | INFO |   ag2: {'mean': 0.7180181741714478, 'std': 0.1817733496427536, 'active_ratio': 0.859619140625}
2025-10-15 18:55:51,273 | INFO |   ag1: {'mean': 0.746042788028717, 'std': 0.1836305409669876, 'active_ratio': 0.87615966796875}
2025-10-15 18:55:51,273 | INFO | Building Head - Attention Gate Statistics @ step 14058:
2025-10-15 18:55:51,273 | INFO |   ag3: {'mean': 0.7983736991882324, 'std': 0.18826669454574585, 'active_ratio': 0.8994140625}
2025-10-15 18:55:51,273 | INFO |   ag2: {'mean': 0.8429803848266602, 'std': 0.17862197756767273, 'active_ratio': 0.932861328125}
2025-10-15 18:55:51,273 | INFO |   ag1: {'mean': 0.1069609671831131, 'std': 0.09883955121040344, 'active_ratio': 0.01165771484375}
2025-10-15 18:56:16,571 | INFO | iter is 14100 / 25000 [skipped  391] | loc. loss = 0.0873869359, classif. loss = 0.0189323146
2025-10-15 18:56:47,505 | INFO | iter is 14150 / 25000 [skipped  392] | loc. loss = 0.0490253828, classif. loss = 0.7401378155
2025-10-15 18:57:18,505 | INFO | iter is 14200 / 25000 [skipped  393] | loc. loss = 0.0818125382, classif. loss = 0.4102945924
2025-10-15 18:57:48,852 | INFO | iter is 14250 / 25000 [skipped  395] | loc. loss = 0.0926804319, classif. loss = 0.4535034895
2025-10-15 18:58:19,877 | INFO | iter is 14300 / 25000 [skipped  396] | loc. loss = 0.3667563200, classif. loss = 0.3412156105
2025-10-15 18:58:50,828 | INFO | iter is 14350 / 25000 [skipped  397] | loc. loss = 0.1875430495, classif. loss = 0.0414321236
2025-10-15 18:59:21,177 | INFO | iter is 14400 / 25000 [skipped  399] | loc. loss = 0.1236123964, classif. loss = 1.0435307026
2025-10-15 18:59:52,805 | INFO | iter is 14450 / 25000 [skipped  399] | loc. loss = 0.1620282382, classif. loss = 0.1300104707
2025-10-15 19:00:23,791 | INFO | iter is 14500 / 25000 [skipped  400] | loc. loss = 0.0930776298, classif. loss = 0.3313035071
2025-10-15 19:00:53,547 | INFO | iter is 14550 / 25000 [skipped  403] | loc. loss = 0.1356899440, classif. loss = 0.0490241796
2025-10-15 19:01:23,976 | INFO | iter is 14600 / 25000 [skipped  405] | loc. loss = 0.2147083282, classif. loss = 0.4123459756
2025-10-15 19:01:54,986 | INFO | iter is 14650 / 25000 [skipped  406] | loc. loss = 0.1004941687, classif. loss = 0.0052493168
2025-10-15 19:02:26,055 | INFO | iter is 14700 / 25000 [skipped  407] | loc. loss = 0.1847026646, classif. loss = 0.5027517676
2025-10-15 19:02:57,677 | INFO | iter is 14750 / 25000 [skipped  407] | loc. loss = 0.4795497358, classif. loss = 0.1010965928
2025-10-15 19:03:29,368 | INFO | iter is 14800 / 25000 [skipped  407] | loc. loss = 0.1262706816, classif. loss = 0.3295665383
2025-10-15 19:04:00,368 | INFO | iter is 14850 / 25000 [skipped  408] | loc. loss = 0.3612945676, classif. loss = 0.1416612267
2025-10-15 19:04:31,990 | INFO | iter is 14900 / 25000 [skipped  408] | loc. loss = 0.1405090988, classif. loss = 0.3612267077
2025-10-15 19:05:03,013 | INFO | iter is 14950 / 25000 [skipped  409] | loc. loss = 0.1298927963, classif. loss = 0.0061220070
2025-10-15 19:06:05,128 | INFO | iter is 15050 / 25000 [skipped  411] | loc. loss = 0.1133482903, classif. loss = 0.0259348638
2025-10-15 19:06:34,910 | INFO | iter is 15100 / 25000 [skipped  414] | loc. loss = 0.1886003315, classif. loss = 0.0105911288
2025-10-15 19:07:05,386 | INFO | iter is 15150 / 25000 [skipped  416] | loc. loss = 0.1685781330, classif. loss = 0.1753756702
2025-10-15 19:07:36,419 | INFO | iter is 15200 / 25000 [skipped  417] | loc. loss = 0.1376762092, classif. loss = 0.5957186818
2025-10-15 19:08:07,543 | INFO | iter is 15250 / 25000 [skipped  418] | loc. loss = 0.1697215140, classif. loss = 0.6305546761
2025-10-15 19:08:36,736 | INFO | iter is 15300 / 25000 [skipped  422] | loc. loss = 0.0828689560, classif. loss = 0.0267267935
2025-10-15 19:09:07,237 | INFO | iter is 15350 / 25000 [skipped  424] | loc. loss = 0.1887686104, classif. loss = 0.3966225386
2025-10-15 19:09:38,956 | INFO | iter is 15400 / 25000 [skipped  424] | loc. loss = 0.1756758392, classif. loss = 0.0501240008
2025-10-15 19:10:09,991 | INFO | iter is 15450 / 25000 [skipped  425] | loc. loss = 0.3550707102, classif. loss = 0.0835603029
2025-10-15 19:10:40,400 | INFO | iter is 15500 / 25000 [skipped  427] | loc. loss = 0.1265383214, classif. loss = 0.0609787963
2025-10-15 19:11:10,879 | INFO | iter is 15550 / 25000 [skipped  429] | loc. loss = 0.1965350211, classif. loss = 0.2155558914
2025-10-15 19:11:41,309 | INFO | iter is 15600 / 25000 [skipped  431] | loc. loss = 0.0533770062, classif. loss = 0.2187796831
2025-10-15 19:11:53,956 | INFO | ---------starting evaluation-----------
2025-10-15 19:11:55,360 | INFO | validation:    0/ 531 (2025-10-15_19-11-55)
2025-10-15 19:12:08,236 | INFO | validation:  100/ 531 (2025-10-15_19-12-08)
2025-10-15 19:12:21,081 | INFO | validation:  200/ 531 (2025-10-15_19-12-21)
2025-10-15 19:12:33,923 | INFO | validation:  300/ 531 (2025-10-15_19-12-33)
2025-10-15 19:12:46,773 | INFO | validation:  400/ 531 (2025-10-15_19-12-46)
2025-10-15 19:12:59,626 | INFO | validation:  500/ 531 (2025-10-15_19-12-59)
2025-10-15 19:13:04,017 | INFO | Confusion Matrix of Localization:
[[136755900    268252]
 [   248426   1925886]]
2025-10-15 19:13:04,018 | INFO | Confusion Matrix of Localization - Normalized:
[[0.9980423  0.0019577 ]
 [0.11425499 0.88574501]]
2025-10-15 19:13:04,018 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1678948   66177     806   12461]
 [      0   22230  208770    6768    2755]
 [      0     291   28387   19215    4952]
 [      0   20740   11137    2321   88354]]
2025-10-15 19:13:04,018 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.54820086e-01 3.76349528e-02 4.58373332e-04
  7.08658820e-03]
 [0.00000000e+00 9.24235936e-02 8.67983519e-01 2.81386811e-02
  1.14542060e-02]
 [0.00000000e+00 5.50667045e-03 5.37174756e-01 3.63610559e-01
  9.37080140e-02]
 [0.00000000e+00 1.69234284e-01 9.08757099e-02 1.89388994e-02
  7.20951106e-01]]
2025-10-15 19:13:04,018 | INFO | lofF1 is 88.1725, clfF1 is 68.8945, oaF1 is 74.6779, sub class F1 score is [96.4746 75.2332 46.8916 76.4725]
2025-10-15 19:13:04,018 | INFO | ---------starting train set evaluation-----------
2025-10-15 19:13:04,018 | INFO | Train buffer size: 1520.
2025-10-15 19:13:09,756 | INFO | [TrainBuf] locF1 is 87.9606, clfF1 is 85.1164, oaF1 is 85.9696, sub class F1 score is [97.6239 83.56   78.5824 82.9315]
2025-10-15 19:13:09,768 | INFO | Damage Head - Attention Gate Statistics @ step 15620:
2025-10-15 19:13:09,768 | INFO |   ag3: {'mean': 0.20734670758247375, 'std': 0.26598021388053894, 'active_ratio': 0.1376953125}
2025-10-15 19:13:09,768 | INFO |   ag2: {'mean': 0.6457563638687134, 'std': 0.2329292893409729, 'active_ratio': 0.717529296875}
2025-10-15 19:13:09,768 | INFO |   ag1: {'mean': 0.6988115310668945, 'std': 0.1864672303199768, 'active_ratio': 0.84283447265625}
2025-10-15 19:13:09,769 | INFO | Building Head - Attention Gate Statistics @ step 15620:
2025-10-15 19:13:09,769 | INFO |   ag3: {'mean': 0.8369324803352356, 'std': 0.170600026845932, 'active_ratio': 0.9365234375}
2025-10-15 19:13:09,769 | INFO |   ag2: {'mean': 0.8051271438598633, 'std': 0.18196247518062592, 'active_ratio': 0.9150390625}
2025-10-15 19:13:09,769 | INFO |   ag1: {'mean': 0.0811067745089531, 'std': 0.07676465809345245, 'active_ratio': 0.00421142578125}
2025-10-15 19:13:28,143 | INFO | iter is 15650 / 25000 [skipped  432] | loc. loss = 0.1312167346, classif. loss = 0.2762044668
2025-10-15 19:13:59,042 | INFO | iter is 15700 / 25000 [skipped  433] | loc. loss = 0.0882736295, classif. loss = 0.1888845861
2025-10-15 19:14:30,016 | INFO | iter is 15750 / 25000 [skipped  434] | loc. loss = 0.1101150289, classif. loss = 0.0500704013
2025-10-15 19:14:59,723 | INFO | iter is 15800 / 25000 [skipped  437] | loc. loss = 0.1702302694, classif. loss = 0.2127940804
2025-10-15 19:15:30,667 | INFO | iter is 15850 / 25000 [skipped  438] | loc. loss = 0.1418755054, classif. loss = 1.3329733610
2025-10-15 19:16:01,639 | INFO | iter is 15900 / 25000 [skipped  439] | loc. loss = 0.2076672614, classif. loss = 0.2095489800
2025-10-15 19:16:33,220 | INFO | iter is 15950 / 25000 [skipped  439] | loc. loss = 0.0998076499, classif. loss = 0.4588728547
2025-10-15 19:17:04,187 | INFO | iter is 16000 / 25000 [skipped  440] | loc. loss = 0.0793559104, classif. loss = 0.4161742926
2025-10-15 19:17:33,907 | INFO | iter is 16050 / 25000 [skipped  443] | loc. loss = 0.1854451597, classif. loss = 0.7572587729
2025-10-15 19:18:03,695 | INFO | iter is 16100 / 25000 [skipped  446] | loc. loss = 0.0767081380, classif. loss = 0.9868220687
2025-10-15 19:18:34,036 | INFO | iter is 16150 / 25000 [skipped  448] | loc. loss = 0.1302636117, classif. loss = 0.9495679140
2025-10-15 19:19:05,057 | INFO | iter is 16200 / 25000 [skipped  449] | loc. loss = 0.0956863090, classif. loss = 0.7573306561
2025-10-15 19:19:35,399 | INFO | iter is 16250 / 25000 [skipped  451] | loc. loss = 0.1089260653, classif. loss = 0.0775638595
2025-10-15 19:20:05,208 | INFO | iter is 16300 / 25000 [skipped  454] | loc. loss = 0.1684118658, classif. loss = 0.7138376832
2025-10-15 19:20:36,792 | INFO | iter is 16350 / 25000 [skipped  454] | loc. loss = 0.1598725170, classif. loss = 0.3357776701
2025-10-15 19:21:07,774 | INFO | iter is 16400 / 25000 [skipped  455] | loc. loss = 0.1740072817, classif. loss = 0.6794590950
2025-10-15 19:21:37,577 | INFO | iter is 16450 / 25000 [skipped  458] | loc. loss = 0.1511090994, classif. loss = 0.4013931155
2025-10-15 19:22:08,564 | INFO | iter is 16500 / 25000 [skipped  459] | loc. loss = 0.2373451293, classif. loss = 0.0716878325
2025-10-15 19:22:40,177 | INFO | iter is 16550 / 25000 [skipped  459] | loc. loss = 0.1101067662, classif. loss = 0.1009101495
2025-10-15 19:23:11,860 | INFO | iter is 16600 / 25000 [skipped  459] | loc. loss = 0.1509313434, classif. loss = 0.6560095549
2025-10-15 19:23:42,927 | INFO | iter is 16650 / 25000 [skipped  460] | loc. loss = 0.2200675309, classif. loss = 0.4685887098
2025-10-15 19:24:12,719 | INFO | iter is 16700 / 25000 [skipped  463] | loc. loss = 0.1106064394, classif. loss = 0.5050161481
2025-10-15 19:24:43,728 | INFO | iter is 16750 / 25000 [skipped  464] | loc. loss = 0.1216394454, classif. loss = 2.2813644409
2025-10-15 19:25:14,799 | INFO | iter is 16800 / 25000 [skipped  465] | loc. loss = 0.1300348490, classif. loss = 1.0694270134
2025-10-15 19:25:46,438 | INFO | iter is 16850 / 25000 [skipped  465] | loc. loss = 0.1874473393, classif. loss = 0.4973516464
2025-10-15 19:26:17,531 | INFO | iter is 16900 / 25000 [skipped  466] | loc. loss = 0.0613374561, classif. loss = 0.1264830381
2025-10-15 19:26:49,177 | INFO | iter is 16950 / 25000 [skipped  466] | loc. loss = 0.1992436796, classif. loss = 0.3889025450
2025-10-15 19:27:19,592 | INFO | iter is 17000 / 25000 [skipped  468] | loc. loss = 0.0958883539, classif. loss = 0.1291505098
2025-10-15 19:28:21,129 | INFO | iter is 17100 / 25000 [skipped  471] | loc. loss = 0.1539344490, classif. loss = 0.2567400634
2025-10-15 19:28:50,998 | INFO | iter is 17150 / 25000 [skipped  474] | loc. loss = 0.0983414277, classif. loss = 0.3665392101
2025-10-15 19:29:10,656 | INFO | ---------starting evaluation-----------
2025-10-15 19:29:12,069 | INFO | validation:    0/ 531 (2025-10-15_19-29-12)
2025-10-15 19:29:24,946 | INFO | validation:  100/ 531 (2025-10-15_19-29-24)
2025-10-15 19:29:37,776 | INFO | validation:  200/ 531 (2025-10-15_19-29-37)
2025-10-15 19:29:50,613 | INFO | validation:  300/ 531 (2025-10-15_19-29-50)
2025-10-15 19:30:03,443 | INFO | validation:  400/ 531 (2025-10-15_19-30-03)
2025-10-15 19:30:16,275 | INFO | validation:  500/ 531 (2025-10-15_19-30-16)
2025-10-15 19:30:20,672 | INFO | Confusion Matrix of Localization:
[[136792501    231651]
 [   275508   1898804]]
2025-10-15 19:30:20,672 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99830941 0.00169059]
 [0.12671043 0.87328957]]
2025-10-15 19:30:20,672 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1697883   34596    2803   23110]
 [      0   35040  188515    8945    8023]
 [      0     553   19889   21019   11384]
 [      0   16594    5709    3285   96964]]
2025-10-15 19:30:20,672 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96558845 0.01967479 0.00159407 0.01314269]
 [0.         0.14568253 0.7837712  0.03718979 0.03335648]
 [0.         0.01046457 0.37636484 0.39774813 0.21542246]
 [0.         0.13540375 0.04658431 0.02680495 0.791207  ]]
2025-10-15 19:30:20,673 | INFO | lofF1 is 88.2187, clfF1 is 69.0054, oaF1 is 74.7694, sub class F1 score is [96.7879 77.0657 47.2884 74.009 ]
2025-10-15 19:30:20,673 | INFO | ---------starting train set evaluation-----------
2025-10-15 19:30:20,673 | INFO | Train buffer size: 1518.
2025-10-15 19:30:26,408 | INFO | [TrainBuf] locF1 is 88.3724, clfF1 is 85.7531, oaF1 is 86.5389, sub class F1 score is [97.774  86.6262 79.1816 81.6671]
2025-10-15 19:30:26,420 | INFO | Damage Head - Attention Gate Statistics @ step 17182:
2025-10-15 19:30:26,420 | INFO |   ag3: {'mean': 0.2570088505744934, 'std': 0.20968209207057953, 'active_ratio': 0.1318359375}
2025-10-15 19:30:26,420 | INFO |   ag2: {'mean': 0.6940271854400635, 'std': 0.2172521948814392, 'active_ratio': 0.798583984375}
2025-10-15 19:30:26,420 | INFO |   ag1: {'mean': 0.6401948928833008, 'std': 0.22783058881759644, 'active_ratio': 0.66497802734375}
2025-10-15 19:30:26,421 | INFO | Building Head - Attention Gate Statistics @ step 17182:
2025-10-15 19:30:26,421 | INFO |   ag3: {'mean': 0.8350454568862915, 'std': 0.1725742667913437, 'active_ratio': 0.9365234375}
2025-10-15 19:30:26,421 | INFO |   ag2: {'mean': 0.7835339307785034, 'std': 0.2045312523841858, 'active_ratio': 0.880615234375}
2025-10-15 19:30:26,421 | INFO |   ag1: {'mean': 0.11365881562232971, 'std': 0.10397589951753616, 'active_ratio': 0.01312255859375}
2025-10-15 19:30:37,794 | INFO | iter is 17200 / 25000 [skipped  475] | loc. loss = 0.1498076022, classif. loss = 0.0024740649
2025-10-15 19:31:08,760 | INFO | iter is 17250 / 25000 [skipped  476] | loc. loss = 0.1309698373, classif. loss = 0.2541352808
2025-10-15 19:31:39,172 | INFO | iter is 17300 / 25000 [skipped  478] | loc. loss = 0.0843782350, classif. loss = 0.7035423517
2025-10-15 19:32:09,536 | INFO | iter is 17350 / 25000 [skipped  480] | loc. loss = 0.0998520181, classif. loss = 0.3687926531
2025-10-15 19:32:38,657 | INFO | iter is 17400 / 25000 [skipped  484] | loc. loss = 0.0584651567, classif. loss = 0.1045390218
2025-10-15 19:33:09,684 | INFO | iter is 17450 / 25000 [skipped  485] | loc. loss = 0.1950846910, classif. loss = 0.3321070671
2025-10-15 19:33:40,643 | INFO | iter is 17500 / 25000 [skipped  486] | loc. loss = 0.1074909344, classif. loss = 0.1300484240
2025-10-15 19:34:11,711 | INFO | iter is 17550 / 25000 [skipped  487] | loc. loss = 0.1557334214, classif. loss = 0.8944287300
2025-10-15 19:34:43,317 | INFO | iter is 17600 / 25000 [skipped  487] | loc. loss = 0.1265526414, classif. loss = 0.9864485264
2025-10-15 19:35:15,001 | INFO | iter is 17650 / 25000 [skipped  487] | loc. loss = 0.2210364193, classif. loss = 0.7986673713
2025-10-15 19:35:46,632 | INFO | iter is 17700 / 25000 [skipped  487] | loc. loss = 0.1831209958, classif. loss = 0.3563925624
2025-10-15 19:36:17,668 | INFO | iter is 17750 / 25000 [skipped  488] | loc. loss = 0.1754911542, classif. loss = 0.0509188697
2025-10-15 19:36:48,740 | INFO | iter is 17800 / 25000 [skipped  489] | loc. loss = 0.2115370035, classif. loss = 0.0172978900
2025-10-15 19:37:20,370 | INFO | iter is 17850 / 25000 [skipped  489] | loc. loss = 0.0811083764, classif. loss = 0.1202367023
2025-10-15 19:37:51,393 | INFO | iter is 17900 / 25000 [skipped  490] | loc. loss = 0.1999449134, classif. loss = 0.7813184261
2025-10-15 19:38:22,484 | INFO | iter is 17950 / 25000 [skipped  491] | loc. loss = 0.0738688707, classif. loss = 0.8637810349
2025-10-15 19:38:52,889 | INFO | iter is 18000 / 25000 [skipped  493] | loc. loss = 0.1857333034, classif. loss = 0.0145576894
2025-10-15 19:39:23,987 | INFO | iter is 18050 / 25000 [skipped  494] | loc. loss = 0.1553352922, classif. loss = 0.0025202273
2025-10-15 19:39:55,635 | INFO | iter is 18100 / 25000 [skipped  494] | loc. loss = 0.4168828130, classif. loss = 1.9618406296
2025-10-15 19:40:26,743 | INFO | iter is 18150 / 25000 [skipped  495] | loc. loss = 0.1248538718, classif. loss = 0.2225013077
2025-10-15 19:40:56,541 | INFO | iter is 18200 / 25000 [skipped  498] | loc. loss = 0.1736000627, classif. loss = 0.4559403658
2025-10-15 19:41:27,595 | INFO | iter is 18250 / 25000 [skipped  499] | loc. loss = 0.1677765399, classif. loss = 0.8932325840
2025-10-15 19:42:29,143 | INFO | iter is 18350 / 25000 [skipped  502] | loc. loss = 0.1599293947, classif. loss = 0.5775555372
2025-10-15 19:43:30,046 | INFO | iter is 18450 / 25000 [skipped  506] | loc. loss = 0.0910615027, classif. loss = 0.2634635866
2025-10-15 19:44:31,561 | INFO | iter is 18550 / 25000 [skipped  509] | loc. loss = 0.1586630642, classif. loss = 0.0389675088
2025-10-15 19:45:03,216 | INFO | iter is 18600 / 25000 [skipped  509] | loc. loss = 0.1798554212, classif. loss = 0.1308290660
2025-10-15 19:45:33,691 | INFO | iter is 18650 / 25000 [skipped  511] | loc. loss = 0.1066631973, classif. loss = 0.1004703045
2025-10-15 19:46:02,886 | INFO | iter is 18700 / 25000 [skipped  515] | loc. loss = 0.1103426218, classif. loss = 0.0085727163
2025-10-15 19:46:30,109 | INFO | ---------starting evaluation-----------
2025-10-15 19:46:31,516 | INFO | validation:    0/ 531 (2025-10-15_19-46-31)
2025-10-15 19:46:44,416 | INFO | validation:  100/ 531 (2025-10-15_19-46-44)
2025-10-15 19:46:57,292 | INFO | validation:  200/ 531 (2025-10-15_19-46-57)
2025-10-15 19:47:10,194 | INFO | validation:  300/ 531 (2025-10-15_19-47-10)
2025-10-15 19:47:23,073 | INFO | validation:  400/ 531 (2025-10-15_19-47-23)
2025-10-15 19:47:35,965 | INFO | validation:  500/ 531 (2025-10-15_19-47-35)
2025-10-15 19:47:40,373 | INFO | Confusion Matrix of Localization:
[[136830738    193414]
 [   295696   1878616]]
2025-10-15 19:47:40,373 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99858847 0.00141153]
 [0.1359952  0.8640048 ]]
2025-10-15 19:47:40,373 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1690617   53847    2115   11813]
 [      0   23331  198366   10128    8698]
 [      0     662   18974   24738    8471]
 [      0   26431    4019    3552   88550]]
2025-10-15 19:47:40,373 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96145626 0.03062286 0.0012028  0.00671807]
 [0.         0.09700112 0.82472778 0.04210824 0.03616286]
 [0.         0.0125272  0.35905005 0.46812376 0.16029899]
 [0.         0.21567171 0.03279424 0.02898362 0.72255043]]
2025-10-15 19:47:40,373 | INFO | lofF1 is 88.4816, clfF1 is 71.7118, oaF1 is 76.7428, sub class F1 score is [96.6223 76.9264 52.9846 73.7658]
2025-10-15 19:47:40,374 | INFO | ---------starting train set evaluation-----------
2025-10-15 19:47:40,374 | INFO | Train buffer size: 1521.
2025-10-15 19:47:46,132 | INFO | [TrainBuf] locF1 is 88.3598, clfF1 is 85.0611, oaF1 is 86.0507, sub class F1 score is [97.7071 84.9324 77.6235 82.4161]
2025-10-15 19:47:46,144 | INFO | Damage Head - Attention Gate Statistics @ step 18744:
2025-10-15 19:47:46,145 | INFO |   ag3: {'mean': 0.29744037985801697, 'std': 0.21336758136749268, 'active_ratio': 0.140625}
2025-10-15 19:47:46,145 | INFO |   ag2: {'mean': 0.6197200417518616, 'std': 0.23666825890541077, 'active_ratio': 0.675537109375}
2025-10-15 19:47:46,145 | INFO |   ag1: {'mean': 0.6740325093269348, 'std': 0.23127761483192444, 'active_ratio': 0.71551513671875}
2025-10-15 19:47:46,145 | INFO | Building Head - Attention Gate Statistics @ step 18744:
2025-10-15 19:47:46,145 | INFO |   ag3: {'mean': 0.7892981767654419, 'std': 0.21492239832878113, 'active_ratio': 0.8828125}
2025-10-15 19:47:46,145 | INFO |   ag2: {'mean': 0.7439396381378174, 'std': 0.22743980586528778, 'active_ratio': 0.830078125}
2025-10-15 19:47:46,145 | INFO |   ag1: {'mean': 0.08044439554214478, 'std': 0.06429096311330795, 'active_ratio': 0.001708984375}
2025-10-15 19:47:49,947 | INFO | iter is 18750 / 25000 [skipped  516] | loc. loss = 0.1843259186, classif. loss = 0.2755879462
2025-10-15 19:48:20,901 | INFO | iter is 18800 / 25000 [skipped  517] | loc. loss = 0.0721206143, classif. loss = 0.3728000522
2025-10-15 19:48:51,829 | INFO | iter is 18850 / 25000 [skipped  518] | loc. loss = 0.1311157793, classif. loss = 0.5437124968
2025-10-15 19:49:22,750 | INFO | iter is 18900 / 25000 [skipped  519] | loc. loss = 0.0290637817, classif. loss = 0.0112621961
2025-10-15 19:49:52,514 | INFO | iter is 18950 / 25000 [skipped  522] | loc. loss = 0.1591209620, classif. loss = 1.3438463211
2025-10-15 19:50:23,461 | INFO | iter is 19000 / 25000 [skipped  523] | loc. loss = 0.1278549731, classif. loss = 0.2300809026
2025-10-15 19:50:54,468 | INFO | iter is 19050 / 25000 [skipped  524] | loc. loss = 0.1785604209, classif. loss = 0.0493517220
2025-10-15 19:51:25,418 | INFO | iter is 19100 / 25000 [skipped  525] | loc. loss = 0.1198574007, classif. loss = 0.4750225842
2025-10-15 19:51:56,998 | INFO | iter is 19150 / 25000 [skipped  525] | loc. loss = 0.0482292660, classif. loss = 0.0622797459
2025-10-15 19:52:27,340 | INFO | iter is 19200 / 25000 [skipped  527] | loc. loss = 0.1244748756, classif. loss = 1.0497319698
2025-10-15 19:52:58,982 | INFO | iter is 19250 / 25000 [skipped  527] | loc. loss = 0.1550417989, classif. loss = 1.6544467211
2025-10-15 19:53:30,559 | INFO | iter is 19300 / 25000 [skipped  527] | loc. loss = 0.1367497295, classif. loss = 0.6474973559
2025-10-15 19:54:01,588 | INFO | iter is 19350 / 25000 [skipped  528] | loc. loss = 0.1371984929, classif. loss = 0.0301449019
2025-10-15 19:54:31,948 | INFO | iter is 19400 / 25000 [skipped  530] | loc. loss = 0.2009230852, classif. loss = 0.5133400559
2025-10-15 19:55:01,094 | INFO | iter is 19450 / 25000 [skipped  534] | loc. loss = 0.1666502059, classif. loss = 0.5306007266
2025-10-15 19:55:31,507 | INFO | iter is 19500 / 25000 [skipped  536] | loc. loss = 0.1112574190, classif. loss = 0.0440519825
2025-10-15 19:56:02,487 | INFO | iter is 19550 / 25000 [skipped  537] | loc. loss = 0.1051184535, classif. loss = 0.2566128969
2025-10-15 19:56:34,087 | INFO | iter is 19600 / 25000 [skipped  537] | loc. loss = 0.2601947188, classif. loss = 0.0344045907
2025-10-15 19:57:05,745 | INFO | iter is 19650 / 25000 [skipped  537] | loc. loss = 0.0770509541, classif. loss = 0.6202282310
2025-10-15 19:57:37,413 | INFO | iter is 19700 / 25000 [skipped  537] | loc. loss = 0.0793419257, classif. loss = 0.3354628682
2025-10-15 19:58:08,417 | INFO | iter is 19750 / 25000 [skipped  538] | loc. loss = 0.1194744334, classif. loss = 3.4833202362
2025-10-15 19:58:39,423 | INFO | iter is 19800 / 25000 [skipped  539] | loc. loss = 0.1107247770, classif. loss = 0.7521778345
2025-10-15 19:59:11,112 | INFO | iter is 19850 / 25000 [skipped  539] | loc. loss = 0.1424417645, classif. loss = 0.2779392898
2025-10-15 19:59:42,122 | INFO | iter is 19900 / 25000 [skipped  540] | loc. loss = 0.0810366720, classif. loss = 0.0374272615
2025-10-15 20:00:13,800 | INFO | iter is 19950 / 25000 [skipped  540] | loc. loss = 0.0262410510, classif. loss = 0.0255924612
2025-10-15 20:00:45,416 | INFO | iter is 20000 / 25000 [skipped  540] | loc. loss = 0.1090569198, classif. loss = 1.1405115128
2025-10-15 20:01:14,643 | INFO | iter is 20050 / 25000 [skipped  544] | loc. loss = 0.1878898144, classif. loss = 0.3999217749
2025-10-15 20:01:43,818 | INFO | iter is 20100 / 25000 [skipped  548] | loc. loss = 0.1705913246, classif. loss = 0.1685553044
2025-10-15 20:02:14,293 | INFO | iter is 20150 / 25000 [skipped  550] | loc. loss = 0.2154473662, classif. loss = 0.8321552873
2025-10-15 20:02:44,695 | INFO | iter is 20200 / 25000 [skipped  552] | loc. loss = 0.1629905403, classif. loss = 0.0365592055
2025-10-15 20:03:13,937 | INFO | iter is 20250 / 25000 [skipped  556] | loc. loss = 0.0953756943, classif. loss = 0.6137235165
2025-10-15 20:03:43,737 | INFO | iter is 20300 / 25000 [skipped  559] | loc. loss = 0.1233316511, classif. loss = 0.7216156721
2025-10-15 20:03:46,302 | INFO | ---------starting evaluation-----------
2025-10-15 20:03:47,705 | INFO | validation:    0/ 531 (2025-10-15_20-03-47)
2025-10-15 20:04:00,583 | INFO | validation:  100/ 531 (2025-10-15_20-04-00)
2025-10-15 20:04:13,419 | INFO | validation:  200/ 531 (2025-10-15_20-04-13)
2025-10-15 20:04:26,251 | INFO | validation:  300/ 531 (2025-10-15_20-04-26)
2025-10-15 20:04:39,084 | INFO | validation:  400/ 531 (2025-10-15_20-04-39)
2025-10-15 20:04:51,923 | INFO | validation:  500/ 531 (2025-10-15_20-04-51)
2025-10-15 20:04:56,320 | INFO | Confusion Matrix of Localization:
[[136756027    268125]
 [   225943   1948369]]
2025-10-15 20:04:56,320 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99804323 0.00195677]
 [0.10391471 0.89608529]]
2025-10-15 20:04:56,321 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1710159   33415     688   14130]
 [      0   30668  198447    5404    6004]
 [      0     862   25111   20089    6783]
 [      0   23002    7309    2906   89335]]
2025-10-15 20:04:56,321 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.72569825e-01 1.90031574e-02 3.91266566e-04
  8.03575085e-03]
 [0.00000000e+00 1.27505478e-01 8.25064547e-01 2.24677058e-02
  2.49622697e-02]
 [0.00000000e+00 1.63118554e-02 4.75182136e-01 3.80149494e-01
  1.28356514e-01]
 [0.00000000e+00 1.87691755e-01 5.96399896e-02 2.37123833e-02
  7.28955872e-01]]
2025-10-15 20:04:56,321 | INFO | lofF1 is 88.7477, clfF1 is 70.4508, oaF1 is 75.9398, sub class F1 score is [97.0831 78.6232 49.0382 74.8187]
2025-10-15 20:04:56,322 | INFO | ---------starting train set evaluation-----------
2025-10-15 20:04:56,322 | INFO | Train buffer size: 1517.
2025-10-15 20:05:02,007 | INFO | [TrainBuf] locF1 is 88.6020, clfF1 is 85.0010, oaF1 is 86.0813, sub class F1 score is [97.8034 85.7419 76.6215 82.5109]
2025-10-15 20:05:02,019 | INFO | Damage Head - Attention Gate Statistics @ step 20306:
2025-10-15 20:05:02,020 | INFO |   ag3: {'mean': 0.34228017926216125, 'std': 0.21246737241744995, 'active_ratio': 0.2255859375}
2025-10-15 20:05:02,020 | INFO |   ag2: {'mean': 0.6005578637123108, 'std': 0.23758576810359955, 'active_ratio': 0.66552734375}
2025-10-15 20:05:02,020 | INFO |   ag1: {'mean': 0.5331256985664368, 'std': 0.27180954813957214, 'active_ratio': 0.499755859375}
2025-10-15 20:05:02,020 | INFO | Building Head - Attention Gate Statistics @ step 20306:
2025-10-15 20:05:02,020 | INFO |   ag3: {'mean': 0.6928741335868835, 'std': 0.263115257024765, 'active_ratio': 0.7275390625}
2025-10-15 20:05:02,020 | INFO |   ag2: {'mean': 0.7849275469779968, 'std': 0.21605385839939117, 'active_ratio': 0.861083984375}
2025-10-15 20:05:02,020 | INFO |   ag1: {'mean': 0.10866062343120575, 'std': 0.10535953938961029, 'active_ratio': 0.0135498046875}
2025-10-15 20:05:29,826 | INFO | iter is 20350 / 25000 [skipped  561] | loc. loss = 0.2577854097, classif. loss = 1.2489528656
2025-10-15 20:06:00,753 | INFO | iter is 20400 / 25000 [skipped  562] | loc. loss = 0.2786756158, classif. loss = 0.3522323966
2025-10-15 20:06:31,067 | INFO | iter is 20450 / 25000 [skipped  564] | loc. loss = 0.1746829897, classif. loss = 0.0090097766
2025-10-15 20:07:02,076 | INFO | iter is 20500 / 25000 [skipped  565] | loc. loss = 0.1377427727, classif. loss = 1.0969024897
2025-10-15 20:07:32,395 | INFO | iter is 20550 / 25000 [skipped  567] | loc. loss = 0.2875218689, classif. loss = 0.0949507654
2025-10-15 20:08:03,397 | INFO | iter is 20600 / 25000 [skipped  568] | loc. loss = 0.1252194643, classif. loss = 0.3650575280
2025-10-15 20:08:34,960 | INFO | iter is 20650 / 25000 [skipped  568] | loc. loss = 0.1464046091, classif. loss = 0.0227164477
2025-10-15 20:09:05,963 | INFO | iter is 20700 / 25000 [skipped  569] | loc. loss = 0.1401299089, classif. loss = 0.0359427854
2025-10-15 20:09:35,689 | INFO | iter is 20750 / 25000 [skipped  572] | loc. loss = 0.1640595794, classif. loss = 0.0233542062
2025-10-15 20:10:05,420 | INFO | iter is 20800 / 25000 [skipped  575] | loc. loss = 0.1290960014, classif. loss = 0.1264502555
2025-10-15 20:10:36,446 | INFO | iter is 20850 / 25000 [skipped  576] | loc. loss = 0.1931985319, classif. loss = 0.1760264486
2025-10-15 20:11:06,796 | INFO | iter is 20900 / 25000 [skipped  578] | loc. loss = 0.1049828306, classif. loss = 0.3369455040
2025-10-15 20:11:37,157 | INFO | iter is 20950 / 25000 [skipped  580] | loc. loss = 0.0678633377, classif. loss = 0.2784276307
2025-10-15 20:12:07,571 | INFO | iter is 21000 / 25000 [skipped  582] | loc. loss = 0.1812264025, classif. loss = 0.0154661136
2025-10-15 20:12:36,093 | INFO | iter is 21050 / 25000 [skipped  587] | loc. loss = 0.1432731450, classif. loss = 0.5377411842
2025-10-15 20:13:07,135 | INFO | iter is 21100 / 25000 [skipped  588] | loc. loss = 0.1344283223, classif. loss = 0.0424731672
2025-10-15 20:13:37,501 | INFO | iter is 21150 / 25000 [skipped  590] | loc. loss = 0.0352070332, classif. loss = 1.5314881802
2025-10-15 20:14:09,168 | INFO | iter is 21200 / 25000 [skipped  590] | loc. loss = 0.1596214324, classif. loss = 0.4698328674
2025-10-15 20:14:40,774 | INFO | iter is 21250 / 25000 [skipped  590] | loc. loss = 0.0651966631, classif. loss = 0.6452577114
2025-10-15 20:15:11,820 | INFO | iter is 21300 / 25000 [skipped  591] | loc. loss = 0.1923435330, classif. loss = 0.0886650085
2025-10-15 20:15:42,209 | INFO | iter is 21350 / 25000 [skipped  593] | loc. loss = 0.1610349864, classif. loss = 0.0588085651
2025-10-15 20:16:12,025 | INFO | iter is 21400 / 25000 [skipped  596] | loc. loss = 0.1270613372, classif. loss = 1.0120451450
2025-10-15 20:16:43,047 | INFO | iter is 21450 / 25000 [skipped  597] | loc. loss = 0.0648597926, classif. loss = 0.0265664402
2025-10-15 20:17:14,066 | INFO | iter is 21500 / 25000 [skipped  598] | loc. loss = 0.1150962412, classif. loss = 0.8113792539
2025-10-15 20:17:44,527 | INFO | iter is 21550 / 25000 [skipped  600] | loc. loss = 0.1327035725, classif. loss = 0.0017536033
2025-10-15 20:18:16,174 | INFO | iter is 21600 / 25000 [skipped  600] | loc. loss = 0.1531392038, classif. loss = 0.0797742531
2025-10-15 20:18:47,877 | INFO | iter is 21650 / 25000 [skipped  600] | loc. loss = 0.0736594573, classif. loss = 0.2557009757
2025-10-15 20:19:18,886 | INFO | iter is 21700 / 25000 [skipped  601] | loc. loss = 0.2002546936, classif. loss = 0.2971386909
2025-10-15 20:19:49,915 | INFO | iter is 21750 / 25000 [skipped  602] | loc. loss = 0.1942875981, classif. loss = 0.3815466464
2025-10-15 20:20:20,332 | INFO | iter is 21800 / 25000 [skipped  604] | loc. loss = 0.1118725911, classif. loss = 0.2697023153
2025-10-15 20:20:50,785 | INFO | iter is 21850 / 25000 [skipped  606] | loc. loss = 0.1195008457, classif. loss = 0.0745434836
2025-10-15 20:21:02,180 | INFO | ---------starting evaluation-----------
2025-10-15 20:21:03,588 | INFO | validation:    0/ 531 (2025-10-15_20-21-03)
2025-10-15 20:21:16,510 | INFO | validation:  100/ 531 (2025-10-15_20-21-16)
2025-10-15 20:21:29,400 | INFO | validation:  200/ 531 (2025-10-15_20-21-29)
2025-10-15 20:21:42,283 | INFO | validation:  300/ 531 (2025-10-15_20-21-42)
2025-10-15 20:21:55,165 | INFO | validation:  400/ 531 (2025-10-15_20-21-55)
2025-10-15 20:22:08,065 | INFO | validation:  500/ 531 (2025-10-15_20-22-08)
2025-10-15 20:22:12,469 | INFO | Confusion Matrix of Localization:
[[136790715    233437]
 [   242971   1931341]]
2025-10-15 20:22:12,470 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99829638 0.00170362]
 [0.11174615 0.88825385]]
2025-10-15 20:22:12,470 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1707758   38108    1256   11270]
 [      0   26981  203877    4927    4738]
 [      0     662   21479   20657   10047]
 [      0   25215    7584    1728   88025]]
2025-10-15 20:22:12,470 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.71204373e-01 2.16720731e-02 7.14288964e-04
  6.40926483e-03]
 [0.00000000e+00 1.12176382e-01 8.47640350e-01 2.04845275e-02
  1.96987398e-02]
 [0.00000000e+00 1.25272022e-02 4.06452834e-01 3.90897909e-01
  1.90122055e-01]
 [0.00000000e+00 2.05749396e-01 6.18839350e-02 1.41001371e-02
  7.18266532e-01]]
2025-10-15 20:22:12,470 | INFO | lofF1 is 89.0206, clfF1 is 71.4335, oaF1 is 76.7096, sub class F1 score is [97.0591 79.7062 50.7462 74.3982]
2025-10-15 20:22:12,470 | INFO | ---------starting train set evaluation-----------
2025-10-15 20:22:12,471 | INFO | Train buffer size: 1517.
2025-10-15 20:22:18,167 | INFO | [TrainBuf] locF1 is 88.3616, clfF1 is 86.5951, oaF1 is 87.1251, sub class F1 score is [98.0624 86.3106 80.213  83.7415]
2025-10-15 20:22:18,179 | INFO | Damage Head - Attention Gate Statistics @ step 21868:
2025-10-15 20:22:18,179 | INFO |   ag3: {'mean': 0.36352574825286865, 'std': 0.20399056375026703, 'active_ratio': 0.197265625}
2025-10-15 20:22:18,179 | INFO |   ag2: {'mean': 0.6850765943527222, 'std': 0.20389746129512787, 'active_ratio': 0.804443359375}
2025-10-15 20:22:18,179 | INFO |   ag1: {'mean': 0.7605801820755005, 'std': 0.19426773488521576, 'active_ratio': 0.86627197265625}
2025-10-15 20:22:18,179 | INFO | Building Head - Attention Gate Statistics @ step 21868:
2025-10-15 20:22:18,179 | INFO |   ag3: {'mean': 0.6965968608856201, 'std': 0.24348337948322296, 'active_ratio': 0.7626953125}
2025-10-15 20:22:18,179 | INFO |   ag2: {'mean': 0.7168452143669128, 'std': 0.25373032689094543, 'active_ratio': 0.779541015625}
2025-10-15 20:22:18,179 | INFO |   ag1: {'mean': 0.09438327699899673, 'std': 0.1013811007142067, 'active_ratio': 0.0125732421875}
2025-10-15 20:22:37,753 | INFO | iter is 21900 / 25000 [skipped  607] | loc. loss = 0.2152098566, classif. loss = 0.6286406517
2025-10-15 20:23:07,489 | INFO | iter is 21950 / 25000 [skipped  610] | loc. loss = 0.0512270816, classif. loss = 0.0381434523
2025-10-15 20:23:39,023 | INFO | iter is 22000 / 25000 [skipped  610] | loc. loss = 0.0709737912, classif. loss = 0.5057045221
2025-10-15 20:24:08,784 | INFO | iter is 22050 / 25000 [skipped  613] | loc. loss = 0.1772802919, classif. loss = 0.0200329199
2025-10-15 20:24:40,317 | INFO | iter is 22100 / 25000 [skipped  613] | loc. loss = 0.0438540578, classif. loss = 1.1772119999
2025-10-15 20:25:10,673 | INFO | iter is 22150 / 25000 [skipped  615] | loc. loss = 0.1385500729, classif. loss = 0.8417220712
2025-10-15 20:25:42,225 | INFO | iter is 22200 / 25000 [skipped  615] | loc. loss = 0.0759480745, classif. loss = 0.1002657935
2025-10-15 20:26:12,009 | INFO | iter is 22250 / 25000 [skipped  618] | loc. loss = 0.1314335167, classif. loss = 0.0198985375
2025-10-15 20:26:43,584 | INFO | iter is 22300 / 25000 [skipped  618] | loc. loss = 0.1841675639, classif. loss = 0.5862690210
2025-10-15 20:27:15,150 | INFO | iter is 22350 / 25000 [skipped  618] | loc. loss = 0.1446734965, classif. loss = 0.5056905746
2025-10-15 20:27:46,779 | INFO | iter is 22400 / 25000 [skipped  618] | loc. loss = 0.1288764477, classif. loss = 0.0251083076
2025-10-15 20:28:17,740 | INFO | iter is 22450 / 25000 [skipped  619] | loc. loss = 0.2350242436, classif. loss = 1.1325607300
2025-10-15 20:28:49,388 | INFO | iter is 22500 / 25000 [skipped  619] | loc. loss = 0.1332292408, classif. loss = 0.5295119882
2025-10-15 20:29:18,511 | INFO | iter is 22550 / 25000 [skipped  623] | loc. loss = 0.3604172766, classif. loss = 2.1150543690
2025-10-15 20:29:48,261 | INFO | iter is 22600 / 25000 [skipped  626] | loc. loss = 0.4560006559, classif. loss = 1.9005110264
2025-10-15 20:30:18,066 | INFO | iter is 22650 / 25000 [skipped  629] | loc. loss = 0.2348773479, classif. loss = 0.0762119368
2025-10-15 20:30:47,823 | INFO | iter is 22700 / 25000 [skipped  632] | loc. loss = 0.2043986470, classif. loss = 0.6380969882
2025-10-15 20:31:19,473 | INFO | iter is 22750 / 25000 [skipped  632] | loc. loss = 0.1481252760, classif. loss = 0.0122288857
2025-10-15 20:31:51,093 | INFO | iter is 22800 / 25000 [skipped  632] | loc. loss = 0.2000535578, classif. loss = 0.2479781359
2025-10-15 20:32:50,679 | INFO | iter is 22900 / 25000 [skipped  638] | loc. loss = 0.0926354229, classif. loss = 0.5343676805
2025-10-15 20:33:21,672 | INFO | iter is 22950 / 25000 [skipped  639] | loc. loss = 0.1154370382, classif. loss = 0.3349171281
2025-10-15 20:33:52,124 | INFO | iter is 23000 / 25000 [skipped  641] | loc. loss = 0.0698300302, classif. loss = 0.0927378088
2025-10-15 20:34:21,904 | INFO | iter is 23050 / 25000 [skipped  644] | loc. loss = 0.1172684282, classif. loss = 0.4693194628
2025-10-15 20:34:51,679 | INFO | iter is 23100 / 25000 [skipped  647] | loc. loss = 0.0611879751, classif. loss = 0.0514532998
2025-10-15 20:35:22,749 | INFO | iter is 23150 / 25000 [skipped  648] | loc. loss = 0.0937007219, classif. loss = 1.1600034237
2025-10-15 20:36:24,236 | INFO | iter is 23250 / 25000 [skipped  651] | loc. loss = 0.1281034946, classif. loss = 0.1768367589
2025-10-15 20:36:54,635 | INFO | iter is 23300 / 25000 [skipped  653] | loc. loss = 0.2549615204, classif. loss = 0.5168576241
2025-10-15 20:37:25,659 | INFO | iter is 23350 / 25000 [skipped  654] | loc. loss = 0.0376747623, classif. loss = 0.0008148473
2025-10-15 20:37:56,683 | INFO | iter is 23400 / 25000 [skipped  655] | loc. loss = 0.1323834956, classif. loss = 2.0991439819
2025-10-15 20:38:15,111 | INFO | ---------starting evaluation-----------
2025-10-15 20:38:16,520 | INFO | validation:    0/ 531 (2025-10-15_20-38-16)
2025-10-15 20:38:29,395 | INFO | validation:  100/ 531 (2025-10-15_20-38-29)
2025-10-15 20:38:42,245 | INFO | validation:  200/ 531 (2025-10-15_20-38-42)
2025-10-15 20:38:55,091 | INFO | validation:  300/ 531 (2025-10-15_20-38-55)
2025-10-15 20:39:07,939 | INFO | validation:  400/ 531 (2025-10-15_20-39-07)
2025-10-15 20:39:20,777 | INFO | validation:  500/ 531 (2025-10-15_20-39-20)
2025-10-15 20:39:25,176 | INFO | Confusion Matrix of Localization:
[[136745116    279036]
 [   229099   1945213]]
2025-10-15 20:39:25,176 | INFO | Confusion Matrix of Localization - Normalized:
[[0.9979636 0.0020364]
 [0.1053662 0.8946338]]
2025-10-15 20:39:25,177 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1683405   58457    1427   15103]
 [      0   20550  208454    5740    5779]
 [      0     649   21999   24203    5994]
 [      0   20393    7504    2758   91897]]
2025-10-15 20:39:25,177 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.57354788e-01 3.32445780e-02 8.11536904e-04
  8.58909731e-03]
 [0.00000000e+00 8.54388146e-02 8.66669716e-01 2.38646616e-02
  2.40268082e-02]
 [0.00000000e+00 1.22811997e-02 4.16292932e-01 4.57999811e-01
  1.13426057e-01]
 [0.00000000e+00 1.66402833e-01 6.12311509e-02 2.25047327e-02
  7.49861283e-01]]
2025-10-15 20:39:25,177 | INFO | lofF1 is 88.4477, clfF1 is 73.6338, oaF1 is 78.0780, sub class F1 score is [96.6533 77.6456 55.6563 76.1604]
2025-10-15 20:39:25,177 | INFO | ---------starting train set evaluation-----------
2025-10-15 20:39:25,177 | INFO | Train buffer size: 1512.
2025-10-15 20:39:30,894 | INFO | [TrainBuf] locF1 is 88.8129, clfF1 is 86.7517, oaF1 is 87.3700, sub class F1 score is [97.9907 85.6107 79.5868 85.7788]
2025-10-15 20:39:30,906 | INFO | Damage Head - Attention Gate Statistics @ step 23430:
2025-10-15 20:39:30,906 | INFO |   ag3: {'mean': 0.34279054403305054, 'std': 0.27400025725364685, 'active_ratio': 0.2314453125}
2025-10-15 20:39:30,906 | INFO |   ag2: {'mean': 0.635603666305542, 'std': 0.22850443422794342, 'active_ratio': 0.724853515625}
2025-10-15 20:39:30,906 | INFO |   ag1: {'mean': 0.6802890300750732, 'std': 0.20934289693832397, 'active_ratio': 0.76446533203125}
2025-10-15 20:39:30,907 | INFO | Building Head - Attention Gate Statistics @ step 23430:
2025-10-15 20:39:30,907 | INFO |   ag3: {'mean': 0.8090301156044006, 'std': 0.2138994336128235, 'active_ratio': 0.8759765625}
2025-10-15 20:39:30,907 | INFO |   ag2: {'mean': 0.7668570280075073, 'std': 0.2401430308818817, 'active_ratio': 0.8271484375}
2025-10-15 20:39:30,907 | INFO |   ag1: {'mean': 0.15681549906730652, 'std': 0.19320052862167358, 'active_ratio': 0.08685302734375}
2025-10-15 20:39:43,530 | INFO | iter is 23450 / 25000 [skipped  656] | loc. loss = 0.1587844193, classif. loss = 0.3657382131
2025-10-15 20:40:13,803 | INFO | iter is 23500 / 25000 [skipped  658] | loc. loss = 0.2074830234, classif. loss = 0.6029784679
2025-10-15 20:40:44,173 | INFO | iter is 23550 / 25000 [skipped  660] | loc. loss = 0.1772102416, classif. loss = 0.0099089229
2025-10-15 20:41:15,116 | INFO | iter is 23600 / 25000 [skipped  661] | loc. loss = 0.1287062168, classif. loss = 0.6483030319
2025-10-15 20:41:46,042 | INFO | iter is 23650 / 25000 [skipped  662] | loc. loss = 0.1309760511, classif. loss = 0.3468560576
2025-10-15 20:42:17,039 | INFO | iter is 23700 / 25000 [skipped  663] | loc. loss = 0.1037254706, classif. loss = 0.0101660630
2025-10-15 20:42:48,037 | INFO | iter is 23750 / 25000 [skipped  664] | loc. loss = 0.0994462520, classif. loss = 0.9874041080
2025-10-15 20:43:18,978 | INFO | iter is 23800 / 25000 [skipped  665] | loc. loss = 0.1637790203, classif. loss = 0.7632645369
2025-10-15 20:43:48,758 | INFO | iter is 23850 / 25000 [skipped  668] | loc. loss = 0.1750974357, classif. loss = 0.2597104013
2025-10-15 20:44:18,484 | INFO | iter is 23900 / 25000 [skipped  671] | loc. loss = 0.1635363400, classif. loss = 0.3258959353
2025-10-15 20:44:50,055 | INFO | iter is 23950 / 25000 [skipped  671] | loc. loss = 0.0388479345, classif. loss = 0.3250500858
2025-10-15 20:45:19,854 | INFO | iter is 24000 / 25000 [skipped  674] | loc. loss = 0.0959872976, classif. loss = 0.2077290565
2025-10-15 20:45:51,438 | INFO | iter is 24050 / 25000 [skipped  674] | loc. loss = 0.1782382876, classif. loss = 0.3945111632
2025-10-15 20:46:23,086 | INFO | iter is 24100 / 25000 [skipped  674] | loc. loss = 0.0556782670, classif. loss = 0.3805202842
2025-10-15 20:46:54,057 | INFO | iter is 24150 / 25000 [skipped  675] | loc. loss = 0.1214011759, classif. loss = 0.0745455995
2025-10-15 20:47:25,089 | INFO | iter is 24200 / 25000 [skipped  676] | loc. loss = 0.0611466169, classif. loss = 0.3544559777
2025-10-15 20:47:56,668 | INFO | iter is 24250 / 25000 [skipped  676] | loc. loss = 0.2241540253, classif. loss = 0.5088241696
2025-10-15 20:48:28,330 | INFO | iter is 24300 / 25000 [skipped  676] | loc. loss = 0.1514772624, classif. loss = 0.1290467232
2025-10-15 20:48:59,316 | INFO | iter is 24350 / 25000 [skipped  677] | loc. loss = 0.1652149111, classif. loss = 0.2454715222
2025-10-15 20:49:29,734 | INFO | iter is 24400 / 25000 [skipped  679] | loc. loss = 0.1080843136, classif. loss = 0.2016434371
2025-10-15 20:50:01,346 | INFO | iter is 24450 / 25000 [skipped  679] | loc. loss = 0.0976853073, classif. loss = 0.0569486767
2025-10-15 20:50:31,114 | INFO | iter is 24500 / 25000 [skipped  682] | loc. loss = 0.1006066650, classif. loss = 0.4577650726
2025-10-15 20:51:02,796 | INFO | iter is 24550 / 25000 [skipped  682] | loc. loss = 0.0469454043, classif. loss = 0.5733171701
2025-10-15 20:51:33,816 | INFO | iter is 24600 / 25000 [skipped  683] | loc. loss = 0.0972552896, classif. loss = 0.3837462366
2025-10-15 20:52:04,832 | INFO | iter is 24650 / 25000 [skipped  684] | loc. loss = 0.1050876305, classif. loss = 1.1229264736
2025-10-15 20:52:35,910 | INFO | iter is 24700 / 25000 [skipped  685] | loc. loss = 0.1081173122, classif. loss = 0.0170948692
2025-10-15 20:53:07,551 | INFO | iter is 24750 / 25000 [skipped  685] | loc. loss = 0.0631887242, classif. loss = 0.2299971581
2025-10-15 20:53:38,578 | INFO | iter is 24800 / 25000 [skipped  686] | loc. loss = 0.1404029727, classif. loss = 0.6175426245
2025-10-15 20:54:09,609 | INFO | iter is 24850 / 25000 [skipped  687] | loc. loss = 0.2133157849, classif. loss = 0.0367742144
2025-10-15 20:54:40,084 | INFO | iter is 24900 / 25000 [skipped  689] | loc. loss = 0.1062249690, classif. loss = 0.3333006203
2025-10-15 20:55:11,128 | INFO | iter is 24950 / 25000 [skipped  690] | loc. loss = 0.1009822115, classif. loss = 0.0659404397
2025-10-15 20:55:37,134 | INFO | ---------starting evaluation-----------
2025-10-15 20:55:38,540 | INFO | validation:    0/ 531 (2025-10-15_20-55-38)
2025-10-15 20:55:51,407 | INFO | validation:  100/ 531 (2025-10-15_20-55-51)
2025-10-15 20:56:04,229 | INFO | validation:  200/ 531 (2025-10-15_20-56-04)
2025-10-15 20:56:17,051 | INFO | validation:  300/ 531 (2025-10-15_20-56-17)
2025-10-15 20:56:29,881 | INFO | validation:  400/ 531 (2025-10-15_20-56-29)
2025-10-15 20:56:42,724 | INFO | validation:  500/ 531 (2025-10-15_20-56-42)
2025-10-15 20:56:47,127 | INFO | Confusion Matrix of Localization:
[[136789342    234810]
 [   262703   1911609]]
2025-10-15 20:56:47,127 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99828636 0.00171364]
 [0.12082121 0.87917879]]
2025-10-15 20:56:47,127 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1679099   48570    1014   29709]
 [      0   26884  203329    2607    7703]
 [      0     662   32479   11581    8123]
 [      0    9954    5416    1412  105770]]
2025-10-15 20:56:47,127 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.54905960e-01 2.76218272e-02 5.76663224e-04
  1.68955500e-02]
 [0.00000000e+00 1.11773094e-01 8.45361982e-01 1.08388803e-02
  3.20260432e-02]
 [0.00000000e+00 1.25272022e-02 6.14608761e-01 2.19150345e-01
  1.53713691e-01]
 [0.00000000e+00 8.12226647e-02 4.41934852e-02 1.15216398e-02
  8.63062210e-01]]
2025-10-15 20:56:47,127 | INFO | lofF1 is 88.4854, clfF1 is 60.3110, oaF1 is 68.7634, sub class F1 score is [96.639  76.6821 33.3463 77.2447]
2025-10-15 20:56:47,128 | INFO | ---------starting train set evaluation-----------
2025-10-15 20:56:47,128 | INFO | Train buffer size: 1527.
2025-10-15 20:56:52,853 | INFO | [TrainBuf] locF1 is 88.7263, clfF1 is 86.9294, oaF1 is 87.4685, sub class F1 score is [97.8941 86.5351 79.5931 85.6213]
2025-10-15 20:56:52,865 | INFO | Damage Head - Attention Gate Statistics @ step 24992:
2025-10-15 20:56:52,865 | INFO |   ag3: {'mean': 0.39046815037727356, 'std': 0.2065652310848236, 'active_ratio': 0.236328125}
2025-10-15 20:56:52,865 | INFO |   ag2: {'mean': 0.611566424369812, 'std': 0.2245880663394928, 'active_ratio': 0.677978515625}
2025-10-15 20:56:52,865 | INFO |   ag1: {'mean': 0.8052372932434082, 'std': 0.16682866215705872, 'active_ratio': 0.9344482421875}
2025-10-15 20:56:52,866 | INFO | Building Head - Attention Gate Statistics @ step 24992:
2025-10-15 20:56:52,866 | INFO |   ag3: {'mean': 0.7759069204330444, 'std': 0.22978489100933075, 'active_ratio': 0.8466796875}
2025-10-15 20:56:52,866 | INFO |   ag2: {'mean': 0.8796677589416504, 'std': 0.1569773405790329, 'active_ratio': 0.956298828125}
2025-10-15 20:56:52,866 | INFO |   ag1: {'mean': 0.16902601718902588, 'std': 0.17865754663944244, 'active_ratio': 0.07464599609375}
2025-10-15 20:56:56,648 | INFO | iter is 25000 / 25000 [skipped  693] | loc. loss = 0.1333493590, classif. loss = 0.0004054855
2025-10-15 20:56:56,648 | INFO | -----------Training is completed-----------
2025-10-15 20:56:56,907 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD/model_step25000_last.pth
2025-10-15 20:56:56,908 | INFO | !! Total Skipped: 693 (2.77%)
2025-10-15 20:56:56,909 | INFO | ---------starting evaluation-----------
2025-10-15 20:56:58,272 | INFO | validation:    0/ 531 (2025-10-15_20-56-58)
2025-10-15 20:57:11,125 | INFO | validation:  100/ 531 (2025-10-15_20-57-11)
2025-10-15 20:57:23,970 | INFO | validation:  200/ 531 (2025-10-15_20-57-23)
2025-10-15 20:57:36,822 | INFO | validation:  300/ 531 (2025-10-15_20-57-36)
2025-10-15 20:57:49,671 | INFO | validation:  400/ 531 (2025-10-15_20-57-49)
2025-10-15 20:58:02,518 | INFO | validation:  500/ 531 (2025-10-15_20-58-02)
2025-10-15 20:58:06,927 | INFO | Confusion Matrix of Localization:
[[136819483    204669]
 [   294401   1879911]]
2025-10-15 20:58:06,927 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99850633 0.00149367]
 [0.13539961 0.86460039]]
2025-10-15 20:58:06,927 | INFO | Confusion Matrix of Classification:
[[      0       0       0       0       0]
 [      0 1678028   49766     504   30094]
 [      0   26408  203990    1064    9061]
 [      0     662   32421   10964    8798]
 [      0   10419    5028    1127  105978]]
2025-10-15 20:58:06,927 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.54296880e-01 2.83019941e-02 2.86625508e-04
  1.71145001e-02]
 [0.00000000e+00 1.09794074e-01 8.48110160e-01 4.42369337e-03
  3.76720729e-02]
 [0.00000000e+00 1.25272022e-02 6.13511212e-01 2.07474690e-01
  1.66486896e-01]
 [0.00000000e+00 8.50169724e-02 4.10274822e-02 9.19609635e-03
  8.64759449e-01]]
2025-10-15 20:58:06,927 | INFO | lofF1 is 88.2817, clfF1 is 59.9188, oaF1 is 68.4276, sub class F1 score is [96.6075 76.7272 32.9724 76.6615]
2025-10-15 20:58:06,928 | INFO | loc_f1_score=88.2817, harmonic_mean_f1=59.9188, oaf1=68.4276, damage_f1_score=array([96.6075, 76.7272, 32.9724, 76.6615])
2025-10-15 20:58:06,952 | INFO | Removed non-best model: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD/model_step3124.pth
2025-10-15 20:58:06,976 | INFO | Removed non-best model: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD/model_step9372.pth
2025-10-15 20:58:06,999 | INFO | Removed non-best model: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD/model_step1562.pth
2025-10-15 20:58:07,023 | INFO | Removed non-best model: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD/model_step7810.pth
2025-10-15 20:58:07,023 | INFO | Best model kept: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-15_16-20-21_MambaBDA_Base_PakistanFloodingWithValid_AGBD/model_step12496_best.pth
2025-10-15 20:58:07,023 | INFO | ---------starting train set evaluation-----------
2025-10-15 20:58:07,023 | INFO | Train buffer size: 6.
2025-10-15 20:58:07,046 | INFO | [TrainBuf] locF1 is 84.7014, clfF1 is 0.0000, oaF1 is 25.4104, sub class F1 score is [99.1316 68.9937  0.     93.8088]
2025-10-15 20:58:07,048 | INFO | Validation Results:
2025-10-15 20:58:07,048 | INFO | [TEST ] Step  1562: (83.8192, 56.4926, 64.6905, array([96.2184, 71.1193, 32.5577, 63.9502]))
2025-10-15 20:58:07,048 | INFO | [TRAIN] Step  1562: (74.7209, 54.2567, 60.3959, array([94.9475, 60.6501, 32.6484, 62.2117]))

2025-10-15 20:58:07,048 | INFO | [TEST ] Step  3124: (85.3577, 65.8081, 71.673, array([96.1287, 72.5389, 44.5479, 70.6885]))
2025-10-15 20:58:07,048 | INFO | [TRAIN] Step  3124: (83.3905, 65.4464, 70.8296, array([96.26  , 70.1046, 44.7305, 70.8733]))

2025-10-15 20:58:07,048 | INFO | [TEST ] Step  4686: (86.3354, 59.7332, 67.7138, array([96.7848, 75.9101, 34.7791, 68.0001]))
2025-10-15 20:58:07,049 | INFO | [TRAIN] Step  4686: (85.348, 73.3625, 76.9582, array([96.4151, 73.4657, 59.5887, 72.6827]))

2025-10-15 20:58:07,049 | INFO | [TEST ] Step  6248: (87.3027, 62.2092, 69.7373, array([96.8503, 77.5358, 36.3722, 73.6206]))
2025-10-15 20:58:07,049 | INFO | [TRAIN] Step  6248: (85.5861, 74.7325, 77.9886, array([96.5452, 74.9058, 59.3712, 77.0826]))

2025-10-15 20:58:07,049 | INFO | [TEST ] Step  7810: (85.0854, 67.9508, 73.0912, array([93.9891, 66.0285, 51.7451, 72.695 ]))
2025-10-15 20:58:07,049 | INFO | [TRAIN] Step  7810: (86.3868, 76.9053, 79.7498, array([96.6655, 75.8875, 64.6898, 76.7384]))

2025-10-15 20:58:07,049 | INFO | [TEST ] Step  9372: (87.6209, 71.8998, 76.6162, array([96.4482, 77.7071, 54.7855, 70.7072]))
2025-10-15 20:58:07,049 | INFO | [TRAIN] Step  9372: (86.8151, 80.4926, 82.3894, array([97.07  , 78.5748, 72.267 , 77.9554]))

2025-10-15 20:58:07,049 | INFO | [TEST ] Step 10934: (87.2678, 64.7417, 71.4995, array([96.6498, 62.0047, 47.1512, 70.9162]))
2025-10-15 20:58:07,049 | INFO | [TRAIN] Step 10934: (86.8898, 80.0743, 82.1189, array([97.0846, 78.4862, 70.8299, 78.1621]))

2025-10-15 20:58:07,049 | INFO | [TEST ] Step 12496: (87.8402, 75.6328, 79.295, array([96.9555, 78.1321, 61.8222, 73.5356]))
2025-10-15 20:58:07,049 | INFO | [TRAIN] Step 12496: (86.9791, 81.3034, 83.0061, array([97.2535, 80.3137, 72.9797, 78.355 ]))

2025-10-15 20:58:07,049 | INFO | [TEST ] Step 14058: (88.2015, 73.0354, 77.5852, array([96.6033, 76.6475, 55.1207, 75.5996]))
2025-10-15 20:58:07,049 | INFO | [TRAIN] Step 14058: (87.877, 81.9969, 83.761, array([97.4754, 83.4924, 70.4343, 80.9812]))

2025-10-15 20:58:07,049 | INFO | [TEST ] Step 15620: (88.1725, 68.8945, 74.6779, array([96.4746, 75.2332, 46.8916, 76.4725]))
2025-10-15 20:58:07,049 | INFO | [TRAIN] Step 15620: (87.9606, 85.1164, 85.9696, array([97.6239, 83.56  , 78.5824, 82.9315]))

2025-10-15 20:58:07,049 | INFO | [TEST ] Step 17182: (88.2187, 69.0054, 74.7694, array([96.7879, 77.0657, 47.2884, 74.009 ]))
2025-10-15 20:58:07,049 | INFO | [TRAIN] Step 17182: (88.3724, 85.7531, 86.5389, array([97.774 , 86.6262, 79.1816, 81.6671]))

2025-10-15 20:58:07,049 | INFO | [TEST ] Step 18744: (88.4816, 71.7118, 76.7428, array([96.6223, 76.9264, 52.9846, 73.7658]))
2025-10-15 20:58:07,050 | INFO | [TRAIN] Step 18744: (88.3598, 85.0611, 86.0507, array([97.7071, 84.9324, 77.6235, 82.4161]))

2025-10-15 20:58:07,050 | INFO | [TEST ] Step 20306: (88.7477, 70.4508, 75.9398, array([97.0831, 78.6232, 49.0382, 74.8187]))
2025-10-15 20:58:07,050 | INFO | [TRAIN] Step 20306: (88.602, 85.001, 86.0813, array([97.8034, 85.7419, 76.6215, 82.5109]))

2025-10-15 20:58:07,050 | INFO | [TEST ] Step 21868: (89.0206, 71.4335, 76.7096, array([97.0591, 79.7062, 50.7462, 74.3982]))
2025-10-15 20:58:07,050 | INFO | [TRAIN] Step 21868: (88.3616, 86.5951, 87.1251, array([98.0624, 86.3106, 80.213 , 83.7415]))

2025-10-15 20:58:07,050 | INFO | [TEST ] Step 23430: (88.4477, 73.6338, 78.078, array([96.6533, 77.6456, 55.6563, 76.1604]))
2025-10-15 20:58:07,050 | INFO | [TRAIN] Step 23430: (88.8129, 86.7517, 87.37, array([97.9907, 85.6107, 79.5868, 85.7788]))

2025-10-15 20:58:07,050 | INFO | [TEST ] Step 24992: (88.4854, 60.311, 68.7634, array([96.639 , 76.6821, 33.3463, 77.2447]))
2025-10-15 20:58:07,050 | INFO | [TRAIN] Step 24992: (88.7263, 86.9294, 87.4685, array([97.8941, 86.5351, 79.5931, 85.6213]))

2025-10-15 20:58:07,050 | INFO | [TEST ] Step    -1: (88.2817, 59.9188, 68.4276, array([96.6075, 76.7272, 32.9724, 76.6615]))
2025-10-15 20:58:07,050 | INFO | [TRAIN] Step    -1: (84.7014, 0.0, 25.4104, array([99.1316, 68.9937,  0.    , 93.8088]))

2025-10-15 20:58:07,050 | INFO | The accuracy of the best round is: [87.8402, 75.6328, 79.295, array([96.9555, 78.1321, 61.8222, 73.5356])]
2025-10-15 20:58:07,077 | INFO | MAIN - DONE.
2025-10-15 20:58:07,077 | INFO | MAIN - EXIT.
