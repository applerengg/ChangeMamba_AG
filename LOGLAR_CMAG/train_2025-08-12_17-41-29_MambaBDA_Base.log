=> merge config from /storage/alperengenc/change_detection/ChangeMamba_AG/changedetection/configs/vssm1/vssm_base_224.yaml
Successfully load ckpt /storage/alperengenc/change_detection/ChangeMamba_AG/pretrained_weight/vssm_base_0229_ckpt_epoch_237.pth
_IncompatibleKeys(missing_keys=['outnorm0.weight', 'outnorm0.bias', 'outnorm1.weight', 'outnorm1.bias', 'outnorm2.weight', 'outnorm2.bias', 'outnorm3.weight', 'outnorm3.bias'], unexpected_keys=['classifier.norm.weight', 'classifier.norm.bias', 'classifier.head.weight', 'classifier.head.bias'])
False
iter is 50, loc. loss = 0.7180725336074829  , classif. loss = 1.3724994659423828   (2025-08-12_17-41-46)
iter is 100, loc. loss = 0.7358890771865845  , classif. loss = 0.7426309585571289   (2025-08-12_17-42-00)
iter is 150, loc. loss = 0.48044151067733765 , classif. loss = 0.39384084939956665  (2025-08-12_17-42-14)
iter is 200, loc. loss = 0.5579816102981567  , classif. loss = 0.5963493585586548   (2025-08-12_17-42-28)
iter is 250, loc. loss = 0.35975542664527893 , classif. loss = 0.4334752559661865   (2025-08-12_17-42-42)
iter is 300, loc. loss = 0.011397354304790497, classif. loss = 0.3206700384616852   (2025-08-12_17-42-56)
iter is 350, loc. loss = 0.29120051860809326 , classif. loss = 1.1508798599243164   (2025-08-12_17-43-10)
iter is 400, loc. loss = 0.3625431954860687  , classif. loss = 0.8407199382781982   (2025-08-12_17-43-24)
iter is 450, loc. loss = 0.38729244470596313 , classif. loss = 0.5347540974617004   (2025-08-12_17-43-38)
iter is 500, loc. loss = 0.4667113125324249  , classif. loss = 0.30421608686447144  (2025-08-12_17-43-52)
iter is 550, loc. loss = 0.2697279751300812  , classif. loss = 0.17523197829723358  (2025-08-12_17-44-06)
iter is 600, loc. loss = 0.0005199001170694828, classif. loss = 0.056746628135442734 (2025-08-12_17-44-20)
iter is 650, loc. loss = 0.27657458186149597 , classif. loss = 0.13867144286632538  (2025-08-12_17-44-34)
iter is 700, loc. loss = 0.005414735060185194, classif. loss = 0.07518808543682098  (2025-08-12_17-44-48)
iter is 750, loc. loss = 0.19152295589447021 , classif. loss = 0.12051175534725189  (2025-08-12_17-45-02)
iter is 800, loc. loss = 0.19873327016830444 , classif. loss = 1.256129264831543    (2025-08-12_17-45-16)
iter is 850, loc. loss = 0.0022597787901759148, classif. loss = 0.036683812737464905 (2025-08-12_17-45-30)
iter is 900, loc. loss = 0.6416828036308289  , classif. loss = 0.42886877059936523  (2025-08-12_17-45-44)
iter is 950, loc. loss = 0.002931188326328993, classif. loss = 0.05973273515701294  (2025-08-12_17-45-58)
iter is 1000, loc. loss = 0.29277679324150085 , classif. loss = 0.2263563573360443   (2025-08-12_17-46-12)
iter is 1050, loc. loss = 0.3900003433227539  , classif. loss = 0.22792568802833557  (2025-08-12_17-46-26)
iter is 1100, loc. loss = 0.3173239827156067  , classif. loss = 0.13085122406482697  (2025-08-12_17-46-40)
iter is 1150, loc. loss = 0.24268952012062073 , classif. loss = 0.7567817568778992   (2025-08-12_17-46-54)
iter is 1200, loc. loss = 0.3114843964576721  , classif. loss = 0.28711017966270447  (2025-08-12_17-47-08)
iter is 1250, loc. loss = 0.32032179832458496 , classif. loss = 0.2019701898097992   (2025-08-12_17-47-22)
iter is 1300, loc. loss = 0.0007886572857387364, classif. loss = 0.1197829395532608   (2025-08-12_17-47-36)
iter is 1350, loc. loss = 0.3620086908340454  , classif. loss = 0.08986049890518188  (2025-08-12_17-47-50)
iter is 1400, loc. loss = 0.22569189965724945 , classif. loss = 0.18781958520412445  (2025-08-12_17-48-05)
iter is 1450, loc. loss = 0.18102915585041046 , classif. loss = 0.024595480412244797 (2025-08-12_17-48-19)
iter is 1500, loc. loss = 0.4035598337650299  , classif. loss = 0.79979407787323     (2025-08-12_17-48-33)
iter is 1550, loc. loss = 0.00479464465752244 , classif. loss = 0.04246830940246582  (2025-08-12_17-48-47)
iter is 1600, loc. loss = 0.37100374698638916 , classif. loss = 1.2866714000701904   (2025-08-12_17-49-01)
iter is 1650, loc. loss = 0.003942342475056648, classif. loss = 0.03359074145555496  (2025-08-12_17-49-15)
iter is 1700, loc. loss = 0.3459494113922119  , classif. loss = 0.18971258401870728  (2025-08-12_17-49-29)
iter is 1750, loc. loss = 0.0017933633644133806, classif. loss = 0.04406169801950455  (2025-08-12_17-49-43)
iter is 1800, loc. loss = 0.24081285297870636 , classif. loss = 0.36337533593177795  (2025-08-12_17-49-57)
iter is 1850, loc. loss = 0.0007459729677066207, classif. loss = 0.08202724158763885  (2025-08-12_17-50-11)
iter is 1900, loc. loss = 0.27042141556739807 , classif. loss = 0.08991008251905441  (2025-08-12_17-50-25)
iter is 1950, loc. loss = 0.32650354504585266 , classif. loss = 0.09531016647815704  (2025-08-12_17-50-39)
iter is 2000, loc. loss = 0.3387061655521393  , classif. loss = 0.2100929617881775   (2025-08-12_17-50-53)
iter is 2050, loc. loss = 0.2625488340854645  , classif. loss = 0.1696963608264923   (2025-08-12_17-51-07)
iter is 2100, loc. loss = 0.29249489307403564 , classif. loss = 0.4647757112979889   (2025-08-12_17-51-21)
iter is 2150, loc. loss = 0.01209015492349863 , classif. loss = 1.4067450761795044   (2025-08-12_17-51-35)
iter is 2200, loc. loss = 0.000224700866965577, classif. loss = 0.03515190631151199  (2025-08-12_17-51-49)
iter is 2250, loc. loss = 0.0008554537198506296, classif. loss = 0.040778886526823044 (2025-08-12_17-52-03)
iter is 2300, loc. loss = 0.4503815770149231  , classif. loss = 0.35927021503448486  (2025-08-12_17-52-17)
iter is 2350, loc. loss = 0.31226685643196106 , classif. loss = 0.14245954155921936  (2025-08-12_17-52-31)
iter is 2400, loc. loss = 0.004038777202367783, classif. loss = 0.01627020537853241  (2025-08-12_17-52-45)
iter is 2450, loc. loss = 0.25302350521087646 , classif. loss = 0.17625851929187775  (2025-08-12_17-52-59)
iter is 2500, loc. loss = 0.2732934355735779  , classif. loss = 1.6148626804351807   (2025-08-12_17-53-13)
iter is 2550, loc. loss = 0.3339615762233734  , classif. loss = 0.10966867208480835  (2025-08-12_17-53-27)
iter is 2600, loc. loss = 0.43022823333740234 , classif. loss = 0.1967637538909912   (2025-08-12_17-53-41)
iter is 2650, loc. loss = 0.2887568473815918  , classif. loss = 0.09912042319774628  (2025-08-12_17-53-55)
iter is 2700, loc. loss = 0.3270328938961029  , classif. loss = 2.334367275238037    (2025-08-12_17-54-09)
iter is 2750, loc. loss = 0.1766708344221115  , classif. loss = 1.194831132888794    (2025-08-12_17-54-23)
iter is 2800, loc. loss = 0.0006362266140058637, classif. loss = 0.39997398853302     (2025-08-12_17-54-37)
iter is 2850, loc. loss = 0.2935672104358673  , classif. loss = 0.7697471380233765   (2025-08-12_17-54-51)
iter is 2900, loc. loss = 0.16661883890628815 , classif. loss = 0.4038553833961487   (2025-08-12_17-55-05)
iter is 2950, loc. loss = 0.5024224519729614  , classif. loss = 0.45773154497146606  (2025-08-12_17-55-19)
iter is 3000, loc. loss = 0.25802376866340637 , classif. loss = 0.08551468700170517  (2025-08-12_17-55-33)
iter is 3050, loc. loss = 0.14567410945892334 , classif. loss = 1.182432770729065    (2025-08-12_17-55-47)
iter is 3100, loc. loss = 0.29656365513801575 , classif. loss = 0.2909168004989624   (2025-08-12_17-56-01)
iter is 3150, loc. loss = 0.3038809299468994  , classif. loss = 0.9488015174865723   (2025-08-12_17-56-15)
iter is 3200, loc. loss = 0.2724972367286682  , classif. loss = 0.2132788896560669   (2025-08-12_17-56-29)
iter is 3250, loc. loss = 0.2770003378391266  , classif. loss = 0.6410923004150391   (2025-08-12_17-56-43)
iter is 3300, loc. loss = 0.17433319985866547 , classif. loss = 0.12740099430084229  (2025-08-12_17-56-57)
iter is 3350, loc. loss = 0.2577928602695465  , classif. loss = 0.25759243965148926  (2025-08-12_17-57-11)
iter is 3400, loc. loss = 0.31151482462882996 , classif. loss = 0.5471797585487366   (2025-08-12_17-57-25)
iter is 3450, loc. loss = 0.25024595856666565 , classif. loss = 0.23626381158828735  (2025-08-12_17-57-39)
iter is 3500, loc. loss = 0.2232409119606018  , classif. loss = 0.15721581876277924  (2025-08-12_17-57-53)
iter is 3550, loc. loss = 0.00020812875300180167, classif. loss = 0.03206402808427811  (2025-08-12_17-58-07)
iter is 3600, loc. loss = 0.415225088596344   , classif. loss = 0.2755470871925354   (2025-08-12_17-58-21)
iter is 3650, loc. loss = 0.0007619949756190181, classif. loss = 0.023400401696562767 (2025-08-12_17-58-35)
iter is 3700, loc. loss = 0.317342609167099   , classif. loss = 0.06815467774868011  (2025-08-12_17-58-49)
iter is 3750, loc. loss = 0.2651838958263397  , classif. loss = 0.022003173828125    (2025-08-12_17-59-03)
iter is 3800, loc. loss = 0.6198473572731018  , classif. loss = 1.8448209762573242   (2025-08-12_17-59-17)
iter is 3850, loc. loss = 0.2739712595939636  , classif. loss = 0.2355078160762787   (2025-08-12_17-59-31)
iter is 3900, loc. loss = 0.1582692563533783  , classif. loss = 0.042102593928575516 (2025-08-12_17-59-45)
iter is 3950, loc. loss = 0.23641005158424377 , classif. loss = 0.31084346771240234  (2025-08-12_17-59-59)
iter is 4000, loc. loss = 0.5241349935531616  , classif. loss = 0.3339044749736786   (2025-08-12_18-00-13)
iter is 4050, loc. loss = 0.0005199818406254053, classif. loss = 0.022729484364390373 (2025-08-12_18-00-27)
iter is 4100, loc. loss = 0.22857096791267395 , classif. loss = 0.09942713379859924  (2025-08-12_18-00-41)
iter is 4150, loc. loss = 0.45951712131500244 , classif. loss = 0.3102990388870239   (2025-08-12_18-00-55)
iter is 4200, loc. loss = 0.23043745756149292 , classif. loss = 0.05231577530503273  (2025-08-12_18-01-09)
iter is 4250, loc. loss = 0.0006955133285373449, classif. loss = 0.0333755686879158   (2025-08-12_18-01-23)
iter is 4300, loc. loss = 0.2295425981283188  , classif. loss = 0.08294901251792908  (2025-08-12_18-01-37)
iter is 4350, loc. loss = 0.13715746998786926 , classif. loss = 0.0358576700091362   (2025-08-12_18-01-51)
iter is 4400, loc. loss = 0.16965672373771667 , classif. loss = 0.026702353730797768 (2025-08-12_18-02-05)
iter is 4450, loc. loss = 0.28034707903862    , classif. loss = 0.09678584337234497  (2025-08-12_18-02-19)
iter is 4500, loc. loss = 0.0010903483489528298, classif. loss = 0.03282073512673378  (2025-08-12_18-02-33)
iter is 4550, loc. loss = 0.0003112301928922534, classif. loss = 0.018242403864860535 (2025-08-12_18-02-47)
iter is 4600, loc. loss = 0.39788520336151123 , classif. loss = 0.36332371830940247  (2025-08-12_18-03-01)
iter is 4650, loc. loss = 0.2402571588754654  , classif. loss = 0.11116041243076324  (2025-08-12_18-03-15)
iter is 4700, loc. loss = 0.0022180378437042236, classif. loss = 0.015402357093989849 (2025-08-12_18-03-29)
iter is 4750, loc. loss = 0.5118435025215149  , classif. loss = 1.8984893560409546   (2025-08-12_18-03-43)
iter is 4800, loc. loss = 0.3468256890773773  , classif. loss = 0.07480992376804352  (2025-08-12_18-03-57)
iter is 4850, loc. loss = 0.5057430267333984  , classif. loss = 0.1752551645040512   (2025-08-12_18-04-11)
iter is 4900, loc. loss = 0.2784828245639801  , classif. loss = 1.1428053379058838   (2025-08-12_18-04-25)
iter is 4950, loc. loss = 0.359561949968338   , classif. loss = 0.5750362873077393   (2025-08-12_18-04-39)
iter is 5000, loc. loss = 0.2645494341850281  , classif. loss = 0.07497154176235199  (2025-08-12_18-04-53)
---------starting evaluation-----------
validation:    0/1866 (2025-08-12_18-04-54)
validation:  100/1866 (2025-08-12_18-05-36)
validation:  200/1866 (2025-08-12_18-06-19)
validation:  300/1866 (2025-08-12_18-07-01)
validation:  400/1866 (2025-08-12_18-07-44)
validation:  500/1866 (2025-08-12_18-08-26)
validation:  600/1866 (2025-08-12_18-09-09)
validation:  700/1866 (2025-08-12_18-09-51)
validation:  800/1866 (2025-08-12_18-10-34)
validation:  900/1866 (2025-08-12_18-11-16)
validation: 1000/1866 (2025-08-12_18-11-58)
validation: 1100/1866 (2025-08-12_18-12-41)
validation: 1200/1866 (2025-08-12_18-13-23)
validation: 1300/1866 (2025-08-12_18-14-06)
validation: 1400/1866 (2025-08-12_18-14-48)
validation: 1500/1866 (2025-08-12_18-15-31)
validation: 1600/1866 (2025-08-12_18-16-13)
validation: 1700/1866 (2025-08-12_18-16-56)
validation: 1800/1866 (2025-08-12_18-17-38)
lofF1 is 0.7437891435784205, clfF1 is 0.0, oaF1 is 0.22313674307352616, sub class F1 score is [0.39187828 0.         0.         0.        ]
iter is 5050, loc. loss = 0.3903900384902954  , classif. loss = 0.17035594582557678  (2025-08-12_18-18-22)
iter is 5100, loc. loss = 0.18864157795906067 , classif. loss = 0.2030782699584961   (2025-08-12_18-18-39)
iter is 5150, loc. loss = 0.274301141500473   , classif. loss = 0.2973431348800659   (2025-08-12_18-19-00)
iter is 5200, loc. loss = 0.13010820746421814 , classif. loss = 0.06260782480239868  (2025-08-12_18-19-15)
iter is 5250, loc. loss = 0.2837238609790802  , classif. loss = 0.14985138177871704  (2025-08-12_18-19-30)
iter is 5300, loc. loss = 0.32964643836021423 , classif. loss = 0.2041294425725937   (2025-08-12_18-19-47)
iter is 5350, loc. loss = 0.004001953639090061, classif. loss = 0.02249329909682274  (2025-08-12_18-20-01)
iter is 5400, loc. loss = 0.11569385230541229 , classif. loss = 1.8324089050292969   (2025-08-12_18-20-15)
iter is 5450, loc. loss = 0.00459077674895525 , classif. loss = 0.8386896848678589   (2025-08-12_18-20-30)
iter is 5500, loc. loss = 0.2118656188249588  , classif. loss = 0.22857555747032166  (2025-08-12_18-20-45)
iter is 5550, loc. loss = 0.0024539614096283913, classif. loss = 0.24031537771224976  (2025-08-12_18-20-59)
iter is 5600, loc. loss = 0.19775953888893127 , classif. loss = 1.062997579574585    (2025-08-12_18-21-13)
iter is 5650, loc. loss = 0.009209606796503067, classif. loss = 0.0318136028945446   (2025-08-12_18-21-27)
iter is 5700, loc. loss = 0.26525402069091797 , classif. loss = 0.17818617820739746  (2025-08-12_18-21-41)
iter is 5750, loc. loss = 0.16255754232406616 , classif. loss = 0.11793376505374908  (2025-08-12_18-21-56)
iter is 5800, loc. loss = 0.0004154294729232788, classif. loss = 0.0139173474162817   (2025-08-12_18-22-10)
iter is 5850, loc. loss = 0.33589571714401245 , classif. loss = 0.31799983978271484  (2025-08-12_18-22-24)
iter is 5900, loc. loss = 0.2766541838645935  , classif. loss = 0.07855551689863205  (2025-08-12_18-22-38)
iter is 5950, loc. loss = 0.3264096975326538  , classif. loss = 1.2423863410949707   (2025-08-12_18-22-52)
iter is 6000, loc. loss = 0.2842382788658142  , classif. loss = 0.1892630159854889   (2025-08-12_18-23-06)
iter is 6050, loc. loss = 0.007974972948431969, classif. loss = 0.04939596727490425  (2025-08-12_18-23-20)
iter is 6100, loc. loss = 0.000695999595336616, classif. loss = 0.025046691298484802 (2025-08-12_18-23-35)
iter is 6150, loc. loss = 0.1630474030971527  , classif. loss = 0.15032020211219788  (2025-08-12_18-23-49)
iter is 6200, loc. loss = 0.11951905488967896 , classif. loss = 0.019897490739822388 (2025-08-12_18-24-03)
iter is 6250, loc. loss = 0.36397409439086914 , classif. loss = 0.9028880596160889   (2025-08-12_18-24-17)
iter is 6300, loc. loss = 0.2956721782684326  , classif. loss = 0.2780705690383911   (2025-08-12_18-24-31)
iter is 6350, loc. loss = 0.005203811917454004, classif. loss = 0.030854951590299606 (2025-08-12_18-24-45)
iter is 6400, loc. loss = 0.25598394870758057 , classif. loss = 0.2176668792963028   (2025-08-12_18-24-59)
iter is 6450, loc. loss = 0.2942717969417572  , classif. loss = 0.22801584005355835  (2025-08-12_18-25-13)
iter is 6500, loc. loss = 0.004391858819872141, classif. loss = 0.11157020181417465  (2025-08-12_18-25-27)
iter is 6550, loc. loss = 0.15500736236572266 , classif. loss = 0.11752966791391373  (2025-08-12_18-25-41)
iter is 6600, loc. loss = 0.1770997792482376  , classif. loss = 0.29263508319854736  (2025-08-12_18-25-55)
iter is 6650, loc. loss = 0.0005916248774155974, classif. loss = 0.011343598365783691 (2025-08-12_18-26-09)
iter is 6700, loc. loss = 0.12607605755329132 , classif. loss = 0.034470126032829285 (2025-08-12_18-26-23)
iter is 6750, loc. loss = 0.20802974700927734 , classif. loss = 0.19907286763191223  (2025-08-12_18-26-38)
iter is 6800, loc. loss = 0.10070963948965073 , classif. loss = 0.06242162734270096  (2025-08-12_18-26-52)
iter is 6850, loc. loss = 0.13034312427043915 , classif. loss = 0.04183381423354149  (2025-08-12_18-27-06)
iter is 6900, loc. loss = 0.20484180748462677 , classif. loss = 0.05911068245768547  (2025-08-12_18-27-20)
iter is 6950, loc. loss = 0.3814695179462433  , classif. loss = 0.16326569020748138  (2025-08-12_18-27-34)
iter is 7000, loc. loss = 0.007394660264253616, classif. loss = 0.869255781173706    (2025-08-12_18-27-48)
iter is 7050, loc. loss = 0.32137781381607056 , classif. loss = 0.4012211561203003   (2025-08-12_18-28-02)
iter is 7100, loc. loss = 0.39546602964401245 , classif. loss = 0.281972736120224    (2025-08-12_18-28-16)
iter is 7150, loc. loss = 0.4235893785953522  , classif. loss = 0.12717832624912262  (2025-08-12_18-28-30)
iter is 7200, loc. loss = 0.00014073355123400688, classif. loss = 0.018605966120958328 (2025-08-12_18-28-44)
iter is 7250, loc. loss = 0.15277977287769318 , classif. loss = 0.0591948963701725   (2025-08-12_18-28-58)
iter is 7300, loc. loss = 0.3106541335582733  , classif. loss = 0.21047547459602356  (2025-08-12_18-29-12)
iter is 7350, loc. loss = 0.42997464537620544 , classif. loss = 0.18277789652347565  (2025-08-12_18-29-26)
iter is 7400, loc. loss = 0.00441872188821435 , classif. loss = 0.05434933304786682  (2025-08-12_18-29-41)
iter is 7450, loc. loss = 0.14308862388134003 , classif. loss = 0.13471630215644836  (2025-08-12_18-29-55)
iter is 7500, loc. loss = 0.227530375123024   , classif. loss = 0.1555863320827484   (2025-08-12_18-30-09)
iter is 7550, loc. loss = 0.5129662752151489  , classif. loss = 0.5263763070106506   (2025-08-12_18-30-23)
iter is 7600, loc. loss = 0.41655468940734863 , classif. loss = 1.7134995460510254   (2025-08-12_18-30-37)
iter is 7650, loc. loss = 0.32273679971694946 , classif. loss = 0.287793904542923    (2025-08-12_18-30-51)
iter is 7700, loc. loss = 0.0001041361247189343, classif. loss = 0.03326255455613136  (2025-08-12_18-31-05)
iter is 7750, loc. loss = 0.0010009139077737927, classif. loss = 0.07400073111057281  (2025-08-12_18-31-19)
iter is 7800, loc. loss = 0.005623406730592251, classif. loss = 0.324118971824646    (2025-08-12_18-31-33)
iter is 7850, loc. loss = 0.22899925708770752 , classif. loss = 0.1470307558774948   (2025-08-12_18-31-47)
iter is 7900, loc. loss = 0.0023201347794383764, classif. loss = 0.03894065320491791  (2025-08-12_18-32-01)
iter is 7950, loc. loss = 0.14521627128124237 , classif. loss = 0.09520797431468964  (2025-08-12_18-32-15)
iter is 8000, loc. loss = 0.30909299850463867 , classif. loss = 0.1295347809791565   (2025-08-12_18-32-29)
iter is 8050, loc. loss = 0.0004526380798779428, classif. loss = 0.03490849584341049  (2025-08-12_18-32-43)
iter is 8100, loc. loss = 0.008864451199769974, classif. loss = 0.345267117023468    (2025-08-12_18-32-57)
iter is 8150, loc. loss = 0.22920528054237366 , classif. loss = 0.07589125633239746  (2025-08-12_18-33-11)
iter is 8200, loc. loss = 0.016916317865252495, classif. loss = 0.21021410822868347  (2025-08-12_18-33-25)
iter is 8250, loc. loss = 0.37163370847702026 , classif. loss = 0.2586140036582947   (2025-08-12_18-33-40)
iter is 8300, loc. loss = 0.5265846848487854  , classif. loss = 1.2915265560150146   (2025-08-12_18-33-54)
iter is 8350, loc. loss = 0.4091024398803711  , classif. loss = 0.26440632343292236  (2025-08-12_18-34-08)
iter is 8400, loc. loss = 0.23716409504413605 , classif. loss = 0.23262815177440643  (2025-08-12_18-34-22)
iter is 8450, loc. loss = 0.21357963979244232 , classif. loss = 0.4427495002746582   (2025-08-12_18-34-36)
iter is 8500, loc. loss = 0.4165686368942261  , classif. loss = 0.3763495087623596   (2025-08-12_18-34-50)
iter is 8550, loc. loss = 0.41416648030281067 , classif. loss = 1.170605182647705    (2025-08-12_18-35-04)
iter is 8600, loc. loss = 0.1688053011894226  , classif. loss = 0.038733288645744324 (2025-08-12_18-35-18)
iter is 8650, loc. loss = 0.1775818169116974  , classif. loss = 0.10086165368556976  (2025-08-12_18-35-32)
iter is 8700, loc. loss = 0.00039480862324126065, classif. loss = 0.009151630103588104 (2025-08-12_18-35-46)
iter is 8750, loc. loss = 0.09491895139217377 , classif. loss = 0.06703300029039383  (2025-08-12_18-36-00)
iter is 8800, loc. loss = 0.28297045826911926 , classif. loss = 0.10991409420967102  (2025-08-12_18-36-14)
iter is 8850, loc. loss = 0.16341999173164368 , classif. loss = 0.0324210450053215   (2025-08-12_18-36-28)
iter is 8900, loc. loss = 0.23553261160850525 , classif. loss = 0.0889923945069313   (2025-08-12_18-36-42)
iter is 8950, loc. loss = 0.23932743072509766 , classif. loss = 0.07224348932504654  (2025-08-12_18-36-56)
iter is 9000, loc. loss = 0.0002126203617081046, classif. loss = 0.014219150878489017 (2025-08-12_18-37-10)
iter is 9050, loc. loss = 0.007548950612545013, classif. loss = 0.1847703754901886   (2025-08-12_18-37-25)
iter is 9100, loc. loss = 0.29977813363075256 , classif. loss = 0.3002637028694153   (2025-08-12_18-37-39)
iter is 9150, loc. loss = 0.25942954421043396 , classif. loss = 0.24536074697971344  (2025-08-12_18-37-53)
iter is 9200, loc. loss = 0.3485345244407654  , classif. loss = 0.31727081537246704  (2025-08-12_18-38-07)
iter is 9250, loc. loss = 0.09980655461549759 , classif. loss = 0.027925197035074234 (2025-08-12_18-38-21)
iter is 9300, loc. loss = 0.21132096648216248 , classif. loss = 0.114488884806633    (2025-08-12_18-38-35)
iter is 9350, loc. loss = 0.4225377142429352  , classif. loss = 0.1138361319899559   (2025-08-12_18-38-49)
iter is 9400, loc. loss = 0.33091863989830017 , classif. loss = 1.8766262531280518   (2025-08-12_18-39-03)
iter is 9450, loc. loss = 0.0020837588235735893, classif. loss = 0.02039547823369503  (2025-08-12_18-39-17)
iter is 9500, loc. loss = 0.00011555184028111398, classif. loss = 0.037930142134428024 (2025-08-12_18-39-31)
iter is 9550, loc. loss = 0.2699299454689026  , classif. loss = 0.21214088797569275  (2025-08-12_18-39-45)
iter is 9600, loc. loss = 0.0031589283607900143, classif. loss = 0.05066476762294769  (2025-08-12_18-39-59)
iter is 9650, loc. loss = 0.00039330130675807595, classif. loss = 0.020894277840852737 (2025-08-12_18-40-13)
iter is 9700, loc. loss = 0.0006099715828895569, classif. loss = 0.039552461355924606 (2025-08-12_18-40-27)
iter is 9750, loc. loss = 0.3713807761669159  , classif. loss = 0.29800093173980713  (2025-08-12_18-40-41)
iter is 9800, loc. loss = 0.11345333606004715 , classif. loss = 0.06876987218856812  (2025-08-12_18-40-55)
iter is 9850, loc. loss = 0.3212006092071533  , classif. loss = 0.26851022243499756  (2025-08-12_18-41-09)
iter is 9900, loc. loss = 0.0005218007136136293, classif. loss = 0.01944734901189804  (2025-08-12_18-41-23)
iter is 9950, loc. loss = 0.49576687812805176 , classif. loss = 0.2954404354095459   (2025-08-12_18-41-37)
iter is 10000, loc. loss = 0.14543257653713226 , classif. loss = 0.03801773488521576  (2025-08-12_18-41-52)
---------starting evaluation-----------
validation:    0/1866 (2025-08-12_18-41-52)
validation:  100/1866 (2025-08-12_18-42-36)
validation:  200/1866 (2025-08-12_18-43-20)
validation:  300/1866 (2025-08-12_18-44-04)
validation:  400/1866 (2025-08-12_18-44-47)
validation:  500/1866 (2025-08-12_18-45-31)
validation:  600/1866 (2025-08-12_18-46-14)
validation:  700/1866 (2025-08-12_18-46-58)
validation:  800/1866 (2025-08-12_18-47-41)
validation:  900/1866 (2025-08-12_18-48-24)
validation: 1000/1866 (2025-08-12_18-49-08)
validation: 1100/1866 (2025-08-12_18-49-51)
validation: 1200/1866 (2025-08-12_18-50-34)
validation: 1300/1866 (2025-08-12_18-51-18)
validation: 1400/1866 (2025-08-12_18-52-01)
validation: 1500/1866 (2025-08-12_18-52-44)
validation: 1600/1866 (2025-08-12_18-53-27)
validation: 1700/1866 (2025-08-12_18-54-11)
validation: 1800/1866 (2025-08-12_18-54-55)
lofF1 is 0.7494331690993847, clfF1 is 0.0, oaF1 is 0.2248299507298154, sub class F1 score is [0.37043816 0.         0.         0.        ]
iter is 10050, loc. loss = 0.0006396728567779064, classif. loss = 0.01549251563847065  (2025-08-12_18-55-42)
iter is 10100, loc. loss = 0.1769653856754303  , classif. loss = 0.2446097433567047   (2025-08-12_18-56-06)
iter is 10150, loc. loss = 0.20757459104061127 , classif. loss = 0.1337602436542511   (2025-08-12_18-56-25)
iter is 10200, loc. loss = 0.38774311542510986 , classif. loss = 1.6548998355865479   (2025-08-12_18-56-42)
iter is 10250, loc. loss = 0.12266987562179565 , classif. loss = 0.08433260023593903  (2025-08-12_18-57-01)
iter is 10300, loc. loss = 0.30369243025779724 , classif. loss = 0.21753531694412231  (2025-08-12_18-57-20)
iter is 10350, loc. loss = 0.3236382305622101  , classif. loss = 0.1865011751651764   (2025-08-12_18-57-37)
iter is 10400, loc. loss = 0.17407271265983582 , classif. loss = 0.07550395280122757  (2025-08-12_18-57-55)
iter is 10450, loc. loss = 0.4398340582847595  , classif. loss = 0.20383663475513458  (2025-08-12_18-58-11)
iter is 10500, loc. loss = 0.17054155468940735 , classif. loss = 0.015104936435818672 (2025-08-12_18-58-28)
iter is 10550, loc. loss = 0.0007304160390049219, classif. loss = 0.02295631542801857  (2025-08-12_18-58-45)
iter is 10600, loc. loss = 0.3902183175086975  , classif. loss = 0.2673876881599426   (2025-08-12_18-59-02)
iter is 10650, loc. loss = 0.3175877630710602  , classif. loss = 0.7592150568962097   (2025-08-12_18-59-17)
iter is 10700, loc. loss = 0.0007598957163281739, classif. loss = 0.0339125320315361   (2025-08-12_18-59-32)
iter is 10750, loc. loss = 0.6437458992004395  , classif. loss = 1.2675249576568604   (2025-08-12_18-59-49)
iter is 10800, loc. loss = 0.3602917492389679  , classif. loss = 0.5649837851524353   (2025-08-12_19-00-04)
iter is 10850, loc. loss = 0.2874009907245636  , classif. loss = 0.26259124279022217  (2025-08-12_19-00-18)
iter is 10900, loc. loss = 0.31121742725372314 , classif. loss = 0.04217861592769623  (2025-08-12_19-00-32)
iter is 10950, loc. loss = 0.0007292685913853347, classif. loss = 0.008218472823500633 (2025-08-12_19-00-46)
iter is 11000, loc. loss = 0.0004925634129904211, classif. loss = 0.01031789556145668  (2025-08-12_19-01-00)
iter is 11050, loc. loss = 0.0009752080077305436, classif. loss = 0.013596114702522755 (2025-08-12_19-01-14)
iter is 11100, loc. loss = 0.000513395993039012, classif. loss = 0.012032522819936275 (2025-08-12_19-01-28)
iter is 11150, loc. loss = 0.03182689845561981 , classif. loss = 0.11542530357837677  (2025-08-12_19-01-43)
iter is 11200, loc. loss = 0.19039058685302734 , classif. loss = 0.1610024869441986   (2025-08-12_19-01-57)
iter is 11250, loc. loss = 0.12596382200717926 , classif. loss = 0.10416560620069504  (2025-08-12_19-02-11)
iter is 11300, loc. loss = 0.00028254021890461445, classif. loss = 0.012747256085276604 (2025-08-12_19-02-25)
iter is 11350, loc. loss = 0.000405493366997689, classif. loss = 0.018213782459497452 (2025-08-12_19-02-39)
iter is 11400, loc. loss = 0.3758993446826935  , classif. loss = 1.1839416027069092   (2025-08-12_19-02-53)
iter is 11450, loc. loss = 0.2659079432487488  , classif. loss = 0.151398167014122    (2025-08-12_19-03-07)
iter is 11500, loc. loss = 0.16129247844219208 , classif. loss = 0.04427134245634079  (2025-08-12_19-03-21)
iter is 11550, loc. loss = 0.010919379070401192, classif. loss = 0.24232560396194458  (2025-08-12_19-03-35)
iter is 11600, loc. loss = 0.0002990089124068618, classif. loss = 0.029563535004854202 (2025-08-12_19-03-49)
iter is 11650, loc. loss = 0.27222833037376404 , classif. loss = 1.1859962940216064   (2025-08-12_19-04-03)
iter is 11700, loc. loss = 0.2069864720106125  , classif. loss = 0.5227749347686768   (2025-08-12_19-04-17)
iter is 11750, loc. loss = 0.00047043527592904866, classif. loss = 0.06153246760368347  (2025-08-12_19-04-31)
iter is 11800, loc. loss = 0.22968336939811707 , classif. loss = 0.11183275282382965  (2025-08-12_19-04-45)
iter is 11850, loc. loss = 0.0005906364531256258, classif. loss = 0.02060932293534279  (2025-08-12_19-04-59)
iter is 11900, loc. loss = 0.18106332421302795 , classif. loss = 0.15628886222839355  (2025-08-12_19-05-13)
iter is 11950, loc. loss = 0.133199080824852   , classif. loss = 0.02862890437245369  (2025-08-12_19-05-28)
iter is 12000, loc. loss = 0.18303251266479492 , classif. loss = 0.11640921980142593  (2025-08-12_19-05-42)
iter is 12050, loc. loss = 0.07961057126522064 , classif. loss = 0.127012237906456    (2025-08-12_19-05-56)
iter is 12100, loc. loss = 0.0014377330662682652, classif. loss = 0.023191997781395912 (2025-08-12_19-06-10)
iter is 12150, loc. loss = 0.0005737480241805315, classif. loss = 0.013053394854068756 (2025-08-12_19-06-24)
iter is 12200, loc. loss = 0.23992003500461578 , classif. loss = 0.9676170945167542   (2025-08-12_19-06-38)
iter is 12250, loc. loss = 9.858280827756971e-05, classif. loss = 0.02552281878888607  (2025-08-12_19-06-52)
iter is 12300, loc. loss = 0.0016886290395632386, classif. loss = 0.03544175624847412  (2025-08-12_19-07-06)
iter is 12350, loc. loss = 0.0011995354434475303, classif. loss = 0.011070586740970612 (2025-08-12_19-07-20)
iter is 12400, loc. loss = 0.3057825267314911  , classif. loss = 2.053436517715454    (2025-08-12_19-07-34)
iter is 12450, loc. loss = 0.005646130070090294, classif. loss = 0.15892204642295837  (2025-08-12_19-07-48)
iter is 12500, loc. loss = 0.4776149392127991  , classif. loss = 1.0466209650039673   (2025-08-12_19-08-02)
The accuracy of the best round is  [np.float64(0.7494331690993847), np.float64(0.0), np.float64(0.2248299507298154), array([0.37043816, 0.        , 0.        , 0.        ])]
