2025-10-04 09:41:46,490 | INFO | MAIN - START
2025-10-04 09:41:46,490 | INFO |  > FOCAL LOSS set to True
2025-10-04 09:41:46,490 | INFO |  > ALINGNMENT set to True
2025-10-04 09:41:46,490 | INFO |  > ATTENTION GATE set to -> Building: True, Damage: True
2025-10-04 09:41:46,491 | INFO | Command Line Args:
{
    "cfg": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/configs/vssm1/vssm_base_224.yaml",
    "opts": null,
    "pretrained_weight_path": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/pretrained_weight/vssm_base_0229_ckpt_epoch_237.pth",
    "dataset": "xBD",
    "type": "train",
    "train_dataset_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/train_combined",
    "train_data_list_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/train_combined/train_list2.txt",
    "test_dataset_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/test",
    "test_data_list_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/test/test_list2.txt",
    "shuffle": true,
    "batch_size": 8,
    "crop_size": 256,
    "start_iter": 0,
    "cuda": true,
    "max_iters": 400000,
    "model_type": "MambaBDA_Base",
    "model_param_path": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-04_09-41-45_MambaBDA_Base_xBD_FOCAL_ALIGN_AGBD",
    "resume": null,
    "learning_rate": 0.0001,
    "momentum": 0.9,
    "weight_decay": 0.005,
    "logfile": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/LOGLAR_CMAG/train_2025-10-04_09-41-45_MambaBDA_Base_xBD_FOCAL_ALIGN_AGBD.log",
    "extension": "png",
    "focal_loss": true,
    "enable_alignment": true,
    "enable_attn_gate_building": true,
    "enable_attn_gate_damage": true,
    "deterministic": false,
    "validations": 8,
    "measure_train_scores": true
}
2025-10-04 09:41:46,491 | INFO | Starting in RANDOM mode / not deterministic.
2025-10-04 09:41:46,496 | INFO |  > TRAIN EVALUATION params: TRAIN_BUF_MAXLEN = 1024
2025-10-04 09:41:46,496 | INFO |  > ALIGNMENT params: alignment_args = AlignmentArgs(enabled=True, stages=(1, 2), mid_ch=64)
2025-10-04 09:41:46,496 | INFO |  > ATTENTION GATE params: attn_gate_args = AttentionGateArgs(enable_building_ag=True, enable_damage_ag=True)
2025-10-04 09:41:46,496 | INFO | ChangeMambaBDA class
2025-10-04 09:41:47,711 | INFO |  > FOCAL LOSS params: alpha = [0.6, 1.6, 1.1, 1.1], gamma = 1.5
2025-10-04 09:41:47,711 | INFO | ---------starting training-----------
2025-10-04 09:41:47,777 | INFO | VAL_STEP=6250, (number_of_validations = 8)
2025-10-04 09:42:45,693 | INFO | iter is 50 / 50000 [skipped    1] | loc. loss = 0.3742146790, classif. loss = 0.4182180762
2025-10-04 09:43:36,463 | INFO | iter is 100 / 50000 [skipped    2] | loc. loss = 0.4588539600, classif. loss = 1.0901336670
2025-10-04 09:44:24,219 | INFO | iter is 150 / 50000 [skipped    2] | loc. loss = 0.4640545249, classif. loss = 1.5100922585
2025-10-04 09:45:09,966 | INFO | iter is 200 / 50000 [skipped    3] | loc. loss = 0.2923861444, classif. loss = 0.8383952975
2025-10-04 09:45:53,581 | INFO | iter is 250 / 50000 [skipped    4] | loc. loss = 0.3659276962, classif. loss = 0.6615483761
2025-10-04 09:46:32,044 | INFO | iter is 300 / 50000 [skipped    4] | loc. loss = 0.4022713900, classif. loss = 0.9508951306
2025-10-04 09:47:14,192 | INFO | iter is 350 / 50000 [skipped    4] | loc. loss = 0.3247333467, classif. loss = 1.1936854124
2025-10-04 09:47:52,864 | INFO | iter is 400 / 50000 [skipped    4] | loc. loss = 0.3103506863, classif. loss = 2.5568270683
2025-10-04 09:48:30,848 | INFO | iter is 450 / 50000 [skipped    4] | loc. loss = 0.3826994598, classif. loss = 0.9088439345
2025-10-04 09:49:09,978 | INFO | iter is 500 / 50000 [skipped    5] | loc. loss = 0.3665592968, classif. loss = 0.1471681297
2025-10-04 09:49:45,669 | INFO | iter is 550 / 50000 [skipped    5] | loc. loss = 0.3700733483, classif. loss = 1.2142341137
2025-10-04 09:50:18,500 | INFO | iter is 600 / 50000 [skipped    6] | loc. loss = 0.2731356323, classif. loss = 0.4569132924
2025-10-04 09:50:51,616 | INFO | iter is 650 / 50000 [skipped    6] | loc. loss = 0.2876414657, classif. loss = 1.0938072205
2025-10-04 09:51:24,816 | INFO | iter is 700 / 50000 [skipped    6] | loc. loss = 0.2659646273, classif. loss = 1.9922614098
2025-10-04 09:51:57,492 | INFO | iter is 750 / 50000 [skipped    7] | loc. loss = 0.3623321950, classif. loss = 1.0172948837
2025-10-04 09:52:30,647 | INFO | iter is 800 / 50000 [skipped    7] | loc. loss = 0.2388656288, classif. loss = 0.2924600244
2025-10-04 09:53:03,654 | INFO | iter is 850 / 50000 [skipped    7] | loc. loss = 0.3776696920, classif. loss = 1.3781740665
2025-10-04 09:53:36,274 | INFO | iter is 900 / 50000 [skipped    8] | loc. loss = 0.2485973835, classif. loss = 1.5848197937
2025-10-04 09:54:08,735 | INFO | iter is 950 / 50000 [skipped    9] | loc. loss = 0.2880826294, classif. loss = 0.6708428264
2025-10-04 09:54:42,053 | INFO | iter is 1000 / 50000 [skipped    9] | loc. loss = 0.2519002557, classif. loss = 0.8309369683
2025-10-04 09:55:15,394 | INFO | iter is 1050 / 50000 [skipped    9] | loc. loss = 0.3003890216, classif. loss = 1.9567942619
2025-10-04 09:55:48,503 | INFO | iter is 1100 / 50000 [skipped    9] | loc. loss = 0.2246978730, classif. loss = 1.2770333290
2025-10-04 09:56:21,751 | INFO | iter is 1150 / 50000 [skipped    9] | loc. loss = 0.3025165796, classif. loss = 0.1256194413
2025-10-04 09:56:54,836 | INFO | iter is 1200 / 50000 [skipped    9] | loc. loss = 0.5243530869, classif. loss = 0.3371865153
2025-10-04 09:57:27,948 | INFO | iter is 1250 / 50000 [skipped    9] | loc. loss = 0.3187352717, classif. loss = 1.0720411539
2025-10-04 09:58:01,246 | INFO | iter is 1300 / 50000 [skipped    9] | loc. loss = 0.3057924509, classif. loss = 0.8535530567
2025-10-04 09:58:34,445 | INFO | iter is 1350 / 50000 [skipped    9] | loc. loss = 0.4393441677, classif. loss = 0.2745424509
2025-10-04 09:59:07,551 | INFO | iter is 1400 / 50000 [skipped    9] | loc. loss = 0.3211025894, classif. loss = 0.9716142416
2025-10-04 09:59:39,430 | INFO | iter is 1450 / 50000 [skipped   11] | loc. loss = 0.1600165665, classif. loss = 0.0240198728
2025-10-04 10:00:12,587 | INFO | iter is 1500 / 50000 [skipped   11] | loc. loss = 0.3723781109, classif. loss = 2.3685326576
2025-10-04 10:00:45,028 | INFO | iter is 1550 / 50000 [skipped   12] | loc. loss = 0.1886625141, classif. loss = 1.0135232210
2025-10-04 10:01:18,228 | INFO | iter is 1600 / 50000 [skipped   12] | loc. loss = 0.3733204603, classif. loss = 0.3627535701
2025-10-04 10:01:51,194 | INFO | iter is 1650 / 50000 [skipped   12] | loc. loss = 0.3478208780, classif. loss = 1.3559452295
2025-10-04 10:02:54,878 | INFO | iter is 1750 / 50000 [skipped   16] | loc. loss = 0.3205808997, classif. loss = 0.8852579594
2025-10-04 10:03:27,926 | INFO | iter is 1800 / 50000 [skipped   16] | loc. loss = 0.0827010274, classif. loss = 3.0986855030
2025-10-04 10:04:00,236 | INFO | iter is 1850 / 50000 [skipped   17] | loc. loss = 0.3179047704, classif. loss = 0.6961665750
2025-10-04 10:04:33,325 | INFO | iter is 1900 / 50000 [skipped   17] | loc. loss = 0.1492932141, classif. loss = 0.1381281316
2025-10-04 10:05:06,317 | INFO | iter is 1950 / 50000 [skipped   17] | loc. loss = 0.2344372422, classif. loss = 0.6423993111
2025-10-04 10:05:39,330 | INFO | iter is 2000 / 50000 [skipped   17] | loc. loss = 0.5010943413, classif. loss = 0.9924149513
2025-10-04 10:06:12,336 | INFO | iter is 2050 / 50000 [skipped   17] | loc. loss = 0.1770274639, classif. loss = 0.5163733363
2025-10-04 10:06:45,332 | INFO | iter is 2100 / 50000 [skipped   17] | loc. loss = 0.2617542446, classif. loss = 1.4547450542
2025-10-04 10:07:18,258 | INFO | iter is 2150 / 50000 [skipped   17] | loc. loss = 0.4573642612, classif. loss = 1.4466407299
2025-10-04 10:07:51,235 | INFO | iter is 2200 / 50000 [skipped   17] | loc. loss = 0.4296486974, classif. loss = 2.3054013252
2025-10-04 10:08:22,980 | INFO | iter is 2250 / 50000 [skipped   19] | loc. loss = 0.2234457135, classif. loss = 0.9540621042
2025-10-04 10:08:55,402 | INFO | iter is 2300 / 50000 [skipped   20] | loc. loss = 0.1617107838, classif. loss = 0.7658752203
2025-10-04 10:09:28,373 | INFO | iter is 2350 / 50000 [skipped   20] | loc. loss = 0.1163406968, classif. loss = 2.2719960213
2025-10-04 10:10:01,422 | INFO | iter is 2400 / 50000 [skipped   20] | loc. loss = 0.2563312352, classif. loss = 0.8368746042
2025-10-04 10:10:34,413 | INFO | iter is 2450 / 50000 [skipped   20] | loc. loss = 0.2144786417, classif. loss = 0.6416245699
2025-10-04 10:11:07,407 | INFO | iter is 2500 / 50000 [skipped   20] | loc. loss = 0.2631634176, classif. loss = 0.6864920259
2025-10-04 10:11:40,303 | INFO | iter is 2550 / 50000 [skipped   20] | loc. loss = 0.2563455105, classif. loss = 1.0897432566
2025-10-04 10:12:12,630 | INFO | iter is 2600 / 50000 [skipped   21] | loc. loss = 0.3303989470, classif. loss = 1.0128608942
2025-10-04 10:12:45,589 | INFO | iter is 2650 / 50000 [skipped   21] | loc. loss = 0.2687782347, classif. loss = 0.4809491932
2025-10-04 10:13:18,517 | INFO | iter is 2700 / 50000 [skipped   21] | loc. loss = 0.2397619784, classif. loss = 0.7393999100
2025-10-04 10:13:50,812 | INFO | iter is 2750 / 50000 [skipped   22] | loc. loss = 0.3178229332, classif. loss = 0.3852752447
2025-10-04 10:14:23,708 | INFO | iter is 2800 / 50000 [skipped   22] | loc. loss = 0.1692416817, classif. loss = 0.4022941589
2025-10-04 10:14:56,665 | INFO | iter is 2850 / 50000 [skipped   22] | loc. loss = 0.1745877415, classif. loss = 1.6573826075
2025-10-04 10:16:01,870 | INFO | iter is 2950 / 50000 [skipped   23] | loc. loss = 0.2740282416, classif. loss = 0.7792510986
2025-10-04 10:16:34,769 | INFO | iter is 3000 / 50000 [skipped   23] | loc. loss = 0.3020056188, classif. loss = 0.7720964551
2025-10-04 10:17:06,435 | INFO | iter is 3050 / 50000 [skipped   25] | loc. loss = 0.2575192451, classif. loss = 1.0090771914
2025-10-04 10:17:39,333 | INFO | iter is 3100 / 50000 [skipped   25] | loc. loss = 0.2450878769, classif. loss = 0.6369711757
2025-10-04 10:18:12,244 | INFO | iter is 3150 / 50000 [skipped   25] | loc. loss = 0.2878396511, classif. loss = 0.5880440474
2025-10-04 10:18:45,106 | INFO | iter is 3200 / 50000 [skipped   25] | loc. loss = 0.3800230026, classif. loss = 2.3256702423
2025-10-04 10:19:18,054 | INFO | iter is 3250 / 50000 [skipped   25] | loc. loss = 0.1654419750, classif. loss = 2.0179200172
2025-10-04 10:19:50,396 | INFO | iter is 3300 / 50000 [skipped   26] | loc. loss = 0.5419403911, classif. loss = 0.5632258654
2025-10-04 10:20:23,344 | INFO | iter is 3350 / 50000 [skipped   26] | loc. loss = 0.1929125786, classif. loss = 0.5844892263
2025-10-04 10:20:56,171 | INFO | iter is 3400 / 50000 [skipped   26] | loc. loss = 0.2792710662, classif. loss = 0.8053538799
2025-10-04 10:21:29,022 | INFO | iter is 3450 / 50000 [skipped   26] | loc. loss = 0.3403307796, classif. loss = 0.2199267447
2025-10-04 10:22:01,879 | INFO | iter is 3500 / 50000 [skipped   26] | loc. loss = 0.2852900326, classif. loss = 1.9337623119
2025-10-04 10:22:34,824 | INFO | iter is 3550 / 50000 [skipped   26] | loc. loss = 0.1447326839, classif. loss = 0.4186448157
2025-10-04 10:23:07,670 | INFO | iter is 3600 / 50000 [skipped   26] | loc. loss = 0.2403238565, classif. loss = 0.4288718700
2025-10-04 10:23:40,584 | INFO | iter is 3650 / 50000 [skipped   26] | loc. loss = 0.4930455983, classif. loss = 0.8949201107
2025-10-04 10:24:13,455 | INFO | iter is 3700 / 50000 [skipped   26] | loc. loss = 0.2640598416, classif. loss = 2.0385837555
2025-10-04 10:24:45,674 | INFO | iter is 3750 / 50000 [skipped   27] | loc. loss = 0.4981712997, classif. loss = 0.8035928011
2025-10-04 10:25:18,563 | INFO | iter is 3800 / 50000 [skipped   27] | loc. loss = 0.3173358142, classif. loss = 1.0087701082
2025-10-04 10:25:50,751 | INFO | iter is 3850 / 50000 [skipped   28] | loc. loss = 0.2751930356, classif. loss = 0.1814492643
2025-10-04 10:26:23,549 | INFO | iter is 3900 / 50000 [skipped   28] | loc. loss = 0.2239678055, classif. loss = 0.7820896506
2025-10-04 10:26:56,437 | INFO | iter is 3950 / 50000 [skipped   28] | loc. loss = 0.2107230425, classif. loss = 0.7715061903
2025-10-04 10:27:28,704 | INFO | iter is 4000 / 50000 [skipped   29] | loc. loss = 0.2081836462, classif. loss = 0.1593645513
2025-10-04 10:28:00,897 | INFO | iter is 4050 / 50000 [skipped   30] | loc. loss = 0.1735599637, classif. loss = 0.0838694945
2025-10-04 10:28:33,819 | INFO | iter is 4100 / 50000 [skipped   30] | loc. loss = 0.2989725173, classif. loss = 0.3997296989
2025-10-04 10:29:06,044 | INFO | iter is 4150 / 50000 [skipped   31] | loc. loss = 0.2757523060, classif. loss = 0.6036650538
2025-10-04 10:29:38,837 | INFO | iter is 4200 / 50000 [skipped   31] | loc. loss = 0.1937647909, classif. loss = 0.1013509706
2025-10-04 10:30:11,684 | INFO | iter is 4250 / 50000 [skipped   31] | loc. loss = 0.1952303797, classif. loss = 1.1008191109
2025-10-04 10:30:44,480 | INFO | iter is 4300 / 50000 [skipped   31] | loc. loss = 0.3977200985, classif. loss = 0.5286293626
2025-10-04 10:31:17,307 | INFO | iter is 4350 / 50000 [skipped   31] | loc. loss = 0.2294577807, classif. loss = 0.6049200296
2025-10-04 10:31:49,621 | INFO | iter is 4400 / 50000 [skipped   32] | loc. loss = 0.1964582950, classif. loss = 0.0501214974
2025-10-04 10:32:21,858 | INFO | iter is 4450 / 50000 [skipped   33] | loc. loss = 0.1262899935, classif. loss = 0.1487893313
2025-10-04 10:32:53,473 | INFO | iter is 4500 / 50000 [skipped   35] | loc. loss = 0.3725951314, classif. loss = 0.2196354419
2025-10-04 10:33:25,623 | INFO | iter is 4550 / 50000 [skipped   36] | loc. loss = 0.2397977561, classif. loss = 0.7757130861
2025-10-04 10:33:58,373 | INFO | iter is 4600 / 50000 [skipped   36] | loc. loss = 0.2164511234, classif. loss = 0.1451176703
2025-10-04 10:34:30,696 | INFO | iter is 4650 / 50000 [skipped   37] | loc. loss = 0.3177083135, classif. loss = 0.4962984622
2025-10-04 10:35:03,485 | INFO | iter is 4700 / 50000 [skipped   37] | loc. loss = 0.3221315444, classif. loss = 0.7178182006
2025-10-04 10:35:36,291 | INFO | iter is 4750 / 50000 [skipped   37] | loc. loss = 0.3126116693, classif. loss = 0.0619617552
2025-10-04 10:36:08,591 | INFO | iter is 4800 / 50000 [skipped   38] | loc. loss = 0.1480613351, classif. loss = 0.6079037189
2025-10-04 10:36:41,469 | INFO | iter is 4850 / 50000 [skipped   38] | loc. loss = 0.2484465837, classif. loss = 0.8968725801
2025-10-04 10:37:13,634 | INFO | iter is 4900 / 50000 [skipped   39] | loc. loss = 0.1566125453, classif. loss = 0.5618708134
2025-10-04 10:37:46,410 | INFO | iter is 4950 / 50000 [skipped   39] | loc. loss = 0.1573020369, classif. loss = 0.1739450544
2025-10-04 10:38:19,254 | INFO | iter is 5000 / 50000 [skipped   39] | loc. loss = 0.3241525888, classif. loss = 1.0377845764
2025-10-04 10:38:52,115 | INFO | iter is 5050 / 50000 [skipped   39] | loc. loss = 0.2503936291, classif. loss = 0.5342391133
2025-10-04 10:39:24,933 | INFO | iter is 5100 / 50000 [skipped   39] | loc. loss = 0.2964608967, classif. loss = 2.3885688782
2025-10-04 10:39:57,798 | INFO | iter is 5150 / 50000 [skipped   39] | loc. loss = 0.2030383199, classif. loss = 0.4365426600
2025-10-04 10:40:30,654 | INFO | iter is 5200 / 50000 [skipped   39] | loc. loss = 0.2015516311, classif. loss = 0.4350411296
2025-10-04 10:41:03,447 | INFO | iter is 5250 / 50000 [skipped   39] | loc. loss = 0.2163736820, classif. loss = 0.3908918500
2025-10-04 10:41:36,215 | INFO | iter is 5300 / 50000 [skipped   39] | loc. loss = 0.3114352226, classif. loss = 0.6365728378
2025-10-04 10:42:09,081 | INFO | iter is 5350 / 50000 [skipped   39] | loc. loss = 0.2189442962, classif. loss = 1.0716214180
2025-10-04 10:42:42,008 | INFO | iter is 5400 / 50000 [skipped   39] | loc. loss = 0.2453439981, classif. loss = 1.0956331491
2025-10-04 10:43:14,162 | INFO | iter is 5450 / 50000 [skipped   40] | loc. loss = 0.2009738386, classif. loss = 0.0234711319
2025-10-04 10:43:46,382 | INFO | iter is 5500 / 50000 [skipped   41] | loc. loss = 0.2570568621, classif. loss = 0.1304692328
2025-10-04 10:44:18,556 | INFO | iter is 5550 / 50000 [skipped   42] | loc. loss = 0.2814037800, classif. loss = 0.6194171906
2025-10-04 10:44:51,400 | INFO | iter is 5600 / 50000 [skipped   42] | loc. loss = 0.2151604742, classif. loss = 0.1267866790
2025-10-04 10:45:23,623 | INFO | iter is 5650 / 50000 [skipped   43] | loc. loss = 0.2411502600, classif. loss = 0.8953578472
2025-10-04 10:45:55,871 | INFO | iter is 5700 / 50000 [skipped   44] | loc. loss = 0.2646719217, classif. loss = 0.1134945303
2025-10-04 10:46:28,789 | INFO | iter is 5750 / 50000 [skipped   44] | loc. loss = 0.3976365328, classif. loss = 0.5888113379
2025-10-04 10:47:01,556 | INFO | iter is 5800 / 50000 [skipped   44] | loc. loss = 0.1733354479, classif. loss = 0.0471318811
2025-10-04 10:47:34,403 | INFO | iter is 5850 / 50000 [skipped   44] | loc. loss = 0.2040209472, classif. loss = 1.1270663738
2025-10-04 10:48:07,205 | INFO | iter is 5900 / 50000 [skipped   44] | loc. loss = 0.2477487773, classif. loss = 1.6408782005
2025-10-04 10:48:39,368 | INFO | iter is 5950 / 50000 [skipped   45] | loc. loss = 0.2080251426, classif. loss = 1.1625697613
2025-10-04 10:49:12,218 | INFO | iter is 6000 / 50000 [skipped   45] | loc. loss = 0.1602602005, classif. loss = 0.5566461086
2025-10-04 10:49:45,076 | INFO | iter is 6050 / 50000 [skipped   45] | loc. loss = 0.3921952844, classif. loss = 0.4459241331
2025-10-04 10:50:17,949 | INFO | iter is 6100 / 50000 [skipped   45] | loc. loss = 0.1979839653, classif. loss = 0.6163882017
2025-10-04 10:50:50,738 | INFO | iter is 6150 / 50000 [skipped   45] | loc. loss = 0.2536714673, classif. loss = 0.4992675185
2025-10-04 10:51:23,551 | INFO | iter is 6200 / 50000 [skipped   45] | loc. loss = 0.1073616520, classif. loss = 1.3244694471
2025-10-04 10:51:55,822 | INFO | iter is 6250 / 50000 [skipped   46] | loc. loss = 0.2226121426, classif. loss = 0.7470091581
2025-10-04 10:51:55,823 | INFO | ---------starting evaluation-----------
2025-10-04 10:51:57,171 | INFO | validation:    0/ 933 (2025-10-04_10-51-57)
2025-10-04 10:52:43,896 | INFO | validation:  100/ 933 (2025-10-04_10-52-43)
2025-10-04 10:53:30,576 | INFO | validation:  200/ 933 (2025-10-04_10-53-30)
2025-10-04 10:54:17,253 | INFO | validation:  300/ 933 (2025-10-04_10-54-17)
2025-10-04 10:55:03,908 | INFO | validation:  400/ 933 (2025-10-04_10-55-03)
2025-10-04 10:55:50,562 | INFO | validation:  500/ 933 (2025-10-04_10-55-50)
2025-10-04 10:56:37,258 | INFO | validation:  600/ 933 (2025-10-04_10-56-37)
2025-10-04 10:57:23,923 | INFO | validation:  700/ 933 (2025-10-04_10-57-23)
2025-10-04 10:58:10,605 | INFO | validation:  800/ 933 (2025-10-04_10-58-10)
2025-10-04 10:58:57,273 | INFO | validation:  900/ 933 (2025-10-04_10-58-57)
2025-10-04 10:59:12,924 | INFO | Confusion Matrix of Localization:
[[911036310   9323539]
 [ 10288613  47672946]]
2025-10-04 10:59:12,925 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98986968 0.01013032]
 [0.17750753 0.82249247]]
2025-10-04 10:59:12,925 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42426157   536806   812731    83047]
 [       0  2533209  1497869   689288    21605]
 [       0   787876   677524  3944425   119105]
 [       0   207251   120144   286145  2455750]]
2025-10-04 10:59:12,925 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96733641 0.01223943 0.01853065 0.00189351]
 [0.         0.53421014 0.31587477 0.14535897 0.00455612]
 [0.         0.14250063 0.12254161 0.71341562 0.02154214]
 [0.         0.06752409 0.03914391 0.0932284  0.80010361]]
2025-10-04 10:59:12,925 | INFO | lofF1 is 82.9397, clfF1 is 64.6744, oaF1 is 70.1540, sub class F1 score is [94.4764 39.5513 70.0514 85.4353]
2025-10-04 10:59:13,185 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-04_09-41-45_MambaBDA_Base_xBD_FOCAL_ALIGN_AGBD/model_step6250.pth
2025-10-04 10:59:13,185 | INFO | ---------starting train set evaluation-----------
2025-10-04 10:59:17,143 | INFO | [TrainBuf] locF1 is 82.5259, clfF1 is 64.2365, oaF1 is 69.7233, sub class F1 score is [93.1198 42.3277 63.9327 81.5366]
2025-10-04 10:59:49,962 | INFO | iter is 6300 / 50000 [skipped   46] | loc. loss = 0.4389582574, classif. loss = 2.1494212151
2025-10-04 11:00:22,870 | INFO | iter is 6350 / 50000 [skipped   46] | loc. loss = 0.1883890182, classif. loss = 0.6479980946
2025-10-04 11:00:55,106 | INFO | iter is 6400 / 50000 [skipped   47] | loc. loss = 0.2338045090, classif. loss = 1.4273042679
2025-10-04 11:01:27,954 | INFO | iter is 6450 / 50000 [skipped   47] | loc. loss = 0.3176617920, classif. loss = 1.0962074995
2025-10-04 11:02:00,762 | INFO | iter is 6500 / 50000 [skipped   47] | loc. loss = 0.2432392836, classif. loss = 0.2693588734
2025-10-04 11:02:33,584 | INFO | iter is 6550 / 50000 [skipped   47] | loc. loss = 0.2229370922, classif. loss = 0.4974798858
2025-10-04 11:03:05,799 | INFO | iter is 6600 / 50000 [skipped   48] | loc. loss = 0.2772602141, classif. loss = 1.2119226456
2025-10-04 11:03:38,130 | INFO | iter is 6650 / 50000 [skipped   49] | loc. loss = 0.2707468569, classif. loss = 0.3349812925
2025-10-04 11:04:10,954 | INFO | iter is 6700 / 50000 [skipped   49] | loc. loss = 0.3945758343, classif. loss = 1.2030029297
2025-10-04 11:04:43,779 | INFO | iter is 6750 / 50000 [skipped   49] | loc. loss = 0.2268332094, classif. loss = 0.9822108150
2025-10-04 11:05:16,761 | INFO | iter is 6800 / 50000 [skipped   49] | loc. loss = 0.3177761734, classif. loss = 0.6244446039
2025-10-04 11:05:48,951 | INFO | iter is 6850 / 50000 [skipped   50] | loc. loss = 0.1601379365, classif. loss = 0.0145610748
2025-10-04 11:06:21,830 | INFO | iter is 6900 / 50000 [skipped   50] | loc. loss = 0.2350768447, classif. loss = 0.4509459734
2025-10-04 11:06:54,661 | INFO | iter is 6950 / 50000 [skipped   50] | loc. loss = 0.1852408946, classif. loss = 0.3409533501
2025-10-04 11:07:26,408 | INFO | iter is 7000 / 50000 [skipped   52] | loc. loss = 0.2747161090, classif. loss = 0.9197211862
2025-10-04 11:07:58,679 | INFO | iter is 7050 / 50000 [skipped   53] | loc. loss = 0.1797562093, classif. loss = 0.1339286119
2025-10-04 11:08:31,565 | INFO | iter is 7100 / 50000 [skipped   53] | loc. loss = 0.2423141450, classif. loss = 0.4632534087
2025-10-04 11:09:04,413 | INFO | iter is 7150 / 50000 [skipped   53] | loc. loss = 0.3344742656, classif. loss = 0.3499002159
2025-10-04 11:09:37,284 | INFO | iter is 7200 / 50000 [skipped   53] | loc. loss = 0.1292975992, classif. loss = 0.8957785368
2025-10-04 11:10:10,175 | INFO | iter is 7250 / 50000 [skipped   53] | loc. loss = 0.1822119802, classif. loss = 0.6966516972
2025-10-04 11:10:42,971 | INFO | iter is 7300 / 50000 [skipped   53] | loc. loss = 0.2151719183, classif. loss = 0.5294821262
2025-10-04 11:11:15,861 | INFO | iter is 7350 / 50000 [skipped   53] | loc. loss = 0.1775212586, classif. loss = 0.5504901409
2025-10-04 11:11:48,076 | INFO | iter is 7400 / 50000 [skipped   54] | loc. loss = 0.1897618622, classif. loss = 3.3084559441
2025-10-04 11:12:20,978 | INFO | iter is 7450 / 50000 [skipped   54] | loc. loss = 0.1863039434, classif. loss = 0.2112985253
2025-10-04 11:12:53,234 | INFO | iter is 7500 / 50000 [skipped   55] | loc. loss = 0.3066098094, classif. loss = 1.3235876560
2025-10-04 11:13:26,115 | INFO | iter is 7550 / 50000 [skipped   55] | loc. loss = 0.2940630019, classif. loss = 0.5042055845
2025-10-04 11:13:57,829 | INFO | iter is 7600 / 50000 [skipped   57] | loc. loss = 0.1213490516, classif. loss = 0.0723004416
2025-10-04 11:14:30,068 | INFO | iter is 7650 / 50000 [skipped   58] | loc. loss = 0.2956090271, classif. loss = 1.6777559519
2025-10-04 11:15:03,002 | INFO | iter is 7700 / 50000 [skipped   58] | loc. loss = 0.3130912185, classif. loss = 2.8901591301
2025-10-04 11:15:34,572 | INFO | iter is 7750 / 50000 [skipped   60] | loc. loss = 0.1603194773, classif. loss = 0.5253532529
2025-10-04 11:16:07,492 | INFO | iter is 7800 / 50000 [skipped   60] | loc. loss = 0.2045134604, classif. loss = 0.6038553119
2025-10-04 11:16:39,113 | INFO | iter is 7850 / 50000 [skipped   62] | loc. loss = 0.3003179431, classif. loss = 0.4969725013
2025-10-04 11:17:11,921 | INFO | iter is 7900 / 50000 [skipped   62] | loc. loss = 0.1292316616, classif. loss = 3.0674076080
2025-10-04 11:17:44,717 | INFO | iter is 7950 / 50000 [skipped   62] | loc. loss = 0.3004935384, classif. loss = 0.3391936421
2025-10-04 11:18:17,547 | INFO | iter is 8000 / 50000 [skipped   62] | loc. loss = 0.4335976243, classif. loss = 0.9397045970
2025-10-04 11:18:50,308 | INFO | iter is 8050 / 50000 [skipped   62] | loc. loss = 0.2175442874, classif. loss = 0.4795988500
2025-10-04 11:19:23,217 | INFO | iter is 8100 / 50000 [skipped   62] | loc. loss = 0.1456874758, classif. loss = 0.6305461526
2025-10-04 11:19:56,022 | INFO | iter is 8150 / 50000 [skipped   62] | loc. loss = 0.2948786914, classif. loss = 0.5573979020
2025-10-04 11:20:28,904 | INFO | iter is 8200 / 50000 [skipped   62] | loc. loss = 0.1734973639, classif. loss = 1.0149495602
2025-10-04 11:21:01,689 | INFO | iter is 8250 / 50000 [skipped   62] | loc. loss = 0.1833983362, classif. loss = 0.5491466522
2025-10-04 11:21:34,539 | INFO | iter is 8300 / 50000 [skipped   62] | loc. loss = 0.1152964383, classif. loss = 1.2416341305
2025-10-04 11:22:06,882 | INFO | iter is 8350 / 50000 [skipped   63] | loc. loss = 0.3474946618, classif. loss = 0.4427711070
2025-10-04 11:22:39,684 | INFO | iter is 8400 / 50000 [skipped   63] | loc. loss = 0.1351526827, classif. loss = 1.5670427084
2025-10-04 11:23:12,498 | INFO | iter is 8450 / 50000 [skipped   63] | loc. loss = 0.3430171311, classif. loss = 2.1518836021
2025-10-04 11:23:44,757 | INFO | iter is 8500 / 50000 [skipped   64] | loc. loss = 0.3248306513, classif. loss = 1.0443205833
2025-10-04 11:24:17,636 | INFO | iter is 8550 / 50000 [skipped   64] | loc. loss = 0.1823315471, classif. loss = 0.9629369974
2025-10-04 11:24:49,864 | INFO | iter is 8600 / 50000 [skipped   65] | loc. loss = 0.2156341374, classif. loss = 0.7343835831
2025-10-04 11:25:22,626 | INFO | iter is 8650 / 50000 [skipped   65] | loc. loss = 0.2054729462, classif. loss = 0.2927264273
2025-10-04 11:25:54,909 | INFO | iter is 8700 / 50000 [skipped   66] | loc. loss = 0.2015247196, classif. loss = 0.4808934629
2025-10-04 11:26:27,746 | INFO | iter is 8750 / 50000 [skipped   66] | loc. loss = 0.1826730818, classif. loss = 0.4242680073
2025-10-04 11:27:00,581 | INFO | iter is 8800 / 50000 [skipped   66] | loc. loss = 0.2974737287, classif. loss = 0.3349384367
2025-10-04 11:27:32,730 | INFO | iter is 8850 / 50000 [skipped   67] | loc. loss = 0.2466095686, classif. loss = 1.3852778673
2025-10-04 11:28:05,024 | INFO | iter is 8900 / 50000 [skipped   68] | loc. loss = 0.3068110347, classif. loss = 0.3827894330
2025-10-04 11:28:37,776 | INFO | iter is 8950 / 50000 [skipped   68] | loc. loss = 0.2067361325, classif. loss = 2.0035753250
2025-10-04 11:29:10,545 | INFO | iter is 9000 / 50000 [skipped   68] | loc. loss = 0.2504428625, classif. loss = 0.2276967019
2025-10-04 11:29:43,324 | INFO | iter is 9050 / 50000 [skipped   68] | loc. loss = 0.1829534769, classif. loss = 1.4591796398
2025-10-04 11:30:15,619 | INFO | iter is 9100 / 50000 [skipped   69] | loc. loss = 0.1529317498, classif. loss = 3.8859748840
2025-10-04 11:30:47,839 | INFO | iter is 9150 / 50000 [skipped   70] | loc. loss = 0.4582138956, classif. loss = 0.4625948668
2025-10-04 11:31:20,049 | INFO | iter is 9200 / 50000 [skipped   71] | loc. loss = 0.2571012378, classif. loss = 0.7503388524
2025-10-04 11:31:52,949 | INFO | iter is 9250 / 50000 [skipped   71] | loc. loss = 0.2196559161, classif. loss = 0.1408765018
2025-10-04 11:32:25,880 | INFO | iter is 9300 / 50000 [skipped   71] | loc. loss = 0.1484709680, classif. loss = 0.6557564735
2025-10-04 11:32:57,564 | INFO | iter is 9350 / 50000 [skipped   73] | loc. loss = 0.2713047266, classif. loss = 0.2596849799
2025-10-04 11:33:30,383 | INFO | iter is 9400 / 50000 [skipped   73] | loc. loss = 0.2654891908, classif. loss = 0.5738554597
2025-10-04 11:34:01,422 | INFO | iter is 9450 / 50000 [skipped   76] | loc. loss = 0.1107832789, classif. loss = 0.5338040590
2025-10-04 11:34:34,265 | INFO | iter is 9500 / 50000 [skipped   76] | loc. loss = 0.2914216518, classif. loss = 0.0643251315
2025-10-04 11:35:07,195 | INFO | iter is 9550 / 50000 [skipped   76] | loc. loss = 0.1950107068, classif. loss = 1.3913030624
2025-10-04 11:35:39,451 | INFO | iter is 9600 / 50000 [skipped   77] | loc. loss = 0.1875641942, classif. loss = 0.4631947875
2025-10-04 11:36:11,740 | INFO | iter is 9650 / 50000 [skipped   78] | loc. loss = 0.2481142879, classif. loss = 1.1299644709
2025-10-04 11:36:44,702 | INFO | iter is 9700 / 50000 [skipped   78] | loc. loss = 0.1232411936, classif. loss = 0.9780316949
2025-10-04 11:37:16,959 | INFO | iter is 9750 / 50000 [skipped   79] | loc. loss = 0.1687280685, classif. loss = 0.8503165245
2025-10-04 11:37:49,842 | INFO | iter is 9800 / 50000 [skipped   79] | loc. loss = 0.2470663637, classif. loss = 0.4440635443
2025-10-04 11:38:22,139 | INFO | iter is 9850 / 50000 [skipped   80] | loc. loss = 0.1440894157, classif. loss = 0.0596267059
2025-10-04 11:38:54,958 | INFO | iter is 9900 / 50000 [skipped   80] | loc. loss = 0.1747523844, classif. loss = 0.4600885510
2025-10-04 11:39:27,770 | INFO | iter is 9950 / 50000 [skipped   80] | loc. loss = 0.2140163630, classif. loss = 0.0433387160
2025-10-04 11:40:00,696 | INFO | iter is 10000 / 50000 [skipped   80] | loc. loss = 0.1739788800, classif. loss = 0.6563891172
2025-10-04 11:40:33,582 | INFO | iter is 10050 / 50000 [skipped   80] | loc. loss = 0.1685675681, classif. loss = 0.1854675710
2025-10-04 11:41:06,384 | INFO | iter is 10100 / 50000 [skipped   80] | loc. loss = 0.1585709155, classif. loss = 0.1825996041
2025-10-04 11:41:38,686 | INFO | iter is 10150 / 50000 [skipped   81] | loc. loss = 0.1625348479, classif. loss = 0.9436485767
2025-10-04 11:42:10,921 | INFO | iter is 10200 / 50000 [skipped   82] | loc. loss = 0.2450826168, classif. loss = 0.6359218359
2025-10-04 11:42:43,148 | INFO | iter is 10250 / 50000 [skipped   83] | loc. loss = 0.1501024216, classif. loss = 1.1598732471
2025-10-04 11:43:15,988 | INFO | iter is 10300 / 50000 [skipped   83] | loc. loss = 0.2587913871, classif. loss = 0.5518636703
2025-10-04 11:43:48,876 | INFO | iter is 10350 / 50000 [skipped   83] | loc. loss = 0.3574607968, classif. loss = 0.7967976332
2025-10-04 11:44:20,521 | INFO | iter is 10400 / 50000 [skipped   85] | loc. loss = 0.2281063050, classif. loss = 1.0308887959
2025-10-04 11:44:53,429 | INFO | iter is 10450 / 50000 [skipped   85] | loc. loss = 0.2595996261, classif. loss = 0.7143980265
2025-10-04 11:45:26,212 | INFO | iter is 10500 / 50000 [skipped   85] | loc. loss = 0.2038591206, classif. loss = 0.8910664320
2025-10-04 11:45:59,122 | INFO | iter is 10550 / 50000 [skipped   85] | loc. loss = 0.3528003991, classif. loss = 1.0571432114
2025-10-04 11:46:31,358 | INFO | iter is 10600 / 50000 [skipped   86] | loc. loss = 0.1921025068, classif. loss = 0.1719966233
2025-10-04 11:47:03,054 | INFO | iter is 10650 / 50000 [skipped   88] | loc. loss = 0.1585792899, classif. loss = 0.1643067449
2025-10-04 11:47:35,953 | INFO | iter is 10700 / 50000 [skipped   88] | loc. loss = 0.2635312378, classif. loss = 0.8860120773
2025-10-04 11:48:08,726 | INFO | iter is 10750 / 50000 [skipped   88] | loc. loss = 0.2798422575, classif. loss = 1.0069609880
2025-10-04 11:48:41,606 | INFO | iter is 10800 / 50000 [skipped   88] | loc. loss = 0.1429309249, classif. loss = 3.8383908272
2025-10-04 11:49:14,443 | INFO | iter is 10850 / 50000 [skipped   88] | loc. loss = 0.2274554372, classif. loss = 0.4061829150
2025-10-04 11:49:46,793 | INFO | iter is 10900 / 50000 [skipped   89] | loc. loss = 0.1980434358, classif. loss = 0.5866096020
2025-10-04 11:50:19,650 | INFO | iter is 10950 / 50000 [skipped   89] | loc. loss = 0.1923037916, classif. loss = 1.2953724861
2025-10-04 11:50:52,478 | INFO | iter is 11000 / 50000 [skipped   89] | loc. loss = 0.2342049032, classif. loss = 0.5928868055
2025-10-04 11:51:24,154 | INFO | iter is 11050 / 50000 [skipped   91] | loc. loss = 0.3079508245, classif. loss = 1.0212923288
2025-10-04 11:51:56,412 | INFO | iter is 11100 / 50000 [skipped   92] | loc. loss = 0.1616780609, classif. loss = 0.7189939618
2025-10-04 11:52:29,258 | INFO | iter is 11150 / 50000 [skipped   92] | loc. loss = 0.2579174042, classif. loss = 0.2906634212
2025-10-04 11:53:02,100 | INFO | iter is 11200 / 50000 [skipped   92] | loc. loss = 0.2609920502, classif. loss = 1.6337680817
2025-10-04 11:53:34,432 | INFO | iter is 11250 / 50000 [skipped   93] | loc. loss = 0.2269209176, classif. loss = 0.5126205087
2025-10-04 11:54:07,324 | INFO | iter is 11300 / 50000 [skipped   93] | loc. loss = 0.1928637177, classif. loss = 1.2574039698
2025-10-04 11:54:39,588 | INFO | iter is 11350 / 50000 [skipped   94] | loc. loss = 0.2226724327, classif. loss = 0.2040290534
2025-10-04 11:55:11,839 | INFO | iter is 11400 / 50000 [skipped   95] | loc. loss = 0.3792600632, classif. loss = 0.4001801014
2025-10-04 11:55:44,770 | INFO | iter is 11450 / 50000 [skipped   95] | loc. loss = 0.2714426517, classif. loss = 1.4340167046
2025-10-04 11:56:17,037 | INFO | iter is 11500 / 50000 [skipped   96] | loc. loss = 0.1889677644, classif. loss = 0.4007023275
2025-10-04 11:56:49,891 | INFO | iter is 11550 / 50000 [skipped   96] | loc. loss = 0.1683229357, classif. loss = 0.4700644612
2025-10-04 11:57:22,846 | INFO | iter is 11600 / 50000 [skipped   96] | loc. loss = 0.3058094382, classif. loss = 0.9970880151
2025-10-04 11:57:55,652 | INFO | iter is 11650 / 50000 [skipped   96] | loc. loss = 0.4826655686, classif. loss = 0.3681901693
2025-10-04 11:58:27,874 | INFO | iter is 11700 / 50000 [skipped   97] | loc. loss = 0.1686365157, classif. loss = 0.7008691430
2025-10-04 11:59:00,707 | INFO | iter is 11750 / 50000 [skipped   97] | loc. loss = 0.3241686821, classif. loss = 1.0166300535
2025-10-04 11:59:33,593 | INFO | iter is 11800 / 50000 [skipped   97] | loc. loss = 0.2932499349, classif. loss = 0.8789697289
2025-10-04 12:00:06,450 | INFO | iter is 11850 / 50000 [skipped   97] | loc. loss = 0.1166200563, classif. loss = 0.1634773761
2025-10-04 12:00:39,327 | INFO | iter is 11900 / 50000 [skipped   97] | loc. loss = 0.4791871309, classif. loss = 1.2321475744
2025-10-04 12:01:11,549 | INFO | iter is 11950 / 50000 [skipped   98] | loc. loss = 0.2176856101, classif. loss = 2.0417280197
2025-10-04 12:01:44,491 | INFO | iter is 12000 / 50000 [skipped   98] | loc. loss = 0.1844445318, classif. loss = 0.0079190861
2025-10-04 12:02:17,348 | INFO | iter is 12050 / 50000 [skipped   98] | loc. loss = 0.2008850425, classif. loss = 0.0851234645
2025-10-04 12:02:50,248 | INFO | iter is 12100 / 50000 [skipped   98] | loc. loss = 0.1736445874, classif. loss = 0.5925513506
2025-10-04 12:03:23,127 | INFO | iter is 12150 / 50000 [skipped   98] | loc. loss = 0.2083632946, classif. loss = 0.6796438694
2025-10-04 12:03:55,927 | INFO | iter is 12200 / 50000 [skipped   98] | loc. loss = 0.2363581359, classif. loss = 0.5322696567
2025-10-04 12:04:28,119 | INFO | iter is 12250 / 50000 [skipped   99] | loc. loss = 0.1738269925, classif. loss = 0.1692092121
2025-10-04 12:05:00,347 | INFO | iter is 12300 / 50000 [skipped  100] | loc. loss = 0.1628206074, classif. loss = 0.1355613023
2025-10-04 12:05:32,648 | INFO | iter is 12350 / 50000 [skipped  101] | loc. loss = 0.2795065641, classif. loss = 0.5114349127
2025-10-04 12:06:04,893 | INFO | iter is 12400 / 50000 [skipped  102] | loc. loss = 0.2849767804, classif. loss = 0.6784281731
2025-10-04 12:06:37,800 | INFO | iter is 12450 / 50000 [skipped  102] | loc. loss = 0.1590386629, classif. loss = 0.3247122467
2025-10-04 12:07:10,670 | INFO | iter is 12500 / 50000 [skipped  102] | loc. loss = 0.2276746333, classif. loss = 0.5757072568
2025-10-04 12:07:10,672 | INFO | ---------starting evaluation-----------
2025-10-04 12:07:11,643 | INFO | validation:    0/ 933 (2025-10-04_12-07-11)
2025-10-04 12:07:58,347 | INFO | validation:  100/ 933 (2025-10-04_12-07-58)
2025-10-04 12:08:45,012 | INFO | validation:  200/ 933 (2025-10-04_12-08-45)
2025-10-04 12:09:31,639 | INFO | validation:  300/ 933 (2025-10-04_12-09-31)
2025-10-04 12:10:18,293 | INFO | validation:  400/ 933 (2025-10-04_12-10-18)
2025-10-04 12:11:04,986 | INFO | validation:  500/ 933 (2025-10-04_12-11-04)
2025-10-04 12:11:51,671 | INFO | validation:  600/ 933 (2025-10-04_12-11-51)
2025-10-04 12:12:38,343 | INFO | validation:  700/ 933 (2025-10-04_12-12-38)
2025-10-04 12:13:24,989 | INFO | validation:  800/ 933 (2025-10-04_12-13-24)
2025-10-04 12:14:11,658 | INFO | validation:  900/ 933 (2025-10-04_12-14-11)
2025-10-04 12:14:27,309 | INFO | Confusion Matrix of Localization:
[[912640784   7719065]
 [ 10877164  47084395]]
2025-10-04 12:14:27,309 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99161299 0.00838701]
 [0.18766169 0.81233831]]
2025-10-04 12:14:27,309 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 39588440  3118796   979999   171506]
 [       0   911823  2690262  1091720    48166]
 [       0   491493   589745  4277774   169918]
 [       0   125082    56810   307301  2580097]]
2025-10-04 12:14:27,309 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.90263512 0.07111002 0.02234444 0.00391042]
 [0.         0.19228776 0.56732991 0.23022494 0.01015738]
 [0.         0.08889478 0.1066653  0.77370739 0.03073253]
 [0.         0.04075275 0.01850917 0.1001212  0.84061689]]
2025-10-04 12:14:27,309 | INFO | lofF1 is 83.5089, clfF1 is 69.5776, oaF1 is 73.7570, sub class F1 score is [93.176  48.0508 70.2096 85.4481]
2025-10-04 12:14:27,572 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-04_09-41-45_MambaBDA_Base_xBD_FOCAL_ALIGN_AGBD/model_step12500.pth
2025-10-04 12:14:27,572 | INFO | ---------starting train set evaluation-----------
2025-10-04 12:14:31,583 | INFO | [TrainBuf] locF1 is 84.1316, clfF1 is 62.4203, oaF1 is 68.9337, sub class F1 score is [93.7562 38.3033 64.1149 85.3869]
2025-10-04 12:15:04,441 | INFO | iter is 12550 / 50000 [skipped  102] | loc. loss = 0.2695291042, classif. loss = 0.0356724858
2025-10-04 12:15:36,767 | INFO | iter is 12600 / 50000 [skipped  103] | loc. loss = 0.1723271608, classif. loss = 1.1846218109
2025-10-04 12:16:09,620 | INFO | iter is 12650 / 50000 [skipped  103] | loc. loss = 0.2157696635, classif. loss = 1.2622909546
2025-10-04 12:16:41,409 | INFO | iter is 12700 / 50000 [skipped  105] | loc. loss = 0.2036526650, classif. loss = 0.1502162516
2025-10-04 12:17:13,708 | INFO | iter is 12750 / 50000 [skipped  106] | loc. loss = 0.1613490731, classif. loss = 0.7119228840
2025-10-04 12:17:45,361 | INFO | iter is 12800 / 50000 [skipped  108] | loc. loss = 0.1329202652, classif. loss = 0.5150240660
2025-10-04 12:18:17,135 | INFO | iter is 12850 / 50000 [skipped  110] | loc. loss = 0.2088446468, classif. loss = 0.9490010738
2025-10-04 12:18:48,838 | INFO | iter is 12900 / 50000 [skipped  112] | loc. loss = 0.2212919295, classif. loss = 1.3882012367
2025-10-04 12:19:20,449 | INFO | iter is 12950 / 50000 [skipped  114] | loc. loss = 0.1591304839, classif. loss = 1.0559405088
2025-10-04 12:19:53,390 | INFO | iter is 13000 / 50000 [skipped  114] | loc. loss = 0.2185588181, classif. loss = 0.5111044645
2025-10-04 12:20:26,240 | INFO | iter is 13050 / 50000 [skipped  114] | loc. loss = 0.1783081293, classif. loss = 0.4875751734
2025-10-04 12:20:59,152 | INFO | iter is 13100 / 50000 [skipped  114] | loc. loss = 0.2126601785, classif. loss = 0.4237571955
2025-10-04 12:21:31,428 | INFO | iter is 13150 / 50000 [skipped  115] | loc. loss = 0.2132996619, classif. loss = 0.4795337617
2025-10-04 12:22:04,329 | INFO | iter is 13200 / 50000 [skipped  115] | loc. loss = 0.1538510174, classif. loss = 0.7515634894
2025-10-04 12:22:37,207 | INFO | iter is 13250 / 50000 [skipped  115] | loc. loss = 0.1666035205, classif. loss = 1.0486603975
2025-10-04 12:23:09,521 | INFO | iter is 13300 / 50000 [skipped  116] | loc. loss = 0.2133850306, classif. loss = 0.2160255164
2025-10-04 12:23:42,420 | INFO | iter is 13350 / 50000 [skipped  116] | loc. loss = 0.1442440748, classif. loss = 0.7997848392
2025-10-04 12:24:14,760 | INFO | iter is 13400 / 50000 [skipped  117] | loc. loss = 0.2861887813, classif. loss = 0.1262698770
2025-10-04 12:24:47,615 | INFO | iter is 13450 / 50000 [skipped  117] | loc. loss = 0.1960667074, classif. loss = 0.6289718151
2025-10-04 12:25:19,263 | INFO | iter is 13500 / 50000 [skipped  119] | loc. loss = 0.2584782839, classif. loss = 0.8544738293
2025-10-04 12:25:52,116 | INFO | iter is 13550 / 50000 [skipped  119] | loc. loss = 0.2724239528, classif. loss = 0.5415605903
2025-10-04 12:26:24,993 | INFO | iter is 13600 / 50000 [skipped  119] | loc. loss = 0.1938323081, classif. loss = 1.4812793732
2025-10-04 12:26:57,828 | INFO | iter is 13650 / 50000 [skipped  119] | loc. loss = 0.3935374022, classif. loss = 0.0446392447
2025-10-04 12:27:30,708 | INFO | iter is 13700 / 50000 [skipped  119] | loc. loss = 0.1815598458, classif. loss = 1.2357025146
2025-10-04 12:28:03,605 | INFO | iter is 13750 / 50000 [skipped  119] | loc. loss = 0.3063559234, classif. loss = 0.2497670352
2025-10-04 12:28:36,444 | INFO | iter is 13800 / 50000 [skipped  119] | loc. loss = 0.2486374676, classif. loss = 0.6822535992
2025-10-04 12:29:08,786 | INFO | iter is 13850 / 50000 [skipped  120] | loc. loss = 0.1343100667, classif. loss = 0.0900155455
2025-10-04 12:29:41,686 | INFO | iter is 13900 / 50000 [skipped  120] | loc. loss = 0.2510407567, classif. loss = 0.2488949299
2025-10-04 12:30:14,530 | INFO | iter is 13950 / 50000 [skipped  120] | loc. loss = 0.2381885350, classif. loss = 0.3241590261
2025-10-04 12:30:46,815 | INFO | iter is 14000 / 50000 [skipped  121] | loc. loss = 0.1718005538, classif. loss = 0.6102023721
2025-10-04 12:31:19,681 | INFO | iter is 14050 / 50000 [skipped  121] | loc. loss = 0.1662708372, classif. loss = 0.1198373064
2025-10-04 12:31:51,381 | INFO | iter is 14100 / 50000 [skipped  123] | loc. loss = 0.2064270526, classif. loss = 0.2401397526
2025-10-04 12:32:23,678 | INFO | iter is 14150 / 50000 [skipped  124] | loc. loss = 0.2805717289, classif. loss = 0.6410655975
2025-10-04 12:32:55,901 | INFO | iter is 14200 / 50000 [skipped  125] | loc. loss = 0.2598443031, classif. loss = 0.0852698311
2025-10-04 12:33:28,791 | INFO | iter is 14250 / 50000 [skipped  125] | loc. loss = 0.1320007741, classif. loss = 0.8186368942
2025-10-04 12:34:01,688 | INFO | iter is 14300 / 50000 [skipped  125] | loc. loss = 0.3450560868, classif. loss = 0.0842310712
2025-10-04 12:34:34,590 | INFO | iter is 14350 / 50000 [skipped  125] | loc. loss = 0.2437694520, classif. loss = 0.6902397871
2025-10-04 12:35:07,396 | INFO | iter is 14400 / 50000 [skipped  125] | loc. loss = 0.2030404061, classif. loss = 0.8115102053
2025-10-04 12:35:40,298 | INFO | iter is 14450 / 50000 [skipped  125] | loc. loss = 0.1664268672, classif. loss = 0.0497758836
2025-10-04 12:36:13,148 | INFO | iter is 14500 / 50000 [skipped  125] | loc. loss = 0.1975806653, classif. loss = 1.6960976124
2025-10-04 12:37:17,752 | INFO | iter is 14600 / 50000 [skipped  127] | loc. loss = 0.1737521887, classif. loss = 1.1344106197
2025-10-04 12:37:50,751 | INFO | iter is 14650 / 50000 [skipped  127] | loc. loss = 0.1533685774, classif. loss = 0.4763152003
2025-10-04 12:38:23,043 | INFO | iter is 14700 / 50000 [skipped  128] | loc. loss = 0.4686853886, classif. loss = 4.9220108986
2025-10-04 12:38:55,932 | INFO | iter is 14750 / 50000 [skipped  128] | loc. loss = 0.0775028244, classif. loss = 0.9043492079
2025-10-04 12:39:28,791 | INFO | iter is 14800 / 50000 [skipped  128] | loc. loss = 0.1934372932, classif. loss = 0.5210785866
2025-10-04 12:40:01,686 | INFO | iter is 14850 / 50000 [skipped  128] | loc. loss = 0.2793345749, classif. loss = 3.6655764580
2025-10-04 12:40:34,613 | INFO | iter is 14900 / 50000 [skipped  128] | loc. loss = 0.1935031563, classif. loss = 1.0351634026
2025-10-04 12:41:07,545 | INFO | iter is 14950 / 50000 [skipped  128] | loc. loss = 0.2629365027, classif. loss = 0.8529289961
2025-10-04 12:41:40,426 | INFO | iter is 15000 / 50000 [skipped  128] | loc. loss = 0.2661147416, classif. loss = 1.1221599579
2025-10-04 12:42:13,283 | INFO | iter is 15050 / 50000 [skipped  128] | loc. loss = 0.1624379158, classif. loss = 0.7564020753
2025-10-04 12:42:46,090 | INFO | iter is 15100 / 50000 [skipped  128] | loc. loss = 0.1391651928, classif. loss = 0.6431823373
2025-10-04 12:43:18,460 | INFO | iter is 15150 / 50000 [skipped  129] | loc. loss = 0.0842875540, classif. loss = 0.2662579119
2025-10-04 12:43:50,710 | INFO | iter is 15200 / 50000 [skipped  130] | loc. loss = 0.1880465895, classif. loss = 1.2266130447
2025-10-04 12:44:23,567 | INFO | iter is 15250 / 50000 [skipped  130] | loc. loss = 0.2576894760, classif. loss = 0.6996912956
2025-10-04 12:44:56,390 | INFO | iter is 15300 / 50000 [skipped  130] | loc. loss = 0.1387807280, classif. loss = 0.8049316406
2025-10-04 12:45:29,262 | INFO | iter is 15350 / 50000 [skipped  130] | loc. loss = 0.1709278226, classif. loss = 1.1406810284
2025-10-04 12:46:02,118 | INFO | iter is 15400 / 50000 [skipped  130] | loc. loss = 0.1378534734, classif. loss = 0.0475639924
2025-10-04 12:46:35,059 | INFO | iter is 15450 / 50000 [skipped  130] | loc. loss = 0.2192714065, classif. loss = 0.6824073195
2025-10-04 12:47:07,938 | INFO | iter is 15500 / 50000 [skipped  130] | loc. loss = 0.2027081400, classif. loss = 1.1819775105
2025-10-04 12:47:40,908 | INFO | iter is 15550 / 50000 [skipped  130] | loc. loss = 0.2000300437, classif. loss = 0.0667607486
2025-10-04 12:48:13,182 | INFO | iter is 15600 / 50000 [skipped  131] | loc. loss = 0.1663935333, classif. loss = 0.8130337000
2025-10-04 12:48:46,090 | INFO | iter is 15650 / 50000 [skipped  131] | loc. loss = 0.2498486936, classif. loss = 0.2353492230
2025-10-04 12:49:19,041 | INFO | iter is 15700 / 50000 [skipped  131] | loc. loss = 0.2561273873, classif. loss = 0.3445721567
2025-10-04 12:49:51,924 | INFO | iter is 15750 / 50000 [skipped  131] | loc. loss = 0.2608406544, classif. loss = 0.6435911655
2025-10-04 12:50:24,878 | INFO | iter is 15800 / 50000 [skipped  131] | loc. loss = 0.2067833841, classif. loss = 0.0610345341
2025-10-04 12:50:57,801 | INFO | iter is 15850 / 50000 [skipped  131] | loc. loss = 0.2297715843, classif. loss = 0.5774922371
2025-10-04 12:51:30,112 | INFO | iter is 15900 / 50000 [skipped  132] | loc. loss = 0.2917992473, classif. loss = 0.5705860853
2025-10-04 12:52:03,083 | INFO | iter is 15950 / 50000 [skipped  132] | loc. loss = 0.1954971850, classif. loss = 0.3821352124
2025-10-04 12:52:35,943 | INFO | iter is 16000 / 50000 [skipped  132] | loc. loss = 0.3280149698, classif. loss = 2.1127948761
2025-10-04 12:53:08,750 | INFO | iter is 16050 / 50000 [skipped  132] | loc. loss = 0.2416655719, classif. loss = 1.1389901638
2025-10-04 12:53:41,607 | INFO | iter is 16100 / 50000 [skipped  132] | loc. loss = 0.2455694377, classif. loss = 0.6668810844
2025-10-04 12:54:14,497 | INFO | iter is 16150 / 50000 [skipped  132] | loc. loss = 0.2652431726, classif. loss = 0.1212965995
2025-10-04 12:54:47,300 | INFO | iter is 16200 / 50000 [skipped  132] | loc. loss = 0.1507583261, classif. loss = 2.7492439747
2025-10-04 12:55:20,190 | INFO | iter is 16250 / 50000 [skipped  132] | loc. loss = 0.1862493753, classif. loss = 0.7725266218
2025-10-04 12:55:53,038 | INFO | iter is 16300 / 50000 [skipped  132] | loc. loss = 0.2254368812, classif. loss = 0.9849282503
2025-10-04 12:56:25,969 | INFO | iter is 16350 / 50000 [skipped  132] | loc. loss = 0.2154577374, classif. loss = 0.6160655618
2025-10-04 12:56:58,892 | INFO | iter is 16400 / 50000 [skipped  132] | loc. loss = 0.1262880117, classif. loss = 0.0415786803
2025-10-04 12:57:31,107 | INFO | iter is 16450 / 50000 [skipped  133] | loc. loss = 0.2208397090, classif. loss = 0.2165760696
2025-10-04 12:58:04,081 | INFO | iter is 16500 / 50000 [skipped  133] | loc. loss = 0.2371303439, classif. loss = 0.7501711249
2025-10-04 12:58:37,038 | INFO | iter is 16550 / 50000 [skipped  133] | loc. loss = 0.2700820863, classif. loss = 0.9192854166
2025-10-04 12:59:09,831 | INFO | iter is 16600 / 50000 [skipped  133] | loc. loss = 0.1447671354, classif. loss = 1.0115453005
2025-10-04 12:59:42,655 | INFO | iter is 16650 / 50000 [skipped  133] | loc. loss = 0.0848534182, classif. loss = 0.1337890774
2025-10-04 13:00:14,973 | INFO | iter is 16700 / 50000 [skipped  134] | loc. loss = 0.1609661877, classif. loss = 0.0247826576
2025-10-04 13:01:19,528 | INFO | iter is 16800 / 50000 [skipped  136] | loc. loss = 0.2242863923, classif. loss = 1.2634258270
2025-10-04 13:01:52,420 | INFO | iter is 16850 / 50000 [skipped  136] | loc. loss = 0.2212242335, classif. loss = 1.1370583773
2025-10-04 13:02:24,771 | INFO | iter is 16900 / 50000 [skipped  137] | loc. loss = 0.1896519810, classif. loss = 0.6788281202
2025-10-04 13:02:57,599 | INFO | iter is 16950 / 50000 [skipped  137] | loc. loss = 0.2503263354, classif. loss = 0.8627246618
2025-10-04 13:03:30,564 | INFO | iter is 17000 / 50000 [skipped  137] | loc. loss = 0.2306596041, classif. loss = 0.7670161724
2025-10-04 13:04:03,458 | INFO | iter is 17050 / 50000 [skipped  137] | loc. loss = 0.1938887089, classif. loss = 0.6976459026
2025-10-04 13:04:35,685 | INFO | iter is 17100 / 50000 [skipped  138] | loc. loss = 0.1863712072, classif. loss = 0.9726442099
2025-10-04 13:05:07,508 | INFO | iter is 17150 / 50000 [skipped  140] | loc. loss = 0.2662618458, classif. loss = 0.9689205885
2025-10-04 13:05:40,404 | INFO | iter is 17200 / 50000 [skipped  140] | loc. loss = 0.1555572003, classif. loss = 1.2488408089
2025-10-04 13:06:13,302 | INFO | iter is 17250 / 50000 [skipped  140] | loc. loss = 0.1923602074, classif. loss = 0.5960557461
2025-10-04 13:06:46,175 | INFO | iter is 17300 / 50000 [skipped  140] | loc. loss = 0.1414559633, classif. loss = 0.6502002478
2025-10-04 13:07:19,121 | INFO | iter is 17350 / 50000 [skipped  140] | loc. loss = 0.3144875765, classif. loss = 1.2399487495
2025-10-04 13:07:51,404 | INFO | iter is 17400 / 50000 [skipped  141] | loc. loss = 0.1513362825, classif. loss = 0.0048969127
2025-10-04 13:08:24,344 | INFO | iter is 17450 / 50000 [skipped  141] | loc. loss = 0.1716034710, classif. loss = 1.4804329872
2025-10-04 13:08:57,222 | INFO | iter is 17500 / 50000 [skipped  141] | loc. loss = 0.0815579444, classif. loss = 0.9029021859
2025-10-04 13:09:30,165 | INFO | iter is 17550 / 50000 [skipped  141] | loc. loss = 0.3206749856, classif. loss = 2.3218975067
2025-10-04 13:10:02,418 | INFO | iter is 17600 / 50000 [skipped  142] | loc. loss = 0.2803902328, classif. loss = 0.0849180669
2025-10-04 13:10:35,256 | INFO | iter is 17650 / 50000 [skipped  142] | loc. loss = 0.2475942969, classif. loss = 1.3297204971
2025-10-04 13:11:08,162 | INFO | iter is 17700 / 50000 [skipped  142] | loc. loss = 0.3071720898, classif. loss = 0.3373904228
2025-10-04 13:11:40,409 | INFO | iter is 17750 / 50000 [skipped  143] | loc. loss = 0.1955229640, classif. loss = 0.8787379861
2025-10-04 13:12:13,314 | INFO | iter is 17800 / 50000 [skipped  143] | loc. loss = 0.1764893830, classif. loss = 0.1861308813
2025-10-04 13:12:46,147 | INFO | iter is 17850 / 50000 [skipped  143] | loc. loss = 0.1882003695, classif. loss = 0.0555225164
2025-10-04 13:13:19,004 | INFO | iter is 17900 / 50000 [skipped  143] | loc. loss = 0.2638555169, classif. loss = 1.2683928013
2025-10-04 13:13:51,844 | INFO | iter is 17950 / 50000 [skipped  143] | loc. loss = 0.2190470099, classif. loss = 1.6211876869
2025-10-04 13:14:24,758 | INFO | iter is 18000 / 50000 [skipped  143] | loc. loss = 0.1408187002, classif. loss = 0.0296190493
2025-10-04 13:14:56,973 | INFO | iter is 18050 / 50000 [skipped  144] | loc. loss = 0.2749513984, classif. loss = 1.6621782780
2025-10-04 13:15:28,661 | INFO | iter is 18100 / 50000 [skipped  146] | loc. loss = 0.2191550136, classif. loss = 0.7886613607
2025-10-04 13:16:01,501 | INFO | iter is 18150 / 50000 [skipped  146] | loc. loss = 0.1675797999, classif. loss = 0.4160318077
2025-10-04 13:16:34,380 | INFO | iter is 18200 / 50000 [skipped  146] | loc. loss = 0.1757310629, classif. loss = 0.9904940128
2025-10-04 13:17:07,280 | INFO | iter is 18250 / 50000 [skipped  146] | loc. loss = 0.2494156361, classif. loss = 1.1908270121
2025-10-04 13:17:39,543 | INFO | iter is 18300 / 50000 [skipped  147] | loc. loss = 0.1999076307, classif. loss = 0.3116862774
2025-10-04 13:18:12,483 | INFO | iter is 18350 / 50000 [skipped  147] | loc. loss = 0.1602058560, classif. loss = 0.0611816272
2025-10-04 13:18:44,729 | INFO | iter is 18400 / 50000 [skipped  148] | loc. loss = 0.1100962386, classif. loss = 0.4502366781
2025-10-04 13:19:17,590 | INFO | iter is 18450 / 50000 [skipped  148] | loc. loss = 0.3268380761, classif. loss = 1.9411031008
2025-10-04 13:19:49,873 | INFO | iter is 18500 / 50000 [skipped  149] | loc. loss = 0.2090795338, classif. loss = 0.9297001362
2025-10-04 13:20:22,716 | INFO | iter is 18550 / 50000 [skipped  149] | loc. loss = 0.1682637185, classif. loss = 1.4718129635
2025-10-04 13:20:55,052 | INFO | iter is 18600 / 50000 [skipped  150] | loc. loss = 0.2466838211, classif. loss = 1.5370445251
2025-10-04 13:21:27,927 | INFO | iter is 18650 / 50000 [skipped  150] | loc. loss = 0.1836900264, classif. loss = 3.6072320938
2025-10-04 13:22:00,829 | INFO | iter is 18700 / 50000 [skipped  150] | loc. loss = 0.7568206787, classif. loss = 0.0670949444
2025-10-04 13:22:33,711 | INFO | iter is 18750 / 50000 [skipped  150] | loc. loss = 0.1508062929, classif. loss = 1.9617435932
2025-10-04 13:22:33,712 | INFO | ---------starting evaluation-----------
2025-10-04 13:22:34,679 | INFO | validation:    0/ 933 (2025-10-04_13-22-34)
2025-10-04 13:23:21,448 | INFO | validation:  100/ 933 (2025-10-04_13-23-21)
2025-10-04 13:24:08,133 | INFO | validation:  200/ 933 (2025-10-04_13-24-08)
2025-10-04 13:24:54,800 | INFO | validation:  300/ 933 (2025-10-04_13-24-54)
2025-10-04 13:25:41,476 | INFO | validation:  400/ 933 (2025-10-04_13-25-41)
2025-10-04 13:26:28,154 | INFO | validation:  500/ 933 (2025-10-04_13-26-28)
2025-10-04 13:27:14,840 | INFO | validation:  600/ 933 (2025-10-04_13-27-14)
2025-10-04 13:28:01,514 | INFO | validation:  700/ 933 (2025-10-04_13-28-01)
2025-10-04 13:28:48,199 | INFO | validation:  800/ 933 (2025-10-04_13-28-48)
2025-10-04 13:29:34,879 | INFO | validation:  900/ 933 (2025-10-04_13-29-34)
2025-10-04 13:29:50,515 | INFO | Confusion Matrix of Localization:
[[911614687   8745162]
 [  9336303  48625256]]
2025-10-04 13:29:50,516 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99049811 0.00950189]
 [0.1610775  0.8389225 ]]
2025-10-04 13:29:50,516 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41839343  1111424   850421    57553]
 [       0  1421884  2429775   866131    24181]
 [       0   550501   805729  4066451   106249]
 [       0   207692    69149   300736  2491713]]
2025-10-04 13:29:50,516 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95395677 0.02534099 0.01939    0.00131224]
 [0.         0.29985084 0.51239769 0.18265211 0.00509936]
 [0.         0.09956737 0.14572964 0.73548607 0.01921692]
 [0.         0.06766777 0.02252931 0.09798227 0.81182065]]
2025-10-04 13:29:50,516 | INFO | lofF1 is 84.3222, clfF1 is 72.5135, oaF1 is 76.0561, sub class F1 score is [95.2212 53.0632 70.0347 86.6836]
2025-10-04 13:29:50,778 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-04_09-41-45_MambaBDA_Base_xBD_FOCAL_ALIGN_AGBD/model_step18750.pth
2025-10-04 13:29:50,778 | INFO | ---------starting train set evaluation-----------
2025-10-04 13:29:54,747 | INFO | [TrainBuf] locF1 is 84.7933, clfF1 is 69.6971, oaF1 is 74.2260, sub class F1 score is [95.025  48.6799 69.1498 84.2892]
2025-10-04 13:30:27,106 | INFO | iter is 18800 / 50000 [skipped  151] | loc. loss = 0.2260310799, classif. loss = 0.4431867599
2025-10-04 13:30:59,934 | INFO | iter is 18850 / 50000 [skipped  151] | loc. loss = 0.1833902299, classif. loss = 1.0129837990
2025-10-04 13:31:32,961 | INFO | iter is 18900 / 50000 [skipped  151] | loc. loss = 0.1351318508, classif. loss = 0.7904109955
2025-10-04 13:32:05,292 | INFO | iter is 18950 / 50000 [skipped  152] | loc. loss = 0.3421162367, classif. loss = 0.2779902220
2025-10-04 13:32:38,125 | INFO | iter is 19000 / 50000 [skipped  152] | loc. loss = 0.2239607424, classif. loss = 0.5815812349
2025-10-04 13:33:10,984 | INFO | iter is 19050 / 50000 [skipped  152] | loc. loss = 0.1896586418, classif. loss = 0.9209332466
2025-10-04 13:33:43,908 | INFO | iter is 19100 / 50000 [skipped  152] | loc. loss = 0.1788990796, classif. loss = 0.0587843135
2025-10-04 13:34:16,769 | INFO | iter is 19150 / 50000 [skipped  152] | loc. loss = 0.1899565011, classif. loss = 0.3314604461
2025-10-04 13:34:49,580 | INFO | iter is 19200 / 50000 [skipped  152] | loc. loss = 0.1276980937, classif. loss = 0.5637776256
2025-10-04 13:35:22,548 | INFO | iter is 19250 / 50000 [skipped  152] | loc. loss = 0.1916658133, classif. loss = 0.1051264107
2025-10-04 13:36:27,121 | INFO | iter is 19350 / 50000 [skipped  154] | loc. loss = 0.1770627648, classif. loss = 2.5016994476
2025-10-04 13:36:59,908 | INFO | iter is 19400 / 50000 [skipped  154] | loc. loss = 0.1764247417, classif. loss = 0.3483217955
2025-10-04 13:37:32,274 | INFO | iter is 19450 / 50000 [skipped  155] | loc. loss = 0.1846582890, classif. loss = 0.2908732593
2025-10-04 13:38:05,191 | INFO | iter is 19500 / 50000 [skipped  155] | loc. loss = 0.2134243101, classif. loss = 0.2117507160
2025-10-04 13:38:38,060 | INFO | iter is 19550 / 50000 [skipped  155] | loc. loss = 0.1960116029, classif. loss = 0.9359418154
2025-10-04 13:39:10,920 | INFO | iter is 19600 / 50000 [skipped  155] | loc. loss = 0.2566018999, classif. loss = 0.0156828575
2025-10-04 13:39:43,282 | INFO | iter is 19650 / 50000 [skipped  156] | loc. loss = 0.1238135099, classif. loss = 0.5547531843
2025-10-04 13:40:16,228 | INFO | iter is 19700 / 50000 [skipped  156] | loc. loss = 0.2101447284, classif. loss = 0.1263532639
2025-10-04 13:40:49,145 | INFO | iter is 19750 / 50000 [skipped  156] | loc. loss = 0.2234833837, classif. loss = 0.4920611084
2025-10-04 13:41:22,050 | INFO | iter is 19800 / 50000 [skipped  156] | loc. loss = 0.2488791049, classif. loss = 0.9760269523
2025-10-04 13:41:54,967 | INFO | iter is 19850 / 50000 [skipped  156] | loc. loss = 0.2592594326, classif. loss = 0.8283246160
2025-10-04 13:42:27,799 | INFO | iter is 19900 / 50000 [skipped  156] | loc. loss = 0.1954559088, classif. loss = 1.3072140217
2025-10-04 13:43:00,140 | INFO | iter is 19950 / 50000 [skipped  157] | loc. loss = 0.1778818369, classif. loss = 0.1056555510
2025-10-04 13:43:32,979 | INFO | iter is 20000 / 50000 [skipped  157] | loc. loss = 0.2236794233, classif. loss = 0.6382064223
2025-10-04 13:44:05,856 | INFO | iter is 20050 / 50000 [skipped  157] | loc. loss = 0.2358667552, classif. loss = 0.3428658247
2025-10-04 13:44:38,086 | INFO | iter is 20100 / 50000 [skipped  158] | loc. loss = 0.1895800680, classif. loss = 1.1765353680
2025-10-04 13:45:10,945 | INFO | iter is 20150 / 50000 [skipped  158] | loc. loss = 0.1943952143, classif. loss = 1.2096648216
2025-10-04 13:45:43,782 | INFO | iter is 20200 / 50000 [skipped  158] | loc. loss = 0.1380301267, classif. loss = 0.3377982974
2025-10-04 13:46:16,686 | INFO | iter is 20250 / 50000 [skipped  158] | loc. loss = 0.0673712865, classif. loss = 0.7847466469
2025-10-04 13:46:48,286 | INFO | iter is 20300 / 50000 [skipped  160] | loc. loss = 0.2338756323, classif. loss = 0.6623053551
2025-10-04 13:47:21,104 | INFO | iter is 20350 / 50000 [skipped  160] | loc. loss = 0.2344783843, classif. loss = 0.3635183871
2025-10-04 13:47:53,934 | INFO | iter is 20400 / 50000 [skipped  160] | loc. loss = 0.2569782436, classif. loss = 0.4636772573
2025-10-04 13:48:26,198 | INFO | iter is 20450 / 50000 [skipped  161] | loc. loss = 0.2827076912, classif. loss = 0.7059807777
2025-10-04 13:48:59,095 | INFO | iter is 20500 / 50000 [skipped  161] | loc. loss = 0.2087857872, classif. loss = 1.0447468758
2025-10-04 13:49:31,992 | INFO | iter is 20550 / 50000 [skipped  161] | loc. loss = 0.1910649985, classif. loss = 0.7158932686
2025-10-04 13:50:04,831 | INFO | iter is 20600 / 50000 [skipped  161] | loc. loss = 0.1559841484, classif. loss = 0.6833724976
2025-10-04 13:50:37,738 | INFO | iter is 20650 / 50000 [skipped  161] | loc. loss = 0.2195228934, classif. loss = 0.9573339224
2025-10-04 13:51:09,937 | INFO | iter is 20700 / 50000 [skipped  162] | loc. loss = 0.2487863153, classif. loss = 0.3138433695
2025-10-04 13:51:42,744 | INFO | iter is 20750 / 50000 [skipped  162] | loc. loss = 0.2150443494, classif. loss = 0.6972501278
2025-10-04 13:52:15,036 | INFO | iter is 20800 / 50000 [skipped  163] | loc. loss = 0.1756735593, classif. loss = 0.0407377258
2025-10-04 13:52:47,879 | INFO | iter is 20850 / 50000 [skipped  163] | loc. loss = 0.1522648633, classif. loss = 2.4313566685
2025-10-04 13:53:20,756 | INFO | iter is 20900 / 50000 [skipped  163] | loc. loss = 0.0809459686, classif. loss = 6.3742799759
2025-10-04 13:53:53,665 | INFO | iter is 20950 / 50000 [skipped  163] | loc. loss = 0.2717091441, classif. loss = 1.0327793360
2025-10-04 13:54:26,504 | INFO | iter is 21000 / 50000 [skipped  163] | loc. loss = 0.1062407047, classif. loss = 0.7179234028
2025-10-04 13:54:59,353 | INFO | iter is 21050 / 50000 [skipped  163] | loc. loss = 0.2483603507, classif. loss = 0.5593321323
2025-10-04 13:55:31,620 | INFO | iter is 21100 / 50000 [skipped  164] | loc. loss = 0.2975128293, classif. loss = 0.7439137101
2025-10-04 13:56:03,868 | INFO | iter is 21150 / 50000 [skipped  165] | loc. loss = 0.2474695146, classif. loss = 0.9697518349
2025-10-04 13:56:36,750 | INFO | iter is 21200 / 50000 [skipped  165] | loc. loss = 0.2256634831, classif. loss = 4.5726284981
2025-10-04 13:57:09,634 | INFO | iter is 21250 / 50000 [skipped  165] | loc. loss = 0.2980988026, classif. loss = 0.1666352898
2025-10-04 13:57:41,886 | INFO | iter is 21300 / 50000 [skipped  166] | loc. loss = 0.2280005217, classif. loss = 1.1044504642
2025-10-04 13:58:14,701 | INFO | iter is 21350 / 50000 [skipped  166] | loc. loss = 0.1412761360, classif. loss = 0.8685576916
2025-10-04 13:58:47,606 | INFO | iter is 21400 / 50000 [skipped  166] | loc. loss = 0.1326868683, classif. loss = 2.8900060654
2025-10-04 13:59:20,459 | INFO | iter is 21450 / 50000 [skipped  166] | loc. loss = 0.2372582406, classif. loss = 1.3655098677
2025-10-04 14:00:25,023 | INFO | iter is 21550 / 50000 [skipped  168] | loc. loss = 0.1222781464, classif. loss = 0.8069226742
2025-10-04 14:00:57,886 | INFO | iter is 21600 / 50000 [skipped  168] | loc. loss = 0.2398085594, classif. loss = 1.1164989471
2025-10-04 14:01:28,917 | INFO | iter is 21650 / 50000 [skipped  171] | loc. loss = 0.1553308219, classif. loss = 0.0420317352
2025-10-04 14:02:00,547 | INFO | iter is 21700 / 50000 [skipped  173] | loc. loss = 0.1272258162, classif. loss = 0.1443358064
2025-10-04 14:02:33,455 | INFO | iter is 21750 / 50000 [skipped  173] | loc. loss = 0.2485938966, classif. loss = 0.0106174750
2025-10-04 14:03:06,315 | INFO | iter is 21800 / 50000 [skipped  173] | loc. loss = 0.3277279735, classif. loss = 0.1801878214
2025-10-04 14:03:38,582 | INFO | iter is 21850 / 50000 [skipped  174] | loc. loss = 0.2306209058, classif. loss = 0.4665126801
2025-10-04 14:04:11,452 | INFO | iter is 21900 / 50000 [skipped  174] | loc. loss = 0.1975630075, classif. loss = 0.4350790977
2025-10-04 14:04:44,187 | INFO | iter is 21950 / 50000 [skipped  174] | loc. loss = 0.2110109627, classif. loss = 0.6834349632
2025-10-04 14:05:16,431 | INFO | iter is 22000 / 50000 [skipped  175] | loc. loss = 0.2101694793, classif. loss = 0.7153199911
2025-10-04 14:05:48,676 | INFO | iter is 22050 / 50000 [skipped  176] | loc. loss = 0.3566494584, classif. loss = 1.1808792353
2025-10-04 14:06:21,610 | INFO | iter is 22100 / 50000 [skipped  176] | loc. loss = 0.1898925453, classif. loss = 0.6530562043
2025-10-04 14:06:54,484 | INFO | iter is 22150 / 50000 [skipped  176] | loc. loss = 0.1777807027, classif. loss = 0.6377780437
2025-10-04 14:07:27,281 | INFO | iter is 22200 / 50000 [skipped  176] | loc. loss = 0.2678336799, classif. loss = 0.0212042984
2025-10-04 14:08:00,219 | INFO | iter is 22250 / 50000 [skipped  176] | loc. loss = 0.1603828669, classif. loss = 0.1807539463
2025-10-04 14:08:33,098 | INFO | iter is 22300 / 50000 [skipped  176] | loc. loss = 0.1374054253, classif. loss = 1.0431925058
2025-10-04 14:09:04,235 | INFO | iter is 22350 / 50000 [skipped  179] | loc. loss = 0.2092669755, classif. loss = 1.0323946476
2025-10-04 14:09:36,528 | INFO | iter is 22400 / 50000 [skipped  180] | loc. loss = 0.2223590612, classif. loss = 0.0933879316
2025-10-04 14:10:09,465 | INFO | iter is 22450 / 50000 [skipped  180] | loc. loss = 0.3089647591, classif. loss = 0.5139638782
2025-10-04 14:10:42,290 | INFO | iter is 22500 / 50000 [skipped  180] | loc. loss = 0.2074485719, classif. loss = 0.2075427175
2025-10-04 14:11:14,484 | INFO | iter is 22550 / 50000 [skipped  181] | loc. loss = 0.1577877998, classif. loss = 0.5685209036
2025-10-04 14:11:47,296 | INFO | iter is 22600 / 50000 [skipped  181] | loc. loss = 0.1257197261, classif. loss = 0.0265984684
2025-10-04 14:12:20,210 | INFO | iter is 22650 / 50000 [skipped  181] | loc. loss = 0.0473631956, classif. loss = 0.0858322829
2025-10-04 14:12:53,021 | INFO | iter is 22700 / 50000 [skipped  181] | loc. loss = 0.3317413330, classif. loss = 0.5036031008
2025-10-04 14:13:25,864 | INFO | iter is 22750 / 50000 [skipped  181] | loc. loss = 0.1954168677, classif. loss = 0.8387931585
2025-10-04 14:13:58,135 | INFO | iter is 22800 / 50000 [skipped  182] | loc. loss = 0.1974835992, classif. loss = 0.0292674117
2025-10-04 14:14:31,091 | INFO | iter is 22850 / 50000 [skipped  182] | loc. loss = 0.1683453321, classif. loss = 0.6183044910
2025-10-04 14:15:03,319 | INFO | iter is 22900 / 50000 [skipped  183] | loc. loss = 0.1526479423, classif. loss = 0.7165445685
2025-10-04 14:15:36,257 | INFO | iter is 22950 / 50000 [skipped  183] | loc. loss = 0.2008257508, classif. loss = 0.4294069409
2025-10-04 14:16:09,116 | INFO | iter is 23000 / 50000 [skipped  183] | loc. loss = 0.1924326420, classif. loss = 0.0092148203
2025-10-04 14:16:41,421 | INFO | iter is 23050 / 50000 [skipped  184] | loc. loss = 0.2112629116, classif. loss = 0.1130477116
2025-10-04 14:17:14,221 | INFO | iter is 23100 / 50000 [skipped  184] | loc. loss = 0.2094009072, classif. loss = 0.7668417692
2025-10-04 14:17:47,140 | INFO | iter is 23150 / 50000 [skipped  184] | loc. loss = 0.1692506969, classif. loss = 1.0430625677
2025-10-04 14:18:18,822 | INFO | iter is 23200 / 50000 [skipped  186] | loc. loss = 0.1549762338, classif. loss = 0.5562197566
2025-10-04 14:18:51,690 | INFO | iter is 23250 / 50000 [skipped  186] | loc. loss = 0.2805578113, classif. loss = 0.6496943235
2025-10-04 14:19:23,870 | INFO | iter is 23300 / 50000 [skipped  187] | loc. loss = 0.1862236261, classif. loss = 0.0068201632
2025-10-04 14:19:56,712 | INFO | iter is 23350 / 50000 [skipped  187] | loc. loss = 0.2622006536, classif. loss = 0.1499633491
2025-10-04 14:20:29,598 | INFO | iter is 23400 / 50000 [skipped  187] | loc. loss = 0.2216540873, classif. loss = 0.3580645919
2025-10-04 14:21:01,339 | INFO | iter is 23450 / 50000 [skipped  189] | loc. loss = 0.1363747269, classif. loss = 0.3954148889
2025-10-04 14:21:34,152 | INFO | iter is 23500 / 50000 [skipped  189] | loc. loss = 0.1602416486, classif. loss = 0.5624148250
2025-10-04 14:22:07,062 | INFO | iter is 23550 / 50000 [skipped  189] | loc. loss = 0.2117409706, classif. loss = 0.3907706439
2025-10-04 14:22:39,945 | INFO | iter is 23600 / 50000 [skipped  189] | loc. loss = 0.1595660299, classif. loss = 0.0054637804
2025-10-04 14:23:12,289 | INFO | iter is 23650 / 50000 [skipped  190] | loc. loss = 0.2006400675, classif. loss = 0.4822157621
2025-10-04 14:23:45,096 | INFO | iter is 23700 / 50000 [skipped  190] | loc. loss = 0.3103330135, classif. loss = 1.1257636547
2025-10-04 14:24:17,952 | INFO | iter is 23750 / 50000 [skipped  190] | loc. loss = 0.1595769823, classif. loss = 0.5818043947
2025-10-04 14:24:50,822 | INFO | iter is 23800 / 50000 [skipped  190] | loc. loss = 0.1494586170, classif. loss = 0.3897047043
2025-10-04 14:25:23,734 | INFO | iter is 23850 / 50000 [skipped  190] | loc. loss = 0.1740270853, classif. loss = 0.0955004320
2025-10-04 14:25:56,605 | INFO | iter is 23900 / 50000 [skipped  190] | loc. loss = 0.1818897426, classif. loss = 1.1361463070
2025-10-04 14:26:28,270 | INFO | iter is 23950 / 50000 [skipped  192] | loc. loss = 0.1559382677, classif. loss = 0.4889392257
2025-10-04 14:27:01,141 | INFO | iter is 24000 / 50000 [skipped  192] | loc. loss = 0.2374967337, classif. loss = 0.9370813966
2025-10-04 14:27:32,726 | INFO | iter is 24050 / 50000 [skipped  194] | loc. loss = 0.1916723251, classif. loss = 1.2255083323
2025-10-04 14:28:05,667 | INFO | iter is 24100 / 50000 [skipped  194] | loc. loss = 0.1926081181, classif. loss = 0.1851565838
2025-10-04 14:28:38,516 | INFO | iter is 24150 / 50000 [skipped  194] | loc. loss = 0.1728772968, classif. loss = 0.5022267699
2025-10-04 14:29:10,857 | INFO | iter is 24200 / 50000 [skipped  195] | loc. loss = 0.1389744133, classif. loss = 1.1671440601
2025-10-04 14:29:43,790 | INFO | iter is 24250 / 50000 [skipped  195] | loc. loss = 0.2097675502, classif. loss = 0.1482113004
2025-10-04 14:30:16,661 | INFO | iter is 24300 / 50000 [skipped  195] | loc. loss = 0.1901233047, classif. loss = 0.2314331830
2025-10-04 14:30:48,908 | INFO | iter is 24350 / 50000 [skipped  196] | loc. loss = 0.1355316639, classif. loss = 0.8564316034
2025-10-04 14:31:21,773 | INFO | iter is 24400 / 50000 [skipped  196] | loc. loss = 0.1576166153, classif. loss = 0.8394432068
2025-10-04 14:31:54,666 | INFO | iter is 24450 / 50000 [skipped  196] | loc. loss = 0.2285149395, classif. loss = 0.2369243056
2025-10-04 14:32:26,928 | INFO | iter is 24500 / 50000 [skipped  197] | loc. loss = 0.1736949831, classif. loss = 0.4935319424
2025-10-04 14:32:59,793 | INFO | iter is 24550 / 50000 [skipped  197] | loc. loss = 0.2879537344, classif. loss = 0.2311263084
2025-10-04 14:33:32,642 | INFO | iter is 24600 / 50000 [skipped  197] | loc. loss = 0.1911738962, classif. loss = 0.8131197691
2025-10-04 14:34:04,916 | INFO | iter is 24650 / 50000 [skipped  198] | loc. loss = 0.1888117492, classif. loss = 0.6077835560
2025-10-04 14:34:37,124 | INFO | iter is 24700 / 50000 [skipped  199] | loc. loss = 0.2296232581, classif. loss = 0.1815357804
2025-10-04 14:35:09,352 | INFO | iter is 24750 / 50000 [skipped  200] | loc. loss = 0.1272558570, classif. loss = 0.3190198541
2025-10-04 14:35:42,193 | INFO | iter is 24800 / 50000 [skipped  200] | loc. loss = 0.2250865996, classif. loss = 2.0638518333
2025-10-04 14:36:14,493 | INFO | iter is 24850 / 50000 [skipped  201] | loc. loss = 0.1487890035, classif. loss = 0.5243017673
2025-10-04 14:36:46,774 | INFO | iter is 24900 / 50000 [skipped  202] | loc. loss = 0.1214044392, classif. loss = 0.4357144833
2025-10-04 14:37:19,760 | INFO | iter is 24950 / 50000 [skipped  202] | loc. loss = 0.1612588018, classif. loss = 0.9303729534
2025-10-04 14:37:52,019 | INFO | iter is 25000 / 50000 [skipped  203] | loc. loss = 0.2039713860, classif. loss = 0.9892058372
2025-10-04 14:37:52,020 | INFO | ---------starting evaluation-----------
2025-10-04 14:37:52,974 | INFO | validation:    0/ 933 (2025-10-04_14-37-52)
2025-10-04 14:38:39,724 | INFO | validation:  100/ 933 (2025-10-04_14-38-39)
2025-10-04 14:39:26,389 | INFO | validation:  200/ 933 (2025-10-04_14-39-26)
2025-10-04 14:40:13,027 | INFO | validation:  300/ 933 (2025-10-04_14-40-13)
2025-10-04 14:40:59,685 | INFO | validation:  400/ 933 (2025-10-04_14-40-59)
2025-10-04 14:41:46,354 | INFO | validation:  500/ 933 (2025-10-04_14-41-46)
2025-10-04 14:42:33,021 | INFO | validation:  600/ 933 (2025-10-04_14-42-33)
2025-10-04 14:43:19,665 | INFO | validation:  700/ 933 (2025-10-04_14-43-19)
2025-10-04 14:44:06,342 | INFO | validation:  800/ 933 (2025-10-04_14-44-06)
2025-10-04 14:44:53,053 | INFO | validation:  900/ 933 (2025-10-04_14-44-53)
2025-10-04 14:45:08,665 | INFO | Confusion Matrix of Localization:
[[912683617   7676232]
 [  9803256  48158303]]
2025-10-04 14:45:08,666 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99165953 0.00834047]
 [0.16913375 0.83086625]]
2025-10-04 14:45:08,666 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41878519  1335803   438933   205486]
 [       0  1489026  2572409   629497    51039]
 [       0   649251   817641  3914793   147245]
 [       0   181944    43134   291046  2553166]]
2025-10-04 14:45:08,666 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95485    0.03045694 0.01000788 0.00468518]
 [0.         0.31400993 0.54247675 0.13275007 0.01076325]
 [0.         0.11742797 0.14788413 0.70805617 0.02663174]
 [0.         0.05927886 0.01405341 0.09482519 0.83184254]]
2025-10-04 14:45:08,666 | INFO | lofF1 is 84.6396, clfF1 is 73.2610, oaF1 is 76.6746, sub class F1 score is [95.1163 54.0936 72.4747 84.7352]
2025-10-04 14:45:08,928 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-04_09-41-45_MambaBDA_Base_xBD_FOCAL_ALIGN_AGBD/model_step25000.pth
2025-10-04 14:45:08,928 | INFO | ---------starting train set evaluation-----------
2025-10-04 14:45:12,915 | INFO | [TrainBuf] locF1 is 85.4036, clfF1 is 70.2501, oaF1 is 74.7961, sub class F1 score is [95.1481 49.1034 70.4631 84.2282]
2025-10-04 14:45:45,873 | INFO | iter is 25050 / 50000 [skipped  203] | loc. loss = 0.1818661541, classif. loss = 0.0918888822
2025-10-04 14:46:18,807 | INFO | iter is 25100 / 50000 [skipped  203] | loc. loss = 0.2653101087, classif. loss = 0.6154705882
2025-10-04 14:46:50,493 | INFO | iter is 25150 / 50000 [skipped  205] | loc. loss = 0.2573800683, classif. loss = 0.4766535163
2025-10-04 14:47:23,419 | INFO | iter is 25200 / 50000 [skipped  205] | loc. loss = 0.1887459606, classif. loss = 0.1542537063
2025-10-04 14:47:55,743 | INFO | iter is 25250 / 50000 [skipped  206] | loc. loss = 0.2031547725, classif. loss = 0.1645695269
2025-10-04 14:48:28,634 | INFO | iter is 25300 / 50000 [skipped  206] | loc. loss = 0.2636797428, classif. loss = 0.6457146406
2025-10-04 14:49:01,556 | INFO | iter is 25350 / 50000 [skipped  206] | loc. loss = 0.1218405366, classif. loss = 0.3913329244
2025-10-04 14:49:34,466 | INFO | iter is 25400 / 50000 [skipped  206] | loc. loss = 0.2605436146, classif. loss = 0.0320741981
2025-10-04 14:50:06,820 | INFO | iter is 25450 / 50000 [skipped  207] | loc. loss = 0.2930611372, classif. loss = 0.9692691565
2025-10-04 14:50:39,832 | INFO | iter is 25500 / 50000 [skipped  207] | loc. loss = 0.1732721180, classif. loss = 0.4403205514
2025-10-04 14:51:12,756 | INFO | iter is 25550 / 50000 [skipped  207] | loc. loss = 0.3056861162, classif. loss = 0.5109972358
2025-10-04 14:51:44,518 | INFO | iter is 25600 / 50000 [skipped  209] | loc. loss = 0.1586869210, classif. loss = 0.9104250073
2025-10-04 14:52:17,377 | INFO | iter is 25650 / 50000 [skipped  209] | loc. loss = 0.1575392038, classif. loss = 0.1658093184
2025-10-04 14:52:50,424 | INFO | iter is 25700 / 50000 [skipped  209] | loc. loss = 0.2635805011, classif. loss = 0.5382105112
2025-10-04 14:53:22,730 | INFO | iter is 25750 / 50000 [skipped  210] | loc. loss = 0.2999238968, classif. loss = 0.5110516548
2025-10-04 14:53:55,685 | INFO | iter is 25800 / 50000 [skipped  210] | loc. loss = 0.1668971330, classif. loss = 0.4357520938
2025-10-04 14:54:28,656 | INFO | iter is 25850 / 50000 [skipped  210] | loc. loss = 0.2846004069, classif. loss = 1.3218971491
2025-10-04 14:55:00,923 | INFO | iter is 25900 / 50000 [skipped  211] | loc. loss = 0.2071167380, classif. loss = 0.7137968540
2025-10-04 14:55:33,970 | INFO | iter is 25950 / 50000 [skipped  211] | loc. loss = 0.1650132537, classif. loss = 4.5900635719
2025-10-04 14:56:06,270 | INFO | iter is 26000 / 50000 [skipped  212] | loc. loss = 0.2084911019, classif. loss = 0.7168126106
2025-10-04 14:56:39,233 | INFO | iter is 26050 / 50000 [skipped  212] | loc. loss = 0.2179566622, classif. loss = 0.7984099984
2025-10-04 14:57:43,277 | INFO | iter is 26150 / 50000 [skipped  215] | loc. loss = 0.3223811388, classif. loss = 0.2292170972
2025-10-04 14:58:16,189 | INFO | iter is 26200 / 50000 [skipped  215] | loc. loss = 0.1990486085, classif. loss = 0.4595445991
2025-10-04 14:58:49,061 | INFO | iter is 26250 / 50000 [skipped  215] | loc. loss = 0.1568298489, classif. loss = 0.6942058802
2025-10-04 14:59:21,333 | INFO | iter is 26300 / 50000 [skipped  216] | loc. loss = 0.2180762887, classif. loss = 0.5864540339
2025-10-04 14:59:53,671 | INFO | iter is 26350 / 50000 [skipped  217] | loc. loss = 0.2552150190, classif. loss = 0.0835215747
2025-10-04 15:00:25,400 | INFO | iter is 26400 / 50000 [skipped  219] | loc. loss = 0.3016460538, classif. loss = 0.9488520622
2025-10-04 15:00:58,362 | INFO | iter is 26450 / 50000 [skipped  219] | loc. loss = 0.3157059550, classif. loss = 0.5125905871
2025-10-04 15:01:31,217 | INFO | iter is 26500 / 50000 [skipped  219] | loc. loss = 0.2606116533, classif. loss = 1.3149744272
2025-10-04 15:02:04,071 | INFO | iter is 26550 / 50000 [skipped  219] | loc. loss = 0.1633294821, classif. loss = 1.6175034046
2025-10-04 15:02:36,438 | INFO | iter is 26600 / 50000 [skipped  220] | loc. loss = 0.1387646347, classif. loss = 0.6815289259
2025-10-04 15:03:09,312 | INFO | iter is 26650 / 50000 [skipped  220] | loc. loss = 0.1363978535, classif. loss = 0.4879181981
2025-10-04 15:03:41,656 | INFO | iter is 26700 / 50000 [skipped  221] | loc. loss = 0.1713264585, classif. loss = 0.2911306620
2025-10-04 15:04:14,024 | INFO | iter is 26750 / 50000 [skipped  222] | loc. loss = 0.1277973056, classif. loss = 0.4003068805
2025-10-04 15:04:46,898 | INFO | iter is 26800 / 50000 [skipped  222] | loc. loss = 0.1465751976, classif. loss = 3.0508892536
2025-10-04 15:05:19,803 | INFO | iter is 26850 / 50000 [skipped  222] | loc. loss = 0.2168105841, classif. loss = 0.7122797966
2025-10-04 15:05:52,720 | INFO | iter is 26900 / 50000 [skipped  222] | loc. loss = 0.1166303530, classif. loss = 0.0679617822
2025-10-04 15:06:25,575 | INFO | iter is 26950 / 50000 [skipped  222] | loc. loss = 0.1628908962, classif. loss = 0.1002916843
2025-10-04 15:06:58,004 | INFO | iter is 27000 / 50000 [skipped  223] | loc. loss = 0.1894567460, classif. loss = 0.0292175114
2025-10-04 15:07:30,879 | INFO | iter is 27050 / 50000 [skipped  223] | loc. loss = 0.2014052868, classif. loss = 0.5268988609
2025-10-04 15:08:03,151 | INFO | iter is 27100 / 50000 [skipped  224] | loc. loss = 0.2169133276, classif. loss = 1.4320214987
2025-10-04 15:08:36,019 | INFO | iter is 27150 / 50000 [skipped  224] | loc. loss = 0.1896757931, classif. loss = 0.2324501872
2025-10-04 15:09:08,872 | INFO | iter is 27200 / 50000 [skipped  224] | loc. loss = 0.1530016512, classif. loss = 0.1850460917
2025-10-04 15:09:41,132 | INFO | iter is 27250 / 50000 [skipped  225] | loc. loss = 0.3646692038, classif. loss = 0.9073182344
2025-10-04 15:10:13,377 | INFO | iter is 27300 / 50000 [skipped  226] | loc. loss = 0.2084802985, classif. loss = 0.9495528340
2025-10-04 15:10:45,739 | INFO | iter is 27350 / 50000 [skipped  227] | loc. loss = 0.2776530385, classif. loss = 0.0234263390
2025-10-04 15:11:18,587 | INFO | iter is 27400 / 50000 [skipped  227] | loc. loss = 0.2501744926, classif. loss = 0.2342217714
2025-10-04 15:11:51,475 | INFO | iter is 27450 / 50000 [skipped  227] | loc. loss = 0.1694304347, classif. loss = 0.2903465927
2025-10-04 15:12:24,331 | INFO | iter is 27500 / 50000 [skipped  227] | loc. loss = 0.2118775249, classif. loss = 0.8377305269
2025-10-04 15:12:57,307 | INFO | iter is 27550 / 50000 [skipped  227] | loc. loss = 0.1772727817, classif. loss = 0.6575504541
2025-10-04 15:13:30,155 | INFO | iter is 27600 / 50000 [skipped  227] | loc. loss = 0.2343919873, classif. loss = 0.4746780396
2025-10-04 15:14:02,407 | INFO | iter is 27650 / 50000 [skipped  228] | loc. loss = 0.2360468656, classif. loss = 0.8784978390
2025-10-04 15:14:35,333 | INFO | iter is 27700 / 50000 [skipped  228] | loc. loss = 0.2472733259, classif. loss = 0.7344014645
2025-10-04 15:15:08,281 | INFO | iter is 27750 / 50000 [skipped  228] | loc. loss = 0.1540156603, classif. loss = 0.6477940083
2025-10-04 15:15:39,982 | INFO | iter is 27800 / 50000 [skipped  230] | loc. loss = 0.2094218433, classif. loss = 0.1445450187
2025-10-04 15:16:12,791 | INFO | iter is 27850 / 50000 [skipped  230] | loc. loss = 0.1761356592, classif. loss = 0.5444104075
2025-10-04 15:16:45,071 | INFO | iter is 27900 / 50000 [skipped  231] | loc. loss = 0.2166476846, classif. loss = 0.5913594961
2025-10-04 15:17:17,889 | INFO | iter is 27950 / 50000 [skipped  231] | loc. loss = 0.2042038143, classif. loss = 1.0197949409
2025-10-04 15:17:50,763 | INFO | iter is 28000 / 50000 [skipped  231] | loc. loss = 0.2446230948, classif. loss = 0.5970458388
2025-10-04 15:18:23,096 | INFO | iter is 28050 / 50000 [skipped  232] | loc. loss = 0.1398390830, classif. loss = 1.1388535500
2025-10-04 15:18:55,389 | INFO | iter is 28100 / 50000 [skipped  233] | loc. loss = 0.1077750549, classif. loss = 0.6908728480
2025-10-04 15:19:28,366 | INFO | iter is 28150 / 50000 [skipped  233] | loc. loss = 0.2180038989, classif. loss = 0.1155037060
2025-10-04 15:20:01,259 | INFO | iter is 28200 / 50000 [skipped  233] | loc. loss = 0.3414452970, classif. loss = 1.7223715782
2025-10-04 15:20:34,121 | INFO | iter is 28250 / 50000 [skipped  233] | loc. loss = 0.2366990000, classif. loss = 0.8341418505
2025-10-04 15:21:07,039 | INFO | iter is 28300 / 50000 [skipped  233] | loc. loss = 0.1589670628, classif. loss = 0.1504632086
2025-10-04 15:21:40,030 | INFO | iter is 28350 / 50000 [skipped  233] | loc. loss = 0.1898564696, classif. loss = 0.7734212875
2025-10-04 15:22:11,700 | INFO | iter is 28400 / 50000 [skipped  235] | loc. loss = 0.1747827977, classif. loss = 0.0087015163
2025-10-04 15:22:44,636 | INFO | iter is 28450 / 50000 [skipped  235] | loc. loss = 0.2905225158, classif. loss = 0.3688498735
2025-10-04 15:23:17,491 | INFO | iter is 28500 / 50000 [skipped  235] | loc. loss = 0.1458674073, classif. loss = 0.2289358079
2025-10-04 15:23:49,855 | INFO | iter is 28550 / 50000 [skipped  236] | loc. loss = 0.1781713367, classif. loss = 0.4420545697
2025-10-04 15:24:22,049 | INFO | iter is 28600 / 50000 [skipped  237] | loc. loss = 0.0340125747, classif. loss = 0.1928951144
2025-10-04 15:24:53,791 | INFO | iter is 28650 / 50000 [skipped  239] | loc. loss = 0.2234945297, classif. loss = 2.1336607933
2025-10-04 15:25:26,637 | INFO | iter is 28700 / 50000 [skipped  239] | loc. loss = 0.1887554377, classif. loss = 1.7002716064
2025-10-04 15:25:58,937 | INFO | iter is 28750 / 50000 [skipped  240] | loc. loss = 0.1956295222, classif. loss = 0.7972884178
2025-10-04 15:26:31,793 | INFO | iter is 28800 / 50000 [skipped  240] | loc. loss = 0.2135668397, classif. loss = 0.2049299628
2025-10-04 15:27:04,183 | INFO | iter is 28850 / 50000 [skipped  241] | loc. loss = 0.1844262630, classif. loss = 0.1195685342
2025-10-04 15:27:37,024 | INFO | iter is 28900 / 50000 [skipped  241] | loc. loss = 0.1677065790, classif. loss = 0.1548388749
2025-10-04 15:28:09,279 | INFO | iter is 28950 / 50000 [skipped  242] | loc. loss = 0.2028608322, classif. loss = 0.4616302848
2025-10-04 15:28:42,311 | INFO | iter is 29000 / 50000 [skipped  242] | loc. loss = 0.3033614755, classif. loss = 1.1080708504
2025-10-04 15:29:15,146 | INFO | iter is 29050 / 50000 [skipped  242] | loc. loss = 0.1012584418, classif. loss = 0.0942353830
2025-10-04 15:29:47,508 | INFO | iter is 29100 / 50000 [skipped  243] | loc. loss = 0.1854536235, classif. loss = 0.4138326049
2025-10-04 15:30:20,346 | INFO | iter is 29150 / 50000 [skipped  243] | loc. loss = 0.2192499340, classif. loss = 0.8886672258
2025-10-04 15:30:52,728 | INFO | iter is 29200 / 50000 [skipped  244] | loc. loss = 0.2712112069, classif. loss = 0.4744989872
2025-10-04 15:31:25,644 | INFO | iter is 29250 / 50000 [skipped  244] | loc. loss = 0.1636981517, classif. loss = 0.6239341497
2025-10-04 15:31:58,587 | INFO | iter is 29300 / 50000 [skipped  244] | loc. loss = 0.1301459521, classif. loss = 0.0142890513
2025-10-04 15:32:30,887 | INFO | iter is 29350 / 50000 [skipped  245] | loc. loss = 0.2131760269, classif. loss = 1.0208179951
2025-10-04 15:33:03,817 | INFO | iter is 29400 / 50000 [skipped  245] | loc. loss = 0.1438170373, classif. loss = 0.1898605078
2025-10-04 15:33:36,692 | INFO | iter is 29450 / 50000 [skipped  245] | loc. loss = 0.1274097562, classif. loss = 0.7877063751
2025-10-04 15:34:09,640 | INFO | iter is 29500 / 50000 [skipped  245] | loc. loss = 0.1955451965, classif. loss = 0.0191399828
2025-10-04 15:34:42,516 | INFO | iter is 29550 / 50000 [skipped  245] | loc. loss = 0.1670509428, classif. loss = 1.0580965281
2025-10-04 15:35:15,441 | INFO | iter is 29600 / 50000 [skipped  245] | loc. loss = 0.1855369955, classif. loss = 0.8103185892
2025-10-04 15:35:48,272 | INFO | iter is 29650 / 50000 [skipped  245] | loc. loss = 0.1662552059, classif. loss = 0.0567507744
2025-10-04 15:36:21,080 | INFO | iter is 29700 / 50000 [skipped  245] | loc. loss = 0.4186738729, classif. loss = 0.7323728800
2025-10-04 15:36:53,424 | INFO | iter is 29750 / 50000 [skipped  246] | loc. loss = 0.1323097199, classif. loss = 1.1253151894
2025-10-04 15:37:26,251 | INFO | iter is 29800 / 50000 [skipped  246] | loc. loss = 0.2166666389, classif. loss = 0.2653598785
2025-10-04 15:37:59,094 | INFO | iter is 29850 / 50000 [skipped  246] | loc. loss = 0.1860774755, classif. loss = 1.1006655693
2025-10-04 15:38:31,940 | INFO | iter is 29900 / 50000 [skipped  246] | loc. loss = 0.1201509386, classif. loss = 0.9662528038
2025-10-04 15:39:04,820 | INFO | iter is 29950 / 50000 [skipped  246] | loc. loss = 0.1863307953, classif. loss = 0.0940760896
2025-10-04 15:39:37,070 | INFO | iter is 30000 / 50000 [skipped  247] | loc. loss = 0.1754853427, classif. loss = 1.2989475727
2025-10-04 15:40:09,897 | INFO | iter is 30050 / 50000 [skipped  247] | loc. loss = 0.2106638849, classif. loss = 1.5751017332
2025-10-04 15:40:42,846 | INFO | iter is 30100 / 50000 [skipped  247] | loc. loss = 0.1380374283, classif. loss = 0.4625335932
2025-10-04 15:41:15,722 | INFO | iter is 30150 / 50000 [skipped  247] | loc. loss = 0.2217587531, classif. loss = 0.5442118645
2025-10-04 15:41:48,617 | INFO | iter is 30200 / 50000 [skipped  247] | loc. loss = 0.1058405116, classif. loss = 0.8397492170
2025-10-04 15:42:20,899 | INFO | iter is 30250 / 50000 [skipped  248] | loc. loss = 0.2360878736, classif. loss = 0.6229241490
2025-10-04 15:42:53,265 | INFO | iter is 30300 / 50000 [skipped  249] | loc. loss = 0.1680621058, classif. loss = 0.5889043808
2025-10-04 15:43:26,135 | INFO | iter is 30350 / 50000 [skipped  249] | loc. loss = 0.2176799476, classif. loss = 0.3801301718
2025-10-04 15:43:58,422 | INFO | iter is 30400 / 50000 [skipped  250] | loc. loss = 0.1988830864, classif. loss = 0.2911655307
2025-10-04 15:44:31,330 | INFO | iter is 30450 / 50000 [skipped  250] | loc. loss = 0.2089604437, classif. loss = 0.6914946437
2025-10-04 15:45:04,179 | INFO | iter is 30500 / 50000 [skipped  250] | loc. loss = 0.1780268997, classif. loss = 0.6000880003
2025-10-04 15:45:37,058 | INFO | iter is 30550 / 50000 [skipped  250] | loc. loss = 0.2419941425, classif. loss = 2.4074323177
2025-10-04 15:46:09,307 | INFO | iter is 30600 / 50000 [skipped  251] | loc. loss = 0.2415667474, classif. loss = 1.0076823235
2025-10-04 15:46:42,206 | INFO | iter is 30650 / 50000 [skipped  251] | loc. loss = 0.1891817153, classif. loss = 0.0627027526
2025-10-04 15:47:13,866 | INFO | iter is 30700 / 50000 [skipped  253] | loc. loss = 0.1683558524, classif. loss = 0.9874204397
2025-10-04 15:47:46,758 | INFO | iter is 30750 / 50000 [skipped  253] | loc. loss = 0.2000553310, classif. loss = 0.9432865381
2025-10-04 15:48:19,653 | INFO | iter is 30800 / 50000 [skipped  253] | loc. loss = 0.2534493208, classif. loss = 0.0182380378
2025-10-04 15:48:51,406 | INFO | iter is 30850 / 50000 [skipped  255] | loc. loss = 0.1270134598, classif. loss = 5.1407575607
2025-10-04 15:49:24,217 | INFO | iter is 30900 / 50000 [skipped  255] | loc. loss = 0.3209712505, classif. loss = 0.1069762558
2025-10-04 15:49:56,514 | INFO | iter is 30950 / 50000 [skipped  256] | loc. loss = 0.2534676194, classif. loss = 0.9042639136
2025-10-04 15:50:29,390 | INFO | iter is 31000 / 50000 [skipped  256] | loc. loss = 0.2393631339, classif. loss = 0.0295699425
2025-10-04 15:51:02,341 | INFO | iter is 31050 / 50000 [skipped  256] | loc. loss = 0.1300185770, classif. loss = 0.0355232842
2025-10-04 15:51:34,637 | INFO | iter is 31100 / 50000 [skipped  257] | loc. loss = 0.1357088536, classif. loss = 0.9378688335
2025-10-04 15:52:06,952 | INFO | iter is 31150 / 50000 [skipped  258] | loc. loss = 0.2199199796, classif. loss = 1.9033538103
2025-10-04 15:52:39,763 | INFO | iter is 31200 / 50000 [skipped  258] | loc. loss = 0.2459936142, classif. loss = 0.2212985307
2025-10-04 15:53:12,658 | INFO | iter is 31250 / 50000 [skipped  258] | loc. loss = 0.2344022542, classif. loss = 1.5913913250
2025-10-04 15:53:12,660 | INFO | ---------starting evaluation-----------
2025-10-04 15:53:13,622 | INFO | validation:    0/ 933 (2025-10-04_15-53-13)
2025-10-04 15:54:00,335 | INFO | validation:  100/ 933 (2025-10-04_15-54-00)
2025-10-04 15:54:46,983 | INFO | validation:  200/ 933 (2025-10-04_15-54-46)
2025-10-04 15:55:33,616 | INFO | validation:  300/ 933 (2025-10-04_15-55-33)
2025-10-04 15:56:20,268 | INFO | validation:  400/ 933 (2025-10-04_15-56-20)
2025-10-04 15:57:06,921 | INFO | validation:  500/ 933 (2025-10-04_15-57-06)
2025-10-04 15:57:53,581 | INFO | validation:  600/ 933 (2025-10-04_15-57-53)
2025-10-04 15:58:40,237 | INFO | validation:  700/ 933 (2025-10-04_15-58-40)
2025-10-04 15:59:26,909 | INFO | validation:  800/ 933 (2025-10-04_15-59-26)
2025-10-04 16:00:13,573 | INFO | validation:  900/ 933 (2025-10-04_16-00-13)
2025-10-04 16:00:29,157 | INFO | Confusion Matrix of Localization:
[[911659303   8700546]
 [  9080480  48881079]]
2025-10-04 16:00:29,157 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99054658 0.00945342]
 [0.15666383 0.84333617]]
2025-10-04 16:00:29,157 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 38927191  3112662  1719066    99822]
 [       0   663352  2647045  1386915    44659]
 [       0   364434   600354  4422359   141783]
 [       0    86620    39824   379352  2563494]]
2025-10-04 16:00:29,157 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.88755833 0.07097016 0.03919552 0.00227599]
 [0.         0.13988951 0.55821619 0.29247648 0.00941781]
 [0.         0.06591402 0.10858412 0.79985802 0.02564384]
 [0.         0.02822151 0.01297499 0.12359601 0.83520749]]
2025-10-04 16:00:29,157 | INFO | lofF1 is 84.6109, clfF1 is 68.3072, oaF1 is 73.1983, sub class F1 score is [92.7939 47.5153 65.8255 86.6185]
2025-10-04 16:00:29,158 | INFO | ---------starting train set evaluation-----------
2025-10-04 16:00:33,114 | INFO | [TrainBuf] locF1 is 85.6593, clfF1 is 73.2620, oaF1 is 76.9812, sub class F1 score is [95.2366 52.1641 74.4852 86.9362]
2025-10-04 16:01:05,975 | INFO | iter is 31300 / 50000 [skipped  258] | loc. loss = 0.2288798988, classif. loss = 0.2659640610
2025-10-04 16:01:38,273 | INFO | iter is 31350 / 50000 [skipped  259] | loc. loss = 0.3507550061, classif. loss = 0.0277494080
2025-10-04 16:02:11,115 | INFO | iter is 31400 / 50000 [skipped  259] | loc. loss = 0.1793512851, classif. loss = 1.7183661461
2025-10-04 16:02:43,433 | INFO | iter is 31450 / 50000 [skipped  260] | loc. loss = 0.0586601757, classif. loss = 0.2381491065
2025-10-04 16:03:16,430 | INFO | iter is 31500 / 50000 [skipped  260] | loc. loss = 0.2323937416, classif. loss = 1.4962638617
2025-10-04 16:03:49,337 | INFO | iter is 31550 / 50000 [skipped  260] | loc. loss = 0.1945658624, classif. loss = 0.6644817591
2025-10-04 16:04:22,274 | INFO | iter is 31600 / 50000 [skipped  260] | loc. loss = 0.1757877916, classif. loss = 0.6042471528
2025-10-04 16:04:55,148 | INFO | iter is 31650 / 50000 [skipped  260] | loc. loss = 0.1973807365, classif. loss = 0.6009678841
2025-10-04 16:05:26,955 | INFO | iter is 31700 / 50000 [skipped  262] | loc. loss = 0.1812899560, classif. loss = 0.0501877591
2025-10-04 16:05:59,807 | INFO | iter is 31750 / 50000 [skipped  262] | loc. loss = 0.1783556789, classif. loss = 0.4426182210
2025-10-04 16:06:32,733 | INFO | iter is 31800 / 50000 [skipped  262] | loc. loss = 0.1914151609, classif. loss = 0.3503964543
2025-10-04 16:07:05,679 | INFO | iter is 31850 / 50000 [skipped  262] | loc. loss = 0.1637305319, classif. loss = 0.0389011987
2025-10-04 16:07:38,523 | INFO | iter is 31900 / 50000 [skipped  262] | loc. loss = 0.2457115948, classif. loss = 0.9580320120
2025-10-04 16:08:11,392 | INFO | iter is 31950 / 50000 [skipped  262] | loc. loss = 0.1738618016, classif. loss = 0.3958401680
2025-10-04 16:08:44,278 | INFO | iter is 32000 / 50000 [skipped  262] | loc. loss = 0.2753292918, classif. loss = 0.8655470014
2025-10-04 16:09:17,196 | INFO | iter is 32050 / 50000 [skipped  262] | loc. loss = 0.2002833784, classif. loss = 1.4097849131
2025-10-04 16:09:50,112 | INFO | iter is 32100 / 50000 [skipped  262] | loc. loss = 0.1743924022, classif. loss = 0.0935299173
2025-10-04 16:10:23,112 | INFO | iter is 32150 / 50000 [skipped  262] | loc. loss = 0.1476193964, classif. loss = 0.6168712378
2025-10-04 16:10:56,002 | INFO | iter is 32200 / 50000 [skipped  262] | loc. loss = 0.2269953787, classif. loss = 0.7246058583
2025-10-04 16:11:28,895 | INFO | iter is 32250 / 50000 [skipped  262] | loc. loss = 0.1806301624, classif. loss = 0.8829338551
2025-10-04 16:12:01,817 | INFO | iter is 32300 / 50000 [skipped  262] | loc. loss = 0.2082175761, classif. loss = 0.5552232265
2025-10-04 16:12:34,684 | INFO | iter is 32350 / 50000 [skipped  262] | loc. loss = 0.1705863327, classif. loss = 0.0523683690
2025-10-04 16:13:07,554 | INFO | iter is 32400 / 50000 [skipped  262] | loc. loss = 0.1979550421, classif. loss = 0.1588314176
2025-10-04 16:13:40,474 | INFO | iter is 32450 / 50000 [skipped  262] | loc. loss = 0.4417000413, classif. loss = 0.0677926168
2025-10-04 16:14:13,356 | INFO | iter is 32500 / 50000 [skipped  262] | loc. loss = 0.2784146667, classif. loss = 0.6225995421
2025-10-04 16:14:46,207 | INFO | iter is 32550 / 50000 [skipped  262] | loc. loss = 0.1397031397, classif. loss = 0.6375343204
2025-10-04 16:15:19,132 | INFO | iter is 32600 / 50000 [skipped  262] | loc. loss = 0.1191533059, classif. loss = 0.3687384427
2025-10-04 16:15:51,960 | INFO | iter is 32650 / 50000 [skipped  262] | loc. loss = 0.1548602730, classif. loss = 0.5523877144
2025-10-04 16:16:24,280 | INFO | iter is 32700 / 50000 [skipped  263] | loc. loss = 0.1267998368, classif. loss = 0.0955824852
2025-10-04 16:16:57,110 | INFO | iter is 32750 / 50000 [skipped  263] | loc. loss = 0.1738355011, classif. loss = 0.0361738764
2025-10-04 16:17:30,054 | INFO | iter is 32800 / 50000 [skipped  263] | loc. loss = 0.1451019496, classif. loss = 0.0602489635
2025-10-04 16:18:02,901 | INFO | iter is 32850 / 50000 [skipped  263] | loc. loss = 0.1962214708, classif. loss = 0.8559485674
2025-10-04 16:18:35,797 | INFO | iter is 32900 / 50000 [skipped  263] | loc. loss = 0.1887918413, classif. loss = 0.8874320984
2025-10-04 16:19:08,698 | INFO | iter is 32950 / 50000 [skipped  263] | loc. loss = 0.2055628598, classif. loss = 0.3440137208
2025-10-04 16:19:41,624 | INFO | iter is 33000 / 50000 [skipped  263] | loc. loss = 0.2511823773, classif. loss = 0.2289904058
2025-10-04 16:20:13,905 | INFO | iter is 33050 / 50000 [skipped  264] | loc. loss = 0.2454212755, classif. loss = 0.4413744807
2025-10-04 16:20:46,876 | INFO | iter is 33100 / 50000 [skipped  264] | loc. loss = 0.1734987795, classif. loss = 0.0445915461
2025-10-04 16:21:19,741 | INFO | iter is 33150 / 50000 [skipped  264] | loc. loss = 0.1746622175, classif. loss = 0.9752964973
2025-10-04 16:21:52,621 | INFO | iter is 33200 / 50000 [skipped  264] | loc. loss = 0.1023486257, classif. loss = 0.1514887512
2025-10-04 16:22:25,429 | INFO | iter is 33250 / 50000 [skipped  264] | loc. loss = 0.1939682961, classif. loss = 0.3891632855
2025-10-04 16:22:58,281 | INFO | iter is 33300 / 50000 [skipped  264] | loc. loss = 0.1904638112, classif. loss = 0.8482798338
2025-10-04 16:23:31,157 | INFO | iter is 33350 / 50000 [skipped  264] | loc. loss = 0.1233823001, classif. loss = 0.3840515018
2025-10-04 16:24:04,089 | INFO | iter is 33400 / 50000 [skipped  264] | loc. loss = 0.1814580113, classif. loss = 0.0556914434
2025-10-04 16:24:35,760 | INFO | iter is 33450 / 50000 [skipped  266] | loc. loss = 0.2006159574, classif. loss = 0.5101853609
2025-10-04 16:25:08,550 | INFO | iter is 33500 / 50000 [skipped  266] | loc. loss = 0.1029297262, classif. loss = 0.5650093555
2025-10-04 16:25:41,485 | INFO | iter is 33550 / 50000 [skipped  266] | loc. loss = 0.6060485244, classif. loss = 1.4468146563
2025-10-04 16:26:13,804 | INFO | iter is 33600 / 50000 [skipped  267] | loc. loss = 0.2759972811, classif. loss = 1.3733725548
2025-10-04 16:26:46,756 | INFO | iter is 33650 / 50000 [skipped  267] | loc. loss = 0.2397036850, classif. loss = 0.6551908851
2025-10-04 16:27:19,618 | INFO | iter is 33700 / 50000 [skipped  267] | loc. loss = 0.1922943890, classif. loss = 1.6996357441
2025-10-04 16:27:52,482 | INFO | iter is 33750 / 50000 [skipped  267] | loc. loss = 0.1379456520, classif. loss = 1.4279285669
2025-10-04 16:28:25,325 | INFO | iter is 33800 / 50000 [skipped  267] | loc. loss = 0.1489852816, classif. loss = 0.9857524633
2025-10-04 16:28:58,196 | INFO | iter is 33850 / 50000 [skipped  267] | loc. loss = 0.1727625728, classif. loss = 0.4639877081
2025-10-04 16:29:31,077 | INFO | iter is 33900 / 50000 [skipped  267] | loc. loss = 0.1902872771, classif. loss = 0.1651088893
2025-10-04 16:30:04,036 | INFO | iter is 33950 / 50000 [skipped  267] | loc. loss = 0.1293851584, classif. loss = 1.1673123837
2025-10-04 16:30:36,287 | INFO | iter is 34000 / 50000 [skipped  268] | loc. loss = 0.1455272436, classif. loss = 0.3442362845
2025-10-04 16:31:09,183 | INFO | iter is 34050 / 50000 [skipped  268] | loc. loss = 0.2364239842, classif. loss = 0.4133190215
2025-10-04 16:31:41,453 | INFO | iter is 34100 / 50000 [skipped  269] | loc. loss = 0.2403282672, classif. loss = 0.0622566603
2025-10-04 16:32:13,760 | INFO | iter is 34150 / 50000 [skipped  270] | loc. loss = 0.1855305135, classif. loss = 0.0494004115
2025-10-04 16:32:45,967 | INFO | iter is 34200 / 50000 [skipped  271] | loc. loss = 0.1649351269, classif. loss = 1.8957221508
2025-10-04 16:33:18,356 | INFO | iter is 34250 / 50000 [skipped  272] | loc. loss = 0.2369706631, classif. loss = 0.0155668557
2025-10-04 16:33:51,202 | INFO | iter is 34300 / 50000 [skipped  272] | loc. loss = 0.2109696567, classif. loss = 0.9019282460
2025-10-04 16:34:24,099 | INFO | iter is 34350 / 50000 [skipped  272] | loc. loss = 0.2075218409, classif. loss = 0.5038964748
2025-10-04 16:34:56,370 | INFO | iter is 34400 / 50000 [skipped  273] | loc. loss = 0.1750029624, classif. loss = 0.0409054309
2025-10-04 16:35:29,257 | INFO | iter is 34450 / 50000 [skipped  273] | loc. loss = 0.2414358109, classif. loss = 1.4239541292
2025-10-04 16:36:02,192 | INFO | iter is 34500 / 50000 [skipped  273] | loc. loss = 0.1863670945, classif. loss = 0.6475690603
2025-10-04 16:36:35,028 | INFO | iter is 34550 / 50000 [skipped  273] | loc. loss = 0.3146071434, classif. loss = 0.0537245274
2025-10-04 16:37:07,322 | INFO | iter is 34600 / 50000 [skipped  274] | loc. loss = 0.2163119316, classif. loss = 0.4306218028
2025-10-04 16:37:40,149 | INFO | iter is 34650 / 50000 [skipped  274] | loc. loss = 0.1868816912, classif. loss = 1.1258213520
2025-10-04 16:38:13,074 | INFO | iter is 34700 / 50000 [skipped  274] | loc. loss = 0.2016004622, classif. loss = 0.3601956666
2025-10-04 16:38:45,335 | INFO | iter is 34750 / 50000 [skipped  275] | loc. loss = 0.0759690255, classif. loss = 0.8108364940
2025-10-04 16:39:18,171 | INFO | iter is 34800 / 50000 [skipped  275] | loc. loss = 0.1446569264, classif. loss = 1.1810352802
2025-10-04 16:39:50,424 | INFO | iter is 34850 / 50000 [skipped  276] | loc. loss = 0.1560974717, classif. loss = 0.7225896120
2025-10-04 16:40:22,137 | INFO | iter is 34900 / 50000 [skipped  278] | loc. loss = 0.1266909391, classif. loss = 0.2818206251
2025-10-04 16:40:54,986 | INFO | iter is 34950 / 50000 [skipped  278] | loc. loss = 0.1911464185, classif. loss = 0.5958263874
2025-10-04 16:41:27,312 | INFO | iter is 35000 / 50000 [skipped  279] | loc. loss = 0.2390852571, classif. loss = 0.1839109957
2025-10-04 16:42:00,228 | INFO | iter is 35050 / 50000 [skipped  279] | loc. loss = 0.1579414308, classif. loss = 2.2088699341
2025-10-04 16:42:32,494 | INFO | iter is 35100 / 50000 [skipped  280] | loc. loss = 0.2475879043, classif. loss = 0.5388669968
2025-10-04 16:43:04,803 | INFO | iter is 35150 / 50000 [skipped  281] | loc. loss = 0.2131315321, classif. loss = 0.5353990793
2025-10-04 16:44:09,889 | INFO | iter is 35250 / 50000 [skipped  282] | loc. loss = 0.1437081546, classif. loss = 0.5561416745
2025-10-04 16:44:42,793 | INFO | iter is 35300 / 50000 [skipped  282] | loc. loss = 0.2414173037, classif. loss = 0.0657272488
2025-10-04 16:45:15,678 | INFO | iter is 35350 / 50000 [skipped  282] | loc. loss = 0.3060619235, classif. loss = 0.6046668291
2025-10-04 16:45:47,914 | INFO | iter is 35400 / 50000 [skipped  283] | loc. loss = 0.1772898734, classif. loss = 0.5322908759
2025-10-04 16:46:20,814 | INFO | iter is 35450 / 50000 [skipped  283] | loc. loss = 0.1117773503, classif. loss = 0.4881293774
2025-10-04 16:46:53,723 | INFO | iter is 35500 / 50000 [skipped  283] | loc. loss = 0.1781965643, classif. loss = 0.6389714479
2025-10-04 16:47:26,547 | INFO | iter is 35550 / 50000 [skipped  283] | loc. loss = 0.1978088468, classif. loss = 0.0741225183
2025-10-04 16:47:58,866 | INFO | iter is 35600 / 50000 [skipped  284] | loc. loss = 0.1872788817, classif. loss = 0.0818845853
2025-10-04 16:48:31,755 | INFO | iter is 35650 / 50000 [skipped  284] | loc. loss = 0.2853792906, classif. loss = 0.8950959444
2025-10-04 16:49:03,978 | INFO | iter is 35700 / 50000 [skipped  285] | loc. loss = 0.1546021998, classif. loss = 0.9194931984
2025-10-04 16:49:36,760 | INFO | iter is 35750 / 50000 [skipped  285] | loc. loss = 0.3493435979, classif. loss = 0.2648468018
2025-10-04 16:50:09,608 | INFO | iter is 35800 / 50000 [skipped  285] | loc. loss = 0.2906097174, classif. loss = 1.7869504690
2025-10-04 16:50:42,456 | INFO | iter is 35850 / 50000 [skipped  285] | loc. loss = 0.1557935625, classif. loss = 1.5457969904
2025-10-04 16:51:15,397 | INFO | iter is 35900 / 50000 [skipped  285] | loc. loss = 0.0994868428, classif. loss = 0.3653118610
2025-10-04 16:51:48,276 | INFO | iter is 35950 / 50000 [skipped  285] | loc. loss = 0.2284891903, classif. loss = 0.5319737196
2025-10-04 16:52:21,156 | INFO | iter is 36000 / 50000 [skipped  285] | loc. loss = 0.2148531377, classif. loss = 0.4270911217
2025-10-04 16:52:53,526 | INFO | iter is 36050 / 50000 [skipped  286] | loc. loss = 0.3271468878, classif. loss = 1.0163893700
2025-10-04 16:53:26,373 | INFO | iter is 36100 / 50000 [skipped  286] | loc. loss = 0.1229983047, classif. loss = 0.7737380266
2025-10-04 16:53:58,672 | INFO | iter is 36150 / 50000 [skipped  287] | loc. loss = 0.1209568828, classif. loss = 0.4304754436
2025-10-04 16:54:31,548 | INFO | iter is 36200 / 50000 [skipped  287] | loc. loss = 0.1781021953, classif. loss = 0.6121515036
2025-10-04 16:55:03,903 | INFO | iter is 36250 / 50000 [skipped  288] | loc. loss = 0.2035520226, classif. loss = 1.2172181606
2025-10-04 16:55:36,196 | INFO | iter is 36300 / 50000 [skipped  289] | loc. loss = 0.2631576955, classif. loss = 0.7592846155
2025-10-04 16:56:09,105 | INFO | iter is 36350 / 50000 [skipped  289] | loc. loss = 0.1582974344, classif. loss = 0.7021076679
2025-10-04 16:56:41,921 | INFO | iter is 36400 / 50000 [skipped  289] | loc. loss = 0.1850404143, classif. loss = 0.6752471924
2025-10-04 16:57:14,843 | INFO | iter is 36450 / 50000 [skipped  289] | loc. loss = 0.1211087704, classif. loss = 0.1205198094
2025-10-04 16:57:47,707 | INFO | iter is 36500 / 50000 [skipped  289] | loc. loss = 0.2475479692, classif. loss = 0.6161049604
2025-10-04 16:58:20,580 | INFO | iter is 36550 / 50000 [skipped  289] | loc. loss = 0.2022896558, classif. loss = 0.1358979493
2025-10-04 16:58:53,481 | INFO | iter is 36600 / 50000 [skipped  289] | loc. loss = 0.2669216990, classif. loss = 1.0898392200
2025-10-04 16:59:26,347 | INFO | iter is 36650 / 50000 [skipped  289] | loc. loss = 0.1908980310, classif. loss = 1.0992057323
2025-10-04 16:59:58,550 | INFO | iter is 36700 / 50000 [skipped  290] | loc. loss = 0.1721322834, classif. loss = 0.5950744152
2025-10-04 17:00:31,422 | INFO | iter is 36750 / 50000 [skipped  290] | loc. loss = 0.2342759669, classif. loss = 1.4471049309
2025-10-04 17:01:03,708 | INFO | iter is 36800 / 50000 [skipped  291] | loc. loss = 0.4262176454, classif. loss = 0.0616288185
2025-10-04 17:01:36,603 | INFO | iter is 36850 / 50000 [skipped  291] | loc. loss = 0.1739175618, classif. loss = 0.6646622419
2025-10-04 17:02:09,494 | INFO | iter is 36900 / 50000 [skipped  291] | loc. loss = 0.1516106576, classif. loss = 0.8949989080
2025-10-04 17:02:41,838 | INFO | iter is 36950 / 50000 [skipped  292] | loc. loss = 0.2051179707, classif. loss = 1.8831353188
2025-10-04 17:03:14,632 | INFO | iter is 37000 / 50000 [skipped  292] | loc. loss = 0.1774224043, classif. loss = 0.4966451526
2025-10-04 17:03:46,874 | INFO | iter is 37050 / 50000 [skipped  293] | loc. loss = 0.1686929911, classif. loss = 0.5127981901
2025-10-04 17:04:19,828 | INFO | iter is 37100 / 50000 [skipped  293] | loc. loss = 0.2415660024, classif. loss = 0.8133446574
2025-10-04 17:04:52,665 | INFO | iter is 37150 / 50000 [skipped  293] | loc. loss = 0.1276706904, classif. loss = 0.5896531343
2025-10-04 17:05:25,618 | INFO | iter is 37200 / 50000 [skipped  293] | loc. loss = 0.1755850613, classif. loss = 0.5618085861
2025-10-04 17:05:58,469 | INFO | iter is 37250 / 50000 [skipped  293] | loc. loss = 0.1346127391, classif. loss = 0.1936943531
2025-10-04 17:06:31,449 | INFO | iter is 37300 / 50000 [skipped  293] | loc. loss = 0.2952598333, classif. loss = 0.6858923435
2025-10-04 17:07:04,312 | INFO | iter is 37350 / 50000 [skipped  293] | loc. loss = 0.4259119034, classif. loss = 0.0883293301
2025-10-04 17:07:37,237 | INFO | iter is 37400 / 50000 [skipped  293] | loc. loss = 0.2165639699, classif. loss = 0.8681044579
2025-10-04 17:08:10,099 | INFO | iter is 37450 / 50000 [skipped  293] | loc. loss = 0.2402572185, classif. loss = 0.0561198518
2025-10-04 17:08:42,973 | INFO | iter is 37500 / 50000 [skipped  293] | loc. loss = 0.2229827046, classif. loss = 1.9637062550
2025-10-04 17:08:42,974 | INFO | ---------starting evaluation-----------
2025-10-04 17:08:43,934 | INFO | validation:    0/ 933 (2025-10-04_17-08-43)
2025-10-04 17:09:30,697 | INFO | validation:  100/ 933 (2025-10-04_17-09-30)
2025-10-04 17:10:17,399 | INFO | validation:  200/ 933 (2025-10-04_17-10-17)
2025-10-04 17:11:04,085 | INFO | validation:  300/ 933 (2025-10-04_17-11-04)
2025-10-04 17:11:50,787 | INFO | validation:  400/ 933 (2025-10-04_17-11-50)
2025-10-04 17:12:37,491 | INFO | validation:  500/ 933 (2025-10-04_17-12-37)
2025-10-04 17:13:24,199 | INFO | validation:  600/ 933 (2025-10-04_17-13-24)
2025-10-04 17:14:10,892 | INFO | validation:  700/ 933 (2025-10-04_17-14-10)
2025-10-04 17:14:57,583 | INFO | validation:  800/ 933 (2025-10-04_17-14-57)
2025-10-04 17:15:44,286 | INFO | validation:  900/ 933 (2025-10-04_17-15-44)
2025-10-04 17:15:59,875 | INFO | Confusion Matrix of Localization:
[[910938313   9421536]
 [  8219504  49742055]]
2025-10-04 17:15:59,875 | INFO | Confusion Matrix of Localization - Normalized:
[[0.9897632  0.0102368 ]
 [0.14180957 0.85819043]]
2025-10-04 17:15:59,875 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40545613  2098530   732493   482105]
 [       0   951392  2522715   814335   453529]
 [       0   319659   610877  4246749   351645]
 [       0    43629    13822   269042  2742797]]
2025-10-04 17:15:59,876 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.92445912 0.04784747 0.01670119 0.01099222]
 [0.         0.20063218 0.53199714 0.17172922 0.09564145]
 [0.         0.05781571 0.11048738 0.768096   0.06360091]
 [0.         0.01421469 0.00450332 0.0876561  0.89362589]]
2025-10-04 17:15:59,876 | INFO | lofF1 is 84.9383, clfF1 is 70.2296, oaF1 is 74.6422, sub class F1 score is [94.6012 50.5153 73.2732 77.2688]
2025-10-04 17:15:59,877 | INFO | ---------starting train set evaluation-----------
2025-10-04 17:16:03,836 | INFO | [TrainBuf] locF1 is 85.4813, clfF1 is 73.9807, oaF1 is 77.4309, sub class F1 score is [95.6659 55.0139 71.8995 86.7333]
2025-10-04 17:16:36,713 | INFO | iter is 37550 / 50000 [skipped  293] | loc. loss = 0.1721411049, classif. loss = 0.3987371325
2025-10-04 17:17:09,596 | INFO | iter is 37600 / 50000 [skipped  293] | loc. loss = 0.1930202842, classif. loss = 0.4411245286
2025-10-04 17:17:41,944 | INFO | iter is 37650 / 50000 [skipped  294] | loc. loss = 0.1757775545, classif. loss = 0.0801957846
2025-10-04 17:18:14,174 | INFO | iter is 37700 / 50000 [skipped  295] | loc. loss = 0.2101175934, classif. loss = 0.0240689814
2025-10-04 17:18:47,157 | INFO | iter is 37750 / 50000 [skipped  295] | loc. loss = 0.1436133087, classif. loss = 1.2379858494
2025-10-04 17:19:19,428 | INFO | iter is 37800 / 50000 [skipped  296] | loc. loss = 0.1815292984, classif. loss = 0.6962260008
2025-10-04 17:19:51,767 | INFO | iter is 37850 / 50000 [skipped  297] | loc. loss = 0.2969996035, classif. loss = 0.8372702599
2025-10-04 17:20:24,072 | INFO | iter is 37900 / 50000 [skipped  298] | loc. loss = 0.3496950865, classif. loss = 0.2909908295
2025-10-04 17:20:56,921 | INFO | iter is 37950 / 50000 [skipped  298] | loc. loss = 0.0849235579, classif. loss = 0.1573976725
2025-10-04 17:21:29,114 | INFO | iter is 38000 / 50000 [skipped  299] | loc. loss = 0.0675966442, classif. loss = 0.0445301831
2025-10-04 17:22:01,434 | INFO | iter is 38050 / 50000 [skipped  300] | loc. loss = 0.2764959037, classif. loss = 0.9910393953
2025-10-04 17:22:33,707 | INFO | iter is 38100 / 50000 [skipped  301] | loc. loss = 0.1948062927, classif. loss = 0.4553565383
2025-10-04 17:23:06,658 | INFO | iter is 38150 / 50000 [skipped  301] | loc. loss = 0.1516787857, classif. loss = 1.6057900190
2025-10-04 17:23:38,938 | INFO | iter is 38200 / 50000 [skipped  302] | loc. loss = 0.2572866678, classif. loss = 0.8317042589
2025-10-04 17:24:11,904 | INFO | iter is 38250 / 50000 [skipped  302] | loc. loss = 0.1408021748, classif. loss = 0.4360817671
2025-10-04 17:24:44,837 | INFO | iter is 38300 / 50000 [skipped  302] | loc. loss = 0.2474088073, classif. loss = 0.5180081129
2025-10-04 17:25:17,691 | INFO | iter is 38350 / 50000 [skipped  302] | loc. loss = 0.2831012607, classif. loss = 0.6038839221
2025-10-04 17:25:49,375 | INFO | iter is 38400 / 50000 [skipped  304] | loc. loss = 0.1931261867, classif. loss = 0.8896058798
2025-10-04 17:26:22,315 | INFO | iter is 38450 / 50000 [skipped  304] | loc. loss = 0.2388972640, classif. loss = 0.6296806931
2025-10-04 17:26:54,593 | INFO | iter is 38500 / 50000 [skipped  305] | loc. loss = 0.2352941930, classif. loss = 0.2937372327
2025-10-04 17:27:26,879 | INFO | iter is 38550 / 50000 [skipped  306] | loc. loss = 0.1513775736, classif. loss = 0.0802975968
2025-10-04 17:27:59,713 | INFO | iter is 38600 / 50000 [skipped  306] | loc. loss = 0.1282601207, classif. loss = 0.4193710089
2025-10-04 17:29:03,168 | INFO | iter is 38700 / 50000 [skipped  310] | loc. loss = 0.1547359377, classif. loss = 0.5072886944
2025-10-04 17:29:36,099 | INFO | iter is 38750 / 50000 [skipped  310] | loc. loss = 0.2906292975, classif. loss = 0.0161027797
2025-10-04 17:30:08,953 | INFO | iter is 38800 / 50000 [skipped  310] | loc. loss = 0.2430429757, classif. loss = 0.5675030947
2025-10-04 17:30:41,854 | INFO | iter is 38850 / 50000 [skipped  310] | loc. loss = 0.2723484635, classif. loss = 0.5424599648
2025-10-04 17:31:14,104 | INFO | iter is 38900 / 50000 [skipped  311] | loc. loss = 0.2022455186, classif. loss = 0.6279532909
2025-10-04 17:31:45,882 | INFO | iter is 38950 / 50000 [skipped  313] | loc. loss = 0.1635183990, classif. loss = 0.3718093038
2025-10-04 17:32:18,720 | INFO | iter is 39000 / 50000 [skipped  313] | loc. loss = 0.1323536187, classif. loss = 1.7972958088
2025-10-04 17:32:50,388 | INFO | iter is 39050 / 50000 [skipped  315] | loc. loss = 0.1899880767, classif. loss = 0.3109762669
2025-10-04 17:33:23,370 | INFO | iter is 39100 / 50000 [skipped  315] | loc. loss = 0.2256312072, classif. loss = 0.1101671234
2025-10-04 17:33:55,758 | INFO | iter is 39150 / 50000 [skipped  316] | loc. loss = 0.2179328650, classif. loss = 0.6650883555
2025-10-04 17:34:28,565 | INFO | iter is 39200 / 50000 [skipped  316] | loc. loss = 0.2556554377, classif. loss = 0.6075507402
2025-10-04 17:35:00,801 | INFO | iter is 39250 / 50000 [skipped  317] | loc. loss = 0.1255621463, classif. loss = 0.0641788542
2025-10-04 17:35:33,134 | INFO | iter is 39300 / 50000 [skipped  318] | loc. loss = 0.2057414800, classif. loss = 0.8046162128
2025-10-04 17:36:05,940 | INFO | iter is 39350 / 50000 [skipped  318] | loc. loss = 0.1082146168, classif. loss = 0.0704165846
2025-10-04 17:36:38,874 | INFO | iter is 39400 / 50000 [skipped  318] | loc. loss = 0.1352625042, classif. loss = 1.4300597906
2025-10-04 17:37:11,702 | INFO | iter is 39450 / 50000 [skipped  318] | loc. loss = 0.2286228389, classif. loss = 0.0400618166
2025-10-04 17:37:43,964 | INFO | iter is 39500 / 50000 [skipped  319] | loc. loss = 0.2262424082, classif. loss = 0.1963436306
2025-10-04 17:38:16,917 | INFO | iter is 39550 / 50000 [skipped  319] | loc. loss = 0.1470244527, classif. loss = 0.7054064274
2025-10-04 17:38:49,751 | INFO | iter is 39600 / 50000 [skipped  319] | loc. loss = 0.1237050146, classif. loss = 0.4220814109
2025-10-04 17:39:22,649 | INFO | iter is 39650 / 50000 [skipped  319] | loc. loss = 0.1967026293, classif. loss = 0.0121787209
2025-10-04 17:39:54,904 | INFO | iter is 39700 / 50000 [skipped  320] | loc. loss = 0.1449127197, classif. loss = 0.0298210829
2025-10-04 17:40:26,719 | INFO | iter is 39750 / 50000 [skipped  322] | loc. loss = 0.1743668616, classif. loss = 0.0562512800
2025-10-04 17:40:59,571 | INFO | iter is 39800 / 50000 [skipped  322] | loc. loss = 0.3252614439, classif. loss = 0.0464396998
2025-10-04 17:41:32,471 | INFO | iter is 39850 / 50000 [skipped  322] | loc. loss = 0.1899239868, classif. loss = 0.4424983859
2025-10-04 17:42:05,445 | INFO | iter is 39900 / 50000 [skipped  322] | loc. loss = 0.2399832159, classif. loss = 0.2502821982
2025-10-04 17:42:38,319 | INFO | iter is 39950 / 50000 [skipped  322] | loc. loss = 0.2636460960, classif. loss = 0.0563001484
2025-10-04 17:43:09,928 | INFO | iter is 40000 / 50000 [skipped  324] | loc. loss = 0.1619908512, classif. loss = 0.6446653605
2025-10-04 17:43:42,875 | INFO | iter is 40050 / 50000 [skipped  324] | loc. loss = 0.1055753976, classif. loss = 0.7518780231
2025-10-04 17:44:15,776 | INFO | iter is 40100 / 50000 [skipped  324] | loc. loss = 0.3335600197, classif. loss = 1.6726408005
2025-10-04 17:44:48,645 | INFO | iter is 40150 / 50000 [skipped  324] | loc. loss = 0.1826743931, classif. loss = 0.0892390236
2025-10-04 17:45:20,931 | INFO | iter is 40200 / 50000 [skipped  325] | loc. loss = 0.1919708848, classif. loss = 0.4330474138
2025-10-04 17:45:53,821 | INFO | iter is 40250 / 50000 [skipped  325] | loc. loss = 0.2210376412, classif. loss = 0.6106246114
2025-10-04 17:46:26,705 | INFO | iter is 40300 / 50000 [skipped  325] | loc. loss = 0.2488885224, classif. loss = 0.0640504956
2025-10-04 17:46:58,924 | INFO | iter is 40350 / 50000 [skipped  326] | loc. loss = 0.1787287444, classif. loss = 0.6283509731
2025-10-04 17:47:31,868 | INFO | iter is 40400 / 50000 [skipped  326] | loc. loss = 0.1339439303, classif. loss = 0.0367737785
2025-10-04 17:48:04,723 | INFO | iter is 40450 / 50000 [skipped  326] | loc. loss = 0.2069265097, classif. loss = 0.8290597796
2025-10-04 17:48:37,544 | INFO | iter is 40500 / 50000 [skipped  326] | loc. loss = 0.1230504215, classif. loss = 0.5625739098
2025-10-04 17:49:10,373 | INFO | iter is 40550 / 50000 [skipped  326] | loc. loss = 0.2083400190, classif. loss = 0.4974524081
2025-10-04 17:49:42,629 | INFO | iter is 40600 / 50000 [skipped  327] | loc. loss = 0.1683852822, classif. loss = 0.6994216442
2025-10-04 17:50:15,494 | INFO | iter is 40650 / 50000 [skipped  327] | loc. loss = 0.2464137971, classif. loss = 0.0450559817
2025-10-04 17:50:48,397 | INFO | iter is 40700 / 50000 [skipped  327] | loc. loss = 0.2534802556, classif. loss = 0.1645309031
2025-10-04 17:51:21,292 | INFO | iter is 40750 / 50000 [skipped  327] | loc. loss = 0.1686901450, classif. loss = 0.4047408104
2025-10-04 17:51:54,304 | INFO | iter is 40800 / 50000 [skipped  327] | loc. loss = 0.2004133165, classif. loss = 0.5057361126
2025-10-04 17:52:25,927 | INFO | iter is 40850 / 50000 [skipped  329] | loc. loss = 0.1822768152, classif. loss = 0.9611612558
2025-10-04 17:52:57,686 | INFO | iter is 40900 / 50000 [skipped  331] | loc. loss = 0.2776465714, classif. loss = 0.8509938121
2025-10-04 17:53:29,949 | INFO | iter is 40950 / 50000 [skipped  332] | loc. loss = 0.2317133099, classif. loss = 0.2176093906
2025-10-04 17:54:02,814 | INFO | iter is 41000 / 50000 [skipped  332] | loc. loss = 0.2082350701, classif. loss = 0.9135268331
2025-10-04 17:54:35,699 | INFO | iter is 41050 / 50000 [skipped  332] | loc. loss = 0.1684563309, classif. loss = 0.0081293238
2025-10-04 17:55:08,623 | INFO | iter is 41100 / 50000 [skipped  332] | loc. loss = 0.1711083055, classif. loss = 0.4007655382
2025-10-04 17:55:40,957 | INFO | iter is 41150 / 50000 [skipped  333] | loc. loss = 0.1926534623, classif. loss = 0.5094451308
2025-10-04 17:56:12,081 | INFO | iter is 41200 / 50000 [skipped  336] | loc. loss = 0.1563174874, classif. loss = 0.7792811394
2025-10-04 17:56:44,979 | INFO | iter is 41250 / 50000 [skipped  336] | loc. loss = 0.1605047882, classif. loss = 0.2943619788
2025-10-04 17:57:17,884 | INFO | iter is 41300 / 50000 [skipped  336] | loc. loss = 0.2647766769, classif. loss = 0.7955548763
2025-10-04 17:57:50,695 | INFO | iter is 41350 / 50000 [skipped  336] | loc. loss = 0.1883366853, classif. loss = 0.3797254860
2025-10-04 17:58:23,054 | INFO | iter is 41400 / 50000 [skipped  337] | loc. loss = 0.1085016727, classif. loss = 0.5997841954
2025-10-04 17:58:55,975 | INFO | iter is 41450 / 50000 [skipped  337] | loc. loss = 0.1592366844, classif. loss = 1.0200200081
2025-10-04 17:59:28,340 | INFO | iter is 41500 / 50000 [skipped  338] | loc. loss = 0.1429955363, classif. loss = 1.5914237499
2025-10-04 18:00:01,252 | INFO | iter is 41550 / 50000 [skipped  338] | loc. loss = 0.2301552743, classif. loss = 0.4042128921
2025-10-04 18:00:34,138 | INFO | iter is 41600 / 50000 [skipped  338] | loc. loss = 0.1392309517, classif. loss = 0.8793565631
2025-10-04 18:01:07,078 | INFO | iter is 41650 / 50000 [skipped  338] | loc. loss = 0.1194987595, classif. loss = 0.9493082166
2025-10-04 18:01:39,454 | INFO | iter is 41700 / 50000 [skipped  339] | loc. loss = 0.1646980792, classif. loss = 0.5700001717
2025-10-04 18:02:11,182 | INFO | iter is 41750 / 50000 [skipped  341] | loc. loss = 0.1403775513, classif. loss = 0.4523596764
2025-10-04 18:02:44,117 | INFO | iter is 41800 / 50000 [skipped  341] | loc. loss = 0.1581985205, classif. loss = 0.3349266052
2025-10-04 18:03:17,063 | INFO | iter is 41850 / 50000 [skipped  341] | loc. loss = 0.1193486601, classif. loss = 0.2813482583
2025-10-04 18:03:50,054 | INFO | iter is 41900 / 50000 [skipped  341] | loc. loss = 0.2665660083, classif. loss = 1.0003280640
2025-10-04 18:04:22,360 | INFO | iter is 41950 / 50000 [skipped  342] | loc. loss = 0.2023629546, classif. loss = 0.7591938972
2025-10-04 18:04:54,806 | INFO | iter is 42000 / 50000 [skipped  343] | loc. loss = 0.2053883374, classif. loss = 0.2525058687
2025-10-04 18:05:27,121 | INFO | iter is 42050 / 50000 [skipped  344] | loc. loss = 0.1070282310, classif. loss = 1.9755275249
2025-10-04 18:05:58,774 | INFO | iter is 42100 / 50000 [skipped  346] | loc. loss = 0.1352598816, classif. loss = 0.1887285560
2025-10-04 18:06:31,746 | INFO | iter is 42150 / 50000 [skipped  346] | loc. loss = 0.1224690452, classif. loss = 0.7835046649
2025-10-04 18:07:04,661 | INFO | iter is 42200 / 50000 [skipped  346] | loc. loss = 0.2001484036, classif. loss = 0.0060991952
2025-10-04 18:07:37,632 | INFO | iter is 42250 / 50000 [skipped  346] | loc. loss = 0.2274726033, classif. loss = 0.5290178061
2025-10-04 18:08:10,535 | INFO | iter is 42300 / 50000 [skipped  346] | loc. loss = 0.2144931555, classif. loss = 0.3380585313
2025-10-04 18:08:43,398 | INFO | iter is 42350 / 50000 [skipped  346] | loc. loss = 0.1949118376, classif. loss = 0.0144690238
2025-10-04 18:09:16,356 | INFO | iter is 42400 / 50000 [skipped  346] | loc. loss = 0.2205591500, classif. loss = 0.6356021166
2025-10-04 18:09:48,694 | INFO | iter is 42450 / 50000 [skipped  347] | loc. loss = 0.1435870677, classif. loss = 0.5802810788
2025-10-04 18:10:21,641 | INFO | iter is 42500 / 50000 [skipped  347] | loc. loss = 0.2112386376, classif. loss = 0.0138470735
2025-10-04 18:10:53,933 | INFO | iter is 42550 / 50000 [skipped  348] | loc. loss = 0.2622802556, classif. loss = 0.0327171646
2025-10-04 18:11:26,335 | INFO | iter is 42600 / 50000 [skipped  349] | loc. loss = 0.1933105439, classif. loss = 0.8035477996
2025-10-04 18:11:59,303 | INFO | iter is 42650 / 50000 [skipped  349] | loc. loss = 0.1284096241, classif. loss = 0.6637868881
2025-10-04 18:12:32,261 | INFO | iter is 42700 / 50000 [skipped  349] | loc. loss = 0.2223970890, classif. loss = 1.3932073116
2025-10-04 18:13:04,626 | INFO | iter is 42750 / 50000 [skipped  350] | loc. loss = 0.2395804971, classif. loss = 0.8249081373
2025-10-04 18:13:37,628 | INFO | iter is 42800 / 50000 [skipped  350] | loc. loss = 0.1514336914, classif. loss = 0.1129624024
2025-10-04 18:14:10,550 | INFO | iter is 42850 / 50000 [skipped  350] | loc. loss = 0.2253671288, classif. loss = 0.9283597469
2025-10-04 18:14:43,453 | INFO | iter is 42900 / 50000 [skipped  350] | loc. loss = 0.2160984725, classif. loss = 0.0994689465
2025-10-04 18:15:16,421 | INFO | iter is 42950 / 50000 [skipped  350] | loc. loss = 0.1970269978, classif. loss = 1.0970230103
2025-10-04 18:15:49,436 | INFO | iter is 43000 / 50000 [skipped  350] | loc. loss = 0.2962483168, classif. loss = 1.0500007868
2025-10-04 18:16:21,176 | INFO | iter is 43050 / 50000 [skipped  352] | loc. loss = 0.2552328706, classif. loss = 0.9097630978
2025-10-04 18:16:54,073 | INFO | iter is 43100 / 50000 [skipped  352] | loc. loss = 0.1794014275, classif. loss = 0.5374881625
2025-10-04 18:17:26,368 | INFO | iter is 43150 / 50000 [skipped  353] | loc. loss = 0.1703099012, classif. loss = 0.3835999370
2025-10-04 18:17:59,349 | INFO | iter is 43200 / 50000 [skipped  353] | loc. loss = 0.1952567101, classif. loss = 0.5039476156
2025-10-04 18:18:32,157 | INFO | iter is 43250 / 50000 [skipped  353] | loc. loss = 0.2353058606, classif. loss = 0.7362228632
2025-10-04 18:19:05,093 | INFO | iter is 43300 / 50000 [skipped  353] | loc. loss = 0.1462341547, classif. loss = 0.2080807984
2025-10-04 18:19:38,048 | INFO | iter is 43350 / 50000 [skipped  353] | loc. loss = 0.2699896097, classif. loss = 0.3717579246
2025-10-04 18:20:10,333 | INFO | iter is 43400 / 50000 [skipped  354] | loc. loss = 0.1130597740, classif. loss = 0.8935174346
2025-10-04 18:20:43,277 | INFO | iter is 43450 / 50000 [skipped  354] | loc. loss = 0.1255607307, classif. loss = 0.9627113342
2025-10-04 18:21:16,198 | INFO | iter is 43500 / 50000 [skipped  354] | loc. loss = 0.1036932319, classif. loss = 0.1236179397
2025-10-04 18:21:49,090 | INFO | iter is 43550 / 50000 [skipped  354] | loc. loss = 0.1270099729, classif. loss = 0.0883289576
2025-10-04 18:22:22,047 | INFO | iter is 43600 / 50000 [skipped  354] | loc. loss = 0.2334613204, classif. loss = 0.0842569917
2025-10-04 18:22:54,943 | INFO | iter is 43650 / 50000 [skipped  354] | loc. loss = 0.1649263203, classif. loss = 0.1708480716
2025-10-04 18:23:27,949 | INFO | iter is 43700 / 50000 [skipped  354] | loc. loss = 0.1701500863, classif. loss = 0.2931592762
2025-10-04 18:24:32,693 | INFO | iter is 43800 / 50000 [skipped  356] | loc. loss = 0.2839897871, classif. loss = 0.4604114890
2025-10-04 18:25:05,643 | INFO | iter is 43850 / 50000 [skipped  356] | loc. loss = 0.1801061183, classif. loss = 0.0069381548
2025-10-04 18:25:38,597 | INFO | iter is 43900 / 50000 [skipped  356] | loc. loss = 0.1634432077, classif. loss = 0.2515155673
2025-10-04 18:26:11,608 | INFO | iter is 43950 / 50000 [skipped  356] | loc. loss = 0.1655103415, classif. loss = 0.0253247395
2025-10-04 18:26:44,538 | INFO | iter is 44000 / 50000 [skipped  356] | loc. loss = 0.2346623987, classif. loss = 0.7692257166
2025-10-04 18:27:17,518 | INFO | iter is 44050 / 50000 [skipped  356] | loc. loss = 0.1642923057, classif. loss = 0.0397229679
2025-10-04 18:27:50,363 | INFO | iter is 44100 / 50000 [skipped  356] | loc. loss = 0.2317733467, classif. loss = 1.9364715815
2025-10-04 18:28:23,208 | INFO | iter is 44150 / 50000 [skipped  356] | loc. loss = 0.1872361004, classif. loss = 0.6813439727
2025-10-04 18:28:56,139 | INFO | iter is 44200 / 50000 [skipped  356] | loc. loss = 0.2445830852, classif. loss = 0.7086437941
2025-10-04 18:29:29,060 | INFO | iter is 44250 / 50000 [skipped  356] | loc. loss = 0.1215872914, classif. loss = 0.9350806475
2025-10-04 18:30:01,897 | INFO | iter is 44300 / 50000 [skipped  356] | loc. loss = 0.0872032344, classif. loss = 0.4855444729
2025-10-04 18:30:34,868 | INFO | iter is 44350 / 50000 [skipped  356] | loc. loss = 0.3105920255, classif. loss = 0.7372373343
2025-10-04 18:31:07,138 | INFO | iter is 44400 / 50000 [skipped  357] | loc. loss = 0.1373332143, classif. loss = 0.3955602646
2025-10-04 18:31:40,082 | INFO | iter is 44450 / 50000 [skipped  357] | loc. loss = 0.1638713628, classif. loss = 0.0072390819
2025-10-04 18:32:12,926 | INFO | iter is 44500 / 50000 [skipped  357] | loc. loss = 0.2501955032, classif. loss = 0.7428743839
2025-10-04 18:32:45,244 | INFO | iter is 44550 / 50000 [skipped  358] | loc. loss = 0.1939740628, classif. loss = 0.5307126641
2025-10-04 18:33:18,166 | INFO | iter is 44600 / 50000 [skipped  358] | loc. loss = 0.1878692061, classif. loss = 0.1891207248
2025-10-04 18:33:50,428 | INFO | iter is 44650 / 50000 [skipped  359] | loc. loss = 0.1438213885, classif. loss = 0.2671900988
2025-10-04 18:34:23,355 | INFO | iter is 44700 / 50000 [skipped  359] | loc. loss = 0.2320833951, classif. loss = 0.7172212005
2025-10-04 18:34:56,217 | INFO | iter is 44750 / 50000 [skipped  359] | loc. loss = 0.3301635981, classif. loss = 1.5387692451
2025-10-04 18:35:28,455 | INFO | iter is 44800 / 50000 [skipped  360] | loc. loss = 0.3906647563, classif. loss = 0.0531845540
2025-10-04 18:36:01,371 | INFO | iter is 44850 / 50000 [skipped  360] | loc. loss = 0.2515141964, classif. loss = 0.0108294468
2025-10-04 18:36:34,263 | INFO | iter is 44900 / 50000 [skipped  360] | loc. loss = 0.0801906809, classif. loss = 1.1371290684
2025-10-04 18:37:07,256 | INFO | iter is 44950 / 50000 [skipped  360] | loc. loss = 0.2271563411, classif. loss = 0.9244389534
2025-10-04 18:37:40,141 | INFO | iter is 45000 / 50000 [skipped  360] | loc. loss = 0.2552623451, classif. loss = 1.9745794535
2025-10-04 18:38:13,104 | INFO | iter is 45050 / 50000 [skipped  360] | loc. loss = 0.2313979715, classif. loss = 1.3550530672
2025-10-04 18:38:45,956 | INFO | iter is 45100 / 50000 [skipped  360] | loc. loss = 0.2034462690, classif. loss = 1.1035255194
2025-10-04 18:39:18,829 | INFO | iter is 45150 / 50000 [skipped  360] | loc. loss = 0.1827545613, classif. loss = 0.6772707701
2025-10-04 18:39:51,234 | INFO | iter is 45200 / 50000 [skipped  361] | loc. loss = 0.2632054389, classif. loss = 0.4106441140
2025-10-04 18:40:24,164 | INFO | iter is 45250 / 50000 [skipped  361] | loc. loss = 0.1487683803, classif. loss = 0.3033138514
2025-10-04 18:40:57,041 | INFO | iter is 45300 / 50000 [skipped  361] | loc. loss = 0.2446327060, classif. loss = 0.5790857673
2025-10-04 18:41:29,937 | INFO | iter is 45350 / 50000 [skipped  361] | loc. loss = 0.2295221686, classif. loss = 0.5987488031
2025-10-04 18:42:02,796 | INFO | iter is 45400 / 50000 [skipped  361] | loc. loss = 0.2329654992, classif. loss = 0.3541462421
2025-10-04 18:42:35,021 | INFO | iter is 45450 / 50000 [skipped  362] | loc. loss = 0.1679510325, classif. loss = 0.0164576769
2025-10-04 18:43:07,834 | INFO | iter is 45500 / 50000 [skipped  362] | loc. loss = 0.2034076303, classif. loss = 0.0373953059
2025-10-04 18:43:40,752 | INFO | iter is 45550 / 50000 [skipped  362] | loc. loss = 0.1647857279, classif. loss = 0.1341375113
2025-10-04 18:44:13,626 | INFO | iter is 45600 / 50000 [skipped  362] | loc. loss = 0.2182704955, classif. loss = 0.0777195618
2025-10-04 18:44:46,522 | INFO | iter is 45650 / 50000 [skipped  362] | loc. loss = 0.1604301482, classif. loss = 0.1158069521
2025-10-04 18:45:19,435 | INFO | iter is 45700 / 50000 [skipped  362] | loc. loss = 0.2189555764, classif. loss = 0.0453007296
2025-10-04 18:45:51,747 | INFO | iter is 45750 / 50000 [skipped  363] | loc. loss = 0.2302814424, classif. loss = 0.5050758123
2025-10-04 18:46:24,627 | INFO | iter is 45800 / 50000 [skipped  363] | loc. loss = 0.2301196754, classif. loss = 0.1436142772
2025-10-04 18:46:57,586 | INFO | iter is 45850 / 50000 [skipped  363] | loc. loss = 0.1780642420, classif. loss = 0.6132705212
2025-10-04 18:47:30,516 | INFO | iter is 45900 / 50000 [skipped  363] | loc. loss = 0.1823387742, classif. loss = 0.7056223154
2025-10-04 18:48:03,477 | INFO | iter is 45950 / 50000 [skipped  363] | loc. loss = 0.1594617367, classif. loss = 0.1172775105
2025-10-04 18:48:35,755 | INFO | iter is 46000 / 50000 [skipped  364] | loc. loss = 0.3022116125, classif. loss = 0.9089911580
2025-10-04 18:49:08,737 | INFO | iter is 46050 / 50000 [skipped  364] | loc. loss = 0.1185451075, classif. loss = 1.6908085346
2025-10-04 18:49:41,588 | INFO | iter is 46100 / 50000 [skipped  364] | loc. loss = 0.2587367594, classif. loss = 0.5576473475
2025-10-04 18:50:13,957 | INFO | iter is 46150 / 50000 [skipped  365] | loc. loss = 0.1570433229, classif. loss = 1.9842581749
2025-10-04 18:50:46,223 | INFO | iter is 46200 / 50000 [skipped  366] | loc. loss = 0.2305323631, classif. loss = 0.0949064642
2025-10-04 18:51:18,580 | INFO | iter is 46250 / 50000 [skipped  367] | loc. loss = 0.2319921851, classif. loss = 0.6640920043
2025-10-04 18:51:50,911 | INFO | iter is 46300 / 50000 [skipped  368] | loc. loss = 0.2009035945, classif. loss = 0.1667996049
2025-10-04 18:52:23,816 | INFO | iter is 46350 / 50000 [skipped  368] | loc. loss = 0.2146241069, classif. loss = 0.8324428797
2025-10-04 18:52:56,632 | INFO | iter is 46400 / 50000 [skipped  368] | loc. loss = 0.2730112076, classif. loss = 0.9273575544
2025-10-04 18:53:29,494 | INFO | iter is 46450 / 50000 [skipped  368] | loc. loss = 0.3099800646, classif. loss = 0.7258872986
2025-10-04 18:54:02,417 | INFO | iter is 46500 / 50000 [skipped  368] | loc. loss = 0.0931992307, classif. loss = 0.1825248003
2025-10-04 18:54:35,316 | INFO | iter is 46550 / 50000 [skipped  368] | loc. loss = 0.1698950529, classif. loss = 0.0440028869
2025-10-04 18:55:07,592 | INFO | iter is 46600 / 50000 [skipped  369] | loc. loss = 0.0935299993, classif. loss = 0.5431826115
2025-10-04 18:55:40,427 | INFO | iter is 46650 / 50000 [skipped  369] | loc. loss = 0.1697438359, classif. loss = 0.1234218255
2025-10-04 18:56:13,368 | INFO | iter is 46700 / 50000 [skipped  369] | loc. loss = 0.1203495562, classif. loss = 0.0484474525
2025-10-04 18:56:45,692 | INFO | iter is 46750 / 50000 [skipped  370] | loc. loss = 0.2644748390, classif. loss = 0.8744899631
2025-10-04 18:57:18,103 | INFO | iter is 46800 / 50000 [skipped  371] | loc. loss = 0.1493455023, classif. loss = 1.0115971565
2025-10-04 18:57:49,785 | INFO | iter is 46850 / 50000 [skipped  373] | loc. loss = 0.2160997242, classif. loss = 0.4936465621
2025-10-04 18:58:22,769 | INFO | iter is 46900 / 50000 [skipped  373] | loc. loss = 0.2684378028, classif. loss = 0.9409097433
2025-10-04 18:58:55,616 | INFO | iter is 46950 / 50000 [skipped  373] | loc. loss = 0.2921860814, classif. loss = 0.5821104050
2025-10-04 18:59:28,542 | INFO | iter is 47000 / 50000 [skipped  373] | loc. loss = 0.1194824651, classif. loss = 0.5350860953
2025-10-04 19:00:00,258 | INFO | iter is 47050 / 50000 [skipped  375] | loc. loss = 0.2031525224, classif. loss = 0.8322063684
2025-10-04 19:00:33,102 | INFO | iter is 47100 / 50000 [skipped  375] | loc. loss = 0.1880505979, classif. loss = 0.6529566050
2025-10-04 19:01:06,058 | INFO | iter is 47150 / 50000 [skipped  375] | loc. loss = 0.1314976662, classif. loss = 0.0078987107
2025-10-04 19:01:38,910 | INFO | iter is 47200 / 50000 [skipped  375] | loc. loss = 0.2358298451, classif. loss = 0.1775150597
2025-10-04 19:02:11,764 | INFO | iter is 47250 / 50000 [skipped  375] | loc. loss = 0.2274972796, classif. loss = 0.3502017260
2025-10-04 19:02:44,650 | INFO | iter is 47300 / 50000 [skipped  375] | loc. loss = 0.0728379190, classif. loss = 0.0028530220
2025-10-04 19:03:17,505 | INFO | iter is 47350 / 50000 [skipped  375] | loc. loss = 0.2223195881, classif. loss = 0.0553730875
2025-10-04 19:03:50,408 | INFO | iter is 47400 / 50000 [skipped  375] | loc. loss = 0.1609459519, classif. loss = 0.0086173825
2025-10-04 19:04:23,234 | INFO | iter is 47450 / 50000 [skipped  375] | loc. loss = 0.2485036850, classif. loss = 1.3606867790
2025-10-04 19:04:56,051 | INFO | iter is 47500 / 50000 [skipped  375] | loc. loss = 0.2304814607, classif. loss = 0.9050968885
2025-10-04 19:05:28,973 | INFO | iter is 47550 / 50000 [skipped  375] | loc. loss = 0.2402336001, classif. loss = 0.0750941485
2025-10-04 19:06:01,760 | INFO | iter is 47600 / 50000 [skipped  375] | loc. loss = 0.1976079047, classif. loss = 0.2798996568
2025-10-04 19:06:34,544 | INFO | iter is 47650 / 50000 [skipped  375] | loc. loss = 0.1455769241, classif. loss = 2.0008144379
2025-10-04 19:07:07,402 | INFO | iter is 47700 / 50000 [skipped  375] | loc. loss = 0.2021018267, classif. loss = 0.6480726004
2025-10-04 19:07:40,223 | INFO | iter is 47750 / 50000 [skipped  375] | loc. loss = 0.2762220800, classif. loss = 1.0646004677
2025-10-04 19:08:13,124 | INFO | iter is 47800 / 50000 [skipped  375] | loc. loss = 0.2374120653, classif. loss = 0.7743088603
2025-10-04 19:08:45,971 | INFO | iter is 47850 / 50000 [skipped  375] | loc. loss = 0.1905580461, classif. loss = 0.1437287927
2025-10-04 19:09:18,861 | INFO | iter is 47900 / 50000 [skipped  375] | loc. loss = 0.1361927837, classif. loss = 0.5274733305
2025-10-04 19:09:51,149 | INFO | iter is 47950 / 50000 [skipped  376] | loc. loss = 0.1421069801, classif. loss = 0.7623381019
2025-10-04 19:10:22,865 | INFO | iter is 48000 / 50000 [skipped  378] | loc. loss = 0.1618873626, classif. loss = 0.0801168829
2025-10-04 19:10:55,094 | INFO | iter is 48050 / 50000 [skipped  379] | loc. loss = 0.2228225470, classif. loss = 0.7011485100
2025-10-04 19:11:27,990 | INFO | iter is 48100 / 50000 [skipped  379] | loc. loss = 0.2543491721, classif. loss = 0.9866837263
2025-10-04 19:12:00,759 | INFO | iter is 48150 / 50000 [skipped  379] | loc. loss = 0.2256641239, classif. loss = 0.2126925439
2025-10-04 19:12:33,599 | INFO | iter is 48200 / 50000 [skipped  379] | loc. loss = 0.1028733402, classif. loss = 0.0849741697
2025-10-04 19:13:06,503 | INFO | iter is 48250 / 50000 [skipped  379] | loc. loss = 0.2327728271, classif. loss = 0.8678303361
2025-10-04 19:13:38,721 | INFO | iter is 48300 / 50000 [skipped  380] | loc. loss = 0.1813807189, classif. loss = 0.2641038597
2025-10-04 19:14:11,643 | INFO | iter is 48350 / 50000 [skipped  380] | loc. loss = 0.0524936020, classif. loss = 0.0066364841
2025-10-04 19:14:44,476 | INFO | iter is 48400 / 50000 [skipped  380] | loc. loss = 0.1940445602, classif. loss = 0.2411963940
2025-10-04 19:15:17,311 | INFO | iter is 48450 / 50000 [skipped  380] | loc. loss = 0.1464584768, classif. loss = 0.4810739458
2025-10-04 19:15:50,157 | INFO | iter is 48500 / 50000 [skipped  380] | loc. loss = 0.1588878036, classif. loss = 0.0372155309
2025-10-04 19:16:23,062 | INFO | iter is 48550 / 50000 [skipped  380] | loc. loss = 0.1700626165, classif. loss = 0.1319343150
2025-10-04 19:16:55,323 | INFO | iter is 48600 / 50000 [skipped  381] | loc. loss = 0.2315710783, classif. loss = 1.1313068867
2025-10-04 19:17:28,224 | INFO | iter is 48650 / 50000 [skipped  381] | loc. loss = 0.1194833294, classif. loss = 0.6396151781
2025-10-04 19:18:01,030 | INFO | iter is 48700 / 50000 [skipped  381] | loc. loss = 0.3215134740, classif. loss = 0.7486943603
2025-10-04 19:18:33,912 | INFO | iter is 48750 / 50000 [skipped  381] | loc. loss = 0.0571589768, classif. loss = 0.2752711177
2025-10-04 19:19:06,111 | INFO | iter is 48800 / 50000 [skipped  382] | loc. loss = 0.0729071423, classif. loss = 0.0171539374
2025-10-04 19:19:38,872 | INFO | iter is 48850 / 50000 [skipped  382] | loc. loss = 0.2756825686, classif. loss = 1.5157753229
2025-10-04 19:20:11,752 | INFO | iter is 48900 / 50000 [skipped  382] | loc. loss = 0.3322689533, classif. loss = 2.3337631226
2025-10-04 19:20:44,587 | INFO | iter is 48950 / 50000 [skipped  382] | loc. loss = 0.2032168508, classif. loss = 0.4967044592
2025-10-04 19:21:17,397 | INFO | iter is 49000 / 50000 [skipped  382] | loc. loss = 0.2614950538, classif. loss = 0.6120108366
2025-10-04 19:21:50,263 | INFO | iter is 49050 / 50000 [skipped  382] | loc. loss = 0.0931613967, classif. loss = 0.0557558201
2025-10-04 19:22:23,124 | INFO | iter is 49100 / 50000 [skipped  382] | loc. loss = 0.1981731355, classif. loss = 0.4379748106
2025-10-04 19:22:55,952 | INFO | iter is 49150 / 50000 [skipped  382] | loc. loss = 0.1329563409, classif. loss = 0.0194800161
2025-10-04 19:23:28,803 | INFO | iter is 49200 / 50000 [skipped  382] | loc. loss = 0.2148257941, classif. loss = 1.2312115431
2025-10-04 19:24:01,686 | INFO | iter is 49250 / 50000 [skipped  382] | loc. loss = 0.1687400788, classif. loss = 1.0168178082
2025-10-04 19:24:32,683 | INFO | iter is 49300 / 50000 [skipped  385] | loc. loss = 0.2487935424, classif. loss = 3.0736279488
2025-10-04 19:25:05,469 | INFO | iter is 49350 / 50000 [skipped  385] | loc. loss = 0.3353958726, classif. loss = 0.5604069829
2025-10-04 19:25:38,327 | INFO | iter is 49400 / 50000 [skipped  385] | loc. loss = 0.2448701560, classif. loss = 0.9958158135
2025-10-04 19:26:11,183 | INFO | iter is 49450 / 50000 [skipped  385] | loc. loss = 0.1920629442, classif. loss = 1.0916571617
2025-10-04 19:26:42,887 | INFO | iter is 49500 / 50000 [skipped  387] | loc. loss = 0.2561845183, classif. loss = 0.2729162574
2025-10-04 19:27:15,154 | INFO | iter is 49550 / 50000 [skipped  388] | loc. loss = 0.1066754162, classif. loss = 0.1161245555
2025-10-04 19:27:48,046 | INFO | iter is 49600 / 50000 [skipped  388] | loc. loss = 0.3012158275, classif. loss = 0.7541598082
2025-10-04 19:28:20,330 | INFO | iter is 49650 / 50000 [skipped  389] | loc. loss = 0.1598512083, classif. loss = 1.0828256607
2025-10-04 19:28:53,181 | INFO | iter is 49700 / 50000 [skipped  389] | loc. loss = 0.2420006543, classif. loss = 0.5109041333
2025-10-04 19:29:26,043 | INFO | iter is 49750 / 50000 [skipped  389] | loc. loss = 0.2606647909, classif. loss = 0.3520894349
2025-10-04 19:29:58,961 | INFO | iter is 49800 / 50000 [skipped  389] | loc. loss = 0.2157354653, classif. loss = 1.1051636934
2025-10-04 19:30:31,857 | INFO | iter is 49850 / 50000 [skipped  389] | loc. loss = 0.1661764383, classif. loss = 0.6357235909
2025-10-04 19:31:04,747 | INFO | iter is 49900 / 50000 [skipped  389] | loc. loss = 0.2089347094, classif. loss = 0.6644721627
2025-10-04 19:31:37,654 | INFO | iter is 49950 / 50000 [skipped  389] | loc. loss = 0.2523310781, classif. loss = 0.4919933081
2025-10-04 19:32:09,519 | INFO | iter is 50000 / 50000 [skipped  390] | loc. loss = 0.2234656364, classif. loss = 0.3576093316
2025-10-04 19:32:09,519 | INFO | -----------Training is completed-----------
2025-10-04 19:32:09,779 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-04_09-41-45_MambaBDA_Base_xBD_FOCAL_ALIGN_AGBD/model_step50000_last.pth
2025-10-04 19:32:09,779 | INFO | !! Total Skipped: 390 (0.78%)
2025-10-04 19:32:09,780 | INFO | ---------starting evaluation-----------
2025-10-04 19:32:10,733 | INFO | validation:    0/ 933 (2025-10-04_19-32-10)
2025-10-04 19:32:57,440 | INFO | validation:  100/ 933 (2025-10-04_19-32-57)
2025-10-04 19:33:44,081 | INFO | validation:  200/ 933 (2025-10-04_19-33-44)
2025-10-04 19:34:30,714 | INFO | validation:  300/ 933 (2025-10-04_19-34-30)
2025-10-04 19:35:17,372 | INFO | validation:  400/ 933 (2025-10-04_19-35-17)
2025-10-04 19:36:04,008 | INFO | validation:  500/ 933 (2025-10-04_19-36-04)
2025-10-04 19:36:50,650 | INFO | validation:  600/ 933 (2025-10-04_19-36-50)
2025-10-04 19:37:37,294 | INFO | validation:  700/ 933 (2025-10-04_19-37-37)
2025-10-04 19:38:23,959 | INFO | validation:  800/ 933 (2025-10-04_19-38-23)
2025-10-04 19:39:10,641 | INFO | validation:  900/ 933 (2025-10-04_19-39-10)
2025-10-04 19:39:26,241 | INFO | Confusion Matrix of Localization:
[[913230160   7129689]
 [ 10815142  47146417]]
2025-10-04 19:39:26,241 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99225337 0.00774663]
 [0.18659163 0.81340837]]
2025-10-04 19:39:26,241 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 39482006  2291417  1922310   163008]
 [       0   819127  2513423  1346890    62531]
 [       0   239293   338755  4851793    99089]
 [       0    62847    57117   461263  2488063]]
2025-10-04 19:39:26,242 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.90020838 0.05224539 0.04382958 0.00371666]
 [0.         0.17273977 0.53003762 0.2840359  0.01318671]
 [0.         0.04328016 0.06126954 0.87752838 0.01792191]
 [0.         0.02047607 0.01860919 0.15028329 0.81063145]]
2025-10-04 19:39:26,242 | INFO | lofF1 is 84.0118, clfF1 is 70.3754, oaF1 is 74.4663, sub class F1 score is [93.4906 50.5582 68.7652 84.5995]
2025-10-04 19:39:26,243 | INFO | loc_f1_score=np.float64(84.0118), harmonic_mean_f1=np.float64(70.3754), oaf1=np.float64(74.4663), damage_f1_score=array([93.4906, 50.5582, 68.7652, 84.5995])
2025-10-04 19:39:26,243 | INFO | ---------starting train set evaluation-----------
2025-10-04 19:39:30,211 | INFO | [TrainBuf] locF1 is 85.8343, clfF1 is 74.5893, oaF1 is 77.9628, sub class F1 score is [95.0667 54.7662 74.4284 87.6201]
2025-10-04 19:39:30,212 | INFO | Validation Results:
2025-10-04 19:39:30,213 | INFO | [TEST ] Step  6250: (np.float64(82.9397), np.float64(64.6744), np.float64(70.154), array([94.4764, 39.5513, 70.0514, 85.4353]))
2025-10-04 19:39:30,213 | INFO | [TRAIN] Step  6250: (np.float64(82.5259), np.float64(64.2365), np.float64(69.7233), array([93.1198, 42.3277, 63.9327, 81.5366]))

2025-10-04 19:39:30,213 | INFO | [TEST ] Step 12500: (np.float64(83.5089), np.float64(69.5776), np.float64(73.757), array([93.176 , 48.0508, 70.2096, 85.4481]))
2025-10-04 19:39:30,213 | INFO | [TRAIN] Step 12500: (np.float64(84.1316), np.float64(62.4203), np.float64(68.9337), array([93.7562, 38.3033, 64.1149, 85.3869]))

2025-10-04 19:39:30,213 | INFO | [TEST ] Step 18750: (np.float64(84.3222), np.float64(72.5135), np.float64(76.0561), array([95.2212, 53.0632, 70.0347, 86.6836]))
2025-10-04 19:39:30,213 | INFO | [TRAIN] Step 18750: (np.float64(84.7933), np.float64(69.6971), np.float64(74.226), array([95.025 , 48.6799, 69.1498, 84.2892]))

2025-10-04 19:39:30,213 | INFO | [TEST ] Step 25000: (np.float64(84.6396), np.float64(73.261), np.float64(76.6746), array([95.1163, 54.0936, 72.4747, 84.7352]))
2025-10-04 19:39:30,213 | INFO | [TRAIN] Step 25000: (np.float64(85.4036), np.float64(70.2501), np.float64(74.7961), array([95.1481, 49.1034, 70.4631, 84.2282]))

2025-10-04 19:39:30,213 | INFO | [TEST ] Step 31250: (np.float64(84.6109), np.float64(68.3072), np.float64(73.1983), array([92.7939, 47.5153, 65.8255, 86.6185]))
2025-10-04 19:39:30,213 | INFO | [TRAIN] Step 31250: (np.float64(85.6593), np.float64(73.262), np.float64(76.9812), array([95.2366, 52.1641, 74.4852, 86.9362]))

2025-10-04 19:39:30,213 | INFO | [TEST ] Step 37500: (np.float64(84.9383), np.float64(70.2296), np.float64(74.6422), array([94.6012, 50.5153, 73.2732, 77.2688]))
2025-10-04 19:39:30,213 | INFO | [TRAIN] Step 37500: (np.float64(85.4813), np.float64(73.9807), np.float64(77.4309), array([95.6659, 55.0139, 71.8995, 86.7333]))

2025-10-04 19:39:30,213 | INFO | [TEST ] Step    -1: (np.float64(84.0118), np.float64(70.3754), np.float64(74.4663), array([93.4906, 50.5582, 68.7652, 84.5995]))
2025-10-04 19:39:30,213 | INFO | [TRAIN] Step    -1: (np.float64(85.8343), np.float64(74.5893), np.float64(77.9628), array([95.0667, 54.7662, 74.4284, 87.6201]))

2025-10-04 19:39:30,214 | INFO | The accuracy of the best round is: [np.float64(84.6396), np.float64(73.261), np.float64(76.6746), array([95.1163, 54.0936, 72.4747, 84.7352])]
2025-10-04 19:39:30,239 | INFO | MAIN - DONE.
2025-10-04 19:39:30,240 | INFO | MAIN - EXIT.
