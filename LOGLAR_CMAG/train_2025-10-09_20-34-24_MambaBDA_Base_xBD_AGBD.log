2025-10-09 20:34:25,775 | INFO | MAIN - START
2025-10-09 20:34:25,775 | INFO |  > FOCAL LOSS set to False
2025-10-09 20:34:25,775 | INFO |  > ALINGNMENT set to False
2025-10-09 20:34:25,775 | INFO |  > ATTENTION GATE set to -> Building: True, Damage: True
2025-10-09 20:34:25,777 | INFO | Command Line Args:
{
    "cfg": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/configs/vssm1/vssm_base_224.yaml",
    "opts": null,
    "pretrained_weight_path": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/pretrained_weight/vssm_base_0229_ckpt_epoch_237.pth",
    "dataset": "xBD",
    "type": "train",
    "train_dataset_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/train_combined",
    "train_data_list_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/train_combined/train_list2.txt",
    "test_dataset_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/test",
    "test_data_list_path": "/mnt/storage1/alpgenc/change_detection/xBD_complete_png/test/test_list2.txt",
    "shuffle": true,
    "batch_size": 8,
    "crop_size": 256,
    "start_iter": 0,
    "cuda": true,
    "max_iters": 400000,
    "model_type": "MambaBDA_Base",
    "model_param_path": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-09_20-34-24_MambaBDA_Base_xBD_AGBD",
    "resume": null,
    "learning_rate": 0.0001,
    "momentum": 0.9,
    "weight_decay": 0.005,
    "logfile": "/mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/LOGLAR_CMAG/train_2025-10-09_20-34-24_MambaBDA_Base_xBD_AGBD.log",
    "extension": "png",
    "focal_loss": false,
    "enable_alignment": false,
    "enable_attn_gate_building": true,
    "enable_attn_gate_damage": true,
    "deterministic": false,
    "validations": 16,
    "measure_train_scores": true
}
2025-10-09 20:34:25,777 | INFO | Starting in RANDOM mode / not deterministic.
2025-10-09 20:34:25,782 | INFO |  > TRAIN EVALUATION params: TRAIN_BUF_MAXLEN = 8000
2025-10-09 20:34:25,782 | INFO |  > ALIGNMENT params: alignment_args = AlignmentArgs(enabled=False, stages=None, mid_ch=None)
2025-10-09 20:34:25,782 | INFO |  > ATTENTION GATE params: attn_gate_args = AttentionGateArgs(enable_building_ag=True, enable_damage_ag=True)
2025-10-09 20:34:25,782 | INFO | ChangeMambaBDA class
2025-10-09 20:34:27,047 | INFO | ---------starting training-----------
2025-10-09 20:34:27,112 | INFO | VAL_STEP=3125, (number_of_validations = 16)
2025-10-09 20:35:02,070 | INFO | iter is 50 / 50000 [skipped    0] | loc. loss = 0.4374357760, classif. loss = 1.4409745932
2025-10-09 20:35:34,355 | INFO | iter is 100 / 50000 [skipped    0] | loc. loss = 0.3577159643, classif. loss = 3.2088081837
2025-10-09 20:36:06,588 | INFO | iter is 150 / 50000 [skipped    0] | loc. loss = 0.5202807188, classif. loss = 6.5303750038
2025-10-09 20:36:38,892 | INFO | iter is 200 / 50000 [skipped    0] | loc. loss = 0.3353009224, classif. loss = 1.7410391569
2025-10-09 20:37:11,305 | INFO | iter is 250 / 50000 [skipped    0] | loc. loss = 0.3960855901, classif. loss = 1.3729426861
2025-10-09 20:37:43,080 | INFO | iter is 300 / 50000 [skipped    1] | loc. loss = 0.3813201189, classif. loss = 0.3165196776
2025-10-09 20:38:15,527 | INFO | iter is 350 / 50000 [skipped    1] | loc. loss = 0.2748525441, classif. loss = 1.7825436592
2025-10-09 20:38:47,301 | INFO | iter is 400 / 50000 [skipped    2] | loc. loss = 0.3883161843, classif. loss = 2.5325143337
2025-10-09 20:39:19,794 | INFO | iter is 450 / 50000 [skipped    2] | loc. loss = 0.3105566800, classif. loss = 0.7903518677
2025-10-09 20:39:52,134 | INFO | iter is 500 / 50000 [skipped    2] | loc. loss = 0.3740924001, classif. loss = 0.6100466847
2025-10-09 20:40:24,574 | INFO | iter is 550 / 50000 [skipped    2] | loc. loss = 0.4068294466, classif. loss = 3.0675241947
2025-10-09 20:40:57,092 | INFO | iter is 600 / 50000 [skipped    2] | loc. loss = 0.3047572076, classif. loss = 0.8683825731
2025-10-09 20:41:29,584 | INFO | iter is 650 / 50000 [skipped    2] | loc. loss = 0.2890475690, classif. loss = 1.2448621988
2025-10-09 20:42:01,471 | INFO | iter is 700 / 50000 [skipped    3] | loc. loss = 0.2417086065, classif. loss = 0.2053662241
2025-10-09 20:42:33,885 | INFO | iter is 750 / 50000 [skipped    3] | loc. loss = 0.4469967186, classif. loss = 1.5188701153
2025-10-09 20:43:05,190 | INFO | iter is 800 / 50000 [skipped    5] | loc. loss = 0.3196903467, classif. loss = 1.3216150999
2025-10-09 20:43:37,650 | INFO | iter is 850 / 50000 [skipped    5] | loc. loss = 0.2971421778, classif. loss = 0.8497393131
2025-10-09 20:44:09,507 | INFO | iter is 900 / 50000 [skipped    6] | loc. loss = 0.3668614924, classif. loss = 1.5789945126
2025-10-09 20:44:41,449 | INFO | iter is 950 / 50000 [skipped    7] | loc. loss = 0.3925167322, classif. loss = 1.1723511219
2025-10-09 20:45:13,921 | INFO | iter is 1000 / 50000 [skipped    7] | loc. loss = 0.3262992501, classif. loss = 1.1411991119
2025-10-09 20:45:46,538 | INFO | iter is 1050 / 50000 [skipped    7] | loc. loss = 0.2516197562, classif. loss = 1.4329074621
2025-10-09 20:46:19,090 | INFO | iter is 1100 / 50000 [skipped    7] | loc. loss = 0.4493035674, classif. loss = 1.0403683186
2025-10-09 20:46:51,052 | INFO | iter is 1150 / 50000 [skipped    8] | loc. loss = 0.2211298645, classif. loss = 2.6368887424
2025-10-09 20:47:23,623 | INFO | iter is 1200 / 50000 [skipped    8] | loc. loss = 0.5035753250, classif. loss = 0.3967103362
2025-10-09 20:47:56,156 | INFO | iter is 1250 / 50000 [skipped    8] | loc. loss = 0.2650636733, classif. loss = 0.1067063659
2025-10-09 20:48:28,221 | INFO | iter is 1300 / 50000 [skipped    9] | loc. loss = 0.2861521840, classif. loss = 0.6683647633
2025-10-09 20:49:00,743 | INFO | iter is 1350 / 50000 [skipped    9] | loc. loss = 0.2140717208, classif. loss = 2.2745060921
2025-10-09 20:49:33,276 | INFO | iter is 1400 / 50000 [skipped    9] | loc. loss = 0.3599851727, classif. loss = 1.1527476311
2025-10-09 20:50:05,813 | INFO | iter is 1450 / 50000 [skipped    9] | loc. loss = 0.2932621241, classif. loss = 2.1107590199
2025-10-09 20:50:38,366 | INFO | iter is 1500 / 50000 [skipped    9] | loc. loss = 0.5770626664, classif. loss = 0.4415029883
2025-10-09 20:51:10,411 | INFO | iter is 1550 / 50000 [skipped   10] | loc. loss = 0.1621591598, classif. loss = 0.6053079963
2025-10-09 20:51:42,978 | INFO | iter is 1600 / 50000 [skipped   10] | loc. loss = 0.1715025604, classif. loss = 0.1440440118
2025-10-09 20:52:15,606 | INFO | iter is 1650 / 50000 [skipped   10] | loc. loss = 0.2602207959, classif. loss = 1.1349443197
2025-10-09 20:52:47,556 | INFO | iter is 1700 / 50000 [skipped   11] | loc. loss = 0.2781963944, classif. loss = 0.1010399237
2025-10-09 20:53:20,106 | INFO | iter is 1750 / 50000 [skipped   11] | loc. loss = 0.2677947283, classif. loss = 2.6620855331
2025-10-09 20:53:52,758 | INFO | iter is 1800 / 50000 [skipped   11] | loc. loss = 0.2626503408, classif. loss = 0.2372462749
2025-10-09 20:54:24,805 | INFO | iter is 1850 / 50000 [skipped   12] | loc. loss = 0.2804206610, classif. loss = 3.3780875206
2025-10-09 20:54:57,480 | INFO | iter is 1900 / 50000 [skipped   12] | loc. loss = 0.3093968928, classif. loss = 1.4113821983
2025-10-09 20:55:30,104 | INFO | iter is 1950 / 50000 [skipped   12] | loc. loss = 0.2313790470, classif. loss = 1.9693274498
2025-10-09 20:56:02,737 | INFO | iter is 2000 / 50000 [skipped   12] | loc. loss = 0.3061778247, classif. loss = 0.9759294987
2025-10-09 20:56:35,437 | INFO | iter is 2050 / 50000 [skipped   12] | loc. loss = 0.2878026664, classif. loss = 0.5220654011
2025-10-09 20:57:08,144 | INFO | iter is 2100 / 50000 [skipped   12] | loc. loss = 0.3477673531, classif. loss = 0.3088895977
2025-10-09 20:57:40,933 | INFO | iter is 2150 / 50000 [skipped   12] | loc. loss = 0.1995399743, classif. loss = 1.3764733076
2025-10-09 20:58:13,603 | INFO | iter is 2200 / 50000 [skipped   12] | loc. loss = 0.1938063651, classif. loss = 0.9377275705
2025-10-09 20:58:46,271 | INFO | iter is 2250 / 50000 [skipped   12] | loc. loss = 0.3214763105, classif. loss = 0.9217668772
2025-10-09 20:59:19,045 | INFO | iter is 2300 / 50000 [skipped   12] | loc. loss = 0.4245929718, classif. loss = 1.6056332588
2025-10-09 20:59:50,582 | INFO | iter is 2350 / 50000 [skipped   14] | loc. loss = 0.1668899804, classif. loss = 1.1272995472
2025-10-09 21:00:23,378 | INFO | iter is 2400 / 50000 [skipped   14] | loc. loss = 0.3031847477, classif. loss = 1.2197914124
2025-10-09 21:00:56,085 | INFO | iter is 2450 / 50000 [skipped   14] | loc. loss = 0.2025530636, classif. loss = 1.5136620998
2025-10-09 21:01:28,812 | INFO | iter is 2500 / 50000 [skipped   14] | loc. loss = 0.2596411407, classif. loss = 0.6279860735
2025-10-09 21:02:01,546 | INFO | iter is 2550 / 50000 [skipped   14] | loc. loss = 0.3021279275, classif. loss = 0.2846453786
2025-10-09 21:02:34,358 | INFO | iter is 2600 / 50000 [skipped   14] | loc. loss = 0.3234451413, classif. loss = 1.2829983234
2025-10-09 21:03:07,121 | INFO | iter is 2650 / 50000 [skipped   14] | loc. loss = 0.2768547535, classif. loss = 0.6887178421
2025-10-09 21:03:39,849 | INFO | iter is 2700 / 50000 [skipped   14] | loc. loss = 0.2791996300, classif. loss = 0.0985681415
2025-10-09 21:04:12,692 | INFO | iter is 2750 / 50000 [skipped   14] | loc. loss = 0.3075324595, classif. loss = 2.1169586182
2025-10-09 21:04:44,798 | INFO | iter is 2800 / 50000 [skipped   15] | loc. loss = 0.3552668095, classif. loss = 0.3103290796
2025-10-09 21:05:17,520 | INFO | iter is 2850 / 50000 [skipped   15] | loc. loss = 0.2111351788, classif. loss = 0.4722690582
2025-10-09 21:05:50,366 | INFO | iter is 2900 / 50000 [skipped   15] | loc. loss = 0.2729096413, classif. loss = 0.7496433854
2025-10-09 21:06:23,154 | INFO | iter is 2950 / 50000 [skipped   15] | loc. loss = 0.2820130587, classif. loss = 0.8762084246
2025-10-09 21:06:55,423 | INFO | iter is 3000 / 50000 [skipped   16] | loc. loss = 0.2032680959, classif. loss = 0.4730078280
2025-10-09 21:07:26,989 | INFO | iter is 3050 / 50000 [skipped   18] | loc. loss = 0.2168089896, classif. loss = 0.5498664975
2025-10-09 21:07:59,146 | INFO | iter is 3100 / 50000 [skipped   19] | loc. loss = 0.1974113435, classif. loss = 2.2533245087
2025-10-09 21:08:15,607 | INFO | ---------starting evaluation-----------
2025-10-09 21:08:17,385 | INFO | validation:    0/ 933 (2025-10-09_21-08-17)
2025-10-09 21:09:03,750 | INFO | validation:  100/ 933 (2025-10-09_21-09-03)
2025-10-09 21:09:50,015 | INFO | validation:  200/ 933 (2025-10-09_21-09-50)
2025-10-09 21:10:36,258 | INFO | validation:  300/ 933 (2025-10-09_21-10-36)
2025-10-09 21:11:22,495 | INFO | validation:  400/ 933 (2025-10-09_21-11-22)
2025-10-09 21:12:08,767 | INFO | validation:  500/ 933 (2025-10-09_21-12-08)
2025-10-09 21:12:55,037 | INFO | validation:  600/ 933 (2025-10-09_21-12-55)
2025-10-09 21:13:41,285 | INFO | validation:  700/ 933 (2025-10-09_21-13-41)
2025-10-09 21:14:27,542 | INFO | validation:  800/ 933 (2025-10-09_21-14-27)
2025-10-09 21:15:13,785 | INFO | validation:  900/ 933 (2025-10-09_21-15-13)
2025-10-09 21:15:29,764 | INFO | Confusion Matrix of Localization:
[[911180184   9179665]
 [ 13073892  44887667]]
2025-10-09 21:15:29,765 | INFO | Confusion Matrix of Localization - Normalized:
[[0.990026   0.009974  ]
 [0.22556143 0.77443857]]
2025-10-09 21:15:29,765 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 43302930    32386   491066    32359]
 [       0  3798463   229113   618872    95523]
 [       0  1387628   101278  3940386    99638]
 [       0   652483    12093   307021  2097693]]
2025-10-09 21:15:29,765 | INFO | Confusion Matrix of Classification - Normalized:
[[           nan            nan            nan            nan
             nan]
 [0.00000000e+00 9.87327247e-01 7.38416089e-04 1.11965366e-02
  7.37800476e-04]
 [0.00000000e+00 8.01030415e-01 4.83159851e-02 1.30509444e-01
  2.01441552e-02]
 [0.00000000e+00 2.50975867e-01 1.83178300e-02 7.12685095e-01
  1.80212084e-02]
 [0.00000000e+00 2.12584344e-01 3.93999915e-03 1.00029974e-01
  6.83445683e-01]]
2025-10-09 21:15:29,765 | INFO | lofF1 is 80.1359, clfF1 is 26.8318, oaF1 is 42.8231, sub class F1 score is [93.1243  8.9553 72.3918 77.7715]
2025-10-09 21:15:30,025 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-09_20-34-24_MambaBDA_Base_xBD_AGBD/model_step3125.pth
2025-10-09 21:15:30,025 | INFO | ---------starting train set evaluation-----------
2025-10-09 21:15:30,025 | INFO | Train buffer size: 3106.
2025-10-09 21:15:42,172 | INFO | [TrainBuf] locF1 is 73.3252, clfF1 is 37.1090, oaF1 is 47.9739, sub class F1 score is [89.9403 16.7314 43.1191 72.9262]
2025-10-09 21:15:57,790 | INFO | iter is 3150 / 50000 [skipped   20] | loc. loss = 0.2688935399, classif. loss = 1.3241875172
2025-10-09 21:16:29,085 | INFO | iter is 3200 / 50000 [skipped   22] | loc. loss = 0.2707128525, classif. loss = 0.6857643127
2025-10-09 21:17:01,645 | INFO | iter is 3250 / 50000 [skipped   22] | loc. loss = 0.1836714447, classif. loss = 0.1803754270
2025-10-09 21:17:34,155 | INFO | iter is 3300 / 50000 [skipped   22] | loc. loss = 0.3782973886, classif. loss = 2.5099470615
2025-10-09 21:18:06,152 | INFO | iter is 3350 / 50000 [skipped   23] | loc. loss = 0.2663656175, classif. loss = 0.3567500114
2025-10-09 21:18:38,591 | INFO | iter is 3400 / 50000 [skipped   23] | loc. loss = 0.2107691616, classif. loss = 1.9690592289
2025-10-09 21:19:09,856 | INFO | iter is 3450 / 50000 [skipped   25] | loc. loss = 0.3276065290, classif. loss = 4.2607622147
2025-10-09 21:19:42,381 | INFO | iter is 3500 / 50000 [skipped   25] | loc. loss = 0.1813839376, classif. loss = 1.5733563900
2025-10-09 21:20:14,882 | INFO | iter is 3550 / 50000 [skipped   25] | loc. loss = 0.2045625150, classif. loss = 0.6153096557
2025-10-09 21:20:47,489 | INFO | iter is 3600 / 50000 [skipped   25] | loc. loss = 0.2265953422, classif. loss = 0.3786782026
2025-10-09 21:21:19,490 | INFO | iter is 3650 / 50000 [skipped   26] | loc. loss = 0.2844349742, classif. loss = 0.7835979462
2025-10-09 21:21:50,997 | INFO | iter is 3700 / 50000 [skipped   28] | loc. loss = 0.1805890054, classif. loss = 1.3819893599
2025-10-09 21:22:23,561 | INFO | iter is 3750 / 50000 [skipped   28] | loc. loss = 0.2496940494, classif. loss = 0.9582421184
2025-10-09 21:22:56,191 | INFO | iter is 3800 / 50000 [skipped   28] | loc. loss = 0.2538960874, classif. loss = 0.5127490759
2025-10-09 21:23:27,523 | INFO | iter is 3850 / 50000 [skipped   30] | loc. loss = 0.2345836908, classif. loss = 0.4135847390
2025-10-09 21:23:59,600 | INFO | iter is 3900 / 50000 [skipped   31] | loc. loss = 0.3165691495, classif. loss = 0.0769332945
2025-10-09 21:24:31,625 | INFO | iter is 3950 / 50000 [skipped   32] | loc. loss = 0.3329498172, classif. loss = 0.1783653647
2025-10-09 21:25:04,164 | INFO | iter is 4000 / 50000 [skipped   32] | loc. loss = 0.2454158664, classif. loss = 0.0470543876
2025-10-09 21:25:36,737 | INFO | iter is 4050 / 50000 [skipped   32] | loc. loss = 0.2967154384, classif. loss = 0.7792505026
2025-10-09 21:26:09,224 | INFO | iter is 4100 / 50000 [skipped   32] | loc. loss = 0.3186508417, classif. loss = 0.3471100926
2025-10-09 21:26:41,822 | INFO | iter is 4150 / 50000 [skipped   32] | loc. loss = 0.1197862402, classif. loss = 0.1256696284
2025-10-09 21:27:14,367 | INFO | iter is 4200 / 50000 [skipped   32] | loc. loss = 0.2857720554, classif. loss = 0.9606429935
2025-10-09 21:27:46,412 | INFO | iter is 4250 / 50000 [skipped   33] | loc. loss = 0.2244711816, classif. loss = 1.4800013304
2025-10-09 21:28:19,008 | INFO | iter is 4300 / 50000 [skipped   33] | loc. loss = 0.2402510643, classif. loss = 0.8902831078
2025-10-09 21:28:51,623 | INFO | iter is 4350 / 50000 [skipped   33] | loc. loss = 0.1414183378, classif. loss = 3.1718029976
2025-10-09 21:29:24,242 | INFO | iter is 4400 / 50000 [skipped   33] | loc. loss = 0.3364211023, classif. loss = 1.3916965723
2025-10-09 21:29:55,609 | INFO | iter is 4450 / 50000 [skipped   35] | loc. loss = 0.2425898314, classif. loss = 1.0068500042
2025-10-09 21:30:27,667 | INFO | iter is 4500 / 50000 [skipped   36] | loc. loss = 0.3128261566, classif. loss = 0.9784659743
2025-10-09 21:31:32,421 | INFO | iter is 4600 / 50000 [skipped   37] | loc. loss = 0.2098371685, classif. loss = 0.9257974625
2025-10-09 21:32:05,084 | INFO | iter is 4650 / 50000 [skipped   37] | loc. loss = 0.2958213091, classif. loss = 0.7578895092
2025-10-09 21:32:37,705 | INFO | iter is 4700 / 50000 [skipped   37] | loc. loss = 0.3029029667, classif. loss = 0.2010098100
2025-10-09 21:33:09,878 | INFO | iter is 4750 / 50000 [skipped   38] | loc. loss = 0.1718852967, classif. loss = 1.3136839867
2025-10-09 21:33:41,910 | INFO | iter is 4800 / 50000 [skipped   39] | loc. loss = 0.1900072247, classif. loss = 0.1507777572
2025-10-09 21:34:14,029 | INFO | iter is 4850 / 50000 [skipped   40] | loc. loss = 0.2050909847, classif. loss = 1.1879572868
2025-10-09 21:34:46,106 | INFO | iter is 4900 / 50000 [skipped   41] | loc. loss = 0.2419914901, classif. loss = 0.6465128064
2025-10-09 21:35:18,821 | INFO | iter is 4950 / 50000 [skipped   41] | loc. loss = 0.2415786982, classif. loss = 1.6677403450
2025-10-09 21:35:50,893 | INFO | iter is 5000 / 50000 [skipped   42] | loc. loss = 0.1941213459, classif. loss = 0.7905609608
2025-10-09 21:36:22,989 | INFO | iter is 5050 / 50000 [skipped   43] | loc. loss = 0.2293343842, classif. loss = 0.7385802865
2025-10-09 21:36:55,715 | INFO | iter is 5100 / 50000 [skipped   43] | loc. loss = 0.1896824241, classif. loss = 0.5563906431
2025-10-09 21:37:28,413 | INFO | iter is 5150 / 50000 [skipped   43] | loc. loss = 0.2793458402, classif. loss = 0.7237532139
2025-10-09 21:38:00,565 | INFO | iter is 5200 / 50000 [skipped   44] | loc. loss = 0.3243972957, classif. loss = 0.2423620522
2025-10-09 21:38:33,238 | INFO | iter is 5250 / 50000 [skipped   44] | loc. loss = 0.1830435991, classif. loss = 0.1901344806
2025-10-09 21:39:04,817 | INFO | iter is 5300 / 50000 [skipped   46] | loc. loss = 0.2971199155, classif. loss = 0.6990106106
2025-10-09 21:39:36,912 | INFO | iter is 5350 / 50000 [skipped   47] | loc. loss = 0.3174770474, classif. loss = 0.9653879404
2025-10-09 21:40:09,069 | INFO | iter is 5400 / 50000 [skipped   48] | loc. loss = 0.3161685467, classif. loss = 0.0532467663
2025-10-09 21:40:41,293 | INFO | iter is 5450 / 50000 [skipped   49] | loc. loss = 0.3409061432, classif. loss = 1.3773655891
2025-10-09 21:41:11,678 | INFO | iter is 5500 / 50000 [skipped   53] | loc. loss = 0.2787765861, classif. loss = 1.2243446112
2025-10-09 21:41:44,518 | INFO | iter is 5550 / 50000 [skipped   53] | loc. loss = 0.1925529242, classif. loss = 0.1404186785
2025-10-09 21:42:16,614 | INFO | iter is 5600 / 50000 [skipped   54] | loc. loss = 0.2780592740, classif. loss = 0.0978754759
2025-10-09 21:42:49,400 | INFO | iter is 5650 / 50000 [skipped   54] | loc. loss = 0.1737695932, classif. loss = 0.5529446006
2025-10-09 21:43:21,498 | INFO | iter is 5700 / 50000 [skipped   55] | loc. loss = 0.2414836287, classif. loss = 0.5844653845
2025-10-09 21:43:54,388 | INFO | iter is 5750 / 50000 [skipped   55] | loc. loss = 0.3005125523, classif. loss = 0.9164214134
2025-10-09 21:44:27,091 | INFO | iter is 5800 / 50000 [skipped   55] | loc. loss = 0.3029744923, classif. loss = 0.0870986134
2025-10-09 21:44:59,874 | INFO | iter is 5850 / 50000 [skipped   55] | loc. loss = 0.1946788877, classif. loss = 0.4243449569
2025-10-09 21:45:32,595 | INFO | iter is 5900 / 50000 [skipped   55] | loc. loss = 0.2351691425, classif. loss = 1.3864824772
2025-10-09 21:46:05,347 | INFO | iter is 5950 / 50000 [skipped   55] | loc. loss = 0.2189316750, classif. loss = 0.0030128937
2025-10-09 21:46:38,208 | INFO | iter is 6000 / 50000 [skipped   55] | loc. loss = 0.2070011497, classif. loss = 2.1648745537
2025-10-09 21:47:10,992 | INFO | iter is 6050 / 50000 [skipped   55] | loc. loss = 0.1575585455, classif. loss = 0.2061401606
2025-10-09 21:47:43,870 | INFO | iter is 6100 / 50000 [skipped   55] | loc. loss = 0.2104409933, classif. loss = 1.8243969679
2025-10-09 21:48:16,651 | INFO | iter is 6150 / 50000 [skipped   55] | loc. loss = 0.2717616856, classif. loss = 0.1563264877
2025-10-09 21:48:49,541 | INFO | iter is 6200 / 50000 [skipped   55] | loc. loss = 0.3412909806, classif. loss = 0.4410849214
2025-10-09 21:49:22,370 | INFO | iter is 6250 / 50000 [skipped   55] | loc. loss = 0.2396133542, classif. loss = 0.0195065662
2025-10-09 21:49:22,372 | INFO | ---------starting evaluation-----------
2025-10-09 21:49:24,270 | INFO | validation:    0/ 933 (2025-10-09_21-49-24)
2025-10-09 21:50:10,828 | INFO | validation:  100/ 933 (2025-10-09_21-50-10)
2025-10-09 21:50:57,321 | INFO | validation:  200/ 933 (2025-10-09_21-50-57)
2025-10-09 21:51:43,794 | INFO | validation:  300/ 933 (2025-10-09_21-51-43)
2025-10-09 21:52:30,276 | INFO | validation:  400/ 933 (2025-10-09_21-52-30)
2025-10-09 21:53:16,767 | INFO | validation:  500/ 933 (2025-10-09_21-53-16)
2025-10-09 21:54:03,285 | INFO | validation:  600/ 933 (2025-10-09_21-54-03)
2025-10-09 21:54:49,732 | INFO | validation:  700/ 933 (2025-10-09_21-54-49)
2025-10-09 21:55:36,193 | INFO | validation:  800/ 933 (2025-10-09_21-55-36)
2025-10-09 21:56:22,663 | INFO | validation:  900/ 933 (2025-10-09_21-56-22)
2025-10-09 21:56:38,881 | INFO | Confusion Matrix of Localization:
[[908333296  12026553]
 [  9314345  48647214]]
2025-10-09 21:56:38,881 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98693277 0.01306723]
 [0.16069866 0.83930134]]
2025-10-09 21:56:38,881 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40965665  1939156   820605   133315]
 [       0  1568037  2360666   657519   155749]
 [       0   536607   708572  3980535   303216]
 [       0   153402    92751   251182  2571955]]
2025-10-09 21:56:38,881 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.9340365  0.04421367 0.01871018 0.00303964]
 [0.         0.33067199 0.4978238  0.13865943 0.03284478]
 [0.         0.0970544  0.12815717 0.71994672 0.05484171]
 [0.         0.04997964 0.03021904 0.08183717 0.83796415]]
2025-10-09 21:56:38,881 | INFO | lofF1 is 82.0113, clfF1 is 69.3093, oaF1 is 73.1199, sub class F1 score is [94.0848 47.9658 70.8358 82.5201]
2025-10-09 21:56:39,143 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-09_20-34-24_MambaBDA_Base_xBD_AGBD/model_step6250.pth
2025-10-09 21:56:39,144 | INFO | ---------starting train set evaluation-----------
2025-10-09 21:56:39,144 | INFO | Train buffer size: 3089.
2025-10-09 21:56:51,370 | INFO | [TrainBuf] locF1 is 81.3585, clfF1 is 57.2931, oaF1 is 64.5127, sub class F1 score is [93.2222 33.2123 59.7527 81.6695]
2025-10-09 21:57:23,349 | INFO | iter is 6300 / 50000 [skipped   56] | loc. loss = 0.3042759895, classif. loss = 0.0098128160
2025-10-09 21:57:55,869 | INFO | iter is 6350 / 50000 [skipped   56] | loc. loss = 0.2939478159, classif. loss = 0.7550209761
2025-10-09 21:58:28,388 | INFO | iter is 6400 / 50000 [skipped   56] | loc. loss = 0.1684670448, classif. loss = 0.5683802962
2025-10-09 21:58:59,869 | INFO | iter is 6450 / 50000 [skipped   58] | loc. loss = 0.1881750971, classif. loss = 0.0086024180
2025-10-09 21:59:31,743 | INFO | iter is 6500 / 50000 [skipped   59] | loc. loss = 0.3970676064, classif. loss = 0.6677706838
2025-10-09 22:00:04,332 | INFO | iter is 6550 / 50000 [skipped   59] | loc. loss = 0.2265875041, classif. loss = 1.9601341486
2025-10-09 22:00:36,853 | INFO | iter is 6600 / 50000 [skipped   59] | loc. loss = 0.2980952263, classif. loss = 0.5703002214
2025-10-09 22:01:08,838 | INFO | iter is 6650 / 50000 [skipped   60] | loc. loss = 0.2373353094, classif. loss = 0.5687849522
2025-10-09 22:01:41,466 | INFO | iter is 6700 / 50000 [skipped   60] | loc. loss = 0.1874693632, classif. loss = 0.0239572097
2025-10-09 22:02:14,020 | INFO | iter is 6750 / 50000 [skipped   60] | loc. loss = 0.2557510138, classif. loss = 0.9984295368
2025-10-09 22:02:45,427 | INFO | iter is 6800 / 50000 [skipped   62] | loc. loss = 0.2287335992, classif. loss = 0.3490006626
2025-10-09 22:03:18,003 | INFO | iter is 6850 / 50000 [skipped   62] | loc. loss = 0.1822719872, classif. loss = 0.4435111284
2025-10-09 22:03:49,997 | INFO | iter is 6900 / 50000 [skipped   63] | loc. loss = 0.2356590033, classif. loss = 0.4570842087
2025-10-09 22:04:22,553 | INFO | iter is 6950 / 50000 [skipped   63] | loc. loss = 0.0974513143, classif. loss = 0.0333244316
2025-10-09 22:04:55,173 | INFO | iter is 7000 / 50000 [skipped   63] | loc. loss = 0.2395102084, classif. loss = 1.1200697422
2025-10-09 22:05:27,842 | INFO | iter is 7050 / 50000 [skipped   63] | loc. loss = 0.2190018445, classif. loss = 1.2126674652
2025-10-09 22:05:59,263 | INFO | iter is 7100 / 50000 [skipped   65] | loc. loss = 0.1264526099, classif. loss = 0.9199073911
2025-10-09 22:06:31,939 | INFO | iter is 7150 / 50000 [skipped   65] | loc. loss = 0.2033080906, classif. loss = 0.7440407276
2025-10-09 22:07:04,003 | INFO | iter is 7200 / 50000 [skipped   66] | loc. loss = 0.1712770313, classif. loss = 1.4855606556
2025-10-09 22:07:35,474 | INFO | iter is 7250 / 50000 [skipped   68] | loc. loss = 0.2470319867, classif. loss = 0.5902773142
2025-10-09 22:08:07,443 | INFO | iter is 7300 / 50000 [skipped   69] | loc. loss = 0.1894649863, classif. loss = 0.0056109577
2025-10-09 22:08:39,519 | INFO | iter is 7350 / 50000 [skipped   70] | loc. loss = 0.2413564622, classif. loss = 2.1552381516
2025-10-09 22:09:12,052 | INFO | iter is 7400 / 50000 [skipped   70] | loc. loss = 0.1476428807, classif. loss = 0.0712620765
2025-10-09 22:09:44,159 | INFO | iter is 7450 / 50000 [skipped   71] | loc. loss = 0.5423905849, classif. loss = 0.4283777475
2025-10-09 22:10:16,833 | INFO | iter is 7500 / 50000 [skipped   71] | loc. loss = 0.3128854334, classif. loss = 0.1618302464
2025-10-09 22:10:48,857 | INFO | iter is 7550 / 50000 [skipped   72] | loc. loss = 0.3269088268, classif. loss = 1.2078802586
2025-10-09 22:11:21,562 | INFO | iter is 7600 / 50000 [skipped   72] | loc. loss = 0.2742240429, classif. loss = 0.4391701221
2025-10-09 22:11:53,007 | INFO | iter is 7650 / 50000 [skipped   74] | loc. loss = 0.2321089506, classif. loss = 1.2507851124
2025-10-09 22:12:25,094 | INFO | iter is 7700 / 50000 [skipped   75] | loc. loss = 0.2015838325, classif. loss = 0.6898537874
2025-10-09 22:12:57,752 | INFO | iter is 7750 / 50000 [skipped   75] | loc. loss = 0.2299495935, classif. loss = 2.8855257034
2025-10-09 22:13:30,543 | INFO | iter is 7800 / 50000 [skipped   75] | loc. loss = 0.1905821860, classif. loss = 1.0027974844
2025-10-09 22:14:03,266 | INFO | iter is 7850 / 50000 [skipped   75] | loc. loss = 0.0874257833, classif. loss = 1.2991368771
2025-10-09 22:14:35,953 | INFO | iter is 7900 / 50000 [skipped   75] | loc. loss = 0.1765112579, classif. loss = 1.3878819942
2025-10-09 22:15:08,717 | INFO | iter is 7950 / 50000 [skipped   75] | loc. loss = 0.1584061235, classif. loss = 1.8167942762
2025-10-09 22:15:41,377 | INFO | iter is 8000 / 50000 [skipped   75] | loc. loss = 0.1865915358, classif. loss = 0.5296868086
2025-10-09 22:16:14,109 | INFO | iter is 8050 / 50000 [skipped   75] | loc. loss = 0.2213735431, classif. loss = 0.7518582940
2025-10-09 22:16:46,796 | INFO | iter is 8100 / 50000 [skipped   75] | loc. loss = 0.2810886502, classif. loss = 0.2089046091
2025-10-09 22:17:19,531 | INFO | iter is 8150 / 50000 [skipped   75] | loc. loss = 0.2501577735, classif. loss = 1.1852228642
2025-10-09 22:17:52,321 | INFO | iter is 8200 / 50000 [skipped   75] | loc. loss = 0.2342927903, classif. loss = 0.3779583573
2025-10-09 22:18:25,060 | INFO | iter is 8250 / 50000 [skipped   75] | loc. loss = 0.2419113368, classif. loss = 0.5262440443
2025-10-09 22:18:57,881 | INFO | iter is 8300 / 50000 [skipped   75] | loc. loss = 0.1828618348, classif. loss = 0.2722767591
2025-10-09 22:19:30,665 | INFO | iter is 8350 / 50000 [skipped   75] | loc. loss = 0.1850686520, classif. loss = 1.4247264862
2025-10-09 22:20:03,493 | INFO | iter is 8400 / 50000 [skipped   75] | loc. loss = 0.2285901308, classif. loss = 0.5431450009
2025-10-09 22:20:36,300 | INFO | iter is 8450 / 50000 [skipped   75] | loc. loss = 0.3363130987, classif. loss = 1.8319364786
2025-10-09 22:21:09,129 | INFO | iter is 8500 / 50000 [skipped   75] | loc. loss = 0.1508196294, classif. loss = 0.4487701058
2025-10-09 22:21:40,765 | INFO | iter is 8550 / 50000 [skipped   77] | loc. loss = 0.1766207218, classif. loss = 0.5100054741
2025-10-09 22:22:12,954 | INFO | iter is 8600 / 50000 [skipped   78] | loc. loss = 0.1559771895, classif. loss = 0.8291729689
2025-10-09 22:22:45,202 | INFO | iter is 8650 / 50000 [skipped   79] | loc. loss = 0.1849645674, classif. loss = 0.6602554917
2025-10-09 22:23:18,054 | INFO | iter is 8700 / 50000 [skipped   79] | loc. loss = 0.2057206482, classif. loss = 0.8482486010
2025-10-09 22:23:50,418 | INFO | iter is 8750 / 50000 [skipped   80] | loc. loss = 0.2610351443, classif. loss = 0.6489793062
2025-10-09 22:24:23,182 | INFO | iter is 8800 / 50000 [skipped   80] | loc. loss = 0.1419564635, classif. loss = 0.6387603283
2025-10-09 22:24:56,055 | INFO | iter is 8850 / 50000 [skipped   80] | loc. loss = 0.2439583540, classif. loss = 0.0576520935
2025-10-09 22:25:27,118 | INFO | iter is 8900 / 50000 [skipped   83] | loc. loss = 0.2568559051, classif. loss = 0.2224314511
2025-10-09 22:25:59,957 | INFO | iter is 8950 / 50000 [skipped   83] | loc. loss = 0.2388075590, classif. loss = 1.5019980669
2025-10-09 22:26:32,804 | INFO | iter is 9000 / 50000 [skipped   83] | loc. loss = 0.1126748845, classif. loss = 0.0459495299
2025-10-09 22:27:05,127 | INFO | iter is 9050 / 50000 [skipped   84] | loc. loss = 0.1887023151, classif. loss = 0.8203172684
2025-10-09 22:27:38,031 | INFO | iter is 9100 / 50000 [skipped   84] | loc. loss = 0.2245427072, classif. loss = 1.6293532848
2025-10-09 22:28:10,857 | INFO | iter is 9150 / 50000 [skipped   84] | loc. loss = 0.2076846212, classif. loss = 0.4134178758
2025-10-09 22:28:43,767 | INFO | iter is 9200 / 50000 [skipped   84] | loc. loss = 0.2048374265, classif. loss = 1.7137366533
2025-10-09 22:29:16,652 | INFO | iter is 9250 / 50000 [skipped   84] | loc. loss = 0.2729192376, classif. loss = 0.1056622863
2025-10-09 22:29:49,641 | INFO | iter is 9300 / 50000 [skipped   84] | loc. loss = 0.1721550971, classif. loss = 1.0078843832
2025-10-09 22:30:22,526 | INFO | iter is 9350 / 50000 [skipped   84] | loc. loss = 0.2307207584, classif. loss = 0.9353422523
2025-10-09 22:30:38,985 | INFO | ---------starting evaluation-----------
2025-10-09 22:30:40,970 | INFO | validation:    0/ 933 (2025-10-09_22-30-40)
2025-10-09 22:31:27,472 | INFO | validation:  100/ 933 (2025-10-09_22-31-27)
2025-10-09 22:32:13,921 | INFO | validation:  200/ 933 (2025-10-09_22-32-13)
2025-10-09 22:33:00,351 | INFO | validation:  300/ 933 (2025-10-09_22-33-00)
2025-10-09 22:33:46,788 | INFO | validation:  400/ 933 (2025-10-09_22-33-46)
2025-10-09 22:34:33,220 | INFO | validation:  500/ 933 (2025-10-09_22-34-33)
2025-10-09 22:35:19,676 | INFO | validation:  600/ 933 (2025-10-09_22-35-19)
2025-10-09 22:36:06,113 | INFO | validation:  700/ 933 (2025-10-09_22-36-06)
2025-10-09 22:36:52,585 | INFO | validation:  800/ 933 (2025-10-09_22-36-52)
2025-10-09 22:37:39,073 | INFO | validation:  900/ 933 (2025-10-09_22-37-39)
2025-10-09 22:37:55,358 | INFO | Confusion Matrix of Localization:
[[911705741   8654108]
 [ 10503547  47458012]]
2025-10-09 22:37:55,358 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99059704 0.00940296]
 [0.18121574 0.81878426]]
2025-10-09 22:37:55,358 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42252400   816392   717431    72518]
 [       0  1781048  2135510   803570    21843]
 [       0   675121   830089  3923910    99810]
 [       0   164758   166228   278326  2459978]]
2025-10-09 22:37:55,358 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.96337467 0.01861412 0.01635777 0.00165344]
 [0.         0.37559234 0.45034227 0.16945907 0.00460631]
 [0.         0.12210699 0.15013556 0.70970513 0.01805232]
 [0.         0.05367952 0.05415845 0.09068091 0.80148112]]
2025-10-09 22:37:55,358 | INFO | lofF1 is 83.2059, clfF1 is 70.4000, oaF1 is 74.2418, sub class F1 score is [95.2359 49.1476 69.745  85.9615]
2025-10-09 22:37:55,620 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-09_20-34-24_MambaBDA_Base_xBD_AGBD/model_step9375.pth
2025-10-09 22:37:55,620 | INFO | ---------starting train set evaluation-----------
2025-10-09 22:37:55,620 | INFO | Train buffer size: 3096.
2025-10-09 22:38:07,524 | INFO | [TrainBuf] locF1 is 82.6118, clfF1 is 59.1213, oaF1 is 66.1684, sub class F1 score is [93.5188 35.1475 62.1407 80.512 ]
2025-10-09 22:38:23,164 | INFO | iter is 9400 / 50000 [skipped   85] | loc. loss = 0.2291773558, classif. loss = 1.6687597036
2025-10-09 22:38:55,081 | INFO | iter is 9450 / 50000 [skipped   86] | loc. loss = 0.2018627375, classif. loss = 0.7352677584
2025-10-09 22:39:27,545 | INFO | iter is 9500 / 50000 [skipped   86] | loc. loss = 0.2699792683, classif. loss = 1.2119350433
2025-10-09 22:40:00,131 | INFO | iter is 9550 / 50000 [skipped   86] | loc. loss = 0.2567549646, classif. loss = 0.9037345648
2025-10-09 22:40:32,043 | INFO | iter is 9600 / 50000 [skipped   87] | loc. loss = 0.2412999868, classif. loss = 0.5334139466
2025-10-09 22:41:03,528 | INFO | iter is 9650 / 50000 [skipped   89] | loc. loss = 0.2790520787, classif. loss = 0.0660499483
2025-10-09 22:41:36,169 | INFO | iter is 9700 / 50000 [skipped   89] | loc. loss = 0.1442921460, classif. loss = 0.0533844307
2025-10-09 22:42:08,115 | INFO | iter is 9750 / 50000 [skipped   90] | loc. loss = 0.2020523399, classif. loss = 0.1026878059
2025-10-09 22:42:40,690 | INFO | iter is 9800 / 50000 [skipped   90] | loc. loss = 0.3436498046, classif. loss = 0.2108653486
2025-10-09 22:43:13,212 | INFO | iter is 9850 / 50000 [skipped   90] | loc. loss = 0.2370349765, classif. loss = 0.4188756943
2025-10-09 22:43:45,205 | INFO | iter is 9900 / 50000 [skipped   91] | loc. loss = 0.2437549233, classif. loss = 1.0620682240
2025-10-09 22:44:17,716 | INFO | iter is 9950 / 50000 [skipped   91] | loc. loss = 0.2489016056, classif. loss = 0.3985418975
2025-10-09 22:44:50,384 | INFO | iter is 10000 / 50000 [skipped   91] | loc. loss = 0.4504734874, classif. loss = 0.0268028378
2025-10-09 22:45:23,049 | INFO | iter is 10050 / 50000 [skipped   91] | loc. loss = 0.2434027940, classif. loss = 0.9795038700
2025-10-09 22:45:55,643 | INFO | iter is 10100 / 50000 [skipped   91] | loc. loss = 0.3046995699, classif. loss = 0.1749004722
2025-10-09 22:46:28,330 | INFO | iter is 10150 / 50000 [skipped   91] | loc. loss = 0.0996227041, classif. loss = 4.0329461098
2025-10-09 22:47:00,967 | INFO | iter is 10200 / 50000 [skipped   91] | loc. loss = 0.1801028699, classif. loss = 0.9875583053
2025-10-09 22:47:33,621 | INFO | iter is 10250 / 50000 [skipped   91] | loc. loss = 0.2460863590, classif. loss = 0.0233004093
2025-10-09 22:48:06,272 | INFO | iter is 10300 / 50000 [skipped   91] | loc. loss = 0.2700417042, classif. loss = 0.9592388868
2025-10-09 22:48:38,933 | INFO | iter is 10350 / 50000 [skipped   91] | loc. loss = 0.2199706137, classif. loss = 0.4834032953
2025-10-09 22:49:11,015 | INFO | iter is 10400 / 50000 [skipped   92] | loc. loss = 0.1901551187, classif. loss = 1.9878480434
2025-10-09 22:49:43,726 | INFO | iter is 10450 / 50000 [skipped   92] | loc. loss = 0.1408913881, classif. loss = 0.1103936136
2025-10-09 22:50:15,874 | INFO | iter is 10500 / 50000 [skipped   93] | loc. loss = 0.2238340676, classif. loss = 0.6217618585
2025-10-09 22:50:47,918 | INFO | iter is 10550 / 50000 [skipped   94] | loc. loss = 0.3560569286, classif. loss = 0.8728260994
2025-10-09 22:51:20,686 | INFO | iter is 10600 / 50000 [skipped   94] | loc. loss = 0.1581279635, classif. loss = 0.1373515427
2025-10-09 22:51:53,327 | INFO | iter is 10650 / 50000 [skipped   94] | loc. loss = 0.2721238136, classif. loss = 0.3665345311
2025-10-09 22:52:25,474 | INFO | iter is 10700 / 50000 [skipped   95] | loc. loss = 0.2130689919, classif. loss = 0.6057858467
2025-10-09 22:52:58,185 | INFO | iter is 10750 / 50000 [skipped   95] | loc. loss = 0.3451015651, classif. loss = 0.9752833843
2025-10-09 22:53:30,354 | INFO | iter is 10800 / 50000 [skipped   96] | loc. loss = 0.2857085764, classif. loss = 0.0620116889
2025-10-09 22:54:02,484 | INFO | iter is 10850 / 50000 [skipped   97] | loc. loss = 0.2414771318, classif. loss = 0.8791922927
2025-10-09 22:54:35,250 | INFO | iter is 10900 / 50000 [skipped   97] | loc. loss = 0.1940509975, classif. loss = 0.8371143341
2025-10-09 22:55:08,037 | INFO | iter is 10950 / 50000 [skipped   97] | loc. loss = 0.2396856248, classif. loss = 0.7021486759
2025-10-09 22:55:40,724 | INFO | iter is 11000 / 50000 [skipped   97] | loc. loss = 0.1148009300, classif. loss = 0.1513705999
2025-10-09 22:56:13,464 | INFO | iter is 11050 / 50000 [skipped   97] | loc. loss = 0.2217805237, classif. loss = 0.3309756219
2025-10-09 22:56:46,232 | INFO | iter is 11100 / 50000 [skipped   97] | loc. loss = 0.1451640725, classif. loss = 0.0089128930
2025-10-09 22:57:18,456 | INFO | iter is 11150 / 50000 [skipped   98] | loc. loss = 0.1857624054, classif. loss = 0.0613128915
2025-10-09 22:57:51,248 | INFO | iter is 11200 / 50000 [skipped   98] | loc. loss = 0.1868327409, classif. loss = 0.4854612052
2025-10-09 22:58:23,993 | INFO | iter is 11250 / 50000 [skipped   98] | loc. loss = 0.2056962550, classif. loss = 0.6012678146
2025-10-09 22:58:56,821 | INFO | iter is 11300 / 50000 [skipped   98] | loc. loss = 0.1705344766, classif. loss = 0.7334378958
2025-10-09 22:59:28,991 | INFO | iter is 11350 / 50000 [skipped   99] | loc. loss = 0.2758693099, classif. loss = 0.7519807816
2025-10-09 23:00:01,127 | INFO | iter is 11400 / 50000 [skipped  100] | loc. loss = 0.2826264799, classif. loss = 1.3525744677
2025-10-09 23:00:33,286 | INFO | iter is 11450 / 50000 [skipped  101] | loc. loss = 0.1373933703, classif. loss = 0.1356928349
2025-10-09 23:01:06,075 | INFO | iter is 11500 / 50000 [skipped  101] | loc. loss = 0.1633274555, classif. loss = 0.7925474644
2025-10-09 23:01:38,804 | INFO | iter is 11550 / 50000 [skipped  101] | loc. loss = 0.2016716599, classif. loss = 0.9338612556
2025-10-09 23:02:11,615 | INFO | iter is 11600 / 50000 [skipped  101] | loc. loss = 0.1496979594, classif. loss = 1.2285660505
2025-10-09 23:02:43,781 | INFO | iter is 11650 / 50000 [skipped  102] | loc. loss = 0.1932241023, classif. loss = 0.7080471516
2025-10-09 23:03:16,561 | INFO | iter is 11700 / 50000 [skipped  102] | loc. loss = 0.1769207120, classif. loss = 1.2349076271
2025-10-09 23:03:49,409 | INFO | iter is 11750 / 50000 [skipped  102] | loc. loss = 0.1885622591, classif. loss = 0.9197117090
2025-10-09 23:04:22,211 | INFO | iter is 11800 / 50000 [skipped  102] | loc. loss = 0.1350992620, classif. loss = 0.8141018152
2025-10-09 23:04:55,080 | INFO | iter is 11850 / 50000 [skipped  102] | loc. loss = 0.2477423996, classif. loss = 0.4689348936
2025-10-09 23:05:27,850 | INFO | iter is 11900 / 50000 [skipped  102] | loc. loss = 0.2636159062, classif. loss = 1.7257215977
2025-10-09 23:06:00,203 | INFO | iter is 11950 / 50000 [skipped  103] | loc. loss = 0.1817824990, classif. loss = 0.0415364727
2025-10-09 23:06:33,065 | INFO | iter is 12000 / 50000 [skipped  103] | loc. loss = 0.1658112705, classif. loss = 0.3087961972
2025-10-09 23:07:04,840 | INFO | iter is 12050 / 50000 [skipped  105] | loc. loss = 0.2336726189, classif. loss = 0.1132252067
2025-10-09 23:07:36,536 | INFO | iter is 12100 / 50000 [skipped  107] | loc. loss = 0.1228703856, classif. loss = 0.0565921590
2025-10-09 23:08:09,365 | INFO | iter is 12150 / 50000 [skipped  107] | loc. loss = 0.2331874222, classif. loss = 1.0976406336
2025-10-09 23:08:42,314 | INFO | iter is 12200 / 50000 [skipped  107] | loc. loss = 0.2294398695, classif. loss = 1.6690289974
2025-10-09 23:09:15,198 | INFO | iter is 12250 / 50000 [skipped  107] | loc. loss = 0.1911540926, classif. loss = 1.1225287914
2025-10-09 23:09:48,156 | INFO | iter is 12300 / 50000 [skipped  107] | loc. loss = 0.1935204417, classif. loss = 0.6775277257
2025-10-09 23:10:20,971 | INFO | iter is 12350 / 50000 [skipped  107] | loc. loss = 0.1801748872, classif. loss = 0.6950784922
2025-10-09 23:10:53,874 | INFO | iter is 12400 / 50000 [skipped  107] | loc. loss = 0.2005456537, classif. loss = 0.3766992390
2025-10-09 23:11:26,732 | INFO | iter is 12450 / 50000 [skipped  107] | loc. loss = 0.1994765401, classif. loss = 1.2616057396
2025-10-09 23:11:59,054 | INFO | iter is 12500 / 50000 [skipped  108] | loc. loss = 0.3452808261, classif. loss = 1.6276533604
2025-10-09 23:11:59,056 | INFO | ---------starting evaluation-----------
2025-10-09 23:12:01,117 | INFO | validation:    0/ 933 (2025-10-09_23-12-01)
2025-10-09 23:12:47,749 | INFO | validation:  100/ 933 (2025-10-09_23-12-47)
2025-10-09 23:13:34,264 | INFO | validation:  200/ 933 (2025-10-09_23-13-34)
2025-10-09 23:14:20,767 | INFO | validation:  300/ 933 (2025-10-09_23-14-20)
2025-10-09 23:15:07,322 | INFO | validation:  400/ 933 (2025-10-09_23-15-07)
2025-10-09 23:15:53,861 | INFO | validation:  500/ 933 (2025-10-09_23-15-53)
2025-10-09 23:16:40,425 | INFO | validation:  600/ 933 (2025-10-09_23-16-40)
2025-10-09 23:17:26,972 | INFO | validation:  700/ 933 (2025-10-09_23-17-26)
2025-10-09 23:18:13,515 | INFO | validation:  800/ 933 (2025-10-09_23-18-13)
2025-10-09 23:19:00,066 | INFO | validation:  900/ 933 (2025-10-09_23-19-00)
2025-10-09 23:19:16,384 | INFO | Confusion Matrix of Localization:
[[909422321  10937528]
 [  9118333  48843226]]
2025-10-09 23:19:16,385 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98811603 0.01188397]
 [0.1573169  0.8426831 ]]
2025-10-09 23:19:16,385 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41928239  1104122   609031   217349]
 [       0  1665472  2236442   799199    40858]
 [       0   615203   448457  4300999   164271]
 [       0   135380    72529   312631  2548750]]
2025-10-09 23:19:16,385 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95598364 0.0251745  0.01388619 0.00495566]
 [0.         0.35121936 0.47162709 0.1685373  0.00861625]
 [0.         0.11126981 0.08111099 0.77790802 0.02971117]
 [0.         0.04410792 0.02363055 0.10185776 0.83040377]]
2025-10-09 23:19:16,385 | INFO | lofF1 is 82.9663, clfF1 is 72.6861, oaF1 is 75.7701, sub class F1 score is [95.0721 51.989  74.4711 84.3885]
2025-10-09 23:19:16,648 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-09_20-34-24_MambaBDA_Base_xBD_AGBD/model_step12500.pth
2025-10-09 23:19:16,649 | INFO | ---------starting train set evaluation-----------
2025-10-09 23:19:16,649 | INFO | Train buffer size: 3101.
2025-10-09 23:19:28,722 | INFO | [TrainBuf] locF1 is 83.3861, clfF1 is 63.6120, oaF1 is 69.5442, sub class F1 score is [94.0907 39.6456 66.7639 82.9768]
2025-10-09 23:20:00,634 | INFO | iter is 12550 / 50000 [skipped  109] | loc. loss = 0.2160770595, classif. loss = 0.5199287534
2025-10-09 23:20:33,067 | INFO | iter is 12600 / 50000 [skipped  109] | loc. loss = 0.1947189569, classif. loss = 0.0339305140
2025-10-09 23:21:05,576 | INFO | iter is 12650 / 50000 [skipped  109] | loc. loss = 0.2082743496, classif. loss = 0.3023776114
2025-10-09 23:21:37,525 | INFO | iter is 12700 / 50000 [skipped  110] | loc. loss = 0.1990828514, classif. loss = 1.1003825665
2025-10-09 23:22:10,075 | INFO | iter is 12750 / 50000 [skipped  110] | loc. loss = 0.2441784590, classif. loss = 0.3436192870
2025-10-09 23:22:42,555 | INFO | iter is 12800 / 50000 [skipped  110] | loc. loss = 0.1943987757, classif. loss = 0.9216661453
2025-10-09 23:23:15,147 | INFO | iter is 12850 / 50000 [skipped  110] | loc. loss = 0.2116245925, classif. loss = 0.3597324789
2025-10-09 23:23:47,731 | INFO | iter is 12900 / 50000 [skipped  110] | loc. loss = 0.2415899932, classif. loss = 1.0011891127
2025-10-09 23:24:20,245 | INFO | iter is 12950 / 50000 [skipped  110] | loc. loss = 0.1022768170, classif. loss = 0.5174763799
2025-10-09 23:24:52,777 | INFO | iter is 13000 / 50000 [skipped  110] | loc. loss = 0.2715689242, classif. loss = 1.4315770864
2025-10-09 23:25:25,329 | INFO | iter is 13050 / 50000 [skipped  110] | loc. loss = 0.2145293057, classif. loss = 0.0948209018
2025-10-09 23:25:57,918 | INFO | iter is 13100 / 50000 [skipped  110] | loc. loss = 0.2256469727, classif. loss = 0.5929723382
2025-10-09 23:26:30,558 | INFO | iter is 13150 / 50000 [skipped  110] | loc. loss = 0.1728884876, classif. loss = 0.7406936884
2025-10-09 23:27:03,171 | INFO | iter is 13200 / 50000 [skipped  110] | loc. loss = 0.1050881147, classif. loss = 0.5306670666
2025-10-09 23:27:35,854 | INFO | iter is 13250 / 50000 [skipped  110] | loc. loss = 0.1441782862, classif. loss = 0.2921872437
2025-10-09 23:28:08,480 | INFO | iter is 13300 / 50000 [skipped  110] | loc. loss = 0.2172110379, classif. loss = 1.4359745979
2025-10-09 23:28:41,170 | INFO | iter is 13350 / 50000 [skipped  110] | loc. loss = 0.2379080653, classif. loss = 0.8774470091
2025-10-09 23:29:13,814 | INFO | iter is 13400 / 50000 [skipped  110] | loc. loss = 0.2461622357, classif. loss = 0.4782322049
2025-10-09 23:29:45,896 | INFO | iter is 13450 / 50000 [skipped  111] | loc. loss = 0.1588381082, classif. loss = 0.4399477541
2025-10-09 23:30:17,972 | INFO | iter is 13500 / 50000 [skipped  112] | loc. loss = 0.4151123762, classif. loss = 1.1113984585
2025-10-09 23:30:50,074 | INFO | iter is 13550 / 50000 [skipped  113] | loc. loss = 0.1995044947, classif. loss = 0.0100721344
2025-10-09 23:31:22,833 | INFO | iter is 13600 / 50000 [skipped  113] | loc. loss = 0.1882943511, classif. loss = 0.8932012320
2025-10-09 23:31:54,908 | INFO | iter is 13650 / 50000 [skipped  114] | loc. loss = 0.1932584345, classif. loss = 0.7622265816
2025-10-09 23:32:27,619 | INFO | iter is 13700 / 50000 [skipped  114] | loc. loss = 0.1396451890, classif. loss = 0.2021791339
2025-10-09 23:33:00,247 | INFO | iter is 13750 / 50000 [skipped  114] | loc. loss = 0.2315463275, classif. loss = 1.0971808434
2025-10-09 23:33:32,942 | INFO | iter is 13800 / 50000 [skipped  114] | loc. loss = 0.2395630479, classif. loss = 1.2842710018
2025-10-09 23:34:05,685 | INFO | iter is 13850 / 50000 [skipped  114] | loc. loss = 0.2315977365, classif. loss = 0.7183663249
2025-10-09 23:34:37,837 | INFO | iter is 13900 / 50000 [skipped  115] | loc. loss = 0.2797793448, classif. loss = 0.8420950174
2025-10-09 23:35:10,061 | INFO | iter is 13950 / 50000 [skipped  116] | loc. loss = 0.1590247601, classif. loss = 1.3910641670
2025-10-09 23:35:42,764 | INFO | iter is 14000 / 50000 [skipped  116] | loc. loss = 0.2884858847, classif. loss = 0.4119946659
2025-10-09 23:36:14,311 | INFO | iter is 14050 / 50000 [skipped  118] | loc. loss = 0.1143330112, classif. loss = 1.5773341656
2025-10-09 23:36:47,119 | INFO | iter is 14100 / 50000 [skipped  118] | loc. loss = 0.2084959447, classif. loss = 1.2380664349
2025-10-09 23:37:19,994 | INFO | iter is 14150 / 50000 [skipped  118] | loc. loss = 0.1893407851, classif. loss = 0.3403105736
2025-10-09 23:37:52,750 | INFO | iter is 14200 / 50000 [skipped  118] | loc. loss = 0.2089763582, classif. loss = 0.7245953679
2025-10-09 23:38:24,910 | INFO | iter is 14250 / 50000 [skipped  119] | loc. loss = 0.1115394384, classif. loss = 0.3661600053
2025-10-09 23:38:56,584 | INFO | iter is 14300 / 50000 [skipped  121] | loc. loss = 0.2156104296, classif. loss = 1.1250976324
2025-10-09 23:39:29,360 | INFO | iter is 14350 / 50000 [skipped  121] | loc. loss = 0.2616047263, classif. loss = 0.7715076208
2025-10-09 23:40:02,182 | INFO | iter is 14400 / 50000 [skipped  121] | loc. loss = 0.1404202878, classif. loss = 1.1093873978
2025-10-09 23:40:33,766 | INFO | iter is 14450 / 50000 [skipped  123] | loc. loss = 0.2922466099, classif. loss = 2.1052598953
2025-10-09 23:41:05,941 | INFO | iter is 14500 / 50000 [skipped  124] | loc. loss = 0.1623930484, classif. loss = 1.4774401188
2025-10-09 23:41:38,133 | INFO | iter is 14550 / 50000 [skipped  125] | loc. loss = 0.2634045184, classif. loss = 0.8146814704
2025-10-09 23:42:10,885 | INFO | iter is 14600 / 50000 [skipped  125] | loc. loss = 0.1836357713, classif. loss = 0.1492234915
2025-10-09 23:42:43,729 | INFO | iter is 14650 / 50000 [skipped  125] | loc. loss = 0.1340838969, classif. loss = 0.8501071930
2025-10-09 23:43:16,471 | INFO | iter is 14700 / 50000 [skipped  125] | loc. loss = 0.2686344087, classif. loss = 0.3432687819
2025-10-09 23:43:48,709 | INFO | iter is 14750 / 50000 [skipped  126] | loc. loss = 0.2214872092, classif. loss = 0.3132314384
2025-10-09 23:44:21,506 | INFO | iter is 14800 / 50000 [skipped  126] | loc. loss = 0.1351433545, classif. loss = 0.9706208706
2025-10-09 23:44:54,330 | INFO | iter is 14850 / 50000 [skipped  126] | loc. loss = 0.2039694339, classif. loss = 0.8712689281
2025-10-09 23:45:26,549 | INFO | iter is 14900 / 50000 [skipped  127] | loc. loss = 0.1959955990, classif. loss = 0.4488341510
2025-10-09 23:45:59,367 | INFO | iter is 14950 / 50000 [skipped  127] | loc. loss = 0.1814788878, classif. loss = 0.0479033217
2025-10-09 23:46:32,195 | INFO | iter is 15000 / 50000 [skipped  127] | loc. loss = 0.1940091848, classif. loss = 0.4192488790
2025-10-09 23:47:05,181 | INFO | iter is 15050 / 50000 [skipped  127] | loc. loss = 0.2498691976, classif. loss = 0.0919477344
2025-10-09 23:47:38,014 | INFO | iter is 15100 / 50000 [skipped  127] | loc. loss = 0.2746811807, classif. loss = 0.4145867229
2025-10-09 23:48:10,835 | INFO | iter is 15150 / 50000 [skipped  127] | loc. loss = 0.2147818804, classif. loss = 1.0230374336
2025-10-09 23:48:43,102 | INFO | iter is 15200 / 50000 [skipped  128] | loc. loss = 0.3128851056, classif. loss = 1.5990881920
2025-10-09 23:49:15,341 | INFO | iter is 15250 / 50000 [skipped  129] | loc. loss = 0.1862517148, classif. loss = 0.3123232126
2025-10-09 23:49:48,225 | INFO | iter is 15300 / 50000 [skipped  129] | loc. loss = 0.2834939957, classif. loss = 0.5863021016
2025-10-09 23:50:19,849 | INFO | iter is 15350 / 50000 [skipped  131] | loc. loss = 0.1576652527, classif. loss = 0.4914654195
2025-10-09 23:50:52,806 | INFO | iter is 15400 / 50000 [skipped  131] | loc. loss = 0.1018069610, classif. loss = 0.6111249924
2025-10-09 23:51:58,004 | INFO | iter is 15500 / 50000 [skipped  132] | loc. loss = 0.1382687390, classif. loss = 0.5336476564
2025-10-09 23:52:30,903 | INFO | iter is 15550 / 50000 [skipped  132] | loc. loss = 0.1030020863, classif. loss = 3.0433757305
2025-10-09 23:53:03,229 | INFO | iter is 15600 / 50000 [skipped  133] | loc. loss = 0.1513789594, classif. loss = 0.1098015457
2025-10-09 23:53:19,659 | INFO | ---------starting evaluation-----------
2025-10-09 23:53:21,719 | INFO | validation:    0/ 933 (2025-10-09_23-53-21)
2025-10-09 23:54:08,366 | INFO | validation:  100/ 933 (2025-10-09_23-54-08)
2025-10-09 23:54:54,880 | INFO | validation:  200/ 933 (2025-10-09_23-54-54)
2025-10-09 23:55:41,373 | INFO | validation:  300/ 933 (2025-10-09_23-55-41)
2025-10-09 23:56:27,887 | INFO | validation:  400/ 933 (2025-10-09_23-56-27)
2025-10-09 23:57:14,387 | INFO | validation:  500/ 933 (2025-10-09_23-57-14)
2025-10-09 23:58:00,899 | INFO | validation:  600/ 933 (2025-10-09_23-58-00)
2025-10-09 23:58:47,429 | INFO | validation:  700/ 933 (2025-10-09_23-58-47)
2025-10-09 23:59:33,945 | INFO | validation:  800/ 933 (2025-10-09_23-59-33)
2025-10-10 00:00:20,478 | INFO | validation:  900/ 933 (2025-10-10_00-00-20)
2025-10-10 00:00:36,508 | INFO | Confusion Matrix of Localization:
[[903903748  16456101]
 [  6326613  51634946]]
2025-10-10 00:00:36,508 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98211993 0.01788007]
 [0.10915188 0.89084812]]
2025-10-10 00:00:36,508 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 39984098  2714520  1036831   123292]
 [       0   998945  2532092  1195128    15806]
 [       0   494555   641740  4272103   120532]
 [       0    94902    90465   378165  2505758]]
2025-10-10 00:00:36,508 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.91165631 0.06189234 0.02364024 0.00281112]
 [0.         0.21066029 0.53397459 0.25203191 0.00333321]
 [0.         0.08944859 0.11606947 0.77268169 0.02180024]
 [0.         0.03091985 0.02947424 0.12320928 0.81639663]]
2025-10-10 00:00:36,509 | INFO | lofF1 is 81.9260, clfF1 is 68.9402, oaF1 is 72.8359, sub class F1 score is [93.6053 47.237  68.8429 85.8919]
2025-10-10 00:00:36,511 | INFO | ---------starting train set evaluation-----------
2025-10-10 00:00:36,511 | INFO | Train buffer size: 3100.
2025-10-10 00:00:48,577 | INFO | [TrainBuf] locF1 is 83.9845, clfF1 is 65.3844, oaF1 is 70.9644, sub class F1 score is [94.5335 41.9888 67.7044 83.2471]
2025-10-10 00:01:04,868 | INFO | iter is 15650 / 50000 [skipped  133] | loc. loss = 0.1725350171, classif. loss = 0.1480134130
2025-10-10 00:01:36,852 | INFO | iter is 15700 / 50000 [skipped  134] | loc. loss = 0.1205752715, classif. loss = 0.5844591856
2025-10-10 00:02:08,809 | INFO | iter is 15750 / 50000 [skipped  135] | loc. loss = 0.2214940786, classif. loss = 1.0639486313
2025-10-10 00:02:41,467 | INFO | iter is 15800 / 50000 [skipped  135] | loc. loss = 0.2884483337, classif. loss = 0.8575373888
2025-10-10 00:03:13,423 | INFO | iter is 15850 / 50000 [skipped  136] | loc. loss = 0.1431881636, classif. loss = 0.6874506474
2025-10-10 00:03:45,454 | INFO | iter is 15900 / 50000 [skipped  137] | loc. loss = 0.2429686040, classif. loss = 0.0057616001
2025-10-10 00:04:18,115 | INFO | iter is 15950 / 50000 [skipped  137] | loc. loss = 0.2372048199, classif. loss = 1.1265799999
2025-10-10 00:04:50,698 | INFO | iter is 16000 / 50000 [skipped  137] | loc. loss = 0.1867758334, classif. loss = 0.0592606887
2025-10-10 00:05:22,049 | INFO | iter is 16050 / 50000 [skipped  139] | loc. loss = 0.2768849432, classif. loss = 0.3777241707
2025-10-10 00:05:54,646 | INFO | iter is 16100 / 50000 [skipped  139] | loc. loss = 0.2515030503, classif. loss = 0.6712779999
2025-10-10 00:06:26,671 | INFO | iter is 16150 / 50000 [skipped  140] | loc. loss = 0.2343877554, classif. loss = 0.9950715303
2025-10-10 00:06:59,221 | INFO | iter is 16200 / 50000 [skipped  140] | loc. loss = 0.1690482199, classif. loss = 0.3617216349
2025-10-10 00:07:31,825 | INFO | iter is 16250 / 50000 [skipped  140] | loc. loss = 0.2050471902, classif. loss = 0.1124502569
2025-10-10 00:08:04,427 | INFO | iter is 16300 / 50000 [skipped  140] | loc. loss = 0.2918477952, classif. loss = 0.0974552333
2025-10-10 00:08:36,997 | INFO | iter is 16350 / 50000 [skipped  140] | loc. loss = 0.0942149013, classif. loss = 1.7456279993
2025-10-10 00:09:09,137 | INFO | iter is 16400 / 50000 [skipped  141] | loc. loss = 0.1846095771, classif. loss = 0.3379445970
2025-10-10 00:09:41,127 | INFO | iter is 16450 / 50000 [skipped  142] | loc. loss = 0.2445644587, classif. loss = 1.6851007938
2025-10-10 00:10:13,742 | INFO | iter is 16500 / 50000 [skipped  142] | loc. loss = 0.2403813154, classif. loss = 0.3330372274
2025-10-10 00:10:46,262 | INFO | iter is 16550 / 50000 [skipped  142] | loc. loss = 0.1745971441, classif. loss = 0.1256506741
2025-10-10 00:11:18,865 | INFO | iter is 16600 / 50000 [skipped  142] | loc. loss = 0.1668257862, classif. loss = 0.3885688186
2025-10-10 00:11:51,515 | INFO | iter is 16650 / 50000 [skipped  142] | loc. loss = 0.2925207615, classif. loss = 0.3354777098
2025-10-10 00:12:24,025 | INFO | iter is 16700 / 50000 [skipped  142] | loc. loss = 0.2015320361, classif. loss = 0.3556768298
2025-10-10 00:12:56,163 | INFO | iter is 16750 / 50000 [skipped  143] | loc. loss = 0.2548748553, classif. loss = 0.2100873291
2025-10-10 00:13:28,107 | INFO | iter is 16800 / 50000 [skipped  144] | loc. loss = 0.3291119039, classif. loss = 0.3768616319
2025-10-10 00:13:59,562 | INFO | iter is 16850 / 50000 [skipped  146] | loc. loss = 0.1390003860, classif. loss = 1.1556429863
2025-10-10 00:14:32,155 | INFO | iter is 16900 / 50000 [skipped  146] | loc. loss = 0.2941224575, classif. loss = 0.4064956605
2025-10-10 00:15:04,829 | INFO | iter is 16950 / 50000 [skipped  146] | loc. loss = 0.2005700767, classif. loss = 2.7162213326
2025-10-10 00:15:36,925 | INFO | iter is 17000 / 50000 [skipped  147] | loc. loss = 0.2020021677, classif. loss = 0.4494693279
2025-10-10 00:16:09,581 | INFO | iter is 17050 / 50000 [skipped  147] | loc. loss = 0.1771371514, classif. loss = 0.1963367313
2025-10-10 00:16:41,723 | INFO | iter is 17100 / 50000 [skipped  148] | loc. loss = 0.2977600098, classif. loss = 0.6836082935
2025-10-10 00:17:14,412 | INFO | iter is 17150 / 50000 [skipped  148] | loc. loss = 0.1315871626, classif. loss = 1.5620266199
2025-10-10 00:17:47,137 | INFO | iter is 17200 / 50000 [skipped  148] | loc. loss = 0.2868919075, classif. loss = 0.8447225094
2025-10-10 00:18:19,136 | INFO | iter is 17250 / 50000 [skipped  149] | loc. loss = 0.1516271681, classif. loss = 1.7746046782
2025-10-10 00:18:51,844 | INFO | iter is 17300 / 50000 [skipped  149] | loc. loss = 0.2052634060, classif. loss = 0.1736882329
2025-10-10 00:19:24,550 | INFO | iter is 17350 / 50000 [skipped  149] | loc. loss = 0.2135016322, classif. loss = 1.2617498636
2025-10-10 00:19:56,565 | INFO | iter is 17400 / 50000 [skipped  150] | loc. loss = 0.2174752057, classif. loss = 0.5918099880
2025-10-10 00:20:29,296 | INFO | iter is 17450 / 50000 [skipped  150] | loc. loss = 0.2462533265, classif. loss = 0.4265522361
2025-10-10 00:21:00,790 | INFO | iter is 17500 / 50000 [skipped  152] | loc. loss = 0.1133466065, classif. loss = 1.8016567230
2025-10-10 00:21:32,955 | INFO | iter is 17550 / 50000 [skipped  153] | loc. loss = 0.2722862363, classif. loss = 0.8663965464
2025-10-10 00:22:05,068 | INFO | iter is 17600 / 50000 [skipped  154] | loc. loss = 0.2538947463, classif. loss = 0.8905900717
2025-10-10 00:22:37,782 | INFO | iter is 17650 / 50000 [skipped  154] | loc. loss = 0.1738066971, classif. loss = 0.0142379692
2025-10-10 00:23:10,575 | INFO | iter is 17700 / 50000 [skipped  154] | loc. loss = 0.2746356726, classif. loss = 0.4564040303
2025-10-10 00:23:42,747 | INFO | iter is 17750 / 50000 [skipped  155] | loc. loss = 0.2049132138, classif. loss = 0.6651784778
2025-10-10 00:24:15,522 | INFO | iter is 17800 / 50000 [skipped  155] | loc. loss = 0.2121451944, classif. loss = 0.6798488498
2025-10-10 00:24:47,693 | INFO | iter is 17850 / 50000 [skipped  156] | loc. loss = 0.2128907144, classif. loss = 1.9890389442
2025-10-10 00:25:19,901 | INFO | iter is 17900 / 50000 [skipped  157] | loc. loss = 0.2751616538, classif. loss = 0.0661251247
2025-10-10 00:25:52,021 | INFO | iter is 17950 / 50000 [skipped  158] | loc. loss = 0.1720916778, classif. loss = 0.6300008297
2025-10-10 00:26:24,803 | INFO | iter is 18000 / 50000 [skipped  158] | loc. loss = 0.1178150848, classif. loss = 0.4947481453
2025-10-10 00:26:57,537 | INFO | iter is 18050 / 50000 [skipped  158] | loc. loss = 0.2358652949, classif. loss = 0.4416781366
2025-10-10 00:27:30,316 | INFO | iter is 18100 / 50000 [skipped  158] | loc. loss = 0.1886591613, classif. loss = 0.7539044023
2025-10-10 00:28:03,159 | INFO | iter is 18150 / 50000 [skipped  158] | loc. loss = 0.1026131213, classif. loss = 0.0392365009
2025-10-10 00:28:35,290 | INFO | iter is 18200 / 50000 [skipped  159] | loc. loss = 0.1224129722, classif. loss = 0.1426867396
2025-10-10 00:29:07,579 | INFO | iter is 18250 / 50000 [skipped  160] | loc. loss = 0.2497512400, classif. loss = 0.0128237605
2025-10-10 00:29:40,371 | INFO | iter is 18300 / 50000 [skipped  160] | loc. loss = 0.1943442225, classif. loss = 0.4327698052
2025-10-10 00:30:13,214 | INFO | iter is 18350 / 50000 [skipped  160] | loc. loss = 0.2836186588, classif. loss = 1.0003168583
2025-10-10 00:30:46,051 | INFO | iter is 18400 / 50000 [skipped  160] | loc. loss = 0.1966334283, classif. loss = 0.4952661395
2025-10-10 00:31:18,886 | INFO | iter is 18450 / 50000 [skipped  160] | loc. loss = 0.1561884582, classif. loss = 0.0560282022
2025-10-10 00:31:51,677 | INFO | iter is 18500 / 50000 [skipped  160] | loc. loss = 0.1997312009, classif. loss = 0.6692001224
2025-10-10 00:32:24,558 | INFO | iter is 18550 / 50000 [skipped  160] | loc. loss = 0.1924442798, classif. loss = 0.7568339705
2025-10-10 00:32:57,422 | INFO | iter is 18600 / 50000 [skipped  160] | loc. loss = 0.2075358182, classif. loss = 0.1544755101
2025-10-10 00:33:29,676 | INFO | iter is 18650 / 50000 [skipped  161] | loc. loss = 0.3246079385, classif. loss = 0.5992145538
2025-10-10 00:34:01,973 | INFO | iter is 18700 / 50000 [skipped  162] | loc. loss = 0.1512033939, classif. loss = 1.0715339184
2025-10-10 00:34:34,118 | INFO | iter is 18750 / 50000 [skipped  163] | loc. loss = 0.2624723911, classif. loss = 0.5887297392
2025-10-10 00:34:34,120 | INFO | ---------starting evaluation-----------
2025-10-10 00:34:36,211 | INFO | validation:    0/ 933 (2025-10-10_00-34-36)
2025-10-10 00:35:22,512 | INFO | validation:  100/ 933 (2025-10-10_00-35-22)
2025-10-10 00:36:08,731 | INFO | validation:  200/ 933 (2025-10-10_00-36-08)
2025-10-10 00:36:54,950 | INFO | validation:  300/ 933 (2025-10-10_00-36-54)
2025-10-10 00:37:41,190 | INFO | validation:  400/ 933 (2025-10-10_00-37-41)
2025-10-10 00:38:27,410 | INFO | validation:  500/ 933 (2025-10-10_00-38-27)
2025-10-10 00:39:13,650 | INFO | validation:  600/ 933 (2025-10-10_00-39-13)
2025-10-10 00:39:59,876 | INFO | validation:  700/ 933 (2025-10-10_00-39-59)
2025-10-10 00:40:46,116 | INFO | validation:  800/ 933 (2025-10-10_00-40-46)
2025-10-10 00:41:32,359 | INFO | validation:  900/ 933 (2025-10-10_00-41-32)
2025-10-10 00:41:48,322 | INFO | Confusion Matrix of Localization:
[[910601539   9758310]
 [  8945487  49016072]]
2025-10-10 00:41:48,322 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98939729 0.01060271]
 [0.15433482 0.84566518]]
2025-10-10 00:41:48,322 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40586643  1930476  1267454    74168]
 [       0  1056600  2754722   904339    26310]
 [       0   457779   713818  4276260    81073]
 [       0   192815    79602   365689  2431184]]
2025-10-10 00:41:48,322 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.92539462 0.04401576 0.02889855 0.00169107]
 [0.         0.22281874 0.58092342 0.19070952 0.00554833]
 [0.         0.08279703 0.12910599 0.77343356 0.01466342]
 [0.         0.06282072 0.02593499 0.11914449 0.7920998 ]]
2025-10-10 00:41:48,323 | INFO | lofF1 is 83.9777, clfF1 is 72.3566, oaF1 is 75.8429, sub class F1 score is [94.2204 53.9053 69.2923 85.5746]
2025-10-10 00:41:48,583 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-09_20-34-24_MambaBDA_Base_xBD_AGBD/model_step18750.pth
2025-10-10 00:41:48,583 | INFO | ---------starting train set evaluation-----------
2025-10-10 00:41:48,583 | INFO | Train buffer size: 3095.
2025-10-10 00:42:00,590 | INFO | [TrainBuf] locF1 is 84.1434, clfF1 is 67.0849, oaF1 is 72.2025, sub class F1 score is [95.0446 43.2444 70.4317 84.875 ]
2025-10-10 00:42:33,083 | INFO | iter is 18800 / 50000 [skipped  163] | loc. loss = 0.2391596884, classif. loss = 0.9047445059
2025-10-10 00:43:04,927 | INFO | iter is 18850 / 50000 [skipped  164] | loc. loss = 0.1501836926, classif. loss = 0.4772649705
2025-10-10 00:43:37,429 | INFO | iter is 18900 / 50000 [skipped  164] | loc. loss = 0.0903163403, classif. loss = 0.3926989138
2025-10-10 00:44:09,886 | INFO | iter is 18950 / 50000 [skipped  164] | loc. loss = 0.2373853922, classif. loss = 0.8147304654
2025-10-10 00:44:42,355 | INFO | iter is 19000 / 50000 [skipped  164] | loc. loss = 0.1806148738, classif. loss = 0.8506841660
2025-10-10 00:45:14,915 | INFO | iter is 19050 / 50000 [skipped  164] | loc. loss = 0.2382098734, classif. loss = 0.6147463322
2025-10-10 00:45:47,481 | INFO | iter is 19100 / 50000 [skipped  164] | loc. loss = 0.2957741022, classif. loss = 0.1292437613
2025-10-10 00:46:20,101 | INFO | iter is 19150 / 50000 [skipped  164] | loc. loss = 0.1908102036, classif. loss = 0.0545430444
2025-10-10 00:46:52,651 | INFO | iter is 19200 / 50000 [skipped  164] | loc. loss = 0.2292529196, classif. loss = 1.0984075069
2025-10-10 00:47:25,249 | INFO | iter is 19250 / 50000 [skipped  164] | loc. loss = 0.2527850270, classif. loss = 0.3205822408
2025-10-10 00:47:57,201 | INFO | iter is 19300 / 50000 [skipped  165] | loc. loss = 0.2327487767, classif. loss = 0.3628352880
2025-10-10 00:48:29,859 | INFO | iter is 19350 / 50000 [skipped  165] | loc. loss = 0.1485910565, classif. loss = 0.0444153920
2025-10-10 00:49:02,426 | INFO | iter is 19400 / 50000 [skipped  165] | loc. loss = 0.1156064123, classif. loss = 1.2029455900
2025-10-10 00:49:35,006 | INFO | iter is 19450 / 50000 [skipped  165] | loc. loss = 0.1867789328, classif. loss = 0.0223006792
2025-10-10 00:50:07,675 | INFO | iter is 19500 / 50000 [skipped  165] | loc. loss = 0.1647119075, classif. loss = 0.3699214458
2025-10-10 00:50:40,185 | INFO | iter is 19550 / 50000 [skipped  165] | loc. loss = 0.2830047607, classif. loss = 0.0903212801
2025-10-10 00:51:12,873 | INFO | iter is 19600 / 50000 [skipped  165] | loc. loss = 0.1625631452, classif. loss = 1.2089731693
2025-10-10 00:51:44,905 | INFO | iter is 19650 / 50000 [skipped  166] | loc. loss = 0.2061867267, classif. loss = 0.0783132166
2025-10-10 00:52:17,580 | INFO | iter is 19700 / 50000 [skipped  166] | loc. loss = 0.2260276377, classif. loss = 1.1392083168
2025-10-10 00:52:49,634 | INFO | iter is 19750 / 50000 [skipped  167] | loc. loss = 0.3131375909, classif. loss = 0.7085516453
2025-10-10 00:53:22,272 | INFO | iter is 19800 / 50000 [skipped  167] | loc. loss = 0.1677679420, classif. loss = 0.7664176226
2025-10-10 00:53:53,813 | INFO | iter is 19850 / 50000 [skipped  169] | loc. loss = 0.1340698898, classif. loss = 1.2899792194
2025-10-10 00:54:26,492 | INFO | iter is 19900 / 50000 [skipped  169] | loc. loss = 0.2064027935, classif. loss = 0.2074163407
2025-10-10 00:54:58,608 | INFO | iter is 19950 / 50000 [skipped  170] | loc. loss = 0.2352564782, classif. loss = 0.0371065848
2025-10-10 00:55:31,250 | INFO | iter is 20000 / 50000 [skipped  170] | loc. loss = 0.2618810833, classif. loss = 0.1025730744
2025-10-10 00:56:03,992 | INFO | iter is 20050 / 50000 [skipped  170] | loc. loss = 0.2424075902, classif. loss = 0.8622879982
2025-10-10 00:56:36,109 | INFO | iter is 20100 / 50000 [skipped  171] | loc. loss = 0.2499684840, classif. loss = 0.0524382815
2025-10-10 00:57:08,836 | INFO | iter is 20150 / 50000 [skipped  171] | loc. loss = 0.1970797926, classif. loss = 0.5579673052
2025-10-10 00:57:40,962 | INFO | iter is 20200 / 50000 [skipped  172] | loc. loss = 0.2357724309, classif. loss = 0.1380199492
2025-10-10 00:58:13,659 | INFO | iter is 20250 / 50000 [skipped  172] | loc. loss = 0.1652171761, classif. loss = 0.3042483926
2025-10-10 00:58:46,439 | INFO | iter is 20300 / 50000 [skipped  172] | loc. loss = 0.2620247602, classif. loss = 0.7552337646
2025-10-10 00:59:18,541 | INFO | iter is 20350 / 50000 [skipped  173] | loc. loss = 0.2543799877, classif. loss = 0.3034783006
2025-10-10 00:59:51,373 | INFO | iter is 20400 / 50000 [skipped  173] | loc. loss = 0.2043631822, classif. loss = 0.0123880394
2025-10-10 01:00:24,044 | INFO | iter is 20450 / 50000 [skipped  173] | loc. loss = 0.2763212323, classif. loss = 0.6789573431
2025-10-10 01:00:56,833 | INFO | iter is 20500 / 50000 [skipped  173] | loc. loss = 0.2925455272, classif. loss = 0.4061098099
2025-10-10 01:01:29,589 | INFO | iter is 20550 / 50000 [skipped  173] | loc. loss = 0.2758277655, classif. loss = 0.0298174210
2025-10-10 01:02:02,297 | INFO | iter is 20600 / 50000 [skipped  173] | loc. loss = 0.1572793424, classif. loss = 0.0045641041
2025-10-10 01:02:34,558 | INFO | iter is 20650 / 50000 [skipped  174] | loc. loss = 0.2371242940, classif. loss = 0.2409115136
2025-10-10 01:03:06,754 | INFO | iter is 20700 / 50000 [skipped  175] | loc. loss = 0.2084847093, classif. loss = 0.4814371765
2025-10-10 01:03:39,518 | INFO | iter is 20750 / 50000 [skipped  175] | loc. loss = 0.3245188892, classif. loss = 1.0580766201
2025-10-10 01:04:12,288 | INFO | iter is 20800 / 50000 [skipped  175] | loc. loss = 0.1690196246, classif. loss = 1.7183830738
2025-10-10 01:04:45,123 | INFO | iter is 20850 / 50000 [skipped  175] | loc. loss = 0.2966771722, classif. loss = 0.0540534630
2025-10-10 01:05:17,312 | INFO | iter is 20900 / 50000 [skipped  176] | loc. loss = 0.2970829308, classif. loss = 0.4869322181
2025-10-10 01:05:50,129 | INFO | iter is 20950 / 50000 [skipped  176] | loc. loss = 0.2176336795, classif. loss = 0.8433950543
2025-10-10 01:06:55,227 | INFO | iter is 21050 / 50000 [skipped  177] | loc. loss = 0.2581800818, classif. loss = 1.3950769901
2025-10-10 01:07:28,092 | INFO | iter is 21100 / 50000 [skipped  177] | loc. loss = 0.2230319083, classif. loss = 1.2682230473
2025-10-10 01:08:00,861 | INFO | iter is 21150 / 50000 [skipped  177] | loc. loss = 0.0845245793, classif. loss = 0.4820667207
2025-10-10 01:08:33,766 | INFO | iter is 21200 / 50000 [skipped  177] | loc. loss = 0.2127546966, classif. loss = 0.8256995678
2025-10-10 01:09:05,987 | INFO | iter is 21250 / 50000 [skipped  178] | loc. loss = 0.1454468518, classif. loss = 0.8173086643
2025-10-10 01:09:38,942 | INFO | iter is 21300 / 50000 [skipped  178] | loc. loss = 0.1577078849, classif. loss = 0.0677040741
2025-10-10 01:10:11,189 | INFO | iter is 21350 / 50000 [skipped  179] | loc. loss = 0.2223796397, classif. loss = 0.3573396206
2025-10-10 01:10:43,485 | INFO | iter is 21400 / 50000 [skipped  180] | loc. loss = 0.2065511793, classif. loss = 0.5801012516
2025-10-10 01:11:15,234 | INFO | iter is 21450 / 50000 [skipped  182] | loc. loss = 0.1672577411, classif. loss = 0.7093057632
2025-10-10 01:11:46,825 | INFO | iter is 21500 / 50000 [skipped  184] | loc. loss = 0.2402786613, classif. loss = 1.3775823116
2025-10-10 01:12:19,117 | INFO | iter is 21550 / 50000 [skipped  185] | loc. loss = 0.1454685032, classif. loss = 0.4684534669
2025-10-10 01:12:51,997 | INFO | iter is 21600 / 50000 [skipped  185] | loc. loss = 0.3054181039, classif. loss = 1.4734385014
2025-10-10 01:13:24,918 | INFO | iter is 21650 / 50000 [skipped  185] | loc. loss = 0.2486440688, classif. loss = 0.1240675896
2025-10-10 01:13:57,790 | INFO | iter is 21700 / 50000 [skipped  185] | loc. loss = 0.2045951188, classif. loss = 1.8198063374
2025-10-10 01:14:30,728 | INFO | iter is 21750 / 50000 [skipped  185] | loc. loss = 0.1021398008, classif. loss = 0.0361762531
2025-10-10 01:15:03,570 | INFO | iter is 21800 / 50000 [skipped  185] | loc. loss = 0.2187348902, classif. loss = 0.6495960951
2025-10-10 01:15:34,669 | INFO | iter is 21850 / 50000 [skipped  188] | loc. loss = 0.2652181685, classif. loss = 0.1630121171
2025-10-10 01:15:51,125 | INFO | ---------starting evaluation-----------
2025-10-10 01:15:53,243 | INFO | validation:    0/ 933 (2025-10-10_01-15-53)
2025-10-10 01:16:39,759 | INFO | validation:  100/ 933 (2025-10-10_01-16-39)
2025-10-10 01:17:26,242 | INFO | validation:  200/ 933 (2025-10-10_01-17-26)
2025-10-10 01:18:12,698 | INFO | validation:  300/ 933 (2025-10-10_01-18-12)
2025-10-10 01:18:59,139 | INFO | validation:  400/ 933 (2025-10-10_01-18-59)
2025-10-10 01:19:45,582 | INFO | validation:  500/ 933 (2025-10-10_01-19-45)
2025-10-10 01:20:32,019 | INFO | validation:  600/ 933 (2025-10-10_01-20-32)
2025-10-10 01:21:18,468 | INFO | validation:  700/ 933 (2025-10-10_01-21-18)
2025-10-10 01:22:04,929 | INFO | validation:  800/ 933 (2025-10-10_01-22-04)
2025-10-10 01:22:51,373 | INFO | validation:  900/ 933 (2025-10-10_01-22-51)
2025-10-10 01:23:07,435 | INFO | Confusion Matrix of Localization:
[[911670784   8689065]
 [  9611668  48349891]]
2025-10-10 01:23:07,435 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99055906 0.00944094]
 [0.16582832 0.83417168]]
2025-10-10 01:23:07,436 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42830000   379373   584164    65204]
 [       0  2614570  1278097   763158    86146]
 [       0   887285   336641  4161786   143218]
 [       0   227912    15414   318290  2507674]]
2025-10-10 01:23:07,436 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.97654422 0.00864988 0.01331921 0.00148668]
 [0.         0.55136778 0.26952864 0.16093688 0.01816671]
 [0.         0.16048042 0.06088719 0.75272901 0.02590338]
 [0.         0.07425561 0.00502201 0.10370151 0.81702087]]
2025-10-10 01:23:07,436 | INFO | lofF1 is 84.0864, clfF1 is 64.1864, oaF1 is 70.1564, sub class F1 score is [94.7372 37.8611 73.2946 85.418 ]
2025-10-10 01:23:07,437 | INFO | ---------starting train set evaluation-----------
2025-10-10 01:23:07,437 | INFO | Train buffer size: 3100.
2025-10-10 01:23:19,405 | INFO | [TrainBuf] locF1 is 84.5748, clfF1 is 69.2186, oaF1 is 73.8255, sub class F1 score is [94.7563 46.9348 69.6147 86.4784]
2025-10-10 01:23:35,660 | INFO | iter is 21900 / 50000 [skipped  188] | loc. loss = 0.1440717578, classif. loss = 1.0152535439
2025-10-10 01:24:08,181 | INFO | iter is 21950 / 50000 [skipped  188] | loc. loss = 0.1388858408, classif. loss = 0.3769909143
2025-10-10 01:24:40,061 | INFO | iter is 22000 / 50000 [skipped  189] | loc. loss = 0.2759208083, classif. loss = 0.4558720291
2025-10-10 01:25:12,067 | INFO | iter is 22050 / 50000 [skipped  190] | loc. loss = 0.1467633396, classif. loss = 0.1320751458
2025-10-10 01:25:43,955 | INFO | iter is 22100 / 50000 [skipped  191] | loc. loss = 0.3028461933, classif. loss = 0.5365820527
2025-10-10 01:26:16,500 | INFO | iter is 22150 / 50000 [skipped  191] | loc. loss = 0.1601549536, classif. loss = 0.3857066631
2025-10-10 01:26:48,985 | INFO | iter is 22200 / 50000 [skipped  191] | loc. loss = 0.2445121408, classif. loss = 0.7568054199
2025-10-10 01:27:21,563 | INFO | iter is 22250 / 50000 [skipped  191] | loc. loss = 0.1327760667, classif. loss = 0.6236534119
2025-10-10 01:27:54,077 | INFO | iter is 22300 / 50000 [skipped  191] | loc. loss = 0.1649504900, classif. loss = 0.5228135586
2025-10-10 01:28:26,605 | INFO | iter is 22350 / 50000 [skipped  191] | loc. loss = 0.1866564751, classif. loss = 0.4701440334
2025-10-10 01:28:59,254 | INFO | iter is 22400 / 50000 [skipped  191] | loc. loss = 0.1904332787, classif. loss = 0.0458258837
2025-10-10 01:29:31,214 | INFO | iter is 22450 / 50000 [skipped  192] | loc. loss = 0.2175277323, classif. loss = 0.9798064232
2025-10-10 01:30:03,797 | INFO | iter is 22500 / 50000 [skipped  192] | loc. loss = 0.1417796314, classif. loss = 0.1849129200
2025-10-10 01:30:35,735 | INFO | iter is 22550 / 50000 [skipped  193] | loc. loss = 0.3190602362, classif. loss = 0.7666885853
2025-10-10 01:31:08,386 | INFO | iter is 22600 / 50000 [skipped  193] | loc. loss = 0.1947432607, classif. loss = 0.9294046760
2025-10-10 01:31:40,407 | INFO | iter is 22650 / 50000 [skipped  194] | loc. loss = 0.1893367022, classif. loss = 1.0223267078
2025-10-10 01:32:13,042 | INFO | iter is 22700 / 50000 [skipped  194] | loc. loss = 0.2027404904, classif. loss = 1.5008914471
2025-10-10 01:32:45,723 | INFO | iter is 22750 / 50000 [skipped  194] | loc. loss = 0.1250170469, classif. loss = 0.3992265463
2025-10-10 01:33:18,330 | INFO | iter is 22800 / 50000 [skipped  194] | loc. loss = 0.3449104130, classif. loss = 0.8037049174
2025-10-10 01:33:50,315 | INFO | iter is 22850 / 50000 [skipped  195] | loc. loss = 0.2260230035, classif. loss = 0.5347065926
2025-10-10 01:34:22,988 | INFO | iter is 22900 / 50000 [skipped  195] | loc. loss = 0.2195821255, classif. loss = 1.3461430073
2025-10-10 01:34:55,627 | INFO | iter is 22950 / 50000 [skipped  195] | loc. loss = 0.1380303204, classif. loss = 0.7301456928
2025-10-10 01:35:27,144 | INFO | iter is 23000 / 50000 [skipped  197] | loc. loss = 0.2079837620, classif. loss = 3.1500082016
2025-10-10 01:35:59,838 | INFO | iter is 23050 / 50000 [skipped  197] | loc. loss = 0.1846798956, classif. loss = 0.2770690024
2025-10-10 01:36:31,948 | INFO | iter is 23100 / 50000 [skipped  198] | loc. loss = 0.2204291373, classif. loss = 0.5932239294
2025-10-10 01:37:04,649 | INFO | iter is 23150 / 50000 [skipped  198] | loc. loss = 0.2053100616, classif. loss = 0.1413983107
2025-10-10 01:37:37,258 | INFO | iter is 23200 / 50000 [skipped  198] | loc. loss = 0.2470181882, classif. loss = 0.4694746435
2025-10-10 01:38:09,943 | INFO | iter is 23250 / 50000 [skipped  198] | loc. loss = 0.2670093477, classif. loss = 0.0579470024
2025-10-10 01:38:42,564 | INFO | iter is 23300 / 50000 [skipped  198] | loc. loss = 0.1646312475, classif. loss = 0.0208950117
2025-10-10 01:39:15,298 | INFO | iter is 23350 / 50000 [skipped  198] | loc. loss = 0.0496311747, classif. loss = 0.3934980035
2025-10-10 01:39:46,805 | INFO | iter is 23400 / 50000 [skipped  200] | loc. loss = 0.1903953701, classif. loss = 0.6536180973
2025-10-10 01:40:19,613 | INFO | iter is 23450 / 50000 [skipped  200] | loc. loss = 0.2251074016, classif. loss = 0.0019747075
2025-10-10 01:40:52,377 | INFO | iter is 23500 / 50000 [skipped  200] | loc. loss = 0.1519442350, classif. loss = 0.6912752986
2025-10-10 01:41:24,476 | INFO | iter is 23550 / 50000 [skipped  201] | loc. loss = 0.1201595813, classif. loss = 1.2847394943
2025-10-10 01:41:57,255 | INFO | iter is 23600 / 50000 [skipped  201] | loc. loss = 0.1887909770, classif. loss = 0.7976015806
2025-10-10 01:42:29,367 | INFO | iter is 23650 / 50000 [skipped  202] | loc. loss = 0.1476316005, classif. loss = 0.1648970842
2025-10-10 01:43:01,564 | INFO | iter is 23700 / 50000 [skipped  203] | loc. loss = 0.1346399635, classif. loss = 1.8425161839
2025-10-10 01:43:34,230 | INFO | iter is 23750 / 50000 [skipped  203] | loc. loss = 0.2527508736, classif. loss = 0.3011875153
2025-10-10 01:44:06,999 | INFO | iter is 23800 / 50000 [skipped  203] | loc. loss = 0.1820460707, classif. loss = 0.4373422861
2025-10-10 01:44:39,810 | INFO | iter is 23850 / 50000 [skipped  203] | loc. loss = 0.2128775716, classif. loss = 0.5920921564
2025-10-10 01:45:11,391 | INFO | iter is 23900 / 50000 [skipped  205] | loc. loss = 0.2928542495, classif. loss = 1.3089258671
2025-10-10 01:45:43,510 | INFO | iter is 23950 / 50000 [skipped  206] | loc. loss = 0.1936128438, classif. loss = 0.8479830027
2025-10-10 01:46:15,622 | INFO | iter is 24000 / 50000 [skipped  207] | loc. loss = 0.2055127472, classif. loss = 0.2511558235
2025-10-10 01:46:47,868 | INFO | iter is 24050 / 50000 [skipped  208] | loc. loss = 0.1232573763, classif. loss = 0.2555966377
2025-10-10 01:47:20,655 | INFO | iter is 24100 / 50000 [skipped  208] | loc. loss = 0.1885582209, classif. loss = 0.0789975524
2025-10-10 01:47:53,495 | INFO | iter is 24150 / 50000 [skipped  208] | loc. loss = 0.1161875427, classif. loss = 0.0536914170
2025-10-10 01:48:25,623 | INFO | iter is 24200 / 50000 [skipped  209] | loc. loss = 0.1727761626, classif. loss = 0.8593422771
2025-10-10 01:48:58,498 | INFO | iter is 24250 / 50000 [skipped  209] | loc. loss = 0.2016415894, classif. loss = 0.9067606926
2025-10-10 01:50:03,609 | INFO | iter is 24350 / 50000 [skipped  210] | loc. loss = 0.1947881281, classif. loss = 0.2158091664
2025-10-10 01:50:36,435 | INFO | iter is 24400 / 50000 [skipped  210] | loc. loss = 0.1531156451, classif. loss = 0.1034116447
2025-10-10 01:51:08,581 | INFO | iter is 24450 / 50000 [skipped  211] | loc. loss = 0.2581872046, classif. loss = 0.9070545435
2025-10-10 01:51:40,865 | INFO | iter is 24500 / 50000 [skipped  212] | loc. loss = 0.2260033190, classif. loss = 0.7894651890
2025-10-10 01:52:13,707 | INFO | iter is 24550 / 50000 [skipped  212] | loc. loss = 0.2314959764, classif. loss = 0.1493730247
2025-10-10 01:52:46,037 | INFO | iter is 24600 / 50000 [skipped  213] | loc. loss = 0.2947395444, classif. loss = 0.1778491437
2025-10-10 01:53:18,812 | INFO | iter is 24650 / 50000 [skipped  213] | loc. loss = 0.1877776831, classif. loss = 0.9261718392
2025-10-10 01:54:23,563 | INFO | iter is 24750 / 50000 [skipped  215] | loc. loss = 0.2797599435, classif. loss = 0.4546662569
2025-10-10 01:54:56,427 | INFO | iter is 24800 / 50000 [skipped  215] | loc. loss = 0.1873468906, classif. loss = 1.6371750832
2025-10-10 01:55:29,335 | INFO | iter is 24850 / 50000 [skipped  215] | loc. loss = 0.2038400173, classif. loss = 1.5384917259
2025-10-10 01:56:02,193 | INFO | iter is 24900 / 50000 [skipped  215] | loc. loss = 0.1407189816, classif. loss = 0.8561158180
2025-10-10 01:56:35,092 | INFO | iter is 24950 / 50000 [skipped  215] | loc. loss = 0.1348225027, classif. loss = 1.8443611860
2025-10-10 01:57:07,318 | INFO | iter is 25000 / 50000 [skipped  216] | loc. loss = 0.2553032637, classif. loss = 0.0354010947
2025-10-10 01:57:07,320 | INFO | ---------starting evaluation-----------
2025-10-10 01:57:09,432 | INFO | validation:    0/ 933 (2025-10-10_01-57-09)
2025-10-10 01:57:55,679 | INFO | validation:  100/ 933 (2025-10-10_01-57-55)
2025-10-10 01:58:41,854 | INFO | validation:  200/ 933 (2025-10-10_01-58-41)
2025-10-10 01:59:28,034 | INFO | validation:  300/ 933 (2025-10-10_01-59-28)
2025-10-10 02:00:14,209 | INFO | validation:  400/ 933 (2025-10-10_02-00-14)
2025-10-10 02:01:00,388 | INFO | validation:  500/ 933 (2025-10-10_02-01-00)
2025-10-10 02:01:46,552 | INFO | validation:  600/ 933 (2025-10-10_02-01-46)
2025-10-10 02:02:32,708 | INFO | validation:  700/ 933 (2025-10-10_02-02-32)
2025-10-10 02:03:18,873 | INFO | validation:  800/ 933 (2025-10-10_02-03-18)
2025-10-10 02:04:05,040 | INFO | validation:  900/ 933 (2025-10-10_02-04-05)
2025-10-10 02:04:21,023 | INFO | Confusion Matrix of Localization:
[[912092332   8267517]
 [  9887770  48073789]]
2025-10-10 02:04:21,024 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99101708 0.00898292]
 [0.17059186 0.82940814]]
2025-10-10 02:04:21,024 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40493431  1322092  1811988   231230]
 [       0   950716  2067213  1667268    56774]
 [       0   334525   287359  4730047   176999]
 [       0    78521    22150   333026  2635593]]
2025-10-10 02:04:21,024 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.92326934 0.03014432 0.04131418 0.00527215]
 [0.         0.20048963 0.43593961 0.3515981  0.01197266]
 [0.         0.06050447 0.05197371 0.85550857 0.03201325]
 [0.         0.02558279 0.00721665 0.10850262 0.85869794]]
2025-10-10 02:04:21,024 | INFO | lofF1 is 84.1165, clfF1 is 69.4697, oaF1 is 73.8637, sub class F1 score is [94.4829 48.9815 67.2299 85.4341]
2025-10-10 02:04:21,026 | INFO | ---------starting train set evaluation-----------
2025-10-10 02:04:21,026 | INFO | Train buffer size: 3097.
2025-10-10 02:04:33,106 | INFO | [TrainBuf] locF1 is 84.7722, clfF1 is 66.9340, oaF1 is 72.2855, sub class F1 score is [94.6822 44.5374 66.885  84.7844]
2025-10-10 02:05:05,624 | INFO | iter is 25050 / 50000 [skipped  216] | loc. loss = 0.1185175925, classif. loss = 0.4820771515
2025-10-10 02:05:38,134 | INFO | iter is 25100 / 50000 [skipped  216] | loc. loss = 0.4485166669, classif. loss = 0.0658733770
2025-10-10 02:06:10,693 | INFO | iter is 25150 / 50000 [skipped  216] | loc. loss = 0.2649089396, classif. loss = 0.2357430160
2025-10-10 02:06:43,190 | INFO | iter is 25200 / 50000 [skipped  216] | loc. loss = 0.1637188643, classif. loss = 0.7789902687
2025-10-10 02:07:15,784 | INFO | iter is 25250 / 50000 [skipped  216] | loc. loss = 0.2492814511, classif. loss = 0.7934662104
2025-10-10 02:07:47,637 | INFO | iter is 25300 / 50000 [skipped  217] | loc. loss = 0.1769718528, classif. loss = 2.4819054604
2025-10-10 02:08:20,149 | INFO | iter is 25350 / 50000 [skipped  217] | loc. loss = 0.2209582180, classif. loss = 1.2168803215
2025-10-10 02:08:52,114 | INFO | iter is 25400 / 50000 [skipped  218] | loc. loss = 0.2372642159, classif. loss = 0.1364367753
2025-10-10 02:09:24,637 | INFO | iter is 25450 / 50000 [skipped  218] | loc. loss = 0.3890396357, classif. loss = 0.7971578836
2025-10-10 02:09:57,299 | INFO | iter is 25500 / 50000 [skipped  218] | loc. loss = 0.1640367657, classif. loss = 0.0936778933
2025-10-10 02:10:29,879 | INFO | iter is 25550 / 50000 [skipped  218] | loc. loss = 0.2444305122, classif. loss = 0.4411936402
2025-10-10 02:11:02,536 | INFO | iter is 25600 / 50000 [skipped  218] | loc. loss = 0.2749052942, classif. loss = 0.8396894932
2025-10-10 02:11:34,545 | INFO | iter is 25650 / 50000 [skipped  219] | loc. loss = 0.3572492003, classif. loss = 0.0541212559
2025-10-10 02:12:07,216 | INFO | iter is 25700 / 50000 [skipped  219] | loc. loss = 0.2377397716, classif. loss = 1.2356507778
2025-10-10 02:12:39,233 | INFO | iter is 25750 / 50000 [skipped  220] | loc. loss = 0.2648510039, classif. loss = 0.2447366863
2025-10-10 02:13:11,279 | INFO | iter is 25800 / 50000 [skipped  221] | loc. loss = 0.2713676095, classif. loss = 0.5377516150
2025-10-10 02:13:43,883 | INFO | iter is 25850 / 50000 [skipped  221] | loc. loss = 0.1698451638, classif. loss = 0.0319048092
2025-10-10 02:14:16,462 | INFO | iter is 25900 / 50000 [skipped  221] | loc. loss = 0.1596763879, classif. loss = 0.6324008107
2025-10-10 02:14:49,116 | INFO | iter is 25950 / 50000 [skipped  221] | loc. loss = 0.2248924971, classif. loss = 0.8354036808
2025-10-10 02:15:21,775 | INFO | iter is 26000 / 50000 [skipped  221] | loc. loss = 0.3534061611, classif. loss = 0.0126678543
2025-10-10 02:15:54,485 | INFO | iter is 26050 / 50000 [skipped  221] | loc. loss = 0.1884930730, classif. loss = 0.2834069431
2025-10-10 02:16:26,532 | INFO | iter is 26100 / 50000 [skipped  222] | loc. loss = 0.2998784781, classif. loss = 1.3122117519
2025-10-10 02:16:59,166 | INFO | iter is 26150 / 50000 [skipped  222] | loc. loss = 0.2352887392, classif. loss = 0.0149600487
2025-10-10 02:17:31,805 | INFO | iter is 26200 / 50000 [skipped  222] | loc. loss = 0.3043301702, classif. loss = 0.8197069168
2025-10-10 02:18:04,393 | INFO | iter is 26250 / 50000 [skipped  222] | loc. loss = 0.2192148566, classif. loss = 0.1055023521
2025-10-10 02:18:37,055 | INFO | iter is 26300 / 50000 [skipped  222] | loc. loss = 0.1696032733, classif. loss = 0.7987836003
2025-10-10 02:19:09,795 | INFO | iter is 26350 / 50000 [skipped  222] | loc. loss = 0.2917392254, classif. loss = 0.8845828176
2025-10-10 02:19:41,948 | INFO | iter is 26400 / 50000 [skipped  223] | loc. loss = 0.3177983761, classif. loss = 1.7594306469
2025-10-10 02:20:14,624 | INFO | iter is 26450 / 50000 [skipped  223] | loc. loss = 0.2579190433, classif. loss = 0.0019171441
2025-10-10 02:20:47,394 | INFO | iter is 26500 / 50000 [skipped  223] | loc. loss = 0.2533126473, classif. loss = 0.9167316556
2025-10-10 02:21:20,069 | INFO | iter is 26550 / 50000 [skipped  223] | loc. loss = 0.2266016006, classif. loss = 0.3485239446
2025-10-10 02:21:52,105 | INFO | iter is 26600 / 50000 [skipped  224] | loc. loss = 0.2053566277, classif. loss = 0.1300585568
2025-10-10 02:22:24,866 | INFO | iter is 26650 / 50000 [skipped  224] | loc. loss = 0.2301133871, classif. loss = 0.3890155852
2025-10-10 02:22:57,531 | INFO | iter is 26700 / 50000 [skipped  224] | loc. loss = 0.2185562551, classif. loss = 0.1855394244
2025-10-10 02:23:29,702 | INFO | iter is 26750 / 50000 [skipped  225] | loc. loss = 0.1104770303, classif. loss = 0.3079062104
2025-10-10 02:24:02,455 | INFO | iter is 26800 / 50000 [skipped  225] | loc. loss = 0.2128792554, classif. loss = 0.9789864421
2025-10-10 02:24:35,248 | INFO | iter is 26850 / 50000 [skipped  225] | loc. loss = 0.2570720613, classif. loss = 0.5507183671
2025-10-10 02:25:07,453 | INFO | iter is 26900 / 50000 [skipped  226] | loc. loss = 0.0852205083, classif. loss = 0.0646990463
2025-10-10 02:25:40,259 | INFO | iter is 26950 / 50000 [skipped  226] | loc. loss = 0.2185358107, classif. loss = 0.0516145565
2025-10-10 02:26:12,496 | INFO | iter is 27000 / 50000 [skipped  227] | loc. loss = 0.1552512050, classif. loss = 0.0243010409
2025-10-10 02:26:45,226 | INFO | iter is 27050 / 50000 [skipped  227] | loc. loss = 0.0875428021, classif. loss = 0.9907770157
2025-10-10 02:27:17,998 | INFO | iter is 27100 / 50000 [skipped  227] | loc. loss = 0.2120103240, classif. loss = 0.7354032993
2025-10-10 02:27:50,753 | INFO | iter is 27150 / 50000 [skipped  227] | loc. loss = 0.0695402101, classif. loss = 2.1649899483
2025-10-10 02:28:22,995 | INFO | iter is 27200 / 50000 [skipped  228] | loc. loss = 0.2340918630, classif. loss = 0.0290218443
2025-10-10 02:28:55,740 | INFO | iter is 27250 / 50000 [skipped  228] | loc. loss = 0.1494918317, classif. loss = 0.0286761113
2025-10-10 02:29:28,534 | INFO | iter is 27300 / 50000 [skipped  228] | loc. loss = 0.1276826113, classif. loss = 0.0256810710
2025-10-10 02:30:01,311 | INFO | iter is 27350 / 50000 [skipped  228] | loc. loss = 0.0849535987, classif. loss = 0.0810589120
2025-10-10 02:30:34,003 | INFO | iter is 27400 / 50000 [skipped  228] | loc. loss = 0.1858383119, classif. loss = 0.7711220384
2025-10-10 02:31:06,283 | INFO | iter is 27450 / 50000 [skipped  229] | loc. loss = 0.1474516690, classif. loss = 0.3093554080
2025-10-10 02:31:39,013 | INFO | iter is 27500 / 50000 [skipped  229] | loc. loss = 0.2157537341, classif. loss = 0.1022687703
2025-10-10 02:32:11,332 | INFO | iter is 27550 / 50000 [skipped  230] | loc. loss = 0.1352459639, classif. loss = 1.3633247614
2025-10-10 02:32:43,561 | INFO | iter is 27600 / 50000 [skipped  231] | loc. loss = 0.2949037254, classif. loss = 0.8804730177
2025-10-10 02:33:16,465 | INFO | iter is 27650 / 50000 [skipped  231] | loc. loss = 0.2689622641, classif. loss = 0.6694198251
2025-10-10 02:33:49,317 | INFO | iter is 27700 / 50000 [skipped  231] | loc. loss = 0.2115973383, classif. loss = 0.7505009174
2025-10-10 02:34:22,249 | INFO | iter is 27750 / 50000 [skipped  231] | loc. loss = 0.2232251018, classif. loss = 0.1294992268
2025-10-10 02:34:55,165 | INFO | iter is 27800 / 50000 [skipped  231] | loc. loss = 0.1965601444, classif. loss = 0.6404793859
2025-10-10 02:35:27,981 | INFO | iter is 27850 / 50000 [skipped  231] | loc. loss = 0.2141532004, classif. loss = 0.6834335327
2025-10-10 02:36:00,885 | INFO | iter is 27900 / 50000 [skipped  231] | loc. loss = 0.2429268658, classif. loss = 0.6132172346
2025-10-10 02:36:33,136 | INFO | iter is 27950 / 50000 [skipped  232] | loc. loss = 0.2210332453, classif. loss = 1.2888060808
2025-10-10 02:37:06,036 | INFO | iter is 28000 / 50000 [skipped  232] | loc. loss = 0.1373250037, classif. loss = 0.5116374493
2025-10-10 02:37:38,292 | INFO | iter is 28050 / 50000 [skipped  233] | loc. loss = 0.1723867506, classif. loss = 2.0853123665
2025-10-10 02:38:11,244 | INFO | iter is 28100 / 50000 [skipped  233] | loc. loss = 0.1795630753, classif. loss = 0.4690544009
2025-10-10 02:38:27,692 | INFO | ---------starting evaluation-----------
2025-10-10 02:38:29,820 | INFO | validation:    0/ 933 (2025-10-10_02-38-29)
2025-10-10 02:39:16,315 | INFO | validation:  100/ 933 (2025-10-10_02-39-16)
2025-10-10 02:40:02,749 | INFO | validation:  200/ 933 (2025-10-10_02-40-02)
2025-10-10 02:40:49,189 | INFO | validation:  300/ 933 (2025-10-10_02-40-49)
2025-10-10 02:41:35,628 | INFO | validation:  400/ 933 (2025-10-10_02-41-35)
2025-10-10 02:42:22,049 | INFO | validation:  500/ 933 (2025-10-10_02-42-22)
2025-10-10 02:43:08,472 | INFO | validation:  600/ 933 (2025-10-10_02-43-08)
2025-10-10 02:43:54,901 | INFO | validation:  700/ 933 (2025-10-10_02-43-54)
2025-10-10 02:44:41,350 | INFO | validation:  800/ 933 (2025-10-10_02-44-41)
2025-10-10 02:45:27,812 | INFO | validation:  900/ 933 (2025-10-10_02-45-27)
2025-10-10 02:45:43,816 | INFO | Confusion Matrix of Localization:
[[912678088   7681761]
 [  9677187  48284372]]
2025-10-10 02:45:43,816 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99165352 0.00834648]
 [0.16695871 0.83304129]]
2025-10-10 02:45:43,816 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41902842  1263678   621552    70669]
 [       0  1585428  2470997   645949    39597]
 [       0   615337   776683  4015629   121281]
 [       0   201958    34380   316644  2516308]]
2025-10-10 02:45:43,816 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95540458 0.02881245 0.01417168 0.00161129]
 [0.         0.33433946 0.5210907  0.13621952 0.00835033]
 [0.         0.11129405 0.14047619 0.72629406 0.02193571]
 [0.         0.06579958 0.01120129 0.10316523 0.8198339 ]]
2025-10-10 02:45:43,817 | INFO | lofF1 is 84.7632, clfF1 is 73.0872, oaF1 is 76.5900, sub class F1 score is [95.0562 53.21   72.1671 86.5135]
2025-10-10 02:45:44,092 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-09_20-34-24_MambaBDA_Base_xBD_AGBD/model_step28125.pth
2025-10-10 02:45:44,092 | INFO | ---------starting train set evaluation-----------
2025-10-10 02:45:44,092 | INFO | Train buffer size: 3108.
2025-10-10 02:45:56,185 | INFO | [TrainBuf] locF1 is 85.1231, clfF1 is 68.4551, oaF1 is 73.4555, sub class F1 score is [95.0918 44.9888 70.6918 86.6353]
2025-10-10 02:46:12,424 | INFO | iter is 28150 / 50000 [skipped  233] | loc. loss = 0.3507815003, classif. loss = 0.9317092896
2025-10-10 02:46:44,896 | INFO | iter is 28200 / 50000 [skipped  233] | loc. loss = 0.1661414504, classif. loss = 0.0906420499
2025-10-10 02:47:17,320 | INFO | iter is 28250 / 50000 [skipped  233] | loc. loss = 0.4428302348, classif. loss = 1.0135971308
2025-10-10 02:47:49,807 | INFO | iter is 28300 / 50000 [skipped  233] | loc. loss = 0.1602686942, classif. loss = 0.4373141229
2025-10-10 02:48:21,712 | INFO | iter is 28350 / 50000 [skipped  234] | loc. loss = 0.1176162660, classif. loss = 0.2442487180
2025-10-10 02:48:53,696 | INFO | iter is 28400 / 50000 [skipped  235] | loc. loss = 0.1562454253, classif. loss = 1.4760668278
2025-10-10 02:49:26,249 | INFO | iter is 28450 / 50000 [skipped  235] | loc. loss = 0.2371791601, classif. loss = 1.5360810757
2025-10-10 02:49:58,179 | INFO | iter is 28500 / 50000 [skipped  236] | loc. loss = 0.2309619486, classif. loss = 0.0703968406
2025-10-10 02:50:30,850 | INFO | iter is 28550 / 50000 [skipped  236] | loc. loss = 0.1952010989, classif. loss = 0.3409704864
2025-10-10 02:51:03,395 | INFO | iter is 28600 / 50000 [skipped  236] | loc. loss = 0.1508442909, classif. loss = 1.5736989975
2025-10-10 02:51:36,011 | INFO | iter is 28650 / 50000 [skipped  236] | loc. loss = 0.1861937493, classif. loss = 0.9358481169
2025-10-10 02:52:08,566 | INFO | iter is 28700 / 50000 [skipped  236] | loc. loss = 0.1469257027, classif. loss = 0.3348266184
2025-10-10 02:52:41,209 | INFO | iter is 28750 / 50000 [skipped  236] | loc. loss = 0.1505357176, classif. loss = 0.0853090435
2025-10-10 02:53:13,781 | INFO | iter is 28800 / 50000 [skipped  236] | loc. loss = 0.2251239270, classif. loss = 1.0298786163
2025-10-10 02:53:46,447 | INFO | iter is 28850 / 50000 [skipped  236] | loc. loss = 0.1873129010, classif. loss = 0.1572881937
2025-10-10 02:54:18,460 | INFO | iter is 28900 / 50000 [skipped  237] | loc. loss = 0.2670662403, classif. loss = 0.3006718159
2025-10-10 02:54:50,426 | INFO | iter is 28950 / 50000 [skipped  238] | loc. loss = 0.2211729586, classif. loss = 0.9098221660
2025-10-10 02:55:22,477 | INFO | iter is 29000 / 50000 [skipped  239] | loc. loss = 0.1171840653, classif. loss = 0.1926254034
2025-10-10 02:55:55,079 | INFO | iter is 29050 / 50000 [skipped  239] | loc. loss = 0.2288024426, classif. loss = 0.5128639936
2025-10-10 02:56:27,704 | INFO | iter is 29100 / 50000 [skipped  239] | loc. loss = 0.2069977671, classif. loss = 1.2982057333
2025-10-10 02:57:00,336 | INFO | iter is 29150 / 50000 [skipped  239] | loc. loss = 0.2227284908, classif. loss = 0.0199541058
2025-10-10 02:57:32,443 | INFO | iter is 29200 / 50000 [skipped  240] | loc. loss = 0.1086327508, classif. loss = 1.0171389580
2025-10-10 02:58:05,067 | INFO | iter is 29250 / 50000 [skipped  240] | loc. loss = 0.2029864341, classif. loss = 0.0456952453
2025-10-10 02:58:37,785 | INFO | iter is 29300 / 50000 [skipped  240] | loc. loss = 0.1795800477, classif. loss = 0.0939602107
2025-10-10 02:59:10,395 | INFO | iter is 29350 / 50000 [skipped  240] | loc. loss = 0.1442326605, classif. loss = 0.6793804169
2025-10-10 02:59:43,153 | INFO | iter is 29400 / 50000 [skipped  240] | loc. loss = 0.1754867584, classif. loss = 0.3007751405
2025-10-10 03:00:15,199 | INFO | iter is 29450 / 50000 [skipped  241] | loc. loss = 0.2424900383, classif. loss = 1.1135823727
2025-10-10 03:00:47,279 | INFO | iter is 29500 / 50000 [skipped  242] | loc. loss = 0.1670645475, classif. loss = 0.5927833915
2025-10-10 03:01:19,944 | INFO | iter is 29550 / 50000 [skipped  242] | loc. loss = 0.2385568917, classif. loss = 0.6582516432
2025-10-10 03:01:52,660 | INFO | iter is 29600 / 50000 [skipped  242] | loc. loss = 0.1925155818, classif. loss = 0.8081350327
2025-10-10 03:02:25,362 | INFO | iter is 29650 / 50000 [skipped  242] | loc. loss = 0.2056814134, classif. loss = 0.9359183311
2025-10-10 03:02:58,082 | INFO | iter is 29700 / 50000 [skipped  242] | loc. loss = 0.1937275529, classif. loss = 1.7565276623
2025-10-10 03:03:30,844 | INFO | iter is 29750 / 50000 [skipped  242] | loc. loss = 0.1540181190, classif. loss = 1.0523722172
2025-10-10 03:04:03,534 | INFO | iter is 29800 / 50000 [skipped  242] | loc. loss = 0.2728965878, classif. loss = 0.8950866461
2025-10-10 03:04:36,287 | INFO | iter is 29850 / 50000 [skipped  242] | loc. loss = 0.1856344193, classif. loss = 0.3587003648
2025-10-10 03:05:09,008 | INFO | iter is 29900 / 50000 [skipped  242] | loc. loss = 0.2278085649, classif. loss = 1.8495647907
2025-10-10 03:05:41,870 | INFO | iter is 29950 / 50000 [skipped  242] | loc. loss = 0.1945215464, classif. loss = 0.5536621809
2025-10-10 03:06:14,616 | INFO | iter is 30000 / 50000 [skipped  242] | loc. loss = 0.4047479630, classif. loss = 1.1516084671
2025-10-10 03:06:46,728 | INFO | iter is 30050 / 50000 [skipped  243] | loc. loss = 0.3799532652, classif. loss = 1.3086930513
2025-10-10 03:07:19,488 | INFO | iter is 30100 / 50000 [skipped  243] | loc. loss = 0.1868781447, classif. loss = 0.9371828437
2025-10-10 03:07:50,437 | INFO | iter is 30150 / 50000 [skipped  246] | loc. loss = 0.3366116285, classif. loss = 0.5314570069
2025-10-10 03:08:22,657 | INFO | iter is 30200 / 50000 [skipped  247] | loc. loss = 0.2741733789, classif. loss = 2.8269555569
2025-10-10 03:08:55,417 | INFO | iter is 30250 / 50000 [skipped  247] | loc. loss = 0.2694982290, classif. loss = 0.7290888429
2025-10-10 03:09:27,626 | INFO | iter is 30300 / 50000 [skipped  248] | loc. loss = 0.1594149768, classif. loss = 0.6756892800
2025-10-10 03:10:00,377 | INFO | iter is 30350 / 50000 [skipped  248] | loc. loss = 0.1051512510, classif. loss = 0.0435076430
2025-10-10 03:10:32,610 | INFO | iter is 30400 / 50000 [skipped  249] | loc. loss = 0.2364070415, classif. loss = 0.0132731870
2025-10-10 03:11:05,426 | INFO | iter is 30450 / 50000 [skipped  249] | loc. loss = 0.4050959647, classif. loss = 3.9936077595
2025-10-10 03:11:38,138 | INFO | iter is 30500 / 50000 [skipped  249] | loc. loss = 0.1869641691, classif. loss = 1.2619701624
2025-10-10 03:12:10,943 | INFO | iter is 30550 / 50000 [skipped  249] | loc. loss = 0.1902898699, classif. loss = 1.7716207504
2025-10-10 03:12:43,766 | INFO | iter is 30600 / 50000 [skipped  249] | loc. loss = 0.2448197305, classif. loss = 0.3721128106
2025-10-10 03:13:16,663 | INFO | iter is 30650 / 50000 [skipped  249] | loc. loss = 0.1861092299, classif. loss = 0.5697556734
2025-10-10 03:13:48,833 | INFO | iter is 30700 / 50000 [skipped  250] | loc. loss = 0.1593500525, classif. loss = 1.0612409115
2025-10-10 03:14:21,692 | INFO | iter is 30750 / 50000 [skipped  250] | loc. loss = 0.2383954972, classif. loss = 0.5918866396
2025-10-10 03:14:54,619 | INFO | iter is 30800 / 50000 [skipped  250] | loc. loss = 0.2401835024, classif. loss = 0.7374052405
2025-10-10 03:15:27,522 | INFO | iter is 30850 / 50000 [skipped  250] | loc. loss = 0.2929797769, classif. loss = 1.3551924229
2025-10-10 03:16:00,446 | INFO | iter is 30900 / 50000 [skipped  250] | loc. loss = 0.1576906443, classif. loss = 0.2413295954
2025-10-10 03:16:33,248 | INFO | iter is 30950 / 50000 [skipped  250] | loc. loss = 0.2023848295, classif. loss = 0.5360984802
2025-10-10 03:17:06,144 | INFO | iter is 31000 / 50000 [skipped  250] | loc. loss = 0.2775411010, classif. loss = 1.7358970642
2025-10-10 03:17:38,958 | INFO | iter is 31050 / 50000 [skipped  250] | loc. loss = 0.1569069475, classif. loss = 0.9053736329
2025-10-10 03:18:11,233 | INFO | iter is 31100 / 50000 [skipped  251] | loc. loss = 0.1160804629, classif. loss = 0.1971397549
2025-10-10 03:18:44,082 | INFO | iter is 31150 / 50000 [skipped  251] | loc. loss = 0.1418902576, classif. loss = 0.8010998964
2025-10-10 03:19:16,375 | INFO | iter is 31200 / 50000 [skipped  252] | loc. loss = 0.1500857174, classif. loss = 0.1434613317
2025-10-10 03:19:49,196 | INFO | iter is 31250 / 50000 [skipped  252] | loc. loss = 0.3435891271, classif. loss = 1.0982413292
2025-10-10 03:19:49,198 | INFO | ---------starting evaluation-----------
2025-10-10 03:19:51,336 | INFO | validation:    0/ 933 (2025-10-10_03-19-51)
2025-10-10 03:20:37,893 | INFO | validation:  100/ 933 (2025-10-10_03-20-37)
2025-10-10 03:21:24,414 | INFO | validation:  200/ 933 (2025-10-10_03-21-24)
2025-10-10 03:22:10,904 | INFO | validation:  300/ 933 (2025-10-10_03-22-10)
2025-10-10 03:22:57,386 | INFO | validation:  400/ 933 (2025-10-10_03-22-57)
2025-10-10 03:23:43,878 | INFO | validation:  500/ 933 (2025-10-10_03-23-43)
2025-10-10 03:24:30,360 | INFO | validation:  600/ 933 (2025-10-10_03-24-30)
2025-10-10 03:25:16,815 | INFO | validation:  700/ 933 (2025-10-10_03-25-16)
2025-10-10 03:26:03,276 | INFO | validation:  800/ 933 (2025-10-10_03-26-03)
2025-10-10 03:26:49,746 | INFO | validation:  900/ 933 (2025-10-10_03-26-49)
2025-10-10 03:27:05,794 | INFO | Confusion Matrix of Localization:
[[912241368   8118481]
 [  9253274  48708285]]
2025-10-10 03:27:05,794 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99117901 0.00882099]
 [0.15964502 0.84035498]]
2025-10-10 03:27:05,794 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41379128  1293558  1020324   165731]
 [       0  1215132  2322406  1129311    75122]
 [       0   373019   419637  4563853   172421]
 [       0   129364    39085   334201  2566640]]
2025-10-10 03:27:05,794 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.94346365 0.02949373 0.02326387 0.00377875]
 [0.         0.25625041 0.48975542 0.23815224 0.01584194]
 [0.         0.06746676 0.07589841 0.82544959 0.03118524]
 [0.         0.04214786 0.01273422 0.10888544 0.83623248]]
2025-10-10 03:27:05,795 | INFO | lofF1 is 84.8663, clfF1 is 72.6590, oaF1 is 76.3212, sub class F1 score is [95.1732 52.6822 72.5768 84.8588]
2025-10-10 03:27:05,797 | INFO | ---------starting train set evaluation-----------
2025-10-10 03:27:05,797 | INFO | Train buffer size: 3106.
2025-10-10 03:27:17,888 | INFO | [TrainBuf] locF1 is 85.2048, clfF1 is 70.2958, oaF1 is 74.7685, sub class F1 score is [95.0461 48.552  70.5022 86.201 ]
2025-10-10 03:27:50,429 | INFO | iter is 31300 / 50000 [skipped  252] | loc. loss = 0.2164837718, classif. loss = 0.8669519424
2025-10-10 03:28:22,934 | INFO | iter is 31350 / 50000 [skipped  252] | loc. loss = 0.2217884064, classif. loss = 0.9395455718
2025-10-10 03:28:55,444 | INFO | iter is 31400 / 50000 [skipped  252] | loc. loss = 0.2202250510, classif. loss = 0.9843231440
2025-10-10 03:29:27,954 | INFO | iter is 31450 / 50000 [skipped  252] | loc. loss = 0.2599629164, classif. loss = 0.7379220724
2025-10-10 03:30:00,516 | INFO | iter is 31500 / 50000 [skipped  252] | loc. loss = 0.1394919753, classif. loss = 0.2458852082
2025-10-10 03:30:33,029 | INFO | iter is 31550 / 50000 [skipped  252] | loc. loss = 0.2507419288, classif. loss = 0.9788398743
2025-10-10 03:31:05,642 | INFO | iter is 31600 / 50000 [skipped  252] | loc. loss = 0.1966447234, classif. loss = 0.0072217691
2025-10-10 03:31:38,101 | INFO | iter is 31650 / 50000 [skipped  252] | loc. loss = 0.1228254437, classif. loss = 1.0295596123
2025-10-10 03:32:10,723 | INFO | iter is 31700 / 50000 [skipped  252] | loc. loss = 0.1795755327, classif. loss = 1.3373299837
2025-10-10 03:32:43,336 | INFO | iter is 31750 / 50000 [skipped  252] | loc. loss = 0.1516677737, classif. loss = 0.5591213703
2025-10-10 03:33:14,685 | INFO | iter is 31800 / 50000 [skipped  254] | loc. loss = 0.3983009458, classif. loss = 0.7965931296
2025-10-10 03:33:47,376 | INFO | iter is 31850 / 50000 [skipped  254] | loc. loss = 0.1795689464, classif. loss = 0.1461121738
2025-10-10 03:34:19,339 | INFO | iter is 31900 / 50000 [skipped  255] | loc. loss = 0.0817040205, classif. loss = 0.2511212826
2025-10-10 03:34:50,794 | INFO | iter is 31950 / 50000 [skipped  257] | loc. loss = 0.2132739127, classif. loss = 1.3584883213
2025-10-10 03:35:22,740 | INFO | iter is 32000 / 50000 [skipped  258] | loc. loss = 0.2746835947, classif. loss = 0.3231277466
2025-10-10 03:35:55,353 | INFO | iter is 32050 / 50000 [skipped  258] | loc. loss = 0.2836005688, classif. loss = 0.1796013266
2025-10-10 03:36:27,381 | INFO | iter is 32100 / 50000 [skipped  259] | loc. loss = 0.1648982763, classif. loss = 1.3411467075
2025-10-10 03:36:59,977 | INFO | iter is 32150 / 50000 [skipped  259] | loc. loss = 0.1111222357, classif. loss = 1.0454168320
2025-10-10 03:37:32,673 | INFO | iter is 32200 / 50000 [skipped  259] | loc. loss = 0.3043176234, classif. loss = 0.1346590519
2025-10-10 03:38:05,245 | INFO | iter is 32250 / 50000 [skipped  259] | loc. loss = 0.2311388999, classif. loss = 0.1517628878
2025-10-10 03:38:37,967 | INFO | iter is 32300 / 50000 [skipped  259] | loc. loss = 0.2511568069, classif. loss = 0.3053183556
2025-10-10 03:39:10,044 | INFO | iter is 32350 / 50000 [skipped  260] | loc. loss = 0.2313591838, classif. loss = 0.0202741362
2025-10-10 03:39:42,710 | INFO | iter is 32400 / 50000 [skipped  260] | loc. loss = 0.3194325268, classif. loss = 0.3530113697
2025-10-10 03:40:14,802 | INFO | iter is 32450 / 50000 [skipped  261] | loc. loss = 0.1926441044, classif. loss = 0.0702404827
2025-10-10 03:40:47,493 | INFO | iter is 32500 / 50000 [skipped  261] | loc. loss = 0.2052952349, classif. loss = 0.7745826244
2025-10-10 03:41:20,244 | INFO | iter is 32550 / 50000 [skipped  261] | loc. loss = 0.1558387130, classif. loss = 0.5685906410
2025-10-10 03:41:52,882 | INFO | iter is 32600 / 50000 [skipped  261] | loc. loss = 0.2220612466, classif. loss = 0.1243031546
2025-10-10 03:42:24,985 | INFO | iter is 32650 / 50000 [skipped  262] | loc. loss = 0.1937700659, classif. loss = 0.0236006100
2025-10-10 03:42:57,038 | INFO | iter is 32700 / 50000 [skipped  263] | loc. loss = 0.2278777659, classif. loss = 0.0044068336
2025-10-10 03:43:29,783 | INFO | iter is 32750 / 50000 [skipped  263] | loc. loss = 0.1800090075, classif. loss = 0.0920731574
2025-10-10 03:44:02,480 | INFO | iter is 32800 / 50000 [skipped  263] | loc. loss = 0.1280791312, classif. loss = 0.5230277181
2025-10-10 03:44:35,266 | INFO | iter is 32850 / 50000 [skipped  263] | loc. loss = 0.2345497310, classif. loss = 0.0213681459
2025-10-10 03:45:07,363 | INFO | iter is 32900 / 50000 [skipped  264] | loc. loss = 0.1583885700, classif. loss = 0.2789109945
2025-10-10 03:45:39,489 | INFO | iter is 32950 / 50000 [skipped  265] | loc. loss = 0.1481671035, classif. loss = 0.9847149849
2025-10-10 03:46:12,272 | INFO | iter is 33000 / 50000 [skipped  265] | loc. loss = 0.1409988850, classif. loss = 0.0954972357
2025-10-10 03:46:45,028 | INFO | iter is 33050 / 50000 [skipped  265] | loc. loss = 0.2327598184, classif. loss = 0.3115621507
2025-10-10 03:47:17,803 | INFO | iter is 33100 / 50000 [skipped  265] | loc. loss = 0.4947526455, classif. loss = 2.8835399151
2025-10-10 03:47:50,565 | INFO | iter is 33150 / 50000 [skipped  265] | loc. loss = 0.1285567731, classif. loss = 0.5550990105
2025-10-10 03:48:22,187 | INFO | iter is 33200 / 50000 [skipped  267] | loc. loss = 0.2148804069, classif. loss = 0.2504012883
2025-10-10 03:48:54,935 | INFO | iter is 33250 / 50000 [skipped  267] | loc. loss = 0.2573046982, classif. loss = 0.4113767743
2025-10-10 03:49:27,692 | INFO | iter is 33300 / 50000 [skipped  267] | loc. loss = 0.0913934037, classif. loss = 0.4600480795
2025-10-10 03:50:00,542 | INFO | iter is 33350 / 50000 [skipped  267] | loc. loss = 0.2172720581, classif. loss = 0.7266902924
2025-10-10 03:50:32,661 | INFO | iter is 33400 / 50000 [skipped  268] | loc. loss = 0.2048365623, classif. loss = 0.5349094272
2025-10-10 03:51:05,496 | INFO | iter is 33450 / 50000 [skipped  268] | loc. loss = 0.2122461349, classif. loss = 0.8074510694
2025-10-10 03:51:38,283 | INFO | iter is 33500 / 50000 [skipped  268] | loc. loss = 0.4002614319, classif. loss = 0.0380641036
2025-10-10 03:52:11,026 | INFO | iter is 33550 / 50000 [skipped  268] | loc. loss = 0.2721350491, classif. loss = 0.6448897123
2025-10-10 03:52:43,179 | INFO | iter is 33600 / 50000 [skipped  269] | loc. loss = 0.2349072844, classif. loss = 0.8994989395
2025-10-10 03:53:15,933 | INFO | iter is 33650 / 50000 [skipped  269] | loc. loss = 0.1909082681, classif. loss = 1.2712739706
2025-10-10 03:53:48,147 | INFO | iter is 33700 / 50000 [skipped  270] | loc. loss = 0.2301880568, classif. loss = 0.1507326961
2025-10-10 03:54:20,314 | INFO | iter is 33750 / 50000 [skipped  271] | loc. loss = 0.1076916382, classif. loss = 0.0382744484
2025-10-10 03:54:53,187 | INFO | iter is 33800 / 50000 [skipped  271] | loc. loss = 0.1500972211, classif. loss = 0.5773200989
2025-10-10 03:55:25,530 | INFO | iter is 33850 / 50000 [skipped  272] | loc. loss = 0.1268012226, classif. loss = 0.1153213903
2025-10-10 03:55:58,455 | INFO | iter is 33900 / 50000 [skipped  272] | loc. loss = 0.2649112940, classif. loss = 0.9659452438
2025-10-10 03:56:31,291 | INFO | iter is 33950 / 50000 [skipped  272] | loc. loss = 0.1678024530, classif. loss = 0.2976436317
2025-10-10 03:57:04,162 | INFO | iter is 34000 / 50000 [skipped  272] | loc. loss = 0.1461039782, classif. loss = 0.3009456694
2025-10-10 03:57:37,027 | INFO | iter is 34050 / 50000 [skipped  272] | loc. loss = 0.1909568906, classif. loss = 0.1263592988
2025-10-10 03:58:09,842 | INFO | iter is 34100 / 50000 [skipped  272] | loc. loss = 0.2265702188, classif. loss = 0.7235456705
2025-10-10 03:58:42,098 | INFO | iter is 34150 / 50000 [skipped  273] | loc. loss = 0.2010085881, classif. loss = 0.0881368890
2025-10-10 03:59:14,976 | INFO | iter is 34200 / 50000 [skipped  273] | loc. loss = 0.2512349486, classif. loss = 0.8392299414
2025-10-10 03:59:47,903 | INFO | iter is 34250 / 50000 [skipped  273] | loc. loss = 0.1445957869, classif. loss = 0.1910895407
2025-10-10 04:00:20,186 | INFO | iter is 34300 / 50000 [skipped  274] | loc. loss = 0.2154945135, classif. loss = 1.4703936577
2025-10-10 04:00:53,066 | INFO | iter is 34350 / 50000 [skipped  274] | loc. loss = 0.1909051836, classif. loss = 0.2941206992
2025-10-10 04:01:09,584 | INFO | ---------starting evaluation-----------
2025-10-10 04:01:11,733 | INFO | validation:    0/ 933 (2025-10-10_04-01-11)
2025-10-10 04:01:58,322 | INFO | validation:  100/ 933 (2025-10-10_04-01-58)
2025-10-10 04:02:44,871 | INFO | validation:  200/ 933 (2025-10-10_04-02-44)
2025-10-10 04:03:31,376 | INFO | validation:  300/ 933 (2025-10-10_04-03-31)
2025-10-10 04:04:17,892 | INFO | validation:  400/ 933 (2025-10-10_04-04-17)
2025-10-10 04:05:04,411 | INFO | validation:  500/ 933 (2025-10-10_04-05-04)
2025-10-10 04:05:50,931 | INFO | validation:  600/ 933 (2025-10-10_04-05-50)
2025-10-10 04:06:37,451 | INFO | validation:  700/ 933 (2025-10-10_04-06-37)
2025-10-10 04:07:23,998 | INFO | validation:  800/ 933 (2025-10-10_04-07-23)
2025-10-10 04:08:10,531 | INFO | validation:  900/ 933 (2025-10-10_04-08-10)
2025-10-10 04:08:26,792 | INFO | Confusion Matrix of Localization:
[[912242931   8116918]
 [  9228347  48733212]]
2025-10-10 04:08:26,792 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99118071 0.00881929]
 [0.15921495 0.84078505]]
2025-10-10 04:08:26,792 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 42061060  1151983   582664    63034]
 [       0  1340331  2681935   687636    32069]
 [       0   605645   588424  4211004   123857]
 [       0   207737    45670   244951  2570932]]
2025-10-10 04:08:26,792 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95901202 0.02626576 0.01328501 0.0014372 ]
 [0.         0.28265272 0.56557389 0.14501059 0.0067628 ]
 [0.         0.10954109 0.10642638 0.76163091 0.02240162]
 [0.         0.06768243 0.01487966 0.07980706 0.83763085]]
2025-10-10 04:08:26,792 | INFO | lofF1 is 84.8924, clfF1 is 76.3370, oaF1 is 78.9037, sub class F1 score is [95.5135 58.2397 74.8278 87.7574]
2025-10-10 04:08:27,050 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-09_20-34-24_MambaBDA_Base_xBD_AGBD/model_step34375.pth
2025-10-10 04:08:27,050 | INFO | ---------starting train set evaluation-----------
2025-10-10 04:08:27,050 | INFO | Train buffer size: 3103.
2025-10-10 04:08:39,093 | INFO | [TrainBuf] locF1 is 85.3351, clfF1 is 72.5319, oaF1 is 76.3729, sub class F1 score is [95.2654 51.3412 73.7453 86.1071]
2025-10-10 04:08:55,335 | INFO | iter is 34400 / 50000 [skipped  274] | loc. loss = 0.2040778250, classif. loss = 0.1403148174
2025-10-10 04:09:27,837 | INFO | iter is 34450 / 50000 [skipped  274] | loc. loss = 0.1644713879, classif. loss = 0.8135292530
2025-10-10 04:10:00,349 | INFO | iter is 34500 / 50000 [skipped  274] | loc. loss = 0.1738321334, classif. loss = 1.2862443924
2025-10-10 04:10:32,921 | INFO | iter is 34550 / 50000 [skipped  274] | loc. loss = 0.2194193304, classif. loss = 0.7991405725
2025-10-10 04:11:04,883 | INFO | iter is 34600 / 50000 [skipped  275] | loc. loss = 0.1477603316, classif. loss = 0.6563325524
2025-10-10 04:11:37,457 | INFO | iter is 34650 / 50000 [skipped  275] | loc. loss = 0.1203567982, classif. loss = 0.8775054216
2025-10-10 04:12:09,435 | INFO | iter is 34700 / 50000 [skipped  276] | loc. loss = 0.2212249190, classif. loss = 0.3162369132
2025-10-10 04:12:41,442 | INFO | iter is 34750 / 50000 [skipped  277] | loc. loss = 0.1634824127, classif. loss = 0.8836241961
2025-10-10 04:13:13,967 | INFO | iter is 34800 / 50000 [skipped  277] | loc. loss = 0.1758206338, classif. loss = 1.1382255554
2025-10-10 04:13:46,572 | INFO | iter is 34850 / 50000 [skipped  277] | loc. loss = 0.1858339012, classif. loss = 0.6635189652
2025-10-10 04:14:19,191 | INFO | iter is 34900 / 50000 [skipped  277] | loc. loss = 0.2295234501, classif. loss = 0.6890389919
2025-10-10 04:14:51,734 | INFO | iter is 34950 / 50000 [skipped  277] | loc. loss = 0.2920546234, classif. loss = 0.7482740879
2025-10-10 04:15:24,327 | INFO | iter is 35000 / 50000 [skipped  277] | loc. loss = 0.2223999500, classif. loss = 0.4156923890
2025-10-10 04:16:28,920 | INFO | iter is 35100 / 50000 [skipped  278] | loc. loss = 0.0941615999, classif. loss = 0.5416200161
2025-10-10 04:17:01,473 | INFO | iter is 35150 / 50000 [skipped  278] | loc. loss = 0.2635476887, classif. loss = 0.0925639719
2025-10-10 04:17:34,125 | INFO | iter is 35200 / 50000 [skipped  278] | loc. loss = 0.1558326781, classif. loss = 1.1777360439
2025-10-10 04:18:06,750 | INFO | iter is 35250 / 50000 [skipped  278] | loc. loss = 0.2694698274, classif. loss = 0.4234403968
2025-10-10 04:18:39,353 | INFO | iter is 35300 / 50000 [skipped  278] | loc. loss = 0.1630164236, classif. loss = 0.5790976882
2025-10-10 04:19:11,970 | INFO | iter is 35350 / 50000 [skipped  278] | loc. loss = 0.2578251362, classif. loss = 0.2775716782
2025-10-10 04:19:44,596 | INFO | iter is 35400 / 50000 [skipped  278] | loc. loss = 0.1978768408, classif. loss = 0.8088212013
2025-10-10 04:20:17,337 | INFO | iter is 35450 / 50000 [skipped  278] | loc. loss = 0.2490866780, classif. loss = 0.4613255262
2025-10-10 04:20:49,959 | INFO | iter is 35500 / 50000 [skipped  278] | loc. loss = 0.1865097582, classif. loss = 1.7705675364
2025-10-10 04:21:22,111 | INFO | iter is 35550 / 50000 [skipped  279] | loc. loss = 0.1705242395, classif. loss = 0.4324122369
2025-10-10 04:21:54,799 | INFO | iter is 35600 / 50000 [skipped  279] | loc. loss = 0.1096987277, classif. loss = 0.0486003086
2025-10-10 04:22:27,463 | INFO | iter is 35650 / 50000 [skipped  279] | loc. loss = 0.1072948202, classif. loss = 1.4598240852
2025-10-10 04:22:59,578 | INFO | iter is 35700 / 50000 [skipped  280] | loc. loss = 0.1993741989, classif. loss = 0.7012284994
2025-10-10 04:23:32,234 | INFO | iter is 35750 / 50000 [skipped  280] | loc. loss = 0.2313314527, classif. loss = 1.7946680784
2025-10-10 04:24:04,998 | INFO | iter is 35800 / 50000 [skipped  280] | loc. loss = 0.2685328424, classif. loss = 0.7278882265
2025-10-10 04:24:37,159 | INFO | iter is 35850 / 50000 [skipped  281] | loc. loss = 0.0934215114, classif. loss = 0.0573150180
2025-10-10 04:25:09,348 | INFO | iter is 35900 / 50000 [skipped  282] | loc. loss = 0.1670327187, classif. loss = 0.8555009365
2025-10-10 04:25:42,067 | INFO | iter is 35950 / 50000 [skipped  282] | loc. loss = 0.1439667493, classif. loss = 0.3723033369
2025-10-10 04:26:13,554 | INFO | iter is 36000 / 50000 [skipped  284] | loc. loss = 0.2422640175, classif. loss = 0.5091741085
2025-10-10 04:26:45,762 | INFO | iter is 36050 / 50000 [skipped  285] | loc. loss = 0.3152101636, classif. loss = 0.0338188857
2025-10-10 04:27:18,473 | INFO | iter is 36100 / 50000 [skipped  285] | loc. loss = 0.2249288857, classif. loss = 0.0449808016
2025-10-10 04:27:50,634 | INFO | iter is 36150 / 50000 [skipped  286] | loc. loss = 0.1659944803, classif. loss = 0.4777200818
2025-10-10 04:28:23,354 | INFO | iter is 36200 / 50000 [skipped  286] | loc. loss = 0.2327036560, classif. loss = 0.7329429984
2025-10-10 04:28:54,967 | INFO | iter is 36250 / 50000 [skipped  288] | loc. loss = 0.2863559723, classif. loss = 0.0325485133
2025-10-10 04:29:27,753 | INFO | iter is 36300 / 50000 [skipped  288] | loc. loss = 0.2178113908, classif. loss = 0.1238078773
2025-10-10 04:30:00,527 | INFO | iter is 36350 / 50000 [skipped  288] | loc. loss = 0.2211822718, classif. loss = 0.0606669299
2025-10-10 04:30:33,335 | INFO | iter is 36400 / 50000 [skipped  288] | loc. loss = 0.2760910690, classif. loss = 0.0397351384
2025-10-10 04:31:06,144 | INFO | iter is 36450 / 50000 [skipped  288] | loc. loss = 0.4868962169, classif. loss = 4.4483199120
2025-10-10 04:31:38,372 | INFO | iter is 36500 / 50000 [skipped  289] | loc. loss = 0.2820360065, classif. loss = 0.0621879883
2025-10-10 04:32:11,160 | INFO | iter is 36550 / 50000 [skipped  289] | loc. loss = 0.2491412610, classif. loss = 0.5166098475
2025-10-10 04:32:43,956 | INFO | iter is 36600 / 50000 [skipped  289] | loc. loss = 0.1925246119, classif. loss = 0.0059267879
2025-10-10 04:33:16,147 | INFO | iter is 36650 / 50000 [skipped  290] | loc. loss = 0.1955879480, classif. loss = 0.0563325807
2025-10-10 04:33:48,935 | INFO | iter is 36700 / 50000 [skipped  290] | loc. loss = 0.1967607737, classif. loss = 1.1307481527
2025-10-10 04:34:21,180 | INFO | iter is 36750 / 50000 [skipped  291] | loc. loss = 0.1783260703, classif. loss = 1.0539510250
2025-10-10 04:34:53,454 | INFO | iter is 36800 / 50000 [skipped  292] | loc. loss = 0.0942973271, classif. loss = 0.1269059926
2025-10-10 04:35:26,273 | INFO | iter is 36850 / 50000 [skipped  292] | loc. loss = 0.1517261714, classif. loss = 0.1843523979
2025-10-10 04:35:59,039 | INFO | iter is 36900 / 50000 [skipped  292] | loc. loss = 0.2132899612, classif. loss = 1.5178279877
2025-10-10 04:36:31,348 | INFO | iter is 36950 / 50000 [skipped  293] | loc. loss = 0.2650765479, classif. loss = 1.0743991137
2025-10-10 04:37:03,540 | INFO | iter is 37000 / 50000 [skipped  294] | loc. loss = 0.2142109126, classif. loss = 0.7173320055
2025-10-10 04:37:36,428 | INFO | iter is 37050 / 50000 [skipped  294] | loc. loss = 0.1444735229, classif. loss = 0.1520742774
2025-10-10 04:38:09,243 | INFO | iter is 37100 / 50000 [skipped  294] | loc. loss = 0.2712947130, classif. loss = 0.9845186472
2025-10-10 04:38:42,167 | INFO | iter is 37150 / 50000 [skipped  294] | loc. loss = 0.1340235323, classif. loss = 0.6391928196
2025-10-10 04:39:15,065 | INFO | iter is 37200 / 50000 [skipped  294] | loc. loss = 0.2172189355, classif. loss = 0.6629012823
2025-10-10 04:39:47,310 | INFO | iter is 37250 / 50000 [skipped  295] | loc. loss = 0.0929242522, classif. loss = 0.0248619784
2025-10-10 04:40:20,198 | INFO | iter is 37300 / 50000 [skipped  295] | loc. loss = 0.1886035204, classif. loss = 0.5036619902
2025-10-10 04:40:53,021 | INFO | iter is 37350 / 50000 [skipped  295] | loc. loss = 0.1458519399, classif. loss = 0.6375846267
2025-10-10 04:41:25,302 | INFO | iter is 37400 / 50000 [skipped  296] | loc. loss = 0.1841400266, classif. loss = 0.1894153506
2025-10-10 04:41:58,135 | INFO | iter is 37450 / 50000 [skipped  296] | loc. loss = 0.0944995657, classif. loss = 0.3710459173
2025-10-10 04:42:31,099 | INFO | iter is 37500 / 50000 [skipped  296] | loc. loss = 0.0776369721, classif. loss = 0.1966809332
2025-10-10 04:42:31,101 | INFO | ---------starting evaluation-----------
2025-10-10 04:42:33,254 | INFO | validation:    0/ 933 (2025-10-10_04-42-33)
2025-10-10 04:43:19,780 | INFO | validation:  100/ 933 (2025-10-10_04-43-19)
2025-10-10 04:44:06,253 | INFO | validation:  200/ 933 (2025-10-10_04-44-06)
2025-10-10 04:44:52,727 | INFO | validation:  300/ 933 (2025-10-10_04-44-52)
2025-10-10 04:45:39,247 | INFO | validation:  400/ 933 (2025-10-10_04-45-39)
2025-10-10 04:46:25,754 | INFO | validation:  500/ 933 (2025-10-10_04-46-25)
2025-10-10 04:47:12,261 | INFO | validation:  600/ 933 (2025-10-10_04-47-12)
2025-10-10 04:47:58,758 | INFO | validation:  700/ 933 (2025-10-10_04-47-58)
2025-10-10 04:48:45,256 | INFO | validation:  800/ 933 (2025-10-10_04-48-45)
2025-10-10 04:49:31,782 | INFO | validation:  900/ 933 (2025-10-10_04-49-31)
2025-10-10 04:49:47,693 | INFO | Confusion Matrix of Localization:
[[913971611   6388238]
 [ 11075120  46886439]]
2025-10-10 04:49:47,694 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99305898 0.00694102]
 [0.19107699 0.80892301]]
2025-10-10 04:49:47,694 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41909986  1179451   625207   144097]
 [       0  1371473  2546152   742698    81648]
 [       0   530351   520494  4290314   187771]
 [       0    95203    23277   311837  2638973]]
2025-10-10 04:49:47,694 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.95556747 0.02689204 0.01425501 0.00328548]
 [0.         0.28922003 0.5369396  0.15662221 0.01721816]
 [0.         0.0959229  0.0941401  0.77597546 0.03396154]
 [0.         0.03101792 0.00758384 0.10159907 0.85979917]]
2025-10-10 04:49:47,694 | INFO | lofF1 is 84.3007, clfF1 is 75.2351, oaF1 is 77.9548, sub class F1 score is [95.5042 56.5099 74.6207 86.2159]
2025-10-10 04:49:47,696 | INFO | ---------starting train set evaluation-----------
2025-10-10 04:49:47,696 | INFO | Train buffer size: 3103.
2025-10-10 04:49:59,764 | INFO | [TrainBuf] locF1 is 85.4965, clfF1 is 70.9743, oaF1 is 75.3310, sub class F1 score is [95.1473 49.6036 71.5444 85.388 ]
2025-10-10 04:50:32,200 | INFO | iter is 37550 / 50000 [skipped  296] | loc. loss = 0.1743851006, classif. loss = 0.1705760956
2025-10-10 04:51:03,499 | INFO | iter is 37600 / 50000 [skipped  298] | loc. loss = 0.1822441369, classif. loss = 1.0194536448
2025-10-10 04:51:36,077 | INFO | iter is 37650 / 50000 [skipped  298] | loc. loss = 0.1174922511, classif. loss = 0.0537656695
2025-10-10 04:52:08,586 | INFO | iter is 37700 / 50000 [skipped  298] | loc. loss = 0.2772967815, classif. loss = 0.6896997690
2025-10-10 04:52:40,527 | INFO | iter is 37750 / 50000 [skipped  299] | loc. loss = 0.0846536681, classif. loss = 0.4240242243
2025-10-10 04:53:13,050 | INFO | iter is 37800 / 50000 [skipped  299] | loc. loss = 0.2886229157, classif. loss = 0.5727801323
2025-10-10 04:53:45,616 | INFO | iter is 37850 / 50000 [skipped  299] | loc. loss = 0.1549178958, classif. loss = 0.0213754252
2025-10-10 04:54:17,510 | INFO | iter is 37900 / 50000 [skipped  300] | loc. loss = 0.2083384991, classif. loss = 1.0657658577
2025-10-10 04:54:50,119 | INFO | iter is 37950 / 50000 [skipped  300] | loc. loss = 0.1703559309, classif. loss = 0.1450429857
2025-10-10 04:55:22,757 | INFO | iter is 38000 / 50000 [skipped  300] | loc. loss = 0.2890111208, classif. loss = 0.2476443946
2025-10-10 04:55:54,702 | INFO | iter is 38050 / 50000 [skipped  301] | loc. loss = 0.0809630975, classif. loss = 0.3275899291
2025-10-10 04:56:27,274 | INFO | iter is 38100 / 50000 [skipped  301] | loc. loss = 0.3414860666, classif. loss = 0.4866288900
2025-10-10 04:56:59,800 | INFO | iter is 38150 / 50000 [skipped  301] | loc. loss = 0.2167913765, classif. loss = 0.0679122806
2025-10-10 04:57:31,799 | INFO | iter is 38200 / 50000 [skipped  302] | loc. loss = 0.1693573147, classif. loss = 0.4267536998
2025-10-10 04:58:04,393 | INFO | iter is 38250 / 50000 [skipped  302] | loc. loss = 0.1061802655, classif. loss = 0.1681768894
2025-10-10 04:58:36,477 | INFO | iter is 38300 / 50000 [skipped  303] | loc. loss = 0.4047319591, classif. loss = 0.2058962584
2025-10-10 04:59:08,540 | INFO | iter is 38350 / 50000 [skipped  304] | loc. loss = 0.2752684057, classif. loss = 0.7394985557
2025-10-10 04:59:40,518 | INFO | iter is 38400 / 50000 [skipped  305] | loc. loss = 0.2517038882, classif. loss = 1.2062667608
2025-10-10 05:00:13,299 | INFO | iter is 38450 / 50000 [skipped  305] | loc. loss = 0.1609136760, classif. loss = 0.3107162714
2025-10-10 05:00:45,969 | INFO | iter is 38500 / 50000 [skipped  305] | loc. loss = 0.1310170293, classif. loss = 0.3980465233
2025-10-10 05:01:18,629 | INFO | iter is 38550 / 50000 [skipped  305] | loc. loss = 0.2875190377, classif. loss = 0.8143770695
2025-10-10 05:01:51,299 | INFO | iter is 38600 / 50000 [skipped  305] | loc. loss = 0.0712641925, classif. loss = 1.6276886463
2025-10-10 05:02:24,048 | INFO | iter is 38650 / 50000 [skipped  305] | loc. loss = 0.2426815480, classif. loss = 0.4613966644
2025-10-10 05:02:56,718 | INFO | iter is 38700 / 50000 [skipped  305] | loc. loss = 0.1813279539, classif. loss = 1.2475471497
2025-10-10 05:03:28,819 | INFO | iter is 38750 / 50000 [skipped  306] | loc. loss = 0.2118251324, classif. loss = 0.0610933490
2025-10-10 05:04:01,483 | INFO | iter is 38800 / 50000 [skipped  306] | loc. loss = 0.3370144367, classif. loss = 2.7260510921
2025-10-10 05:04:34,179 | INFO | iter is 38850 / 50000 [skipped  306] | loc. loss = 0.2920159996, classif. loss = 0.2659639716
2025-10-10 05:05:06,878 | INFO | iter is 38900 / 50000 [skipped  306] | loc. loss = 0.1849543899, classif. loss = 1.2522262335
2025-10-10 05:05:39,564 | INFO | iter is 38950 / 50000 [skipped  306] | loc. loss = 0.1177803129, classif. loss = 0.0982271433
2025-10-10 05:06:12,299 | INFO | iter is 39000 / 50000 [skipped  306] | loc. loss = 0.1049973890, classif. loss = 0.9372172356
2025-10-10 05:07:16,009 | INFO | iter is 39100 / 50000 [skipped  309] | loc. loss = 0.3087558746, classif. loss = 0.1181134358
2025-10-10 05:07:48,778 | INFO | iter is 39150 / 50000 [skipped  309] | loc. loss = 0.1226722747, classif. loss = 0.0767123848
2025-10-10 05:08:21,554 | INFO | iter is 39200 / 50000 [skipped  309] | loc. loss = 0.1203138977, classif. loss = 0.0392310396
2025-10-10 05:08:54,357 | INFO | iter is 39250 / 50000 [skipped  309] | loc. loss = 0.1796340048, classif. loss = 0.6456320882
2025-10-10 05:09:27,070 | INFO | iter is 39300 / 50000 [skipped  309] | loc. loss = 0.2321127504, classif. loss = 1.3956872225
2025-10-10 05:09:59,862 | INFO | iter is 39350 / 50000 [skipped  309] | loc. loss = 0.2370885462, classif. loss = 0.1550572515
2025-10-10 05:10:32,664 | INFO | iter is 39400 / 50000 [skipped  309] | loc. loss = 0.1891055405, classif. loss = 0.8220843077
2025-10-10 05:11:04,861 | INFO | iter is 39450 / 50000 [skipped  310] | loc. loss = 0.1655205190, classif. loss = 0.0127508193
2025-10-10 05:11:37,038 | INFO | iter is 39500 / 50000 [skipped  311] | loc. loss = 0.1542092115, classif. loss = 0.0945369005
2025-10-10 05:12:09,754 | INFO | iter is 39550 / 50000 [skipped  311] | loc. loss = 0.2257471830, classif. loss = 1.2969192266
2025-10-10 05:12:41,964 | INFO | iter is 39600 / 50000 [skipped  312] | loc. loss = 0.1302393228, classif. loss = 0.7117014527
2025-10-10 05:13:14,709 | INFO | iter is 39650 / 50000 [skipped  312] | loc. loss = 0.1308487803, classif. loss = 0.0474943072
2025-10-10 05:13:47,570 | INFO | iter is 39700 / 50000 [skipped  312] | loc. loss = 0.2329880297, classif. loss = 0.6595826149
2025-10-10 05:14:20,463 | INFO | iter is 39750 / 50000 [skipped  312] | loc. loss = 0.2640600801, classif. loss = 1.5870141983
2025-10-10 05:14:53,203 | INFO | iter is 39800 / 50000 [skipped  312] | loc. loss = 0.1688018143, classif. loss = 0.5068330765
2025-10-10 05:15:25,481 | INFO | iter is 39850 / 50000 [skipped  313] | loc. loss = 0.1742044240, classif. loss = 0.0235508308
2025-10-10 05:15:57,682 | INFO | iter is 39900 / 50000 [skipped  314] | loc. loss = 0.1476394534, classif. loss = 0.0105096381
2025-10-10 05:16:30,542 | INFO | iter is 39950 / 50000 [skipped  314] | loc. loss = 0.2188766003, classif. loss = 0.1077891961
2025-10-10 05:17:03,295 | INFO | iter is 40000 / 50000 [skipped  314] | loc. loss = 0.2122665197, classif. loss = 0.0546668023
2025-10-10 05:17:36,183 | INFO | iter is 40050 / 50000 [skipped  314] | loc. loss = 0.2583590746, classif. loss = 0.0359113440
2025-10-10 05:18:08,307 | INFO | iter is 40100 / 50000 [skipped  315] | loc. loss = 0.1570922434, classif. loss = 0.6215206385
2025-10-10 05:18:41,203 | INFO | iter is 40150 / 50000 [skipped  315] | loc. loss = 0.1180953383, classif. loss = 0.0086771585
2025-10-10 05:19:14,077 | INFO | iter is 40200 / 50000 [skipped  315] | loc. loss = 0.2062982768, classif. loss = 0.7383128405
2025-10-10 05:19:46,924 | INFO | iter is 40250 / 50000 [skipped  315] | loc. loss = 0.1768817008, classif. loss = 0.1251169294
2025-10-10 05:20:19,824 | INFO | iter is 40300 / 50000 [skipped  315] | loc. loss = 0.1669291258, classif. loss = 0.6258633137
2025-10-10 05:20:52,593 | INFO | iter is 40350 / 50000 [skipped  315] | loc. loss = 0.2680623233, classif. loss = 0.1538056880
2025-10-10 05:21:25,427 | INFO | iter is 40400 / 50000 [skipped  315] | loc. loss = 0.2061640322, classif. loss = 0.9564489126
2025-10-10 05:21:58,246 | INFO | iter is 40450 / 50000 [skipped  315] | loc. loss = 0.2231797874, classif. loss = 0.7566081882
2025-10-10 05:22:31,117 | INFO | iter is 40500 / 50000 [skipped  315] | loc. loss = 0.2198996842, classif. loss = 0.7695485950
2025-10-10 05:23:03,945 | INFO | iter is 40550 / 50000 [skipped  315] | loc. loss = 0.2615695596, classif. loss = 0.3277196884
2025-10-10 05:23:36,303 | INFO | iter is 40600 / 50000 [skipped  316] | loc. loss = 0.2200194299, classif. loss = 0.5305784345
2025-10-10 05:23:52,166 | INFO | ---------starting evaluation-----------
2025-10-10 05:23:54,333 | INFO | validation:    0/ 933 (2025-10-10_05-23-54)
2025-10-10 05:24:40,846 | INFO | validation:  100/ 933 (2025-10-10_05-24-40)
2025-10-10 05:25:27,304 | INFO | validation:  200/ 933 (2025-10-10_05-25-27)
2025-10-10 05:26:13,737 | INFO | validation:  300/ 933 (2025-10-10_05-26-13)
2025-10-10 05:27:00,209 | INFO | validation:  400/ 933 (2025-10-10_05-27-00)
2025-10-10 05:27:46,648 | INFO | validation:  500/ 933 (2025-10-10_05-27-46)
2025-10-10 05:28:33,098 | INFO | validation:  600/ 933 (2025-10-10_05-28-33)
2025-10-10 05:29:19,540 | INFO | validation:  700/ 933 (2025-10-10_05-29-19)
2025-10-10 05:30:05,987 | INFO | validation:  800/ 933 (2025-10-10_05-30-05)
2025-10-10 05:30:52,435 | INFO | validation:  900/ 933 (2025-10-10_05-30-52)
2025-10-10 05:31:08,549 | INFO | Confusion Matrix of Localization:
[[912463945   7895904]
 [  9035861  48925698]]
2025-10-10 05:31:08,549 | INFO | Confusion Matrix of Localization - Normalized:
[[0.99142085 0.00857915]
 [0.15589403 0.84410597]]
2025-10-10 05:31:08,550 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 41444870  1317028   993656   103187]
 [       0  1224521  2150481  1330896    36073]
 [       0   427620   420270  4591499    89541]
 [       0   130224    21963   396582  2520521]]
2025-10-10 05:31:08,550 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.9449626  0.03002886 0.02265583 0.00235271]
 [0.         0.25823039 0.4534994  0.28066304 0.00760717]
 [0.         0.07734227 0.0760129  0.83044983 0.016195  ]
 [0.         0.04242805 0.00715573 0.12920969 0.82120653]]
2025-10-10 05:31:08,550 | INFO | lofF1 is 85.2489, clfF1 is 71.2396, oaF1 is 75.4424, sub class F1 score is [95.1815 49.7123 71.51   86.6365]
2025-10-10 05:31:08,551 | INFO | ---------starting train set evaluation-----------
2025-10-10 05:31:08,552 | INFO | Train buffer size: 3104.
2025-10-10 05:31:20,727 | INFO | [TrainBuf] locF1 is 85.4286, clfF1 is 72.0826, oaF1 is 76.0864, sub class F1 score is [95.7235 51.1968 71.4614 86.8125]
2025-10-10 05:31:37,038 | INFO | iter is 40650 / 50000 [skipped  317] | loc. loss = 0.1244969964, classif. loss = 0.6445543766
2025-10-10 05:32:09,480 | INFO | iter is 40700 / 50000 [skipped  317] | loc. loss = 0.2560838163, classif. loss = 0.0062472830
2025-10-10 05:32:42,036 | INFO | iter is 40750 / 50000 [skipped  317] | loc. loss = 0.1303472668, classif. loss = 0.0569387600
2025-10-10 05:33:14,536 | INFO | iter is 40800 / 50000 [skipped  317] | loc. loss = 0.1045008153, classif. loss = 1.3199352026
2025-10-10 05:33:47,043 | INFO | iter is 40850 / 50000 [skipped  317] | loc. loss = 0.1357509941, classif. loss = 0.0111817736
2025-10-10 05:34:18,925 | INFO | iter is 40900 / 50000 [skipped  318] | loc. loss = 0.1573512107, classif. loss = 0.9842113256
2025-10-10 05:34:51,524 | INFO | iter is 40950 / 50000 [skipped  318] | loc. loss = 0.1441177428, classif. loss = 0.4725623727
2025-10-10 05:35:22,987 | INFO | iter is 41000 / 50000 [skipped  320] | loc. loss = 0.2437135875, classif. loss = 0.4003026187
2025-10-10 05:35:55,476 | INFO | iter is 41050 / 50000 [skipped  320] | loc. loss = 0.1474046558, classif. loss = 1.3368797302
2025-10-10 05:36:28,085 | INFO | iter is 41100 / 50000 [skipped  320] | loc. loss = 0.0587884672, classif. loss = 0.5456353426
2025-10-10 05:37:00,655 | INFO | iter is 41150 / 50000 [skipped  320] | loc. loss = 0.2202195376, classif. loss = 0.0448250622
2025-10-10 05:37:33,215 | INFO | iter is 41200 / 50000 [skipped  320] | loc. loss = 0.1767303944, classif. loss = 0.4669034183
2025-10-10 05:38:05,162 | INFO | iter is 41250 / 50000 [skipped  321] | loc. loss = 0.1602977961, classif. loss = 0.5325303078
2025-10-10 05:38:37,794 | INFO | iter is 41300 / 50000 [skipped  321] | loc. loss = 0.3010093272, classif. loss = 0.8281927109
2025-10-10 05:39:10,428 | INFO | iter is 41350 / 50000 [skipped  321] | loc. loss = 0.1627410650, classif. loss = 0.5994595289
2025-10-10 05:39:42,433 | INFO | iter is 41400 / 50000 [skipped  322] | loc. loss = 0.1702641696, classif. loss = 0.8007642627
2025-10-10 05:40:15,090 | INFO | iter is 41450 / 50000 [skipped  322] | loc. loss = 0.2677862048, classif. loss = 0.7037143111
2025-10-10 05:40:47,664 | INFO | iter is 41500 / 50000 [skipped  322] | loc. loss = 0.1621679068, classif. loss = 0.0428879149
2025-10-10 05:41:20,346 | INFO | iter is 41550 / 50000 [skipped  322] | loc. loss = 0.1979918480, classif. loss = 0.0471468754
2025-10-10 05:41:52,938 | INFO | iter is 41600 / 50000 [skipped  322] | loc. loss = 0.2593569160, classif. loss = 1.1527693272
2025-10-10 05:42:25,636 | INFO | iter is 41650 / 50000 [skipped  322] | loc. loss = 0.2205044031, classif. loss = 0.5333719254
2025-10-10 05:42:57,654 | INFO | iter is 41700 / 50000 [skipped  323] | loc. loss = 0.1372871697, classif. loss = 0.0828735903
2025-10-10 05:43:30,313 | INFO | iter is 41750 / 50000 [skipped  323] | loc. loss = 0.1888264269, classif. loss = 0.0374205150
2025-10-10 05:44:02,466 | INFO | iter is 41800 / 50000 [skipped  324] | loc. loss = 0.1787293553, classif. loss = 0.3518487513
2025-10-10 05:44:35,150 | INFO | iter is 41850 / 50000 [skipped  324] | loc. loss = 0.1174599826, classif. loss = 0.0777828246
2025-10-10 05:45:07,868 | INFO | iter is 41900 / 50000 [skipped  324] | loc. loss = 0.1303575784, classif. loss = 1.3807938099
2025-10-10 05:45:40,484 | INFO | iter is 41950 / 50000 [skipped  324] | loc. loss = 0.2421516031, classif. loss = 0.7136746049
2025-10-10 05:46:13,220 | INFO | iter is 42000 / 50000 [skipped  324] | loc. loss = 0.2300520241, classif. loss = 0.5115365982
2025-10-10 05:46:45,970 | INFO | iter is 42050 / 50000 [skipped  324] | loc. loss = 0.3320102692, classif. loss = 0.0623826087
2025-10-10 05:47:18,086 | INFO | iter is 42100 / 50000 [skipped  325] | loc. loss = 0.0767610967, classif. loss = 0.0067709070
2025-10-10 05:47:50,289 | INFO | iter is 42150 / 50000 [skipped  326] | loc. loss = 0.1536154151, classif. loss = 0.3607829511
2025-10-10 05:48:22,925 | INFO | iter is 42200 / 50000 [skipped  326] | loc. loss = 0.1659908891, classif. loss = 1.0053418875
2025-10-10 05:48:55,678 | INFO | iter is 42250 / 50000 [skipped  326] | loc. loss = 0.1990858316, classif. loss = 0.5579234362
2025-10-10 05:49:28,447 | INFO | iter is 42300 / 50000 [skipped  326] | loc. loss = 0.1953856945, classif. loss = 0.0993022770
2025-10-10 05:50:01,207 | INFO | iter is 42350 / 50000 [skipped  326] | loc. loss = 0.1351829022, classif. loss = 2.5274639130
2025-10-10 05:50:33,921 | INFO | iter is 42400 / 50000 [skipped  326] | loc. loss = 0.2176917493, classif. loss = 0.8765820265
2025-10-10 05:51:06,643 | INFO | iter is 42450 / 50000 [skipped  326] | loc. loss = 0.2540076375, classif. loss = 0.0185795166
2025-10-10 05:51:39,390 | INFO | iter is 42500 / 50000 [skipped  326] | loc. loss = 0.2589563429, classif. loss = 0.8010096550
2025-10-10 05:52:11,524 | INFO | iter is 42550 / 50000 [skipped  327] | loc. loss = 0.1397697031, classif. loss = 0.6582196951
2025-10-10 05:52:44,323 | INFO | iter is 42600 / 50000 [skipped  327] | loc. loss = 0.2481170297, classif. loss = 1.4498612881
2025-10-10 05:53:16,460 | INFO | iter is 42650 / 50000 [skipped  328] | loc. loss = 0.2132733017, classif. loss = 0.0080385450
2025-10-10 05:53:49,292 | INFO | iter is 42700 / 50000 [skipped  328] | loc. loss = 0.3110044301, classif. loss = 0.7878549099
2025-10-10 05:54:22,136 | INFO | iter is 42750 / 50000 [skipped  328] | loc. loss = 0.1937984228, classif. loss = 1.2884738445
2025-10-10 05:54:54,848 | INFO | iter is 42800 / 50000 [skipped  328] | loc. loss = 0.2990520298, classif. loss = 0.0559315011
2025-10-10 05:55:27,074 | INFO | iter is 42850 / 50000 [skipped  329] | loc. loss = 0.1669402868, classif. loss = 1.8633496761
2025-10-10 05:55:59,278 | INFO | iter is 42900 / 50000 [skipped  330] | loc. loss = 0.1729271710, classif. loss = 0.3140602708
2025-10-10 05:56:31,582 | INFO | iter is 42950 / 50000 [skipped  331] | loc. loss = 0.2425020039, classif. loss = 0.2737057805
2025-10-10 05:57:04,378 | INFO | iter is 43000 / 50000 [skipped  331] | loc. loss = 0.1566825360, classif. loss = 1.2310631275
2025-10-10 05:57:36,568 | INFO | iter is 43050 / 50000 [skipped  332] | loc. loss = 0.1753550172, classif. loss = 0.9186424017
2025-10-10 05:58:09,358 | INFO | iter is 43100 / 50000 [skipped  332] | loc. loss = 0.1985473335, classif. loss = 0.8832564354
2025-10-10 05:58:42,232 | INFO | iter is 43150 / 50000 [skipped  332] | loc. loss = 0.2166711092, classif. loss = 1.0318007469
2025-10-10 05:59:15,095 | INFO | iter is 43200 / 50000 [skipped  332] | loc. loss = 0.1290223598, classif. loss = 0.7234417200
2025-10-10 05:59:47,923 | INFO | iter is 43250 / 50000 [skipped  332] | loc. loss = 0.3147998154, classif. loss = 0.7702290416
2025-10-10 06:00:20,156 | INFO | iter is 43300 / 50000 [skipped  333] | loc. loss = 0.1083842367, classif. loss = 0.4279552400
2025-10-10 06:00:52,948 | INFO | iter is 43350 / 50000 [skipped  333] | loc. loss = 0.1340753585, classif. loss = 0.0278446265
2025-10-10 06:01:25,211 | INFO | iter is 43400 / 50000 [skipped  334] | loc. loss = 0.1957927197, classif. loss = 1.1235024929
2025-10-10 06:01:58,061 | INFO | iter is 43450 / 50000 [skipped  334] | loc. loss = 0.1355222017, classif. loss = 0.1670225561
2025-10-10 06:02:29,895 | INFO | iter is 43500 / 50000 [skipped  336] | loc. loss = 0.0554073416, classif. loss = 0.0176035520
2025-10-10 06:03:02,147 | INFO | iter is 43550 / 50000 [skipped  337] | loc. loss = 0.2079652995, classif. loss = 0.9027273655
2025-10-10 06:03:35,036 | INFO | iter is 43600 / 50000 [skipped  337] | loc. loss = 0.2915213406, classif. loss = 0.6424250603
2025-10-10 06:04:07,944 | INFO | iter is 43650 / 50000 [skipped  337] | loc. loss = 0.2832200825, classif. loss = 1.9449805021
2025-10-10 06:04:40,859 | INFO | iter is 43700 / 50000 [skipped  337] | loc. loss = 0.3991519809, classif. loss = 0.4855764806
2025-10-10 06:05:13,777 | INFO | iter is 43750 / 50000 [skipped  337] | loc. loss = 0.2364199162, classif. loss = 0.5291022658
2025-10-10 06:05:13,778 | INFO | ---------starting evaluation-----------
2025-10-10 06:05:15,931 | INFO | validation:    0/ 933 (2025-10-10_06-05-15)
2025-10-10 06:06:02,466 | INFO | validation:  100/ 933 (2025-10-10_06-06-02)
2025-10-10 06:06:48,923 | INFO | validation:  200/ 933 (2025-10-10_06-06-48)
2025-10-10 06:07:35,378 | INFO | validation:  300/ 933 (2025-10-10_06-07-35)
2025-10-10 06:08:21,860 | INFO | validation:  400/ 933 (2025-10-10_06-08-21)
2025-10-10 06:09:08,337 | INFO | validation:  500/ 933 (2025-10-10_06-09-08)
2025-10-10 06:09:54,787 | INFO | validation:  600/ 933 (2025-10-10_06-09-54)
2025-10-10 06:10:41,250 | INFO | validation:  700/ 933 (2025-10-10_06-10-41)
2025-10-10 06:11:27,717 | INFO | validation:  800/ 933 (2025-10-10_06-11-27)
2025-10-10 06:12:14,176 | INFO | validation:  900/ 933 (2025-10-10_06-12-14)
2025-10-10 06:12:30,360 | INFO | Confusion Matrix of Localization:
[[910693332   9666517]
 [  8217122  49744437]]
2025-10-10 06:12:30,361 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98949702 0.01050298]
 [0.14176848 0.85823152]]
2025-10-10 06:12:30,361 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 39832279  1506093  2260425   259944]
 [       0  1045502  1948709  1667215    80545]
 [       0   447018   336348  4523041   222523]
 [       0    75997    25460   301656  2666177]]
2025-10-10 06:12:30,361 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.90819477 0.03433963 0.05153876 0.00592685]
 [0.         0.22047836 0.41094916 0.35158692 0.01698555]
 [0.         0.08085073 0.06083419 0.81806805 0.04024703]
 [0.         0.02476045 0.00829508 0.09828201 0.86866246]]
2025-10-10 06:12:30,361 | INFO | lofF1 is 84.7634, clfF1 is 66.3779, oaF1 is 71.8936, sub class F1 score is [93.4377 45.5381 63.3423 84.661 ]
2025-10-10 06:12:30,363 | INFO | ---------starting train set evaluation-----------
2025-10-10 06:12:30,363 | INFO | Train buffer size: 3105.
2025-10-10 06:12:42,411 | INFO | [TrainBuf] locF1 is 85.3797, clfF1 is 72.3018, oaF1 is 76.2252, sub class F1 score is [95.5787 50.9816 73.1414 86.4005]
2025-10-10 06:13:14,860 | INFO | iter is 43800 / 50000 [skipped  337] | loc. loss = 0.2166663259, classif. loss = 0.5207617879
2025-10-10 06:13:47,370 | INFO | iter is 43850 / 50000 [skipped  337] | loc. loss = 0.2846449316, classif. loss = 0.4283902645
2025-10-10 06:14:19,929 | INFO | iter is 43900 / 50000 [skipped  337] | loc. loss = 0.1619208008, classif. loss = 1.0215202570
2025-10-10 06:14:52,461 | INFO | iter is 43950 / 50000 [skipped  337] | loc. loss = 0.1673986018, classif. loss = 0.0655810758
2025-10-10 06:15:24,453 | INFO | iter is 44000 / 50000 [skipped  338] | loc. loss = 0.1949518323, classif. loss = 0.3582208157
2025-10-10 06:15:57,001 | INFO | iter is 44050 / 50000 [skipped  338] | loc. loss = 0.1367911845, classif. loss = 0.0235253256
2025-10-10 06:16:28,935 | INFO | iter is 44100 / 50000 [skipped  339] | loc. loss = 0.3078553975, classif. loss = 0.0313839689
2025-10-10 06:17:01,568 | INFO | iter is 44150 / 50000 [skipped  339] | loc. loss = 0.1733733267, classif. loss = 1.0764249563
2025-10-10 06:17:34,099 | INFO | iter is 44200 / 50000 [skipped  339] | loc. loss = 0.1793304682, classif. loss = 1.0505698919
2025-10-10 06:18:06,666 | INFO | iter is 44250 / 50000 [skipped  339] | loc. loss = 0.1817509979, classif. loss = 0.6499159336
2025-10-10 06:18:39,140 | INFO | iter is 44300 / 50000 [skipped  339] | loc. loss = 0.2779374123, classif. loss = 0.6924728751
2025-10-10 06:19:11,123 | INFO | iter is 44350 / 50000 [skipped  340] | loc. loss = 0.1479794979, classif. loss = 0.5306561589
2025-10-10 06:19:43,658 | INFO | iter is 44400 / 50000 [skipped  340] | loc. loss = 0.1278556287, classif. loss = 0.0669878274
2025-10-10 06:20:16,294 | INFO | iter is 44450 / 50000 [skipped  340] | loc. loss = 0.2910264134, classif. loss = 0.6490705609
2025-10-10 06:20:48,991 | INFO | iter is 44500 / 50000 [skipped  340] | loc. loss = 0.2085330337, classif. loss = 0.8671991825
2025-10-10 06:21:21,568 | INFO | iter is 44550 / 50000 [skipped  340] | loc. loss = 0.2245821357, classif. loss = 0.6713703871
2025-10-10 06:21:54,268 | INFO | iter is 44600 / 50000 [skipped  340] | loc. loss = 0.1824113727, classif. loss = 0.3122436702
2025-10-10 06:22:26,824 | INFO | iter is 44650 / 50000 [skipped  340] | loc. loss = 0.2032798380, classif. loss = 0.1581538469
2025-10-10 06:22:59,456 | INFO | iter is 44700 / 50000 [skipped  340] | loc. loss = 0.2204203010, classif. loss = 1.1509809494
2025-10-10 06:23:32,251 | INFO | iter is 44750 / 50000 [skipped  340] | loc. loss = 0.1864543855, classif. loss = 0.5612953901
2025-10-10 06:24:04,902 | INFO | iter is 44800 / 50000 [skipped  340] | loc. loss = 0.1552491486, classif. loss = 0.7018488050
2025-10-10 06:24:37,600 | INFO | iter is 44850 / 50000 [skipped  340] | loc. loss = 0.1248831004, classif. loss = 0.0167982951
2025-10-10 06:25:09,579 | INFO | iter is 44900 / 50000 [skipped  341] | loc. loss = 0.1956183165, classif. loss = 1.0816091299
2025-10-10 06:25:42,288 | INFO | iter is 44950 / 50000 [skipped  341] | loc. loss = 0.2566940486, classif. loss = 0.4776876569
2025-10-10 06:26:14,918 | INFO | iter is 45000 / 50000 [skipped  341] | loc. loss = 0.2421459854, classif. loss = 0.8001428843
2025-10-10 06:26:46,999 | INFO | iter is 45050 / 50000 [skipped  342] | loc. loss = 0.2223277241, classif. loss = 0.5333728790
2025-10-10 06:27:19,762 | INFO | iter is 45100 / 50000 [skipped  342] | loc. loss = 0.2028770149, classif. loss = 0.0985903069
2025-10-10 06:27:51,865 | INFO | iter is 45150 / 50000 [skipped  343] | loc. loss = 0.1636888534, classif. loss = 0.6213575602
2025-10-10 06:28:24,660 | INFO | iter is 45200 / 50000 [skipped  343] | loc. loss = 0.0513413288, classif. loss = 0.0140335048
2025-10-10 06:28:57,416 | INFO | iter is 45250 / 50000 [skipped  343] | loc. loss = 0.1715369523, classif. loss = 0.0593828894
2025-10-10 06:29:28,908 | INFO | iter is 45300 / 50000 [skipped  345] | loc. loss = 0.1493665576, classif. loss = 0.0195210837
2025-10-10 06:30:01,707 | INFO | iter is 45350 / 50000 [skipped  345] | loc. loss = 0.2432731539, classif. loss = 0.3187236488
2025-10-10 06:30:34,400 | INFO | iter is 45400 / 50000 [skipped  345] | loc. loss = 0.2813445926, classif. loss = 0.7918381691
2025-10-10 06:31:06,586 | INFO | iter is 45450 / 50000 [skipped  346] | loc. loss = 0.1649391800, classif. loss = 0.0944027305
2025-10-10 06:31:39,272 | INFO | iter is 45500 / 50000 [skipped  346] | loc. loss = 0.3633799851, classif. loss = 0.1009353325
2025-10-10 06:32:12,084 | INFO | iter is 45550 / 50000 [skipped  346] | loc. loss = 0.0788925290, classif. loss = 0.0387242660
2025-10-10 06:32:44,232 | INFO | iter is 45600 / 50000 [skipped  347] | loc. loss = 0.3119309843, classif. loss = 3.3466889858
2025-10-10 06:33:16,950 | INFO | iter is 45650 / 50000 [skipped  347] | loc. loss = 0.1950345933, classif. loss = 0.4483501017
2025-10-10 06:33:49,762 | INFO | iter is 45700 / 50000 [skipped  347] | loc. loss = 0.2377600670, classif. loss = 1.1246516705
2025-10-10 06:34:22,553 | INFO | iter is 45750 / 50000 [skipped  347] | loc. loss = 0.2676355839, classif. loss = 0.4990404546
2025-10-10 06:34:55,394 | INFO | iter is 45800 / 50000 [skipped  347] | loc. loss = 0.1861215532, classif. loss = 0.6189224124
2025-10-10 06:35:28,179 | INFO | iter is 45850 / 50000 [skipped  347] | loc. loss = 0.1704643667, classif. loss = 0.4164249301
2025-10-10 06:36:00,950 | INFO | iter is 45900 / 50000 [skipped  347] | loc. loss = 0.1314468533, classif. loss = 0.0398830771
2025-10-10 06:36:33,241 | INFO | iter is 45950 / 50000 [skipped  348] | loc. loss = 0.3254850805, classif. loss = 0.6186624765
2025-10-10 06:37:05,998 | INFO | iter is 46000 / 50000 [skipped  348] | loc. loss = 0.1805296838, classif. loss = 0.9175478816
2025-10-10 06:37:38,854 | INFO | iter is 46050 / 50000 [skipped  348] | loc. loss = 0.1366466731, classif. loss = 1.3635181189
2025-10-10 06:38:11,074 | INFO | iter is 46100 / 50000 [skipped  349] | loc. loss = 0.0958653912, classif. loss = 0.0265841223
2025-10-10 06:38:42,615 | INFO | iter is 46150 / 50000 [skipped  351] | loc. loss = 0.2122189403, classif. loss = 0.3401547074
2025-10-10 06:39:15,464 | INFO | iter is 46200 / 50000 [skipped  351] | loc. loss = 0.0835176557, classif. loss = 0.4513794184
2025-10-10 06:39:46,467 | INFO | iter is 46250 / 50000 [skipped  354] | loc. loss = 0.1749204993, classif. loss = 0.0849075615
2025-10-10 06:40:19,383 | INFO | iter is 46300 / 50000 [skipped  354] | loc. loss = 0.1247130930, classif. loss = 0.7504231334
2025-10-10 06:40:50,972 | INFO | iter is 46350 / 50000 [skipped  356] | loc. loss = 0.1361707449, classif. loss = 1.5416566133
2025-10-10 06:41:23,730 | INFO | iter is 46400 / 50000 [skipped  356] | loc. loss = 0.1989265680, classif. loss = 0.6698196530
2025-10-10 06:41:56,623 | INFO | iter is 46450 / 50000 [skipped  356] | loc. loss = 0.1898842454, classif. loss = 0.8964343071
2025-10-10 06:42:29,461 | INFO | iter is 46500 / 50000 [skipped  356] | loc. loss = 0.1667088419, classif. loss = 1.1151413918
2025-10-10 06:43:02,403 | INFO | iter is 46550 / 50000 [skipped  356] | loc. loss = 0.1859741062, classif. loss = 0.2202962339
2025-10-10 06:43:35,307 | INFO | iter is 46600 / 50000 [skipped  356] | loc. loss = 0.1971653700, classif. loss = 0.9231094122
2025-10-10 06:44:08,160 | INFO | iter is 46650 / 50000 [skipped  356] | loc. loss = 0.3625206351, classif. loss = 0.4280756414
2025-10-10 06:44:39,901 | INFO | iter is 46700 / 50000 [skipped  358] | loc. loss = 0.3815284669, classif. loss = 0.9523458481
2025-10-10 06:45:12,785 | INFO | iter is 46750 / 50000 [skipped  358] | loc. loss = 0.1708725840, classif. loss = 0.1857492924
2025-10-10 06:45:45,755 | INFO | iter is 46800 / 50000 [skipped  358] | loc. loss = 0.1472397745, classif. loss = 0.4701693654
2025-10-10 06:46:18,633 | INFO | iter is 46850 / 50000 [skipped  358] | loc. loss = 0.2682535648, classif. loss = 0.7450713515
2025-10-10 06:46:34,443 | INFO | ---------starting evaluation-----------
2025-10-10 06:46:36,603 | INFO | validation:    0/ 933 (2025-10-10_06-46-36)
2025-10-10 06:47:22,876 | INFO | validation:  100/ 933 (2025-10-10_06-47-22)
2025-10-10 06:48:09,085 | INFO | validation:  200/ 933 (2025-10-10_06-48-09)
2025-10-10 06:48:55,290 | INFO | validation:  300/ 933 (2025-10-10_06-48-55)
2025-10-10 06:49:41,506 | INFO | validation:  400/ 933 (2025-10-10_06-49-41)
2025-10-10 06:50:27,729 | INFO | validation:  500/ 933 (2025-10-10_06-50-27)
2025-10-10 06:51:13,950 | INFO | validation:  600/ 933 (2025-10-10_06-51-13)
2025-10-10 06:52:00,166 | INFO | validation:  700/ 933 (2025-10-10_06-52-00)
2025-10-10 06:52:46,378 | INFO | validation:  800/ 933 (2025-10-10_06-52-46)
2025-10-10 06:53:32,600 | INFO | validation:  900/ 933 (2025-10-10_06-53-32)
2025-10-10 06:53:48,560 | INFO | Confusion Matrix of Localization:
[[910699077   9660772]
 [  8053443  49908116]]
2025-10-10 06:53:48,560 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98950327 0.01049673]
 [0.13894455 0.86105545]]
2025-10-10 06:53:48,560 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40436498  2396309   895994   129940]
 [       0   916071  2788801   986107    50992]
 [       0   307015   712648  4322180   187087]
 [       0    91125    47812   310254  2620099]]
2025-10-10 06:53:48,560 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.92197124 0.05463698 0.02042909 0.00296269]
 [0.         0.19318359 0.58811009 0.20795298 0.01075333]
 [0.         0.05552883 0.12889438 0.78173896 0.03383783]
 [0.         0.02968928 0.01557754 0.10108331 0.85364987]]
2025-10-10 06:53:48,560 | INFO | lofF1 is 84.9280, clfF1 is 72.4128, oaF1 is 76.1673, sub class F1 score is [94.4674 52.1879 71.7763 86.5089]
2025-10-10 06:53:48,562 | INFO | ---------starting train set evaluation-----------
2025-10-10 06:53:48,562 | INFO | Train buffer size: 3103.
2025-10-10 06:54:00,664 | INFO | [TrainBuf] locF1 is 85.9111, clfF1 is 73.3678, oaF1 is 77.1308, sub class F1 score is [95.7378 52.6346 74.1408 86.297 ]
2025-10-10 06:54:16,904 | INFO | iter is 46900 / 50000 [skipped  359] | loc. loss = 0.2907652557, classif. loss = 0.7202607393
2025-10-10 06:54:49,451 | INFO | iter is 46950 / 50000 [skipped  359] | loc. loss = 0.1294317245, classif. loss = 1.1807167530
2025-10-10 06:55:22,043 | INFO | iter is 47000 / 50000 [skipped  359] | loc. loss = 0.2005912960, classif. loss = 0.9200618267
2025-10-10 06:55:53,995 | INFO | iter is 47050 / 50000 [skipped  360] | loc. loss = 0.2295863330, classif. loss = 0.9595166445
2025-10-10 06:56:26,523 | INFO | iter is 47100 / 50000 [skipped  360] | loc. loss = 0.2338121533, classif. loss = 0.0370569564
2025-10-10 06:56:58,517 | INFO | iter is 47150 / 50000 [skipped  361] | loc. loss = 0.2175113261, classif. loss = 1.6091957092
2025-10-10 06:57:31,040 | INFO | iter is 47200 / 50000 [skipped  361] | loc. loss = 0.0812550560, classif. loss = 0.0045228046
2025-10-10 06:58:01,778 | INFO | iter is 47250 / 50000 [skipped  364] | loc. loss = 0.0701749697, classif. loss = 0.1164325476
2025-10-10 06:58:33,788 | INFO | iter is 47300 / 50000 [skipped  365] | loc. loss = 0.1196900755, classif. loss = 1.5755479336
2025-10-10 06:59:06,291 | INFO | iter is 47350 / 50000 [skipped  365] | loc. loss = 0.1064413041, classif. loss = 0.0285220481
2025-10-10 06:59:38,334 | INFO | iter is 47400 / 50000 [skipped  366] | loc. loss = 0.3656029105, classif. loss = 0.9902830124
2025-10-10 07:00:09,601 | INFO | iter is 47450 / 50000 [skipped  368] | loc. loss = 0.1794178486, classif. loss = 0.6258459091
2025-10-10 07:00:41,537 | INFO | iter is 47500 / 50000 [skipped  369] | loc. loss = 0.1208716035, classif. loss = 0.0998752341
2025-10-10 07:01:14,131 | INFO | iter is 47550 / 50000 [skipped  369] | loc. loss = 0.1568529606, classif. loss = 0.0301271025
2025-10-10 07:01:46,659 | INFO | iter is 47600 / 50000 [skipped  369] | loc. loss = 0.3332907259, classif. loss = 1.2577352524
2025-10-10 07:02:19,300 | INFO | iter is 47650 / 50000 [skipped  369] | loc. loss = 0.1023931429, classif. loss = 0.0365845561
2025-10-10 07:02:51,827 | INFO | iter is 47700 / 50000 [skipped  369] | loc. loss = 0.1966361403, classif. loss = 0.8395251036
2025-10-10 07:03:23,778 | INFO | iter is 47750 / 50000 [skipped  370] | loc. loss = 0.2166055739, classif. loss = 0.0100007067
2025-10-10 07:03:56,423 | INFO | iter is 47800 / 50000 [skipped  370] | loc. loss = 0.2476997823, classif. loss = 0.0622923002
2025-10-10 07:04:28,492 | INFO | iter is 47850 / 50000 [skipped  371] | loc. loss = 0.2408092916, classif. loss = 1.1057128906
2025-10-10 07:05:01,209 | INFO | iter is 47900 / 50000 [skipped  371] | loc. loss = 0.2210296094, classif. loss = 1.3357362747
2025-10-10 07:05:33,240 | INFO | iter is 47950 / 50000 [skipped  372] | loc. loss = 0.1215493008, classif. loss = 0.5135737658
2025-10-10 07:06:05,979 | INFO | iter is 48000 / 50000 [skipped  372] | loc. loss = 0.1519665420, classif. loss = 0.0179013442
2025-10-10 07:06:38,601 | INFO | iter is 48050 / 50000 [skipped  372] | loc. loss = 0.0960193649, classif. loss = 0.3196218610
2025-10-10 07:07:11,187 | INFO | iter is 48100 / 50000 [skipped  372] | loc. loss = 0.0945638046, classif. loss = 0.0288062878
2025-10-10 07:07:43,877 | INFO | iter is 48150 / 50000 [skipped  372] | loc. loss = 0.2355604023, classif. loss = 0.8498725891
2025-10-10 07:08:16,489 | INFO | iter is 48200 / 50000 [skipped  372] | loc. loss = 0.0882561803, classif. loss = 0.0139837991
2025-10-10 07:08:48,578 | INFO | iter is 48250 / 50000 [skipped  373] | loc. loss = 0.2295844853, classif. loss = 1.9115612507
2025-10-10 07:09:21,223 | INFO | iter is 48300 / 50000 [skipped  373] | loc. loss = 0.2488515824, classif. loss = 0.4177114964
2025-10-10 07:09:53,300 | INFO | iter is 48350 / 50000 [skipped  374] | loc. loss = 0.1171202064, classif. loss = 0.9771502018
2025-10-10 07:10:26,065 | INFO | iter is 48400 / 50000 [skipped  374] | loc. loss = 0.3080120087, classif. loss = 0.1541375816
2025-10-10 07:10:58,173 | INFO | iter is 48450 / 50000 [skipped  375] | loc. loss = 0.2261083871, classif. loss = 0.0261898357
2025-10-10 07:11:30,969 | INFO | iter is 48500 / 50000 [skipped  375] | loc. loss = 0.1524465233, classif. loss = 0.0772139281
2025-10-10 07:12:03,708 | INFO | iter is 48550 / 50000 [skipped  375] | loc. loss = 0.2306142747, classif. loss = 0.0356323496
2025-10-10 07:12:36,549 | INFO | iter is 48600 / 50000 [skipped  375] | loc. loss = 0.2983571887, classif. loss = 0.2622921467
2025-10-10 07:13:09,276 | INFO | iter is 48650 / 50000 [skipped  375] | loc. loss = 0.4229289293, classif. loss = 2.1974868774
2025-10-10 07:13:41,996 | INFO | iter is 48700 / 50000 [skipped  375] | loc. loss = 0.1220653430, classif. loss = 1.2982466221
2025-10-10 07:14:14,800 | INFO | iter is 48750 / 50000 [skipped  375] | loc. loss = 0.1378547698, classif. loss = 0.3277892470
2025-10-10 07:14:47,505 | INFO | iter is 48800 / 50000 [skipped  375] | loc. loss = 0.0936861858, classif. loss = 0.1279131174
2025-10-10 07:15:20,265 | INFO | iter is 48850 / 50000 [skipped  375] | loc. loss = 0.1357432604, classif. loss = 0.5377043486
2025-10-10 07:15:53,016 | INFO | iter is 48900 / 50000 [skipped  375] | loc. loss = 0.2200966179, classif. loss = 0.6150133610
2025-10-10 07:16:25,157 | INFO | iter is 48950 / 50000 [skipped  376] | loc. loss = 0.1427881867, classif. loss = 0.1248810887
2025-10-10 07:16:57,356 | INFO | iter is 49000 / 50000 [skipped  377] | loc. loss = 0.2783082724, classif. loss = 0.0116286073
2025-10-10 07:17:29,515 | INFO | iter is 49050 / 50000 [skipped  378] | loc. loss = 0.1508096755, classif. loss = 0.1182667091
2025-10-10 07:18:02,363 | INFO | iter is 49100 / 50000 [skipped  378] | loc. loss = 0.4034571648, classif. loss = 0.1890843064
2025-10-10 07:18:35,155 | INFO | iter is 49150 / 50000 [skipped  378] | loc. loss = 0.1994444430, classif. loss = 0.5564783812
2025-10-10 07:19:07,409 | INFO | iter is 49200 / 50000 [skipped  379] | loc. loss = 0.2537264228, classif. loss = 0.2059107125
2025-10-10 07:19:40,270 | INFO | iter is 49250 / 50000 [skipped  379] | loc. loss = 0.1400241852, classif. loss = 0.1186087430
2025-10-10 07:20:13,013 | INFO | iter is 49300 / 50000 [skipped  379] | loc. loss = 0.3906181455, classif. loss = 1.0058364868
2025-10-10 07:20:45,940 | INFO | iter is 49350 / 50000 [skipped  379] | loc. loss = 0.0821997449, classif. loss = 0.7192017436
2025-10-10 07:21:18,755 | INFO | iter is 49400 / 50000 [skipped  379] | loc. loss = 0.1911954731, classif. loss = 0.0212262422
2025-10-10 07:21:50,971 | INFO | iter is 49450 / 50000 [skipped  380] | loc. loss = 0.2233857214, classif. loss = 0.3649246991
2025-10-10 07:22:23,238 | INFO | iter is 49500 / 50000 [skipped  381] | loc. loss = 0.2752299905, classif. loss = 0.4162759185
2025-10-10 07:22:56,023 | INFO | iter is 49550 / 50000 [skipped  381] | loc. loss = 0.2200964689, classif. loss = 0.8727404475
2025-10-10 07:23:28,959 | INFO | iter is 49600 / 50000 [skipped  381] | loc. loss = 0.1169840768, classif. loss = 0.4822618365
2025-10-10 07:24:01,241 | INFO | iter is 49650 / 50000 [skipped  382] | loc. loss = 0.2634077966, classif. loss = 0.5919422507
2025-10-10 07:24:34,092 | INFO | iter is 49700 / 50000 [skipped  382] | loc. loss = 0.1164424717, classif. loss = 0.0046953098
2025-10-10 07:25:06,427 | INFO | iter is 49750 / 50000 [skipped  383] | loc. loss = 0.1959579885, classif. loss = 0.7801395655
2025-10-10 07:25:39,269 | INFO | iter is 49800 / 50000 [skipped  383] | loc. loss = 0.1235820353, classif. loss = 0.5410234332
2025-10-10 07:26:12,198 | INFO | iter is 49850 / 50000 [skipped  383] | loc. loss = 0.3028459251, classif. loss = 1.8779993057
2025-10-10 07:26:44,455 | INFO | iter is 49900 / 50000 [skipped  384] | loc. loss = 0.4142545760, classif. loss = 0.1331331730
2025-10-10 07:27:16,690 | INFO | iter is 49950 / 50000 [skipped  385] | loc. loss = 0.1670899689, classif. loss = 0.7090591192
2025-10-10 07:27:49,197 | INFO | iter is 50000 / 50000 [skipped  385] | loc. loss = 0.2892259061, classif. loss = 2.1504170895
2025-10-10 07:27:49,197 | INFO | -----------Training is completed-----------
2025-10-10 07:27:49,450 | INFO | Model saved in: /mnt/storage1/alpgenc/change_detection/ChangeMamba_AG/changedetection/deneme_saved_models/tr2025-10-09_20-34-24_MambaBDA_Base_xBD_AGBD/model_step50000_last.pth
2025-10-10 07:27:49,450 | INFO | !! Total Skipped: 385 (0.77%)
2025-10-10 07:27:49,452 | INFO | ---------starting evaluation-----------
2025-10-10 07:27:51,620 | INFO | validation:    0/ 933 (2025-10-10_07-27-51)
2025-10-10 07:28:38,121 | INFO | validation:  100/ 933 (2025-10-10_07-28-38)
2025-10-10 07:29:24,585 | INFO | validation:  200/ 933 (2025-10-10_07-29-24)
2025-10-10 07:30:11,019 | INFO | validation:  300/ 933 (2025-10-10_07-30-11)
2025-10-10 07:30:57,439 | INFO | validation:  400/ 933 (2025-10-10_07-30-57)
2025-10-10 07:31:43,885 | INFO | validation:  500/ 933 (2025-10-10_07-31-43)
2025-10-10 07:32:30,347 | INFO | validation:  600/ 933 (2025-10-10_07-32-30)
2025-10-10 07:33:16,797 | INFO | validation:  700/ 933 (2025-10-10_07-33-16)
2025-10-10 07:34:03,266 | INFO | validation:  800/ 933 (2025-10-10_07-34-03)
2025-10-10 07:34:49,730 | INFO | validation:  900/ 933 (2025-10-10_07-34-49)
2025-10-10 07:35:05,798 | INFO | Confusion Matrix of Localization:
[[910383615   9976234]
 [  7869787  50091772]]
2025-10-10 07:35:05,798 | INFO | Confusion Matrix of Localization - Normalized:
[[0.98916051 0.01083949]
 [0.13577597 0.86422403]]
2025-10-10 07:35:05,798 | INFO | Confusion Matrix of Classification:
[[       0        0        0        0        0]
 [       0 40121678  2297834  1019599   419630]
 [       0  1009937  2519525  1133832    78677]
 [       0   315770   477828  4539612   195720]
 [       0    50457    17611   329195  2672027]]
2025-10-10 07:35:05,798 | INFO | Confusion Matrix of Classification - Normalized:
[[       nan        nan        nan        nan        nan]
 [0.         0.9147932  0.0523917  0.02324734 0.00956776]
 [0.         0.21297832 0.53132442 0.23910564 0.01659162]
 [0.         0.05711232 0.08642323 0.8210652  0.03539925]
 [0.         0.01643931 0.00573781 0.10725445 0.87056844]]
2025-10-10 07:35:05,798 | INFO | lofF1 is 84.8800, clfF1 is 70.8503, oaF1 is 75.0592, sub class F1 score is [94.0096 50.116  72.3377 83.0422]
2025-10-10 07:35:05,800 | INFO | loc_f1_score=84.88, harmonic_mean_f1=70.8503, oaf1=75.0592, damage_f1_score=array([94.0096, 50.116 , 72.3377, 83.0422])
2025-10-10 07:35:05,800 | INFO | ---------starting train set evaluation-----------
2025-10-10 07:35:05,800 | INFO | Train buffer size: 3099.
2025-10-10 07:35:17,840 | INFO | [TrainBuf] locF1 is 85.8319, clfF1 is 72.4471, oaF1 is 76.4626, sub class F1 score is [95.2724 51.3766 72.4956 87.2723]
2025-10-10 07:35:17,861 | INFO | Validation Results:
2025-10-10 07:35:17,862 | INFO | [TEST ] Step  3125: (80.1359, 26.8318, 42.8231, array([93.1243,  8.9553, 72.3918, 77.7715]))
2025-10-10 07:35:17,862 | INFO | [TRAIN] Step  3125: (73.3252, 37.109, 47.9739, array([89.9403, 16.7314, 43.1191, 72.9262]))

2025-10-10 07:35:17,862 | INFO | [TEST ] Step  6250: (82.0113, 69.3093, 73.1199, array([94.0848, 47.9658, 70.8358, 82.5201]))
2025-10-10 07:35:17,862 | INFO | [TRAIN] Step  6250: (81.3585, 57.2931, 64.5127, array([93.2222, 33.2123, 59.7527, 81.6695]))

2025-10-10 07:35:17,862 | INFO | [TEST ] Step  9375: (83.2059, 70.4, 74.2418, array([95.2359, 49.1476, 69.745 , 85.9615]))
2025-10-10 07:35:17,862 | INFO | [TRAIN] Step  9375: (82.6118, 59.1213, 66.1684, array([93.5188, 35.1475, 62.1407, 80.512 ]))

2025-10-10 07:35:17,862 | INFO | [TEST ] Step 12500: (82.9663, 72.6861, 75.7701, array([95.0721, 51.989 , 74.4711, 84.3885]))
2025-10-10 07:35:17,862 | INFO | [TRAIN] Step 12500: (83.3861, 63.612, 69.5442, array([94.0907, 39.6456, 66.7639, 82.9768]))

2025-10-10 07:35:17,862 | INFO | [TEST ] Step 15625: (81.926, 68.9402, 72.8359, array([93.6053, 47.237 , 68.8429, 85.8919]))
2025-10-10 07:35:17,862 | INFO | [TRAIN] Step 15625: (83.9845, 65.3844, 70.9644, array([94.5335, 41.9888, 67.7044, 83.2471]))

2025-10-10 07:35:17,862 | INFO | [TEST ] Step 18750: (83.9777, 72.3566, 75.8429, array([94.2204, 53.9053, 69.2923, 85.5746]))
2025-10-10 07:35:17,862 | INFO | [TRAIN] Step 18750: (84.1434, 67.0849, 72.2025, array([95.0446, 43.2444, 70.4317, 84.875 ]))

2025-10-10 07:35:17,862 | INFO | [TEST ] Step 21875: (84.0864, 64.1864, 70.1564, array([94.7372, 37.8611, 73.2946, 85.418 ]))
2025-10-10 07:35:17,862 | INFO | [TRAIN] Step 21875: (84.5748, 69.2186, 73.8255, array([94.7563, 46.9348, 69.6147, 86.4784]))

2025-10-10 07:35:17,863 | INFO | [TEST ] Step 25000: (84.1165, 69.4697, 73.8637, array([94.4829, 48.9815, 67.2299, 85.4341]))
2025-10-10 07:35:17,863 | INFO | [TRAIN] Step 25000: (84.7722, 66.934, 72.2855, array([94.6822, 44.5374, 66.885 , 84.7844]))

2025-10-10 07:35:17,863 | INFO | [TEST ] Step 28125: (84.7632, 73.0872, 76.59, array([95.0562, 53.21  , 72.1671, 86.5135]))
2025-10-10 07:35:17,863 | INFO | [TRAIN] Step 28125: (85.1231, 68.4551, 73.4555, array([95.0918, 44.9888, 70.6918, 86.6353]))

2025-10-10 07:35:17,863 | INFO | [TEST ] Step 31250: (84.8663, 72.659, 76.3212, array([95.1732, 52.6822, 72.5768, 84.8588]))
2025-10-10 07:35:17,863 | INFO | [TRAIN] Step 31250: (85.2048, 70.2958, 74.7685, array([95.0461, 48.552 , 70.5022, 86.201 ]))

2025-10-10 07:35:17,863 | INFO | [TEST ] Step 34375: (84.8924, 76.337, 78.9037, array([95.5135, 58.2397, 74.8278, 87.7574]))
2025-10-10 07:35:17,863 | INFO | [TRAIN] Step 34375: (85.3351, 72.5319, 76.3729, array([95.2654, 51.3412, 73.7453, 86.1071]))

2025-10-10 07:35:17,863 | INFO | [TEST ] Step 37500: (84.3007, 75.2351, 77.9548, array([95.5042, 56.5099, 74.6207, 86.2159]))
2025-10-10 07:35:17,863 | INFO | [TRAIN] Step 37500: (85.4965, 70.9743, 75.331, array([95.1473, 49.6036, 71.5444, 85.388 ]))

2025-10-10 07:35:17,863 | INFO | [TEST ] Step 40625: (85.2489, 71.2396, 75.4424, array([95.1815, 49.7123, 71.51  , 86.6365]))
2025-10-10 07:35:17,863 | INFO | [TRAIN] Step 40625: (85.4286, 72.0826, 76.0864, array([95.7235, 51.1968, 71.4614, 86.8125]))

2025-10-10 07:35:17,863 | INFO | [TEST ] Step 43750: (84.7634, 66.3779, 71.8936, array([93.4377, 45.5381, 63.3423, 84.661 ]))
2025-10-10 07:35:17,863 | INFO | [TRAIN] Step 43750: (85.3797, 72.3018, 76.2252, array([95.5787, 50.9816, 73.1414, 86.4005]))

2025-10-10 07:35:17,863 | INFO | [TEST ] Step 46875: (84.928, 72.4128, 76.1673, array([94.4674, 52.1879, 71.7763, 86.5089]))
2025-10-10 07:35:17,863 | INFO | [TRAIN] Step 46875: (85.9111, 73.3678, 77.1308, array([95.7378, 52.6346, 74.1408, 86.297 ]))

2025-10-10 07:35:17,863 | INFO | [TEST ] Step    -1: (84.88, 70.8503, 75.0592, array([94.0096, 50.116 , 72.3377, 83.0422]))
2025-10-10 07:35:17,863 | INFO | [TRAIN] Step    -1: (85.8319, 72.4471, 76.4626, array([95.2724, 51.3766, 72.4956, 87.2723]))

2025-10-10 07:35:17,863 | INFO | The accuracy of the best round is: [84.8924, 76.337, 78.9037, array([95.5135, 58.2397, 74.8278, 87.7574])]
2025-10-10 07:35:17,884 | INFO | MAIN - DONE.
2025-10-10 07:35:17,885 | INFO | MAIN - EXIT.
